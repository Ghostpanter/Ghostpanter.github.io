<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Ansible playbook 介绍与操作</title>
    <url>/2023/01/29/Ansible%20playbook%20%E4%BB%8B%E7%BB%8D%E4%B8%8E%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><ul>
<li><code>playbook</code> 与 <code>ad-hoc</code> 相比,是一种完全不同的运用 ansible 的方式，类似与 saltstack 的 state 状态文件。ad-hoc 无法持久使用，playbook 可以持久使用。</li>
<li><code>playbook</code> 是由一个或多个 play 组成的列表，play 的主要功能在于将事先归并为一组的主机装扮成事先通过 ansible 中的 task 定义好的角色。</li>
<li>从根本上来讲，所谓的 task 无非是调用 ansible 的一个 module。将多个 play 组织在一个 playbook 中，即可以让它们联合起来按事先编排的机制完成某一任务。</li>
</ul>
<p>参考文档：<a href="https://ansible-tran.readthedocs.io/en/latest/docs/playbooks.html">https://ansible-tran.readthedocs.io/en/latest/docs/playbooks.html</a></p>
<p>Ansible 的基础介绍和环境部署可以参考这篇文章：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301290902810.png" alt="图片"></p>
<h2 id="二、playbook-核心元素"><a href="#二、playbook-核心元素" class="headerlink" title="二、playbook 核心元素"></a>二、playbook 核心元素</h2><ul>
<li><code>Hosts</code> 执行的远程主机列表</li>
<li><code>Tasks</code> 任务集</li>
<li><code>Varniables</code> 内置变量或自定义变量在 playbook 中调用</li>
<li><code>Templates</code> 模板，即使用模板语法的文件，比如配置文件等</li>
<li><code>Handlers</code> 和 notity 结合使用，由特定条件触发的操作，满足条件方才执行，否则不执行</li>
<li><code>Tags</code> 标签，指定某条任务执行，用于选择运行 playbook 中的部分代码。</li>
</ul>
<h2 id="三、playbook-语法（yaml）"><a href="#三、playbook-语法（yaml）" class="headerlink" title="三、playbook 语法（yaml）"></a>三、playbook 语法（yaml）</h2><ul>
<li>playbook 使用<code>yaml</code>语法格式，后缀可以是<code>yaml</code>,也可以是<code>yml</code>。</li>
<li>YAML( &#x2F;ˈjæməl&#x2F; )参考了其他多种语言，包括：XML、C 语言、Python、Perl 以及电子邮件格式 RFC2822，Clark Evans 在 2001 年 5 月在首次发表了这种语言，另外 Ingy döt Net 与 OrenBen-Kiki 也是这语言的共同设计者。</li>
<li>YAML 格式是类似 JSON 的文件格式。YAML 用于文件的配置编写，JSON 多用于开发设计。</li>
</ul>
<h3 id="1）YAML-介绍"><a href="#1）YAML-介绍" class="headerlink" title="1）YAML 介绍"></a>1）YAML 介绍</h3><h4 id="1、YAML-格式如下"><a href="#1、YAML-格式如下" class="headerlink" title="1、YAML 格式如下"></a>1、YAML 格式如下</h4><ul>
<li>文件的第一行应该以“—”（三个连字符）开始，表明 YAML 文件的开始。</li>
<li>在同一行中，#之后的内容表示注释，类似于 shell，python 和 ruby。</li>
<li>YAML 中的列表元素以“-”开头并且跟着一个空格。后面为元素内容。</li>
<li>同一个列表之中的元素应该保持相同的缩进，否则会被当做错误处理。</li>
<li>play 中 hosts、variables、roles、tasks 等对象的表示方法都是以键值中间以“：”分隔表示，并且“：”之后要加一个空格。</li>
</ul>
<h4 id="2、playbooks-yaml-配置文件解释"><a href="#2、playbooks-yaml-配置文件解释" class="headerlink" title="2、playbooks yaml 配置文件解释"></a>2、playbooks yaml 配置文件解释</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">Hosts：运行指定任务的目标主机</span></span><br><span class="line"><span class="string">remoute_user:在远程主机上执行任务的用户；</span></span><br><span class="line"><span class="attr">sudo_user:</span></span><br><span class="line"><span class="string">tasks:任务列表</span></span><br><span class="line"></span><br><span class="line"><span class="string">tasks的具体格式：</span></span><br><span class="line"></span><br><span class="line"><span class="attr">tasks:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">TASK_NAME</span></span><br><span class="line">    <span class="attr">module:</span> <span class="string">arguments</span></span><br><span class="line">    <span class="attr">notify:</span> <span class="string">HANDLER_NAME</span></span><br><span class="line">    <span class="attr">handlers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">HANDLER_NAME</span></span><br><span class="line">    <span class="attr">module:</span> <span class="string">arguments</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##模块，模块参数：</span></span><br><span class="line"><span class="string">格式如下：</span></span><br><span class="line">    <span class="string">（1）action:</span> <span class="string">module</span> <span class="string">arguments</span></span><br><span class="line">     <span class="string">(2)</span> <span class="attr">module:</span> <span class="string">arguments</span></span><br><span class="line"><span class="string">注意：shell和command模块后直接加命令，而不是key=value类的参数列表</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">handlers：任务，在特定条件下触发；接受到其他任务的通知时被触发；</span></span><br></pre></td></tr></table></figure>

<h4 id="3、示例"><a href="#3、示例" class="headerlink" title="3、示例"></a>3、示例</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install</span> <span class="string">nginx</span>        <span class="comment">##安装模块，需要在被控主机里加上nginx的源</span></span><br><span class="line">      <span class="attr">yum:</span> <span class="string">name=nginx</span> <span class="string">state=present</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">copy</span> <span class="string">nginx.conf</span>    <span class="comment">##复制nginx的配置文件过去，需要在本机的/tmp目录下编辑nginx.conf</span></span><br><span class="line">      <span class="attr">copy:</span> <span class="string">src=/tmp/nginx.conf</span> <span class="string">dest=/etc/nginx/nginx.conf</span> <span class="string">backup=yes</span></span><br><span class="line">      <span class="attr">notify:</span> <span class="string">reload</span>    <span class="comment">#当nginx.conf发生改变时，通知给相应的handlers</span></span><br><span class="line">      <span class="attr">tags:</span> <span class="string">reloadnginx</span>    <span class="comment">#打标签</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">start</span> <span class="string">nginx</span> <span class="string">service</span>    <span class="comment">#服务启动模块</span></span><br><span class="line">      <span class="attr">service:</span> <span class="string">name=nginx</span> <span class="string">state=started</span></span><br><span class="line">      <span class="attr">tags:</span> <span class="string">startnginx</span>    <span class="comment">#打标签</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">handlers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">reload</span></span><br><span class="line">      <span class="attr">service:</span> <span class="string">name=nginx</span> <span class="string">state=restarted</span></span><br></pre></td></tr></table></figure>

<h3 id="2）variables-变量"><a href="#2）variables-变量" class="headerlink" title="2）variables 变量"></a>2）variables 变量</h3><p>variables 变量有四种定义方法。如下：</p>
<h4 id="1、facts-可以直接调用"><a href="#1、facts-可以直接调用" class="headerlink" title="1、facts:可以直接调用"></a>1、facts:可以直接调用</h4><p>ansible 中有 setup 模块，这个模块就是通过 facts 组件来实现的，主要是节点本身的一个系统信息，bios 信息,网络，硬盘等等信息。这里的 variables 也可以直接调用 facts 组件的 facters 我们可以使用<code>setup</code>模块来获取，然后直接放入我们的剧本之中调用即可。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible web -m setup</span><br></pre></td></tr></table></figure>

<p>![图片](data:image&#x2F;svg+xml,%3C%3Fxml version&#x3D;’1.0’ encoding&#x3D;’UTF-8’%3F%3E%3Csvg width&#x3D;’1px’ height&#x3D;’1px’ viewBox&#x3D;’0 0 1 1’ version&#x3D;’1.1’ xmlns&#x3D;’<a href="http://www.w3.org/2000/svg">http://www.w3.org/2000/svg</a>‘ xmlns:xlink&#x3D;’<a href="http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg">http://www.w3.org/1999/xlink&#39;%3E%3Ctitle%3E%3C/title%3E%3Cg</a> stroke&#x3D;’none’ stroke-width&#x3D;’1’ fill&#x3D;’none’ fill-rule&#x3D;’evenodd’ fill-opacity&#x3D;’0’%3E%3Cg transform&#x3D;’translate(-249.000000, -126.000000)’ fill&#x3D;’%23FFFFFF’%3E%3Crect x&#x3D;’249’ y&#x3D;’126’ width&#x3D;’1’ height&#x3D;’1’%3E%3C&#x2F;rect%3E%3C&#x2F;g%3E%3C&#x2F;g%3E%3C&#x2F;svg%3E)</p>
<p>常用的几个参数：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible_all_ipv4_addresses <span class="comment"># ipv4的所有地址</span></span><br><span class="line">ansible_all_ipv6_addresses <span class="comment"># ipv6的所有地址</span></span><br><span class="line">ansible_date_time <span class="comment"># 获取到控制节点时间</span></span><br><span class="line">ansible_default_ipv4 <span class="comment"># 默认的ipv4地址</span></span><br><span class="line">ansible_distribution <span class="comment"># 系统</span></span><br><span class="line">ansible_distribution_major_version <span class="comment"># 系统的大版本</span></span><br><span class="line">ansible_distribution_version <span class="comment"># 系统的版本号</span></span><br><span class="line">ansible_domain <span class="comment">#系统所在的域</span></span><br><span class="line">ansible_env <span class="comment">#系统的环境变量</span></span><br><span class="line">ansible_hostname <span class="comment">#系统的主机名</span></span><br><span class="line">ansible_fqdn <span class="comment">#系统的全名</span></span><br><span class="line">ansible_machine <span class="comment">#系统的架构</span></span><br><span class="line">ansible_memory_mb <span class="comment">#系统的内存信息</span></span><br><span class="line">ansible_os_family <span class="comment"># 系统的家族</span></span><br><span class="line">ansible_pkg_mgr <span class="comment"># 系统的包管理工具</span></span><br><span class="line">ansible_processor_cores <span class="comment">#系统的cpu的核数(每颗)</span></span><br><span class="line">ansible_processor_count <span class="comment">#系统cpu的颗数</span></span><br><span class="line">ansible_processor_vcpus <span class="comment">#系统cpu的总个数=cpu的颗数*CPU的核数</span></span><br><span class="line">ansible_python <span class="comment"># 系统上的python</span></span><br></pre></td></tr></table></figure>

<p>搜索</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible web -m setup -a <span class="string">&#x27;filter=*processor*&#x27;</span></span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301290902770.png" alt="图片"></p>
<h4 id="2、用户自定义变量"><a href="#2、用户自定义变量" class="headerlink" title="2、用户自定义变量"></a>2、用户自定义变量</h4><p>自定义变量有两种方式</p>
<ul>
<li>通过命令行传入</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-playbook命令行中的 -e VARS，--extra-vars VARS，这样就可以直接把自定义的变量传入</span><br></pre></td></tr></table></figure>

<p>使用 playbook 定义变量，实例如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line"></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install</span> &#123;&#123; <span class="string">rpmname</span> &#125;&#125;</span><br><span class="line">      <span class="attr">yum:</span> <span class="string">name=&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;</span> <span class="string">state=present</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">copy</span> &#123;&#123; <span class="string">rpmname</span> &#125;&#125;<span class="string">.conf</span></span><br><span class="line">      <span class="attr">copy:</span> <span class="string">src=/tmp/&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;.conf</span> <span class="string">dest=/etc/&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;/&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;.conf</span> <span class="string">backup=yes</span></span><br><span class="line">      <span class="attr">notify:</span> <span class="string">reload</span></span><br><span class="line">      <span class="attr">tags:</span> <span class="string">reload&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">start</span> &#123;&#123; <span class="string">rpmname</span> &#125;&#125; <span class="string">service</span></span><br><span class="line">      <span class="attr">service:</span> <span class="string">name=&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;</span> <span class="string">state=started</span></span><br><span class="line">      <span class="attr">tags:</span> <span class="string">start&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">handlers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">reload</span></span><br><span class="line">      <span class="attr">service:</span> <span class="string">name=&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;</span> <span class="string">state=restarted</span></span><br></pre></td></tr></table></figure>

<p>使用：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-playbook nginx.yml -e rpmname=keepalived</span><br><span class="line">ansible-playbook nginx.yml --extra-vars rpmname=keepalived</span><br></pre></td></tr></table></figure>

<ul>
<li>在 playbook 中定义变量</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">##在playbook中定义变量如下：</span></span><br><span class="line"><span class="string">vars：</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">var1:</span> <span class="string">value1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">var2:</span> <span class="string">value2</span></span><br></pre></td></tr></table></figure>

<p>使用：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line">  <span class="attr">vars:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">rpmname:</span> <span class="string">keepalived</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install</span> &#123;&#123; <span class="string">rpmname</span> &#125;&#125;</span><br><span class="line">      <span class="attr">yum:</span> <span class="string">name=&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;</span> <span class="string">state=present</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">copy</span> &#123;&#123; <span class="string">rpmname</span> &#125;&#125;<span class="string">.conf</span></span><br><span class="line">      <span class="attr">copy:</span> <span class="string">src=/tmp/&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;.conf</span> <span class="string">dest=/etc/&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;/&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;.conf</span> <span class="string">backup=yes</span></span><br><span class="line">      <span class="attr">notify:</span> <span class="string">reload</span></span><br><span class="line">      <span class="attr">tags:</span> <span class="string">reload&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">start</span> &#123;&#123; <span class="string">rpmname</span> &#125;&#125; <span class="string">service</span></span><br><span class="line">      <span class="attr">service:</span> <span class="string">name=&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;</span> <span class="string">state=started</span></span><br><span class="line">      <span class="attr">tags:</span> <span class="string">start&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">handlers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">reload</span></span><br><span class="line">      <span class="attr">service:</span> <span class="string">name=&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;</span> <span class="string">state=restarted</span></span><br></pre></td></tr></table></figure>

<h4 id="3、通过-roles-传递变量"><a href="#3、通过-roles-传递变量" class="headerlink" title="3、通过 roles 传递变量"></a>3、通过 roles 传递变量</h4><p>下面介绍 roles 会使用 roles 传递变量，小伙伴可以翻到下面看详解讲解。</p>
<h4 id="4、-Host-Inventory"><a href="#4、-Host-Inventory" class="headerlink" title="4、 Host Inventory"></a>4、 Host Inventory</h4><p>可以在主机清单中定义，方法如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#向不同的主机传递不同的变量</span></span><br><span class="line"><span class="string">IP/HOSTNAME</span> <span class="string">varaiable=value</span> <span class="string">var2=value2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#向组中的主机传递相同的变量</span></span><br><span class="line">[<span class="string">groupname:vars</span>]</span><br><span class="line"><span class="string">variable=value</span></span><br></pre></td></tr></table></figure>

<h3 id="3）流程控制"><a href="#3）流程控制" class="headerlink" title="3）流程控制"></a>3）流程控制</h3><h4 id="1、用-when-来表示的条件判断"><a href="#1、用-when-来表示的条件判断" class="headerlink" title="1、用 when 来表示的条件判断"></a>1、用 when 来表示的条件判断</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root#代表用root用户执行，默认是root，可以省略</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">createfile</span></span><br><span class="line">    <span class="attr">copy:</span> <span class="string">content=&quot;test3&quot;</span> <span class="string">dest=/opt/p1.yml</span></span><br><span class="line">    <span class="attr">when:</span> <span class="string">a==&#x27;3&#x27;</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">createfile</span></span><br><span class="line">    <span class="attr">copy:</span> <span class="string">content=&quot;test4&quot;</span> <span class="string">dest=/opt/p1.yml</span></span><br><span class="line">    <span class="attr">when:</span> <span class="string">a==&#x27;4&#x27;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果 a”3”，就将“test3”，写入到 web 组下被管控机的&#x2F;opt&#x2F;p1.yml 中，<br>如果 a”4”，就将“test4”，写入到 web 组下被管控机的&#x2F;opt&#x2F;p1.yml 中。</p>
</blockquote>
<p>执行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 语法校验</span></span><br><span class="line">ansible-playbook  --syntax-check p1.yml</span><br><span class="line"></span><br><span class="line"><span class="comment">#执行</span></span><br><span class="line">ansible-playbook -e <span class="string">&#x27;a=&quot;3&quot;&#x27;</span> p1.yml</span><br></pre></td></tr></table></figure>

<h4 id="2、标签（只执行配置文件中的一个任务）"><a href="#2、标签（只执行配置文件中的一个任务）" class="headerlink" title="2、标签（只执行配置文件中的一个任务）"></a>2、标签（只执行配置文件中的一个任务）</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">installnginx</span></span><br><span class="line">    <span class="attr">yum:</span> <span class="string">name=nginx</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">copyfile</span></span><br><span class="line">    <span class="attr">copy:</span> <span class="string">src=/etc/nginx/nginx.conf</span> <span class="string">dest=/etc/nginx/nginx.conf</span></span><br><span class="line">    <span class="attr">tags:</span> <span class="string">copyfile</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">start</span></span><br><span class="line">    <span class="attr">service:</span> <span class="string">name=nginx</span> <span class="string">static=restarted</span></span><br></pre></td></tr></table></figure>

<p>执行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 语法校验</span></span><br><span class="line">ansible-playbook  --syntax-check p2.yml</span><br><span class="line"></span><br><span class="line"><span class="comment">#执行</span></span><br><span class="line">ansible-playbook -t copyfile p2.yml</span><br></pre></td></tr></table></figure>

<h4 id="3、循环-with-items"><a href="#3、循环-with-items" class="headerlink" title="3、循环 with_items"></a>3、循环 with_items</h4><p>创建三个用户</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">createruser</span></span><br><span class="line">    <span class="attr">user:</span> <span class="string">name=&#123;&#123;</span> <span class="string">item</span> <span class="string">&#125;&#125;</span></span><br><span class="line">    <span class="attr">with_items:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">shy1</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">shy2</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">shy3</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">creategroup</span></span><br><span class="line">    <span class="attr">group:</span> <span class="string">name=&#123;&#123;</span> <span class="string">item</span> <span class="string">&#125;&#125;</span></span><br><span class="line">    <span class="attr">with_items:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">group1</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">group2</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">group3</span></span><br></pre></td></tr></table></figure>

<p>执行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#语法校验</span></span><br><span class="line">ansible-playbook  --syntax-check p3.yml</span><br><span class="line"></span><br><span class="line"><span class="comment">#执行</span></span><br><span class="line">ansible-playbook p3.yml</span><br></pre></td></tr></table></figure>

<h4 id="4、循环嵌套（字典）"><a href="#4、循环嵌套（字典）" class="headerlink" title="4、循环嵌套（字典）"></a>4、循环嵌套（字典）</h4><p>用户 shy1 的属组是 group1,用户 shy2 的属组是 group2，用户 shy3 的属组是 group3</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">creategroup</span></span><br><span class="line">    <span class="attr">group:</span> <span class="string">name=&#123;&#123;item&#125;&#125;</span></span><br><span class="line">    <span class="attr">with_items:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">group3</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">group4</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">group5</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">createuser</span></span><br><span class="line">    <span class="attr">user:</span> <span class="string">name=&#123;&#123;item.user&#125;&#125;</span> <span class="string">group=&#123;&#123;item.group&#125;&#125;</span></span><br><span class="line">    <span class="attr">with_items:</span></span><br><span class="line">    <span class="bullet">-</span> &#123;<span class="attr">&#x27;user&#x27;:</span> <span class="string">shy3</span>,<span class="attr">&#x27;group&#x27;:</span> <span class="string">group3</span>&#125;</span><br><span class="line">    <span class="bullet">-</span> &#123;<span class="attr">&#x27;user&#x27;:</span> <span class="string">shy4</span>,<span class="attr">&#x27;group&#x27;:</span> <span class="string">group4</span>&#125;</span><br><span class="line">    <span class="bullet">-</span> &#123;<span class="attr">&#x27;user&#x27;:</span> <span class="string">shy5</span>,<span class="attr">&#x27;group&#x27;:</span> <span class="string">group5</span>&#125;</span><br></pre></td></tr></table></figure>

<p>执行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#语法校验</span></span><br><span class="line">ansible-playbook  --syntax-check p4.yml</span><br><span class="line"></span><br><span class="line"><span class="comment">#执行</span></span><br><span class="line">ansible-playbook p4.yml</span><br></pre></td></tr></table></figure>

<h3 id="4）模板-templates"><a href="#4）模板-templates" class="headerlink" title="4）模板 templates"></a>4）模板 templates</h3><ul>
<li>模板是一个文本文件，嵌套有脚本（使用模板编程语言编写）</li>
<li>Jinja2 是 python 的一种模板语言，以 Django 的模板语言为原本</li>
</ul>
<p>该模板支持：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">字符串：使用单引号或双引号；</span></span><br><span class="line">  <span class="string">数字：整数，浮点数；</span></span><br><span class="line">  <span class="string">列表：[item1,</span> <span class="string">item2,</span> <span class="string">...]</span></span><br><span class="line">  <span class="string">元组：(item1,</span> <span class="string">item2,</span> <span class="string">...)</span></span><br><span class="line">  <span class="string">字典：&#123;key1:value1,</span> <span class="string">key2:value2,</span> <span class="string">...&#125;</span></span><br><span class="line">  <span class="string">布尔型：true/false</span></span><br><span class="line">  <span class="string">算术运算：</span></span><br><span class="line">    <span class="string">+,</span> <span class="string">-,</span> <span class="string">*,</span> <span class="string">/,</span> <span class="string">//,</span> <span class="string">%,</span> <span class="string">**</span></span><br><span class="line">  <span class="string">比较操作：</span></span><br><span class="line">    <span class="string">==,</span> <span class="type">!=,</span> <span class="string">&gt;,</span> <span class="string">&gt;=,</span> <span class="string">&lt;,</span> <span class="string">&lt;=</span></span><br><span class="line">  <span class="string">逻辑运算：</span></span><br><span class="line">    <span class="string">and,</span> <span class="string">or,</span> <span class="string">not</span></span><br></pre></td></tr></table></figure>

<ul>
<li>通常模板都是通过引用变量来运用的</li>
</ul>
<p>【示例】</p>
<p>1、定义模板</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">user  nginx; <span class="comment">#设置nginx服务的系统使用用户</span></span><br><span class="line">worker_processes  &#123;&#123; ansible_processor_vcpus &#125;&#125;; <span class="comment">#工作进程数</span></span><br><span class="line"></span><br><span class="line">error_log  /var/log/nginx/error.log warn; <span class="comment">#nginx的错误日志</span></span><br><span class="line">pid        /var/run/nginx.pid; <span class="comment">#nginx启动时候的pid</span></span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections  1024; <span class="comment">#每个进程允许的最大连接数</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123; <span class="comment">#http请求配置，一个http可以包含多个server</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#定义 Content-Type</span></span><br><span class="line">    include       /etc/nginx/mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#日志格式 此处main与access_log中的main对应</span></span><br><span class="line">    <span class="comment">#$remote_addr：客户端地址</span></span><br><span class="line">    <span class="comment">#$remote_user：http客户端请求nginx认证的用户名，默认不开启认证模块，不会记录</span></span><br><span class="line">    <span class="comment">#$timelocal：nginx的时间</span></span><br><span class="line">    <span class="comment">#$request：请求method + 路由 + http协议版本</span></span><br><span class="line">    <span class="comment">#status：http reponse 状态码</span></span><br><span class="line">    <span class="comment">#body_bytes_sent：response body的大小</span></span><br><span class="line">    <span class="comment">#$http_referer：referer头信息参数，表示上级页面</span></span><br><span class="line">    <span class="comment">#$http_user_agent：user-agent头信息参数，客户端信息</span></span><br><span class="line">    <span class="comment">#$http_x_forwarded_for：x-forwarded-for头信息参数</span></span><br><span class="line">    log_format  main  <span class="string">&#x27;$http_user_agent&#x27;</span> <span class="string">&#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#访问日志，后面的main表示使用log_format中的main格式记录到access.log中</span></span><br><span class="line">    access_log  /var/log/nginx/access.log  main;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#nginx的一大优势，高效率文件传输</span></span><br><span class="line">    sendfile        on;</span><br><span class="line">    <span class="comment">#tcp_nopush     on;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#客户端与服务端的超时时间，单位秒</span></span><br><span class="line">    keepalive_timeout  65;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#gzip  on;</span></span><br><span class="line">    server &#123; <span class="comment">#http服务，一个server可以配置多个location</span></span><br><span class="line">        listen       &#123;&#123; nginxport &#125;&#125;; <span class="comment">#服务监听端口</span></span><br><span class="line">        server_name  localhost; <span class="comment">#主机名、域名</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#charset koi8-r;</span></span><br><span class="line">        <span class="comment">#access_log  /var/log/nginx/host.access.log  main;</span></span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">            root   /usr/share/nginx/html; <span class="comment">#页面存放目录</span></span><br><span class="line">            index  index.html index.htm; <span class="comment">#默认页面</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#error_page  404              /404.html;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将500 502 503 504的错误页面重定向到 /50x.html</span></span><br><span class="line">        error_page   500 502 503 504  /50x.html;</span><br><span class="line">        location = /50x.html &#123; <span class="comment">#匹配error_page指定的页面路径</span></span><br><span class="line">            root   /usr/share/nginx/html; <span class="comment">#页面存放的目录</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># proxy the PHP scripts to Apache listening on 127.0.0.1:80</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment">#location ~ \.php$ &#123;</span></span><br><span class="line">        <span class="comment">#    proxy_pass   http://127.0.0.1;</span></span><br><span class="line">        <span class="comment">#&#125;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment">#location ~ \.php$ &#123;</span></span><br><span class="line">        <span class="comment">#    root           html;</span></span><br><span class="line">        <span class="comment">#    fastcgi_pass   127.0.0.1:9000;</span></span><br><span class="line">        <span class="comment">#    fastcgi_index  index.php;</span></span><br><span class="line">        <span class="comment">#    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;</span></span><br><span class="line">        <span class="comment">#    include        fastcgi_params;</span></span><br><span class="line">        <span class="comment">#&#125;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># deny access to .htaccess files, if Apache&#x27;s document root</span></span><br><span class="line">        <span class="comment"># concurs with nginx&#x27;s one</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment">#location ~ /\.ht &#123;</span></span><br><span class="line">        <span class="comment">#    deny  all;</span></span><br><span class="line">        <span class="comment">#&#125;</span></span><br><span class="line">    &#125;</span><br><span class="line">    include /etc/nginx/conf.d/*.conf;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>2、定义 yaml 编排</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line">  <span class="attr">vars:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">rpmname:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">nginxport:</span> <span class="number">8088</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install</span> &#123;&#123; <span class="string">rpmname</span> &#125;&#125;</span><br><span class="line">      <span class="attr">yum:</span> <span class="string">name=&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;</span> <span class="string">state=present</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">copy</span> &#123;&#123; <span class="string">rpmname</span> &#125;&#125;<span class="string">.conf</span></span><br><span class="line">      <span class="attr">copy:</span> <span class="string">src=/tmp/&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;.conf</span> <span class="string">dest=/etc/&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;/&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;.conf</span> <span class="string">backup=yes</span></span><br><span class="line">      <span class="attr">notify:</span> <span class="string">reload</span></span><br><span class="line">      <span class="attr">tags:</span> <span class="string">reload&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">start</span> &#123;&#123; <span class="string">rpmname</span> &#125;&#125; <span class="string">service</span></span><br><span class="line">      <span class="attr">service:</span> <span class="string">name=&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;</span> <span class="string">state=started</span></span><br><span class="line">      <span class="attr">tags:</span> <span class="string">start&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">handlers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">reload</span></span><br><span class="line">      <span class="attr">service:</span> <span class="string">name=&#123;&#123;</span> <span class="string">rpmname</span> <span class="string">&#125;&#125;</span> <span class="string">state=restarted</span></span><br></pre></td></tr></table></figure>

<p>使用</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">##使用reloadnginx标签，重新加载剧本</span></span><br><span class="line">ansible-playbook nginx.yml -t reloadnginx</span><br></pre></td></tr></table></figure>

<blockquote>
<p>copy 与 template 的区别</p>
</blockquote>
<ul>
<li>copy 模块不替代参数，template 模块替代参数</li>
<li>template 的参数几乎与 copy 的参数完全相同</li>
</ul>
<h3 id="5）handlers（触发事件）"><a href="#5）handlers（触发事件）" class="headerlink" title="5）handlers（触发事件）"></a>5）handlers（触发事件）</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">notify:触发</span></span><br><span class="line"><span class="string">handlers：触发的动作</span></span><br></pre></td></tr></table></figure>

<p>使用上场景：修改配置文件时</p>
<p>【示例】 正常情况时 handlers 是不会执行的</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">installredis</span></span><br><span class="line">    <span class="attr">yum:</span> <span class="string">name=redis</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">copyfile</span></span><br><span class="line">    <span class="attr">template:</span> <span class="string">src=redis.conf</span> <span class="string">dest=/etc/redis.conf</span></span><br><span class="line">    <span class="attr">tags:</span> <span class="string">copyfile</span></span><br><span class="line">    <span class="attr">notify:</span> <span class="string">restart</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">start</span></span><br><span class="line">    <span class="attr">service:</span> <span class="string">name=redis</span> <span class="string">state=started</span></span><br><span class="line">  <span class="attr">handlers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">restart</span></span><br><span class="line">    <span class="attr">service:</span> <span class="string">name=redis</span></span><br></pre></td></tr></table></figure>

<p>执行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-playbook -t copyfile p6.yml</span><br></pre></td></tr></table></figure>

<h3 id="6）roles"><a href="#6）roles" class="headerlink" title="6）roles"></a>6）roles</h3><h4 id="1、roles-介绍与优势"><a href="#1、roles-介绍与优势" class="headerlink" title="1、roles 介绍与优势"></a>1、roles 介绍与优势</h4><p>一般情况下将 roles 写在**&#x2F;etc&#x2F;ansible&#x2F;roles**中，也可以写在其他任意位置（写在其他位置要自己手动建立一个 roles 文件夹）</p>
<ul>
<li>对于以上所有方式有个缺点就是无法实现同时部署 web、database、keepalived 等不同服务或者不同服务器组合不同的应用就需要写多个 yaml 文件，很难实现灵活的调用</li>
<li>roles 用于层次性，结构化地组织 playbook。roles 能够根据层次结果自动装载变量文件、tasks 以及 handlers 等。</li>
<li>要使用 roles 只需要在 playbook 中使用 include 指令即可。</li>
<li>简单来讲，roles 就是通过分别将变量（vars）、文件（files）、任务（tasks）、模块（modules）以及处理器（handlers）放置于单独的目录中，并且可以便捷的 include 它们地一种机制。</li>
<li>角色一般用于基于主机构建服务的场景中，但是也可以用于构建守护进程等场景中。</li>
</ul>
<h4 id="2、目录结构"><a href="#2、目录结构" class="headerlink" title="2、目录结构"></a>2、目录结构</h4><p>创建目录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -pv ./&#123;nginx,mysql,httpd&#125;/&#123;files,templates,vars,tasks,handlers,meta,default&#125;</span><br></pre></td></tr></table></figure>

<p>![图片](data:image&#x2F;svg+xml,%3C%3Fxml version&#x3D;’1.0’ encoding&#x3D;’UTF-8’%3F%3E%3Csvg width&#x3D;’1px’ height&#x3D;’1px’ viewBox&#x3D;’0 0 1 1’ version&#x3D;’1.1’ xmlns&#x3D;’<a href="http://www.w3.org/2000/svg">http://www.w3.org/2000/svg</a>‘ xmlns:xlink&#x3D;’<a href="http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg">http://www.w3.org/1999/xlink&#39;%3E%3Ctitle%3E%3C/title%3E%3Cg</a> stroke&#x3D;’none’ stroke-width&#x3D;’1’ fill&#x3D;’none’ fill-rule&#x3D;’evenodd’ fill-opacity&#x3D;’0’%3E%3Cg transform&#x3D;’translate(-249.000000, -126.000000)’ fill&#x3D;’%23FFFFFF’%3E%3Crect x&#x3D;’249’ y&#x3D;’126’ width&#x3D;’1’ height&#x3D;’1’%3E%3C&#x2F;rect%3E%3C&#x2F;g%3E%3C&#x2F;g%3E%3C&#x2F;svg%3E)</p>
<ul>
<li>roles&#x2F;</li>
<li>mysql&#x2F;：mysql 服务的 yml 文件</li>
<li>httpd&#x2F;：apached 服务的 yml 文件</li>
<li>nginx&#x2F;：nginx 服务的 yml 文件</li>
<li><code>files/</code>：存储由 copy 或者 script 等模块调用的文件或者脚本；</li>
<li><code>tasks/</code>：此目录中至少应该有一个名为<strong>main.yml</strong>的文件，用于定义各个 task；其他文件需要由<strong>main.yml</strong>进行包含调用；</li>
<li><code>handlers/</code>：此目录中至少应该有一个名为<strong>main.yml</strong>的文件，用于定义各个 handler；其他文件需要由 main.yml 进行包含调用；</li>
<li><code>vars/</code>：此目录至少应该有一个名为<strong>main,yml</strong>的文件，用于定义各个 variable；其他的文件需要由<strong>main.yml</strong>进行包含调用；</li>
<li><code>templates/</code>：存储由 templates 模块调用的模板文件；</li>
<li><code>meta/</code>：此目录中至少应该有一个名为<strong>main.yml</strong>的文件，定义当前角色的特殊设定以及依赖关系，其他文件需要由<strong>main.yml</strong>进行包含调用；</li>
<li><code>default/</code>：此目录至少应该有一个名为<strong>main.yml</strong>的文件，用于设定默认变量；</li>
</ul>
<h4 id="3、实战操作"><a href="#3、实战操作" class="headerlink" title="3、实战操作"></a>3、实战操作</h4><p>【1】创建目录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -pv ./&#123;nginx,mysql,httpd&#125;/&#123;files,templates,vars,tasks,handlers,meta,default&#125;</span><br></pre></td></tr></table></figure>

<p>【2】定义配置文件</p>
<p>先下载 nginx rpm 部署包</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 下载地址：http://nginx.org/packages/centos/7/x86_64/RPMS/</span></span><br><span class="line"> wget http://nginx.org/packages/centos/7/x86_64/RPMS/nginx-1.18.0-1.el7.ngx.x86_64.rpm -O nginx/files/nginx-1.18.0-1.el7.ngx.x86_64.rpm</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>nginx&#x2F;tasks&#x2F;main.yml</strong></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">- name: <span class="built_in">cp</span></span><br><span class="line">  copy: src=nginx-1.18.0-1.el7.ngx.x86_64.rpm dest=/tmp/nginx-1.18.0-1.el7.ngx.x86_64.rpm</span><br><span class="line">- name: install</span><br><span class="line">  yum: name=/tmp/nginx-1.18.0-1.el7.ngx.x86_64.rpm state=latest</span><br><span class="line">- name: conf</span><br><span class="line">  template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf</span><br><span class="line">  tags: nginxconf</span><br><span class="line">  notify: new conf to reload</span><br><span class="line">- name: start service</span><br><span class="line">  service: name=nginx state=started enabled=<span class="literal">true</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>nginx&#x2F;templates&#x2F;nginx.conf.j2</strong></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">user  nginx; <span class="comment">#设置nginx服务的系统使用用户</span></span><br><span class="line">worker_processes  &#123;&#123; ansible_processor_vcpus &#125;&#125;; <span class="comment">#工作进程数</span></span><br><span class="line"></span><br><span class="line">error_log  /var/log/nginx/error.log warn; <span class="comment">#nginx的错误日志</span></span><br><span class="line">pid        /var/run/nginx.pid; <span class="comment">#nginx启动时候的pid</span></span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections  1024; <span class="comment">#每个进程允许的最大连接数</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123; <span class="comment">#http请求配置，一个http可以包含多个server</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#定义 Content-Type</span></span><br><span class="line">    include       /etc/nginx/mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#日志格式 此处main与access_log中的main对应</span></span><br><span class="line">    <span class="comment">#$remote_addr：客户端地址</span></span><br><span class="line">    <span class="comment">#$remote_user：http客户端请求nginx认证的用户名，默认不开启认证模块，不会记录</span></span><br><span class="line">    <span class="comment">#$timelocal：nginx的时间</span></span><br><span class="line">    <span class="comment">#$request：请求method + 路由 + http协议版本</span></span><br><span class="line">    <span class="comment">#status：http reponse 状态码</span></span><br><span class="line">    <span class="comment">#body_bytes_sent：response body的大小</span></span><br><span class="line">    <span class="comment">#$http_referer：referer头信息参数，表示上级页面</span></span><br><span class="line">    <span class="comment">#$http_user_agent：user-agent头信息参数，客户端信息</span></span><br><span class="line">    <span class="comment">#$http_x_forwarded_for：x-forwarded-for头信息参数</span></span><br><span class="line">    log_format  main  <span class="string">&#x27;$http_user_agent&#x27;</span> <span class="string">&#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#访问日志，后面的main表示使用log_format中的main格式记录到access.log中</span></span><br><span class="line">    access_log  /var/log/nginx/access.log  main;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#nginx的一大优势，高效率文件传输</span></span><br><span class="line">    sendfile        on;</span><br><span class="line">    <span class="comment">#tcp_nopush     on;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#客户端与服务端的超时时间，单位秒</span></span><br><span class="line">    keepalive_timeout  65;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#gzip  on;</span></span><br><span class="line">    server &#123; <span class="comment">#http服务，一个server可以配置多个location</span></span><br><span class="line">        listen       &#123;&#123; nginxport &#125;&#125;; <span class="comment">#服务监听端口</span></span><br><span class="line">        server_name  localhost; <span class="comment">#主机名、域名</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#charset koi8-r;</span></span><br><span class="line">        <span class="comment">#access_log  /var/log/nginx/host.access.log  main;</span></span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">            root   /usr/share/nginx/html; <span class="comment">#页面存放目录</span></span><br><span class="line">            index  index.html index.htm; <span class="comment">#默认页面</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#error_page  404              /404.html;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将500 502 503 504的错误页面重定向到 /50x.html</span></span><br><span class="line">        error_page   500 502 503 504  /50x.html;</span><br><span class="line">        location = /50x.html &#123; <span class="comment">#匹配error_page指定的页面路径</span></span><br><span class="line">            root   /usr/share/nginx/html; <span class="comment">#页面存放的目录</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># proxy the PHP scripts to Apache listening on 127.0.0.1:80</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment">#location ~ \.php$ &#123;</span></span><br><span class="line">        <span class="comment">#    proxy_pass   http://127.0.0.1;</span></span><br><span class="line">        <span class="comment">#&#125;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment">#location ~ \.php$ &#123;</span></span><br><span class="line">        <span class="comment">#    root           html;</span></span><br><span class="line">        <span class="comment">#    fastcgi_pass   127.0.0.1:9000;</span></span><br><span class="line">        <span class="comment">#    fastcgi_index  index.php;</span></span><br><span class="line">        <span class="comment">#    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;</span></span><br><span class="line">        <span class="comment">#    include        fastcgi_params;</span></span><br><span class="line">        <span class="comment">#&#125;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># deny access to .htaccess files, if Apache&#x27;s document root</span></span><br><span class="line">        <span class="comment"># concurs with nginx&#x27;s one</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment">#location ~ /\.ht &#123;</span></span><br><span class="line">        <span class="comment">#    deny  all;</span></span><br><span class="line">        <span class="comment">#&#125;</span></span><br><span class="line">    &#125;</span><br><span class="line">    include /etc/nginx/conf.d/*.conf;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>nginx&#x2F;vars&#x2F;main.yml</strong></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nginxport: 9999</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>nginx&#x2F;handlers&#x2F;main.yml</strong></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">new</span> <span class="string">conf</span> <span class="string">to</span> <span class="string">reload</span></span><br><span class="line">  <span class="attr">service:</span> <span class="string">name=nginx</span> <span class="string">state=restarted</span></span><br></pre></td></tr></table></figure>

<ul>
<li>定义剧本文件（<strong>roles.yml</strong>）</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line">  <span class="attr">roles:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">nginx</span></span><br></pre></td></tr></table></figure>

<p>最后的目录结构如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301290902190.png" alt="图片"></p>
<p>执行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-playbook roles.yml</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301290903092.png" alt="图片"></p>
<p>到这里一个完整版的 roles 演示示例就完成了，接下来也会真正使用 ansible playbook roles 应用到真实场景中</p>
]]></content>
      <categories>
        <category>Ansible</category>
        <category>playbook</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
        <tag>playbook</tag>
      </tags>
  </entry>
  <entry>
    <title>CI构建报错提示No such device or addres</title>
    <url>/2023/01/04/CI%E6%9E%84%E5%BB%BA%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BANo%20such%20device%20or%20addres/</url>
    <content><![CDATA[<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>CI构建报错，报错内容如下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">fatal: could not <span class="built_in">read</span> Username <span class="keyword">for</span> <span class="string">&#x27;https://gitee.com&#x27;</span>: No such device or address</span><br></pre></td></tr></table></figure>

<h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><p>这是因为git config文件中没有用户身份信息。</p>
<h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>在请求串中加入身份信息即可： 格式</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">https://[username]:[password]@gitee.com/[username]/project.git</span><br></pre></td></tr></table></figure>

<p>操作如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">##修改.git/config</span></span><br><span class="line"><span class="built_in">cd</span> .git</span><br><span class="line">vim config</span><br><span class="line">​</span><br><span class="line">[init]</span><br><span class="line">        defaultBranch = none</span><br><span class="line">[fetch]</span><br><span class="line">        recurseSubmodules = <span class="literal">false</span></span><br><span class="line">[core]</span><br><span class="line">        repositoryformatversion = 0</span><br><span class="line">        filemode = <span class="literal">true</span></span><br><span class="line">        bare = <span class="literal">false</span></span><br><span class="line">        logallrefupdates = <span class="literal">true</span></span><br><span class="line">[lfs]</span><br><span class="line">        repositoryformatversion = 0</span><br><span class="line">[remote <span class="string">&quot;origin&quot;</span>]</span><br><span class="line">        url = http://gitlab.zjwsd.com/zzh/dataoffice.git    <span class="comment">###此处修改为带用户身份信息的地址</span></span><br><span class="line">        fetch = +refs/heads/*:refs/remotes/origin/*</span><br><span class="line">​</span><br><span class="line">​</span><br><span class="line">url=https://choudalao:12345@gitee.com/choudalao/test.git</span><br><span class="line"><span class="comment">###CI的yaml直接sed替换</span></span><br><span class="line"> - <span class="built_in">export</span> nurl=<span class="string">&quot;url = http://gitlab:wsd12345@gitlab.zjwsd.com/zzh/dataoffice.git&quot;</span></span><br><span class="line"> - sed -i -e <span class="string">&quot;s%url = http://gitlab.zjwsd.com/zzh/dataoffice.git%<span class="variable">$nurl</span>%g &quot;</span> .git/config</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kubernetes</category>
        <category>CICD</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>CICD</tag>
        <tag>Gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title>Ansible 介绍与操作</title>
    <url>/2023/01/29/Ansible%20%E4%BB%8B%E7%BB%8D%E4%B8%8E%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301290845980.png" alt="图片"></p>
<h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><blockquote>
<p><em><code>Ansible</code>是新出现的自动化运维工具，<strong>基于 Python 开发</strong>，集合了众多运维工具（puppet、cfengine、chef、func、fabric）的优点，实现了批量系统配置、批量程序部署、批量运行命令等功能。</em></p>
</blockquote>
<p>Ansible 特点：</p>
<ul>
<li>部署简单，只需要在主控端部署 Ansible 环境，被控端无需作任何操作</li>
<li>默认使用<strong>SSH 协议</strong>对设备进行管理</li>
<li>主从集中化管理</li>
<li>配置简单、功能强大、扩展性强</li>
<li>支持 API 及自定义模块、可以通过 Python 轻松扩展</li>
<li>通过 Playbooks 来定制强大的配置、状态管理</li>
<li>对云计算平台、大数据都有很好的支持</li>
</ul>
<blockquote>
<p>官方文档：<a href="https://docs.ansible.com/ansible/latest/">https://docs.ansible.com/ansible/latest/</a><br>GitHub 地址：<a href="https://github.com/ansible/ansible">https://github.com/ansible/ansible</a></p>
</blockquote>
<h2 id="二、Ansible-架构"><a href="#二、Ansible-架构" class="headerlink" title="二、Ansible 架构"></a>二、Ansible 架构</h2><p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301290846771.png" alt="图片"></p>
<p>上图为 ansible 的基本架构，从上图可以了解到其由以下部分组成：</p>
<ul>
<li><strong>核心</strong>：ansible</li>
<li><strong>核心模块（Core Modules）</strong>：这些都是 ansible 自带的模块</li>
<li><strong>扩展模块（Custom Modules）</strong>：如果核心模块不足以完成某种功能，可以添加扩展模块</li>
<li><strong>插件（Plugins）</strong>：完成模块功能的补充</li>
<li><strong>剧本（Playbooks）</strong>：ansible 的任务配置文件，将多个任务定义在剧本中，由 ansible 自动执行</li>
<li><strong>连接插件（Connectior Plugins）</strong>：ansible 基于连接插件连接到各个主机上，虽然 ansible 是使用 ssh 连接到各个主机的，但是它还支持其他的连接方法，所以需要有连接插件</li>
<li><strong>主机清单（Host Inventory）</strong>：定义 ansible 管理的主机</li>
</ul>
<h2 id="三、Ansible-工作原理"><a href="#三、Ansible-工作原理" class="headerlink" title="三、Ansible 工作原理"></a>三、Ansible 工作原理</h2><p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301290846951.png" alt="图片"><br>从上面的图上可以了解到：</p>
<ul>
<li>管理端支持<code>local 、ssh、zeromq</code> 三种方式连接被管理端，默认使用基于 ssh 的连接，这部分对应上面架构图中的连接模块；</li>
<li>可以按应用类型等方式进行<code>Host Inventory（主机清单）</code>分类，管理节点通过各类模块实现相应的操作，单个模块，单条命令的批量执行，我们可以称之为 ad-hoc；</li>
<li>管理节点可以通过 playbooks 实现多个 task 的集合实现一类功能，如 web 服务的安装部署、数据库服务器的批量备份等。playbooks 我们可以简单的理解为，系统通过组合多条 ad-hoc 操作的配置文件 。</li>
</ul>
<h2 id="四、Ansible-安装与基础配置"><a href="#四、Ansible-安装与基础配置" class="headerlink" title="四、Ansible 安装与基础配置"></a>四、Ansible 安装与基础配置</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install epel-release</span><br><span class="line">yum -y install ansible</span><br><span class="line">ansible --version</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301290846464.png" alt="图片"></p>
<h3 id="1）开启记录日志"><a href="#1）开启记录日志" class="headerlink" title="1）开启记录日志"></a>1）开启记录日志</h3><p>配置文件：<code>/etc/ansible/ansible.cfg</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 去掉前面的&#x27;#&#x27;号</span></span><br><span class="line"><span class="comment">#log_path = /var/log/ansible.log ==&gt; log_path = /var/log/ansible.log</span></span><br></pre></td></tr></table></figure>

<h3 id="2）去掉第一次连接-ssh-ask-确认"><a href="#2）去掉第一次连接-ssh-ask-确认" class="headerlink" title="2）去掉第一次连接 ssh ask 确认"></a>2）去掉第一次连接 ssh ask 确认</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 第一种（推荐）</span></span><br><span class="line">vi /etc/ansible/ansible.cfg</span><br><span class="line"><span class="comment"># 其实就是把#去掉</span></span><br><span class="line"><span class="comment"># host_key_checking = False  ==&gt; host_key_checking = False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二种</span></span><br><span class="line">vi /etc/ssh/ssh_config</span><br><span class="line">StrictHostKeyChecking ask  ==&gt; StrictHostKeyChecking no</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301290847884.png" alt="图片"></p>
<h2 id="五、Ansible-的七个命令"><a href="#五、Ansible-的七个命令" class="headerlink" title="五、Ansible 的七个命令"></a>五、Ansible 的七个命令</h2><blockquote>
<p>安装完 ansible 后，发现 ansible 一共为我们提供了七个指令：<code>ansible</code>、<code>ansible-doc</code>、<code>ansible-galaxy</code>、<code>ansible-lint</code>、<code>ansible-playbook</code>、<code>ansible-pull</code>、<code>ansible-vault</code>。这里我们只查看 usage 部分，详细部分可以通过 “指令 -h” 的方式获取。</p>
</blockquote>
<h3 id="1）ansible"><a href="#1）ansible" class="headerlink" title="1）ansible"></a>1）ansible</h3><p>ansible 是指令核心部分，其主要用于执行 ad-hoc 命令，即单条命令。默认后面需要跟主机和选项部分，<strong>默认不指定模块时</strong>，使用的是<code>command</code>模块。不过默认使用的模块是可以在<code>/etc/ansible/ansible.cfg</code> 中进行修改的<code>#module_name = command</code>。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible 192.168.182.130 -a <span class="string">&#x27;date&#x27;</span></span><br></pre></td></tr></table></figure>

<h3 id="2）ansible-doc"><a href="#2）ansible-doc" class="headerlink" title="2）ansible-doc"></a>2）ansible-doc</h3><p>该指令用于查看模块信息，常用参数有两个-l 和 -s</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#列出所有已安装的模块ansible-doc  -l</span></span><br><span class="line">ansible-doc  -l</span><br><span class="line"><span class="comment">#查看具体某模块的用法，这里如查看command模块</span></span><br><span class="line">ansible-doc  -s <span class="built_in">command</span></span><br></pre></td></tr></table></figure>

<h3 id="3）ansible-playbook"><a href="#3）ansible-playbook" class="headerlink" title="3）ansible-playbook"></a>3）ansible-playbook</h3><p><code>ansible-playbook</code> 命令是使用最多的指令，其通过读取 playbook 文件后，执行相应的动作，这个后面会做为一个重点来讲。</p>
<h3 id="4）ansible-galaxy"><a href="#4）ansible-galaxy" class="headerlink" title="4）ansible-galaxy"></a>4）ansible-galaxy</h3><p><code>ansible-galaxy</code> 指令用于方便的从<a href="https://galaxy.ansible.com/">https://galaxy.ansible.com/</a> 站点下载第三方扩展模块，我们可以形象的理解其类似于 centos 下的 yum、python 下的 pip 或 easy_install 。如下示例：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-galaxy install aeriscloud.docker</span><br></pre></td></tr></table></figure>

<h3 id="5）ansible-lint"><a href="#5）ansible-lint" class="headerlink" title="5）ansible-lint"></a>5）ansible-lint</h3><p>ansible-lint 是对 playbook 的语法进行检查的一个工具。用法如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-lint playbook.yml</span><br></pre></td></tr></table></figure>

<h3 id="6）ansible-pull"><a href="#6）ansible-pull" class="headerlink" title="6）ansible-pull"></a>6）ansible-pull</h3><p>该指令使用需要谈到 ansible 的另一种模式，<strong>pull 模式</strong>，这和我们平常经常用的 push 模式刚好相反，其适用于以下场景：你有数量巨大的机器需要配置，即使使用非常高的线程还是要花费很多时间；你要在一个没有网络连接的机器上运行 Anisble，比如在启动之后安装。</p>
<h3 id="7）ansible-vault"><a href="#7）ansible-vault" class="headerlink" title="7）ansible-vault"></a>7）ansible-vault</h3><ul>
<li><code>ansible-vault</code> 主要应用于配置文件中含有敏感信息，又不希望他能被人看到，<strong>vault 可以帮你加密&#x2F;解密这个配置文件</strong>，属高级用法。</li>
<li>主要对于 playbooks 里比如涉及到配置密码或其他变量时，可以通过该指令加密，这样我们通过 cat 看到的会是一个密码串类的文件，编辑的时候需要输入事先设定的密码才能打开。</li>
<li>这种 playbook 文件在执行时，需要加上 <code>--ask-vault-pass</code>参数，同样需要输入密码后才能正常执行。</li>
</ul>
<h2 id="六、Ansible-主要组成部分"><a href="#六、Ansible-主要组成部分" class="headerlink" title="六、Ansible 主要组成部分"></a>六、Ansible 主要组成部分</h2><h3 id="1）ansible-命令执行来源"><a href="#1）ansible-命令执行来源" class="headerlink" title="1）ansible 命令执行来源"></a>1）ansible 命令执行来源</h3><ul>
<li>USER，普通用户，即 system administrator</li>
<li>USER -&gt; ansile playbook -&gt; ansible</li>
<li>CMDB，（配置管理数据库）API 调用</li>
<li>PUBLIC &#x2F; PRIVATE CLOUD API 调用</li>
</ul>
<h3 id="2）ansible-管理方式"><a href="#2）ansible-管理方式" class="headerlink" title="2）ansible 管理方式"></a>2）ansible 管理方式</h3><ul>
<li><p><code>Ad-Hoc</code>，即 ansible 命令，主要用于临时命令使用场景</p>
</li>
<li><p><code>Ansible-playbook</code>，主要用于长期规划好的，大型项目的场景，需要有前提的规划<br>ansible-playbook（剧本）执行过程：</p>
<ul>
<li>将已有编排好的任务集写入 ansible-playbook</li>
<li>通过 ansible-playbook 命令分拆任务集至逐条 ansible 命令，按预定规则逐条执行</li>
</ul>
</li>
</ul>
<h3 id="3）ansible-主要操作对象"><a href="#3）ansible-主要操作对象" class="headerlink" title="3）ansible 主要操作对象"></a>3）ansible 主要操作对象</h3><ul>
<li>HOSTS：主机</li>
<li>NETWORKING：网络设备</li>
</ul>
<p>注意事项：</p>
<ul>
<li>执行 ansible 的主机一般称为主控端，中控，master 或堡垒机</li>
<li>主控端 python 版本需要在 2.6 或以上</li>
<li>被控端 python 版本小于 2.4 需要安装 python-simplejson</li>
<li>被控端如开启 SELinux 需要安装 libselinux-python</li>
<li>windows 不能作为主控端</li>
</ul>
<h2 id="七、Ansible-连接被控端方式"><a href="#七、Ansible-连接被控端方式" class="headerlink" title="七、Ansible 连接被控端方式"></a>七、Ansible 连接被控端方式</h2><h3 id="1）ssh-密钥"><a href="#1）ssh-密钥" class="headerlink" title="1）ssh 密钥"></a>1）ssh 密钥</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成秘钥</span></span><br><span class="line">ssh-keygen</span><br><span class="line"><span class="comment"># 将秘钥拷贝到被管理服务器上</span></span><br><span class="line">ssh-copy-id  -i ~/.ssh/id_rsa.pub -p 22 root@192.168.182.130</span><br></pre></td></tr></table></figure>

<h3 id="2）账号密码"><a href="#2）账号密码" class="headerlink" title="2）账号密码"></a>2）账号密码</h3><h4 id="1、命令行配置"><a href="#1、命令行配置" class="headerlink" title="1、命令行配置"></a>1、命令行配置</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -k：交互式</span></span><br><span class="line">ansible -uroot -k 192.168.182.130 -m ping</span><br></pre></td></tr></table></figure>

<h4 id="2、配置文件中配置"><a href="#2、配置文件中配置" class="headerlink" title="2、配置文件中配置"></a>2、配置文件中配置</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 默认主机配置文件：/etc/ansible/hosts</span></span><br><span class="line">192.168.182.130 ansible_ssh_user=root ansible_ssh_pass=123456</span><br><span class="line"></span><br><span class="line">[web]</span><br><span class="line">192.168.182.130 ansible_ssh_user=root ansible_ssh_pass=123456</span><br></pre></td></tr></table></figure>

<p>常用的配置参数如下：<br><img src="https://mmbiz.qpic.cn/mmbiz_png/gIkzzLe4eUXn9wDTKicHfxSoX1q2FKE9icQOPGuiaXocOSG2sobUAzuVNv7yo9qWDnktjFvuvBER4A0KebLwibPavA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p>
<h2 id="八、Host-Inventory（主机清单）"><a href="#八、Host-Inventory（主机清单）" class="headerlink" title="八、Host Inventory（主机清单）"></a>八、Host Inventory（主机清单）</h2><p>主机清单配置（默认配置文件：<code>/etc/ansible/hosts</code>）</p>
<h3 id="1）添加被管控节点"><a href="#1）添加被管控节点" class="headerlink" title="1）添加被管控节点"></a>1）添加被管控节点</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">192.168.182.110</span><br></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -m：指定模块</span></span><br><span class="line"><span class="comment"># -a：指定参数</span></span><br><span class="line">ansible 192.168.182.110 -m ping</span><br><span class="line">ansible 192.168.182.110 -m shell -a <span class="string">&quot;df -h&quot;</span></span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301290847753.png" alt="图片"></p>
<h3 id="2）配置主机组"><a href="#2）配置主机组" class="headerlink" title="2）配置主机组"></a>2）配置主机组</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义webservers组</span></span><br><span class="line">[webservers]</span><br><span class="line">192.168.182.110</span><br><span class="line">192.168.182.112</span><br></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -m：指定模块</span></span><br><span class="line"><span class="comment"># -a：指定参数</span></span><br><span class="line">ansible webservers -m ping</span><br><span class="line">ansible webservers -m shell -a <span class="string">&quot;df -h&quot;</span></span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301290847217.png" alt="图片"></p>
<h3 id="3）配置连接用户名和密码"><a href="#3）配置连接用户名和密码" class="headerlink" title="3）配置连接用户名和密码"></a>3）配置连接用户名和密码</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[webservers]</span><br><span class="line">192.168.182.130 ansible_ssh_user=root ansible_ssh_pass=123456</span><br></pre></td></tr></table></figure>

<p>常用配置参数如下：<br><img src="https://mmbiz.qpic.cn/mmbiz_png/gIkzzLe4eUXn9wDTKicHfxSoX1q2FKE9icQOPGuiaXocOSG2sobUAzuVNv7yo9qWDnktjFvuvBER4A0KebLwibPavA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"><br>示例：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible 192.168.182.130 -m ping</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301290847374.png" alt="图片"></p>
<h3 id="4）子分组"><a href="#4）子分组" class="headerlink" title="4）子分组"></a>4）子分组</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[web]</span><br><span class="line">192.168.182.130</span><br><span class="line">192.168.182.110</span><br><span class="line">[mysql]</span><br><span class="line">192.168.182.111</span><br><span class="line"><span class="comment"># 子分组</span></span><br><span class="line">[nfs:children]</span><br><span class="line">web</span><br><span class="line">mysql</span><br><span class="line"><span class="comment"># 对分组统一定义变量</span></span><br><span class="line">[nfs:vars]</span><br><span class="line">ansible_ssh_user=root</span><br><span class="line">ansible_ssh_pass=123456</span><br><span class="line">ansible_ssh_port=22</span><br></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible nfs -m ping</span><br><span class="line"><span class="comment"># -o：一行显示</span></span><br><span class="line">ansible nfs -m ping -o</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301290847056.png" alt="图片"></p>
<h3 id="5）自定义主机列表文件"><a href="#5）自定义主机列表文件" class="headerlink" title="5）自定义主机列表文件"></a>5）自定义主机列表文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span>&gt;hostlist&lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">[web]</span></span><br><span class="line"><span class="string">192.168.182.130</span></span><br><span class="line"><span class="string">192.168.182.110</span></span><br><span class="line"><span class="string">[mysql]</span></span><br><span class="line"><span class="string">192.168.182.111</span></span><br><span class="line"><span class="string"># 子分组</span></span><br><span class="line"><span class="string">[nfs:children]</span></span><br><span class="line"><span class="string">web</span></span><br><span class="line"><span class="string">mysql</span></span><br><span class="line"><span class="string"># 对分组统一定义变量</span></span><br><span class="line"><span class="string">[nfs:vars]</span></span><br><span class="line"><span class="string">ansible_ssh_user=root</span></span><br><span class="line"><span class="string">ansible_ssh_pass=123456</span></span><br><span class="line"><span class="string">ansible_ssh_port=22</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -i：指定主机列表文件</span></span><br><span class="line">ansible -i hostlist nfs -m ping</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301290847589.png" alt="图片"></p>
<h2 id="九、Ad-Hoc（点对点模式）"><a href="#九、Ad-Hoc（点对点模式）" class="headerlink" title="九、Ad-Hoc（点对点模式）"></a>九、Ad-Hoc（点对点模式）</h2><blockquote>
<p>官方文档：<a href="https://docs.ansible.com/ansible/latest/command_guide/intro_adhoc.html">https://docs.ansible.com/ansible/latest/command_guide/intro_adhoc.html</a></p>
</blockquote>
<h3 id="1）简介"><a href="#1）简介" class="headerlink" title="1）简介"></a>1）简介</h3><blockquote>
<p><code>ad-hoc</code> 命令是一种可以快速输入的命令，而且不需要保存起来的命令，一般测试调试时用的多，ad-hoc 简而言之，就是”<strong>临时命令</strong>“。</p>
</blockquote>
<h3 id="2）常用模块"><a href="#2）常用模块" class="headerlink" title="2）常用模块"></a>2）常用模块</h3><h4 id="1、command-模块（默认模块）"><a href="#1、command-模块（默认模块）" class="headerlink" title="1、command 模块（默认模块）"></a>1、command 模块（默认模块）</h4><blockquote>
<p>默认模块，没有 shell 强大，基本上 shell 模块都可以支持 command 模块的功能。</p>
</blockquote>
<p>【1】帮助</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-doc <span class="built_in">command</span></span><br><span class="line"><span class="comment"># 推荐使用下面这个</span></span><br><span class="line">ansible-doc <span class="built_in">command</span> -s</span><br></pre></td></tr></table></figure>

<p>【2】参数解释</p>
<ul>
<li><code>free_form</code>——必须参数，指定需要远程执行的命令。需要说明一点，free_form 参数与其他参数（如果想要使用一个参数，那么则需要为这个参数赋值，也就是 name&#x3D;value 模式）并不相同。比如，当我们想要在远程主机上执行 ls 命令时，我们并不需要写成”free_form&#x3D;ls” ，这样写反而是错误的，因为并没有任何参数的名字是 free_form，当我们想要在远程主机中执行 ls 命令时，直接写成 ls 即可。因为 command 模块的作用是执行命令，所以，任何一个可以在远程主机上执行的命令都可以被称为 free_form。</li>
<li><code>chdir</code>——此参数的作用就是指定一个目录，在执行对应的命令之前，会先进入到 chdir 参数指定的目录中。</li>
<li><code>creates</code>——看到 creates，你可能会从字面上理解这个参数，但是使用这个参数并不会帮助我们创建文件，它的作用是当指定的文件存在时，就不执行对应命令，比如，如果 &#x2F;testdir&#x2F;test 文件存在，就不执行我们指定的命令。</li>
<li><code>removes</code>——与 creates 参数的作用正好相反，它的作用是当指定的文件不存在时，就不执行对应命令，比如，如果 &#x2F;testdir&#x2F;tests 文件不存在，就不执行我们指定的命令，此参数并不会帮助我们删除文件。</li>
</ul>
<p>【3】示例演示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 上面命令表示在 web 主机上执行 ls 命令，因为使用的是 root 用户，所以默认情况下，ls 出的结果是 web 主机中 root 用户家目录中的文件列表。</span></span><br><span class="line">ansible web -m <span class="built_in">command</span> -a <span class="string">&quot;ls&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># chdir 参数表示执行命令之前，会先进入到指定的目录中，所以上面命令表示查看 web 主机上 /testdir 目录中的文件列表，返回显示有2个文件。</span></span><br><span class="line">ansible web -m <span class="built_in">command</span> -a <span class="string">&quot;chdir=/testdir ls&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面命令表示 /testdir/testfile1 文件存在于远程主机中，则不执行对应命令。/testdir/testfile3 不存在，才执行”echo test”命令。</span></span><br><span class="line">ansible web -m <span class="built_in">command</span> -a <span class="string">&quot;creates=/testdir/testfile1 echo test&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面命令表示 /testdir/testfile3 文件不存在于远程主机中，则不执行对应命令。/testdir/testfile1 存在，才执行”echo test”命令。</span></span><br><span class="line">ansible web -m <span class="built_in">command</span> -a <span class="string">&quot;removes=/testdir/testfile1 echo test&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="2、shell-模块"><a href="#2、shell-模块" class="headerlink" title="2、shell 模块"></a>2、shell 模块</h4><blockquote>
<p>shell 模块 [执行远程主机的 shell&#x2F;python 等脚本]。</p>
</blockquote>
<p>【1】查看帮助</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-doc shell -s</span><br></pre></td></tr></table></figure>

<p>【2】示例演示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -o：一行显示</span></span><br><span class="line"><span class="comment"># 安装httpd</span></span><br><span class="line">ansible web -m shell -a <span class="string">&#x27;yum -y install httpd&#x27;</span> -o</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看时间</span></span><br><span class="line">ansible web -m shell -a <span class="string">&#x27;uptime&#x27;</span> -o</span><br></pre></td></tr></table></figure>

<h4 id="3、script-模块"><a href="#3、script-模块" class="headerlink" title="3、script 模块"></a>3、script 模块</h4><blockquote>
<p>script 模块 [在远程主机执行主控端的 shell&#x2F;python 等脚本 ]。</p>
</blockquote>
<p>【1】查看帮助</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-doc script -s</span><br></pre></td></tr></table></figure>

<p>【2】参数解释</p>
<ul>
<li><code>free_form</code>——必须参数，指定需要执行的脚本，脚本位于 ansible 管理主机本地，并没有具体的一个参数名叫 free_form，具体解释请参考 command 模块。</li>
<li><code>chdir</code>——此参数的作用就是指定一个远程主机中的目录，在执行对应的脚本之前，会先进入到 chdir 参数指定的目录中。</li>
<li><code>creates</code>——使用此参数指定一个远程主机中的文件，当指定的文件存在时，就不执行对应脚本，可参考 command 模块中的解释。</li>
<li><code>removes</code>——使用此参数指定一个远程主机中的文件，当指定的文件不存在时，就不执行对应脚本，可参考 command 模块中的解释。</li>
</ul>
<p>【3】示例演示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 下面命令表示 ansible 主机中的 /testdir/testscript.sh 脚本将在 web 主机中执行，执行此脚本之前，会先进入到 web 主机中的 /opt 目录</span></span><br><span class="line">ansible web -m script -a <span class="string">&quot;chdir=/opt /testdir/testscript.sh&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面命令表示，web主机中的 /testdir/testfile1文件已经存在，ansible 主机中的 /testdir/testscript.sh 脚本将不会在 web 主机中执行。</span></span><br><span class="line">ansible web -m script -a <span class="string">&quot;creates=/testdir/testfile1 /testdir/testscript.sh&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面命令表示，web 主机中的 /testdir/testfile1 文件存在，ansible 主机中的 /testdir/testscript.sh 脚本则会在 web 主机中执行。</span></span><br><span class="line">ansible ansible-demo3 -m script -a <span class="string">&quot;removes=/testdir/testfile1 /testdir/testscript.sh&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="4、raw-模块"><a href="#4、raw-模块" class="headerlink" title="4、raw 模块"></a>4、raw 模块</h4><blockquote>
<p>raw 模块 [类似于 command 模块、支持管道传递]。</p>
</blockquote>
<p>【1】查看帮助</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-doc raw -s</span><br></pre></td></tr></table></figure>

<p>【2】示例演示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible web -m raw -a <span class="string">&quot;ifconfig eth0 |sed -n 2p |awk &#x27;&#123;print \$2&#125;&#x27; |awk -F: &#x27;&#123;print \$2&#125;&#x27;&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="5、copy-模块"><a href="#5、copy-模块" class="headerlink" title="5、copy 模块"></a>5、copy 模块</h4><blockquote>
<p>copy 模块 从主控端复制文件到被控端。</p>
</blockquote>
<p>【1】查看帮助</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-doc copy -s</span><br></pre></td></tr></table></figure>

<p>【2】示例演示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -a,--args：后面接参数</span></span><br><span class="line">ansible web -m copy -a <span class="string">&#x27;src=/etc/ansible/hosts dest=/tmp/hosts owner=root group=bin mode=777&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># backup=yes/no：文件存在且文件内容不一样是否备份，默认不备份</span></span><br><span class="line">ansible web -m copy -a <span class="string">&#x27;src=/etc/ansible/hosts dest=/tmp/hosts owner=root group=bin mode=777 backup=yes&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="6、fetch-模块"><a href="#6、fetch-模块" class="headerlink" title="6、fetch 模块"></a>6、fetch 模块</h4><blockquote>
<p>copy 模块从被控端复制文件到主控端，正好跟 copy 相反。</p>
</blockquote>
<p>【1】查看帮助</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-doc fetch -s</span><br></pre></td></tr></table></figure>

<p>【2】示例演示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 跟copy支持的参数差不多，src：远端主机的目录，dest：主控端目录，其实真正存放的目录在：/tmp/192.168.182.129/tmp/up.sh，会按每台主机分组存放</span></span><br><span class="line"><span class="comment">#  This `must&#x27; be a file, not a directory：只支持单个文件获取</span></span><br><span class="line">ansible 192.168.182.129 -m fetch -a <span class="string">&quot;src=/etc/fstab dest=/testdir/ansible/&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="7、unarchive-模块（解包模块）"><a href="#7、unarchive-模块（解包模块）" class="headerlink" title="7、unarchive 模块（解包模块）"></a>7、unarchive 模块（解包模块）</h4><blockquote>
<p>unarchive 模块是解包模块。</p>
</blockquote>
<p>【1】查看帮助</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-doc unarchive -s</span><br></pre></td></tr></table></figure>

<p>【2】参数解释</p>
<ul>
<li><code>copy</code>——默认为 yes，当 copy&#x3D;yes，那么拷贝的文件是从 ansible 主机复制到远程主机上的，如果设置为 copy&#x3D;no，那么会在远程主机上寻找 src 源文件。</li>
<li><code>src</code>——源路径，可以是 ansible 主机上的路径，也可以是远程主机上的路径，如果是远程主机上的路径，则需要设置 copy&#x3D;no。</li>
<li><code>dest</code>——远程主机上的目标路径。</li>
<li><code>mode</code>——设置解压缩后的文件权限。</li>
</ul>
<p>【3】示例演示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible 192.168.182.129 -m unarchive -a <span class="string">&#x27;src=/testdir/ansible/data.tar.gz dest=/tmp/tmp/&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="8、archive-模块（打包模块）"><a href="#8、archive-模块（打包模块）" class="headerlink" title="8、archive 模块（打包模块）"></a>8、archive 模块（打包模块）</h4><blockquote>
<p>unarchive 模块是打包模块。</p>
</blockquote>
<p>【1】查看帮助</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-doc archive -s</span><br></pre></td></tr></table></figure>

<p>【2】示例演示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># path：主控端目录，format：压缩格式，dest：被控端目录文件&#x27;</span></span><br><span class="line">ansible 192.168.182.129 -m archive -a <span class="string">&#x27;path=/tmp/ format=gz dest=/tmp/tmp/t.tar.gz&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="9、user-模块"><a href="#9、user-模块" class="headerlink" title="9、user 模块"></a>9、user 模块</h4><p>【1】查看帮助</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-doc user -s</span><br></pre></td></tr></table></figure>

<p>【2】示例演示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建用户（present：默认，可以不写）</span></span><br><span class="line">ansible web -m user -a <span class="string">&#x27;name=test state=present&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除用户（absent）</span></span><br><span class="line">ansible web -m user -a <span class="string">&#x27;name=test state=absent&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改密码</span></span><br><span class="line"><span class="comment"># 步骤一、生成加密密码</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;777777&#x27;</span>|openssl passwd -1 -stdin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤二、修改秘密</span></span><br><span class="line">ansible web -m user -a <span class="string">&#x27;name=test password=&quot;$1$Jo5FD9Jr$2QB.BuybbtR35ga4O5o8N.&quot;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改shell</span></span><br><span class="line">ansible web -m user -a <span class="string">&#x27;name=test shell=/sbin/noglogin append=yes&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="10、group-模块"><a href="#10、group-模块" class="headerlink" title="10、group 模块"></a>10、group 模块</h4><p>【1】查看帮助</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-doc group -s</span><br></pre></td></tr></table></figure>

<p>【2】示例演示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建</span></span><br><span class="line">ansible 192.168.182.129 -m group -a <span class="string">&#x27;name=testgroup system=yes&#x27;</span></span><br><span class="line"><span class="comment"># 删除</span></span><br><span class="line">ansible 192.168.182.129 -m group -a <span class="string">&#x27;name=testgroup state=absent&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="11、yum-模块"><a href="#11、yum-模块" class="headerlink" title="11、yum 模块"></a>11、yum 模块</h4><p>【1】查看帮助</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-doc yum -s</span><br></pre></td></tr></table></figure>

<p>【2】示例演示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 升级所有包</span></span><br><span class="line">ansible web -m yum -a <span class="string">&#x27;name=&quot;*&quot; state=latest&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装apache</span></span><br><span class="line">ansible web -m yum -a <span class="string">&#x27;name=&quot;httpd&quot; state=latest&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="12、service-模块"><a href="#12、service-模块" class="headerlink" title="12、service 模块"></a>12、service 模块</h4><p>【1】查看帮助</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-doc service -s</span><br></pre></td></tr></table></figure>

<p>【2】示例演示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible web -m service -a <span class="string">&#x27;name=httpd state=started&#x27;</span></span><br><span class="line"></span><br><span class="line">ansible web -m service -a <span class="string">&#x27;name=httpd state=started enabled=yes&#x27;</span></span><br><span class="line"></span><br><span class="line">ansible web -m service -a <span class="string">&#x27;name=httpd state=stopped&#x27;</span></span><br><span class="line"></span><br><span class="line">ansible web -m service -a <span class="string">&#x27;name=httpd state=restarted&#x27;</span></span><br><span class="line"></span><br><span class="line">ansible web -m service -a <span class="string">&#x27;name=httpd state=started enabled=no&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="13、file-模块"><a href="#13、file-模块" class="headerlink" title="13、file 模块"></a>13、file 模块</h4><p>【1】查看帮助</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-doc file -s</span><br></pre></td></tr></table></figure>

<p>【2】示例演示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建文件</span></span><br><span class="line">ansible web -m file -a <span class="string">&#x27;path=/tmp/88.txt mode=777 state=touch&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建目录</span></span><br><span class="line">ansible web -m file -a <span class="string">&#x27;path=/tmp/99 mode=777 state=directory&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除</span></span><br><span class="line">ansible web -m file -a <span class="string">&#x27;path=/tmp/99 state=absent&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="14、setup-模块"><a href="#14、setup-模块" class="headerlink" title="14、setup 模块"></a>14、setup 模块</h4><p>【1】查看帮助</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-doc setup -s</span><br></pre></td></tr></table></figure>

<p>【2】示例演示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible web -m setup</span><br><span class="line"></span><br><span class="line">ansible web -m setup -a <span class="string">&#x27;filter=ansible_all_ipv4_addresses&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="15、cron-模块"><a href="#15、cron-模块" class="headerlink" title="15、cron 模块"></a>15、cron 模块</h4><p>【1】查看帮助</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-doc cron -s</span><br></pre></td></tr></table></figure>

<p>【2】示例演示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建定时任务</span></span><br><span class="line">ansible 192.168.182.129 -m cron -a <span class="string">&#x27;minute=* weekday=1,3,5,6,7 job=&quot;/usr/bin/wall FBI warning&quot; name=warningcron&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭定时任务</span></span><br><span class="line">ansible 192.168.182.129 -m cron -a <span class="string">&#x27;disabled=true job=&quot;/usr/bin/wall FBI warning&quot; name=warningcron&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除定时任务</span></span><br><span class="line">ansible 192.168.182.129 -m cron -a <span class="string">&#x27; job=&quot;/usr/bin/wall FBI warning&quot; name=warningcron state=absent&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="16、hostname-模块"><a href="#16、hostname-模块" class="headerlink" title="16、hostname 模块"></a>16、hostname 模块</h4><p>【1】查看帮助</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-doc hostname -s</span><br></pre></td></tr></table></figure>

<p>【2】示例演示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible 192.168.182.129 -m hostname -a <span class="string">&#x27;name=192.168.182.129&#x27;</span></span><br></pre></td></tr></table></figure>

<p>Ansible 的介绍和简单使用就先到这里了，还有一个 ansible-playbook 是非常重要，</p>
]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title>Ceph 环境部署</title>
    <url>/2023/01/05/Ceph%20%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><blockquote>
<p>Ceph 是当前非常流行的开源分布式存储系统，具有高扩展性、高性能、高可靠性等优点，同时提供<strong>块存储服务</strong>(<code>rbd</code>)、<strong>对象存储服务</strong>(<code>rgw</code>)以及<strong>文件系统存储服务</strong>(<code>cephfs</code>)，Ceph 在存储的时候充分利用存储节点的计算能力，在存储每一个数据时都会通过计算得出该数据的位置，尽量的分布均衡。目前也是 OpenStack 的主流后端存储。</p>
</blockquote>
<p>特点：</p>
<ul>
<li><p><strong>高性能</strong></p>
<ul>
<li>摒弃了传统的集中式存储元数据寻址的方案，采用 CRUSH 算法，数据分布均衡，并行度高。</li>
<li>考虑了容灾域的隔离，能够实现各类负载的副本放置规则，例如跨机房、机架感知等。</li>
<li>能够支持上千个存储节点的规模，支持 TB 到 PB 级的数据。</li>
</ul>
</li>
<li><p><strong>高可用性</strong></p>
<ul>
<li>副本数可以灵活控制。</li>
<li>支持故障域分隔，数据强一致性</li>
<li>多种故障场景自动进行修复自愈。</li>
<li>没有单点故障，自动管理。</li>
</ul>
</li>
<li><p><strong>高可扩展性</strong></p>
<ul>
<li>去中心化。</li>
<li>扩展灵活。</li>
<li>随着节点增加而线性增长。</li>
</ul>
</li>
<li><p><strong>特性丰富</strong></p>
<ul>
<li>支持三种存储接口：块存储、文件存储、对象存储。</li>
<li>支持自定义接口，支持多种语言驱动。</li>
</ul>
</li>
</ul>
<blockquote>
<p><a href="https://github.com/ceph/ceph"><strong>Ceph GitHub 地址</strong></a><br><a href="https://docs.ceph.com/en/latest/start/intro"><strong>官方文档</strong></a></p>
</blockquote>
<h2 id="二、Ceph-架构"><a href="#二、Ceph-架构" class="headerlink" title="二、Ceph 架构"></a>二、Ceph 架构</h2><p>支持三种接口：</p>
<ul>
<li><code>Object</code>：有原生的 API，而且也兼容 Swift 和 S3 的 API。</li>
<li><code>Block</code>：支持精简配置、快照、克隆。</li>
<li><code>File</code>：Posix 接口，支持快照。</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301060831168.png" alt="图片"></p>
<ul>
<li><code>RADOS</code>——全称 Reliable Autonomic Distributed Object Store，即可靠的、自动化的、分布式对象存储系统。RADOS 是 Ceph 集群的精华，用户实现数据分配、Failover 等集群操作。</li>
<li><code>Librados</code>——Rados 提供库，因为 RADOS 是协议很难直接访问，因此上层的 RBD、RGW 和 CephFS 都是通过 librados 访问的，目前提供 PHP、Ruby、Java、Python、C 和 C++支持。</li>
<li><code>MDS</code>——存储 Ceph 文件系统的元数据。</li>
</ul>
<h2 id="三、Ceph-核心组件介绍"><a href="#三、Ceph-核心组件介绍" class="headerlink" title="三、Ceph 核心组件介绍"></a>三、Ceph 核心组件介绍</h2><p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301060830107.png" alt="图片"></p>
<ul>
<li><code>OSD</code>——OSD 是负责物理存储的进程，一般配置成和磁盘一一对应，一块磁盘启动一个 OSD 进程。主要功能是存储数据、复制数据、平衡数据、恢复数据，以及与其它 OSD 间进行心跳检查，负责响应客户端请求返回具体数据的进程等。</li>
</ul>
<blockquote>
<p>OSD 是 Ceph 集群中存储实际用户数据的惟一组件，通常，一个 OSD 守护进程绑定到集群中的一个物理磁盘。因此，通常来说，Ceph 集群中物理磁盘的总数与在每个物理磁盘上存储用户数据的 OSD 守护进程的总数相同。</p>
</blockquote>
<ul>
<li><code>PG</code>——ceph 中引入了 PG（placement group)的概念，PG 是一个虚拟的概念而已，并不对应什么实体。ceph 先将 object 映射成 PG，然后从 PG 映射成 OSD。</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301060831010.png" alt="图片"></p>
<ul>
<li><code>Pool</code>——Pool 是存储对象的逻辑分区，它规定了数据冗余的类型和对应的副本分布策略，支持两种类型：副本（replicated）和 纠删码（ Erasure Code）。</li>
</ul>
<p>Pool、PG 和 OSD 的关系：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">一个Pool里有很多PG；</span><br><span class="line">一个PG里包含一堆对象，一个对象只能属于一个PG；</span><br><span class="line">PG有主从之分，一个PG分布在不同的OSD上（针对三副本类型）;</span><br></pre></td></tr></table></figure>

<ul>
<li><code>Monitor监控</code>——一个 Ceph 集群需要多个 Monitor 组成的小集群，它们通过 Paxos 同步数据，用来保存 OSD 的元数据。负责监控整个 Ceph 集群运行的 Map 视图（如 OSD Map、Monitor Map、PG Map 和 CRUSH Map），维护集群的健康状态，维护展示集群状态的各种图表，管理集群客户端认证与授权。</li>
<li><code>MDS</code>——MDS 全称 Ceph Metadata Server，是 CephFS 服务依赖的元数据服务。负责保存文件系统的元数据，管理目录结构。对象存储和块设备存储不需要元数据服务；如果不使用 CephFS 可以不安装。</li>
<li><code>Mgr</code>——ceph 官方开发了 ceph-mgr，主要目标实现 ceph 集群的管理，为外界提供统一的入口。例如 cephmetrics、zabbix、calamari、prometheus。</li>
</ul>
<p>Ceph manager 守护进程(Ceph -mgr)是在 Kraken 版本中引入的，它与 monitor 守护进程一起运行，为外部监视和管理系统提供额外的监视和接口。</p>
<ul>
<li><code>RGW</code>——RGW 全称 RADOS gateway，是 Ceph 对外提供的对象存储服务，接口与 S3 和 Swift 兼容。</li>
<li><code>CephFS</code>——ceph 文件系统提供了一个符合 posix 标准的文件系统，它使用 Ceph 存储集群在文件系统上存储用户数据。与 RBD（块存储）和 RGW（对象存储）一样，CephFS 服务也作为 librados 的本机接口实现。</li>
</ul>
<h2 id="四、Ceph-三种存储类型"><a href="#四、Ceph-三种存储类型" class="headerlink" title="四、Ceph 三种存储类型"></a>四、Ceph 三种存储类型</h2><h3 id="1）块存储服务-RBD"><a href="#1）块存储服务-RBD" class="headerlink" title="1）块存储服务(RBD)"></a>1）块存储服务(RBD)</h3><blockquote>
<p>块是一个字节序列（通常为 512）。基于块的存储接口是一种成熟且常见的数据存储方式 介质包括硬盘、固态硬盘、CD、软盘，甚至磁带。块设备接口的无处不在非常适合交互 具有包括 Ceph 在内的海量数据存储。Ceph 数据块设备可精简配置、可调整大小，并按条带方式存储数据在多个 OSD。</p>
</blockquote>
<p><strong>优点：</strong></p>
<ul>
<li>通过 Raid 与 LVM 等手段，对数据提供了保护；</li>
<li>多块廉价的硬盘组合起来，提高容量；</li>
<li>多块磁盘组合出来的逻辑盘，提升读写效率；</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>采用 SAN 架构组网时，光纤交换机，造价成本高；</li>
<li>主机之间无法共享数据；</li>
</ul>
<p><strong>使用场景：</strong></p>
<ul>
<li>docker 容器、虚拟机磁盘存储分配；</li>
<li>日志存储；</li>
<li>文件存储；</li>
</ul>
<blockquote>
<p>总结：一个 Linux 内核级的块设备，允许用户像任何其他 Linux 块设备一样访问 Ceph。</p>
</blockquote>
<h3 id="2）文件系统存储服务-CephFS"><a href="#2）文件系统存储服务-CephFS" class="headerlink" title="2）文件系统存储服务(CephFS)"></a>2）文件系统存储服务(CephFS)</h3><blockquote>
<p>Ceph 文件系统（CephFS），是建立在 Ceph 分布式对象存储的顶部， CephFS 提供了最先进的、多用途、高度可用且高性能的文件存储在各种场景应用，包括共享 home 目录、FTP 和 NFS 共享存储等等。</p>
</blockquote>
<p>Ceph 有了块存储，为什么还需要文件系统接口呢？</p>
<blockquote>
<p>主要是因为应用场景的不同,Ceph 的块设备具有优异的读写性能,但不能多处挂载同时读写,目前主要用在 OpenStack 上作为虚拟磁盘,而 Ceph 的文件系统接口读写性能较块设备接口差,但具有优异的 共享性。</p>
</blockquote>
<p><strong>优点：</strong></p>
<ul>
<li>造价低，随便一台机器就可以了。</li>
<li>方便文件共享。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>读写速率低。</li>
<li>传输速率慢。</li>
</ul>
<p><strong>使用场景：</strong></p>
<ul>
<li>日志存储。</li>
<li>有目录结构的文件存储。</li>
</ul>
<h3 id="3）对象存储服务-RGW"><a href="#3）对象存储服务-RGW" class="headerlink" title="3）对象存储服务(RGW)"></a>3）对象存储服务(RGW)</h3><blockquote>
<p>Ceph 对象网关 是构建在 librados.它在应用程序和 Ceph 之间提供了一个 RESTful 网关。存储集群。Ceph 对象存储 支持两种接口：</p>
</blockquote>
<ul>
<li>S3 兼容：通过接口提供对象存储功能 与 Amazon S3 RESTful API 的大部分子集兼容。</li>
<li>快速兼容：通过接口提供对象存储功能 与 OpenStack Swift API 的一大块子集兼容。</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301060831541.png" alt="图片"></p>
<p><strong>优点：</strong></p>
<ul>
<li>具备块存储的读写高速。</li>
<li>具备文件存储的共享等特性。</li>
</ul>
<p><strong>使用场景：</strong></p>
<ul>
<li>图片存储。</li>
<li>视频存储。</li>
</ul>
<h2 id="五、Ceph-版本发行生命周期"><a href="#五、Ceph-版本发行生命周期" class="headerlink" title="五、Ceph 版本发行生命周期"></a>五、Ceph 版本发行生命周期</h2><p>Ceph 从<code>Nautilus</code>版本（14.2.0）开始，每年都会有一个新的稳定版发行，预计是每年的 3 月份发布，每年的新版本都会起一个新的名称（例如，“Mimic”）和一个主版本号（例如，13 代表 <code>Mimic</code>，因为“M”是字母表的第 13 个字母）。</p>
<p>版本号的格式为<code>x.y.z</code>，x 表示发布周期（例如，13 代表 Mimic，17 代表 Quincy），y 表示发布版本类型，即</p>
<ul>
<li>x.0.z - y 等于 0，表示开发版本</li>
<li>x.1.z - y 等于 1，表示发布候选版本（用于测试集群）</li>
<li>x.2.z - y 等于 2，表示稳定&#x2F;错误修复版本（针对用户）</li>
</ul>
<p>在<code>Octopus</code>版本后使用 cephadm 来部署 ceph 集群，如果使用 cephadm 部署，在后期新的版本升级时，可以做到完全自动化，并可以通过 ceph -W cephadm 查看升级进度，升级完成后，无法降级，升级时请不要跨版本升级，例如：当前使用 Octopus 升级到 Quincy，要先把 Octopus 升级到 Pacific，然后在升级至 Quincy，这是最稳妥的方式。</p>
<p>稳定版本的生命周期在第一个发布月份后，大约 2 年时间将停止该版本的更新维护，具体版本发布时间见下表。</p>
<h2 id="六、Ceph-集群部署"><a href="#六、Ceph-集群部署" class="headerlink" title="六、Ceph 集群部署"></a>六、Ceph 集群部署</h2><p>Ceph 的部署工具：</p>
<ul>
<li><code>ceph-deploy</code>：官方的部署工具，不再积极维护 ceph-deploy。它不支持 RHEL8，CentOS 8 或更新的操作系统。</li>
<li><code>ceph-ansible</code>：红帽的部署工具</li>
<li><code>ceph-chef</code>：利用 chef 进行自动部署 Ceph 的工具</li>
<li><code>puppet-ceph</code>：puppet 的 ceph 模块</li>
<li><code>cephadm</code>——cephadm 仅支援 Octopus 及更新版本（推荐）。</li>
</ul>
<h3 id="1）集群部署规划"><a href="#1）集群部署规划" class="headerlink" title="1）集群部署规划"></a>1）集群部署规划</h3><table>
<thead>
<tr>
<th align="center">IP</th>
<th align="center">hostname</th>
<th align="center">角色</th>
<th align="center">磁盘</th>
<th align="center">操作系统</th>
</tr>
</thead>
<tbody><tr>
<td align="center">192.168.182.130</td>
<td align="center">local-168-182-130</td>
<td align="center">monitor,mgr,rgw,mds,osd</td>
<td align="center">2*20G</td>
<td align="center">centos7</td>
</tr>
<tr>
<td align="center">192.168.182.131</td>
<td align="center">local-168-182-131</td>
<td align="center">monitor,mgr,rgw,mds,osd</td>
<td align="center">2*20G</td>
<td align="center">centos7</td>
</tr>
<tr>
<td align="center">192.168.182.132</td>
<td align="center">local-168-182-132</td>
<td align="center">monitor,mgr,rgw,mds,osd</td>
<td align="center">2*20G</td>
<td align="center">centos7</td>
</tr>
</tbody></table>
<ul>
<li><code>monitor</code>：Ceph 监视管理节点，承担 Ceph 集群重要的管理任务，一般需要 3 或 5 个节点。</li>
<li><code>mgr</code>：Ceph 集群管理节点（manager），为外界提供统一的入口。</li>
<li><code>rgw</code>: Ceph 对象网关，是一种服务，使客户端能够利用标准对象存储 API 来访问 Ceph 集群。</li>
<li><code>mds</code>：Ceph 元数据服务器，MetaData Server，主要保存的文件系统服务的元数据，使用文件存储时才需要该组件。</li>
<li><code>osd</code>：Ceph 存储节点 Object Storage Daemon，实际负责数据存储的节点。</li>
</ul>
<h3 id="2）前期准备"><a href="#2）前期准备" class="headerlink" title="2）前期准备"></a>2）前期准备</h3><h4 id="1、关闭-filewalld-服务"><a href="#1、关闭-filewalld-服务" class="headerlink" title="1、关闭 filewalld 服务"></a>1、关闭 filewalld 服务</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl stop firewalld.service</span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld.service</span><br></pre></td></tr></table></figure>

<h4 id="2、关闭并禁用-SELinux"><a href="#2、关闭并禁用-SELinux" class="headerlink" title="2、关闭并禁用 SELinux"></a>2、关闭并禁用 SELinux</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i <span class="string">&#x27;s/^SELINUX=enforcing$/SELINUX=disabled/&#x27;</span> /etc/selinux/config</span><br><span class="line">setenforce 0</span><br></pre></td></tr></table></figure>

<h4 id="3、配置-hosts"><a href="#3、配置-hosts" class="headerlink" title="3、配置 hosts"></a>3、配置 hosts</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">192.168.182.130 local-168-182-130</span><br><span class="line">192.168.182.131 local-168-182-131</span><br><span class="line">192.168.182.132 local-168-182-132</span><br></pre></td></tr></table></figure>

<h4 id="4、ssh-免密配置"><a href="#4、ssh-免密配置" class="headerlink" title="4、ssh 免密配置"></a>4、ssh 免密配置</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-keygen</span><br><span class="line"><span class="comment"># ...一路Enter</span></span><br><span class="line">ssh-copy-id root@local-168-182-130  //会有一次密码输入</span><br><span class="line">ssh-copy-id root@local-168-182-131</span><br><span class="line">ssh-copy-id root@local-168-182-132</span><br></pre></td></tr></table></figure>

<h4 id="4、配置时间同步"><a href="#4、配置时间同步" class="headerlink" title="4、配置时间同步"></a>4、配置时间同步</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y chrony</span><br><span class="line">systemctl <span class="built_in">enable</span> --now chronyd</span><br></pre></td></tr></table></figure>

<h3 id="3）添加磁盘"><a href="#3）添加磁盘" class="headerlink" title="3）添加磁盘"></a>3）添加磁盘</h3><p>如果添加完磁盘，看不到，可以执行以下命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 重新扫描SCSI总线添加设备</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;- - -&quot;</span> &gt; /sys/class/scsi_host/host0/scan</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;- - -&quot;</span> &gt; /sys/class/scsi_host/host1/scan</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;- - -&quot;</span> &gt; /sys/class/scsi_host/host2/scan</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301060832769.png" alt="图片"></p>
<h3 id="4）安装-docker-（所有节点操作，包括新增）"><a href="#4）安装-docker-（所有节点操作，包括新增）" class="headerlink" title="4）安装 docker :（所有节点操作，包括新增）"></a>4）安装 docker :（所有节点操作，包括新增）</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># centos7</span></span><br><span class="line">wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装yum-config-manager配置工具</span></span><br><span class="line">yum -y install yum-utils</span><br><span class="line"><span class="comment"># 设置yum源</span></span><br><span class="line">yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line"><span class="comment"># 安装docker-ce版本</span></span><br><span class="line">yum install -y docker-ce</span><br><span class="line"></span><br><span class="line"><span class="comment">#启动docker服务并开机自启</span></span><br><span class="line">systemctl <span class="built_in">enable</span> --now docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看版本号</span></span><br><span class="line">docker --version</span><br><span class="line"><span class="comment"># 查看版本具体信息</span></span><br><span class="line">docker version</span><br><span class="line"></span><br><span class="line"><span class="comment"># Docker镜像源设置</span></span><br><span class="line"><span class="comment"># 修改文件 /etc/docker/daemon.json，没有这个文件就创建</span></span><br><span class="line"><span class="comment"># 添加以下内容后，重启docker服务：</span></span><br><span class="line"><span class="built_in">cat</span> &gt;/etc/docker/daemon.json&lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">   &quot;registry-mirrors&quot;: [&quot;http://hub-mirror.c.163.com&quot;]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure>

<h3 id="5）安装-cephadm"><a href="#5）安装-cephadm" class="headerlink" title="5）安装 cephadm"></a>5）安装 cephadm</h3><p>下载 cephadm 脚本：（只在主节点操作）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /opt/ceph/my-cluster ; <span class="built_in">cd</span> /opt/ceph/my-cluster</span><br><span class="line">curl --silent --remote-name --location https://github.com/ceph/ceph/raw/octopus/src/cephadm/cephadm  -o cephadm</span><br><span class="line"><span class="built_in">chmod</span> +x cephadm</span><br><span class="line"><span class="comment"># 或者：</span></span><br><span class="line"><span class="comment">#curl https://raw.githubusercontent.com/ceph/ceph/v15.2.1/src/cephadm/cephadm -o cephadm</span></span><br><span class="line"><span class="comment">#chmod +x cephadm</span></span><br><span class="line"><span class="comment">#//**//下载出错：配置/etc/hosts 文件--—&gt; 199.232.28.133 raw.githubusercontent.com</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装python3:（所有节点执行）</span></span><br><span class="line">yum install python3 -y</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置ceph存储库  ：（或指定版本）</span></span><br><span class="line">./cephadm add-repo --release octopus</span><br><span class="line"><span class="comment">#或</span></span><br><span class="line"><span class="comment">#./cephadm add-repo --version 15.2.1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始安装ceph-common，ceph工具</span></span><br><span class="line">./cephadm install ceph-common ceph</span><br><span class="line"><span class="comment"># 安装cephadm工具</span></span><br><span class="line">./cephadm install</span><br><span class="line"><span class="built_in">which</span> cephadm</span><br><span class="line"><span class="built_in">which</span> ceph</span><br></pre></td></tr></table></figure>

<h3 id="6）初始化-ceph-集群"><a href="#6）初始化-ceph-集群" class="headerlink" title="6）初始化 ceph 集群"></a>6）初始化 ceph 集群</h3><p>当前节点安装 mon、 mgr 角色,部署 prometheus、 grafana、 alertmanager、 node-exporter 等服务。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#先安装一个节点，其它节点通过后面的命令添加到集群中即可</span></span><br><span class="line"><span class="comment">#您需要知道用于集群的第一个监视器守护程序的IP地址。</span></span><br><span class="line"><span class="comment">#如果有多个网络和接口，要确保选择任何可供访问Ceph群集的主机访问的网络和接口。</span></span><br><span class="line"></span><br><span class="line">cephadm bootstrap --mon-ip 192.168.182.130</span><br><span class="line"></span><br><span class="line"><span class="comment">##### 命令特点：</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#在本地主机上为新集群创建监视和管理器守护程序。</span></span><br><span class="line"><span class="comment">#为Ceph集群生成一个新的SSH密钥，并将其添加到root用户的/root/.ssh/authorized_keys文件中。</span></span><br><span class="line"><span class="comment">#将与新集群进行通信所需的最小配置文件编写为/etc/ceph/ceph.conf。</span></span><br><span class="line"><span class="comment">#将client.admin管理密钥的副本写入/etc/ceph/ceph.client.admin.keyring。</span></span><br><span class="line"><span class="comment">#将公用密钥的副本写入 /etc/ceph/ceph.pub。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看部署的服务</span></span><br><span class="line">docker ps</span><br><span class="line"></span><br><span class="line"><span class="comment">#=======输出信息=======</span></span><br><span class="line">Ceph Dashboard is now available at:</span><br><span class="line"></span><br><span class="line">             URL: https://local-168-182-130:8443/</span><br><span class="line">            User: admin</span><br><span class="line">        Password: 0ard2l57ji</span><br><span class="line"></span><br><span class="line">You can access the Ceph CLI with:</span><br><span class="line"></span><br><span class="line">        sudo /usr/sbin/cephadm shell --fsid d1e9b986-89b8-11ed-bec2-000c29ca76a9 -c /etc/ceph/ceph.conf -k /etc/ceph/ceph.client.admin.keyring</span><br><span class="line"></span><br><span class="line">Please consider enabling telemetry to <span class="built_in">help</span> improve Ceph:</span><br><span class="line"></span><br><span class="line">        ceph telemetry on</span><br><span class="line"></span><br><span class="line">For more information see:</span><br><span class="line"></span><br><span class="line">        https://docs.ceph.com/docs/master/mgr/telemetry/</span><br></pre></td></tr></table></figure>

<p>根据提示可知，有个 web 地址：<code>https://ip:8443/</code>，这里的截图是部署完之后的截图。<br><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301060832172.png" alt="图片"></p>
<p>通过 ceph 命令查看集群状态</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph -s</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301060832202.png" alt="图片"></p>
<h3 id="7）添加新节点"><a href="#7）添加新节点" class="headerlink" title="7）添加新节点"></a>7）添加新节点</h3><p>在新主机的根用户 authorized_keys 文件中安装群集的公共 SSH 密钥 ：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-copy-id -f -i /etc/ceph/ceph.pub root@local-168-182-131</span><br><span class="line">ssh-copy-id -f -i /etc/ceph/ceph.pub root@local-168-182-132</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301060832101.png" alt="图片"></p>
<p>配置新节点</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph orch host add local-168-182-131</span><br><span class="line">ceph orch host add local-168-182-132</span><br><span class="line"></span><br><span class="line"><span class="comment">#第一次部署新节点时直接用上边的命令即可：</span></span><br><span class="line"><span class="comment">#但是之后的节点新增有可能上述命令出错：</span></span><br><span class="line">ceph orch host add local-168-182-131 192.168.182.133  <span class="comment">#后边跟上对应的IP</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看节点</span></span><br><span class="line">ceph orch host <span class="built_in">ls</span></span><br></pre></td></tr></table></figure>

<h3 id="8）部署监视器（monitor）"><a href="#8）部署监视器（monitor）" class="headerlink" title="8）部署监视器（monitor）"></a>8）部署监视器（monitor）</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ceph orch apply mon *&lt;number-of-monitors&gt;*</span></span><br><span class="line"><span class="comment"># 确保在此列表中包括第一台（引导）主机。</span></span><br><span class="line">ceph orch apply mon local-168-182-130,local-168-182-131,local-168-182-132</span><br></pre></td></tr></table></figure>

<h3 id="9）部署-osd"><a href="#9）部署-osd" class="headerlink" title="9）部署 osd"></a>9）部署 osd</h3><p>存储设备清单可以显示为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph orch device <span class="built_in">ls</span></span><br></pre></td></tr></table></figure>

<p>可用存储设备的条件：</p>
<ul>
<li>设备必须没有分区。</li>
<li>设备不得具有任何 LVM 状态。</li>
<li>不得安装设备。</li>
<li>该设备不得包含文件系统。</li>
<li>该设备不得包含 Ceph BlueStore OSD。</li>
<li>设备必须大于 5 GB。</li>
</ul>
<h4 id="创建-osd-的方式"><a href="#创建-osd-的方式" class="headerlink" title="创建 osd 的方式"></a>创建 osd 的方式</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 【第一种方式】告诉Ceph使用任何可用和未使用的存储设备：</span></span><br><span class="line">ceph orch apply osd --all-available-devices</span><br><span class="line"></span><br><span class="line"><span class="comment"># 【第二种方式】或者使用下面命令指定使用的磁盘（推荐使用这种方式吧）</span></span><br><span class="line"><span class="comment">#1. ceph orch daemon add osd *&lt;host&gt;*:*&lt;device-path&gt;*</span></span><br><span class="line"><span class="comment">#例如：</span></span><br><span class="line"><span class="comment">#从特定主机上的特定设备创建OSD：</span></span><br><span class="line">ceph orch daemon add osd local-168-182-130:/dev/sdb</span><br><span class="line">ceph orch daemon add osd local-168-182-130:/dev/sdc</span><br><span class="line"></span><br><span class="line">ceph orch daemon add osd local-168-182-131:/dev/sdb</span><br><span class="line">ceph orch daemon add osd local-168-182-131:/dev/sdc</span><br><span class="line"></span><br><span class="line">ceph orch daemon add osd local-168-182-132:/dev/sdb</span><br><span class="line">ceph orch daemon add osd local-168-182-132:/dev/sdc</span><br></pre></td></tr></table></figure>

<h4 id="删除-OSD-节点-安全"><a href="#删除-OSD-节点-安全" class="headerlink" title="删除 OSD 节点:(安全)"></a>删除 OSD 节点:(安全)</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#1.停止osd进程</span></span><br><span class="line">ceph osd stop x  //(x 可以通过ceph osd <span class="built_in">ls</span> 查看)</span><br><span class="line"><span class="comment">#停止osd的进程，这个是通知集群这个osd进程不在了，不提供服务了，因为本身没权重，就不会影响到整体的分布，也就没有迁移</span></span><br><span class="line"><span class="comment">#2.将节点状态标记为out</span></span><br><span class="line">ceph osd out osd.x</span><br><span class="line"><span class="comment">#停止到osd的进程，这个是通知集群这个osd不再映射数据了，不提供服务了，因为本身没权重，就不会影响到整体的分布，也就没有迁移</span></span><br><span class="line"><span class="comment">#3. 从crush中移除节点</span></span><br><span class="line">ceph osd crush remove osd.x</span><br><span class="line">这个是从crush中删除，</span><br><span class="line"><span class="comment">#4. 删除节点</span></span><br><span class="line">ceph osd <span class="built_in">rm</span> osd.x</span><br><span class="line">这个是从集群里面删除这个节点的记录<span class="built_in">ls</span></span><br><span class="line"><span class="comment">#5. 删除节点认证（不删除编号会占住）</span></span><br><span class="line">ceph auth del osd.x</span><br><span class="line">这个是从认证当中去删除这个节点的信息</span><br></pre></td></tr></table></figure>

<h3 id="10）部署-mds-cephFS-元数据守护程序"><a href="#10）部署-mds-cephFS-元数据守护程序" class="headerlink" title="10）部署 mds(cephFS 元数据守护程序)"></a>10）部署 mds(cephFS 元数据守护程序)</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ceph orch apply mds *&lt;fs-name&gt;* --placement=&quot;*&lt;num-daemons&gt;* [*&lt;host1&gt;* ...]&quot;</span></span><br><span class="line"></span><br><span class="line">ceph orch apply mds myfs --placement=<span class="string">&quot;3 local-168-182-130 local-168-182-131 local-168-182-132&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="11）部署-RGW"><a href="#11）部署-RGW" class="headerlink" title="11）部署 RGW"></a>11）部署 RGW</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 为特定领域和区域部署一组radosgw守护程序：</span></span><br><span class="line"><span class="comment"># ceph orch apply rgw *&lt;realm-name&gt;* *&lt;zone-name&gt;* --placement=&quot;*&lt;num-daemons&gt;* [*&lt;host1&gt;* ...]&quot;</span></span><br><span class="line"></span><br><span class="line">ceph orch apply rgw myorg us-east-1 --placement=<span class="string">&quot;3 local-168-182-130 local-168-182-131 local-168-182-132&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">###说明：</span></span><br><span class="line"><span class="comment">#myorg : 领域名  （realm-name）</span></span><br><span class="line"><span class="comment">#us-east-1: 区域名 （zone-name）myrgw</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Cephadm将等待运行正常的群集，并在部署rgw守护程序之前自动创建所提供的领域和区域（realm-name和zone-name不存在的情况）</span></span><br></pre></td></tr></table></figure>

<p>查看集群状态</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph -s</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301060832983.png" alt="图片"></p>
<h3 id="12）添加专用的-ceph-mgr-节点"><a href="#12）添加专用的-ceph-mgr-节点" class="headerlink" title="12）添加专用的 ceph-mgr 节点"></a>12）添加专用的 ceph-mgr 节点</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ceph-mgr节点默认会挑选一主一备</span></span><br><span class="line"><span class="comment"># 添加新节点</span></span><br><span class="line">ceph orch host add local-168-182-131 192.168.182.133</span><br><span class="line"></span><br><span class="line"><span class="comment"># 部署ceph-mgr</span></span><br><span class="line">ceph orch apply mgr local-168-182-130,local-168-182-131,local-168-182-132</span><br><span class="line"></span><br><span class="line"><span class="comment"># ceph orch apply mgr local-168-182-130,local-168-182-131,local-168-182-132,local-168-182-133</span></span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301060832949.png" alt="图片"></p>
]]></content>
      <categories>
        <category>Ceph</category>
      </categories>
      <tags>
        <tag>Ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>CoreDNS 在 K8S 中的作用及监控</title>
    <url>/2023/02/07/CoreDNS%20%E5%9C%A8%20K8S%20%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8%E5%8F%8A%E7%9B%91%E6%8E%A7/</url>
    <content><![CDATA[<h2 id="CoreDNS-在-K8S-中的作用"><a href="#CoreDNS-在-K8S-中的作用" class="headerlink" title="CoreDNS 在 K8S 中的作用"></a>CoreDNS 在 K8S 中的作用</h2><p>CoreDNS 是 Kubernetes 环境的<strong>DNS add-on</strong>[1]组件。它是在控制平面节点中运行的组件之一，使其正常运行和响应是 Kubernetes 集群正常运行的关键。学习如何监控 CoreDNS，以及它最重要的指标是什么，对于运维团队来说是必须的。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302071505193.png" alt="图片">DNS 是每个体系结构中最敏感和最重要的服务之一。应用程序、微服务、服务、主机……如今，万物互联，并不一定意味着只用于内部服务。它也可以应用于外部服务。DNS 负责解析域名并关联内部或外部服务和 PodIP。维护 Pod 的 DNS 记录是一项关键任务，尤其是涉及到临时 Pod 时，IP 地址可以在没有警告的情况下随时更改。</p>
<p>如果您在 Kubernetes 中运行您的工作负载，并且您不知道如何监控 CoreDNS，请继续阅读本文：如何使用 Prometheus 来抓取 CoreDNS 指标，您应该检查哪些指标，以及它们的含义。</p>
<p>在本文中，我们将涵盖以下主题：</p>
<ul>
<li>什么是 Kubernetes CoreDNS？</li>
<li>如何在 Kubernetes 中监控 CoreDNS？</li>
<li>监控 Kubernetes CoreDNS：应该检查哪些指标？</li>
<li>结论</li>
</ul>
<h2 id="什么是-Kubernetes-CoreDNS？"><a href="#什么是-Kubernetes-CoreDNS？" class="headerlink" title="什么是 Kubernetes CoreDNS？"></a>什么是 Kubernetes CoreDNS？</h2><p>从 Kubernetes 1.11 开始，在基于 DNS 的服务发现达到一般可用性 (GA) 之后，引入了<strong>CoreDNS</strong>[2] 作为 kube-dns 的替代方案，CoreDNS 到目前为止一直是 Kubernetes 集群事实上的 DNS 引擎。顾名思义，CoreDNS 是一种用 Go 编写的 DNS 服务，因其灵活性而被广泛采用。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302071506456.png" alt="图片"></p>
<p>谈到 kube-DNS 附加组件，它是以单个 pod 中三个不同容器的形式提供整个 DNS 功能: kubedns、 dnsmasq 和 sidecar。我们来看看这三个容器:</p>
<ul>
<li><code>kubedns</code>：这是 Kubernetes 的 SkyDNS 实现。它负责 Kubernetes 集群内的 DNS 解析。它监视 Kubernetes API 并提供适当的 DNS 记录。</li>
<li><code>dnsmasq</code>: 为 SkyDNS 解析请求提供 DNS 缓存机制。</li>
<li><code>sidecar</code>：此容器导出指标并对 DNS 服务执行健康检查。</li>
</ul>
<p>现在让我们谈谈 CoreDNS！</p>
<p>CoreDNS 解决了 Kube-dns 当时带来的一些问题。Dnsmasq 引入了一些安全漏洞问题，导致在过去需要 Kubernetes 安全补丁。此外，CoreDNS 在一个容器中而不是 kube-dns 中需要的三个容器中提供所有功能，解决了 kube-dns 中外部服务的存根域的一些其他问题。</p>
<p>CoreDNS 在 9153 端口上公开其指标端点，并且可以从 SDN 网络中的 Pod 或主机节点网络访问它。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl get ep kube-dns -n kube-system -o json |jq -r &quot;.subsets&quot;</span></span><br><span class="line">[</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">&quot;addresses&quot;:</span> [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">&quot;ip&quot;:</span> <span class="string">&quot;192.169.107.100&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;nodeName&quot;:</span> <span class="string">&quot;k8s-control-2.lab.example.com&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;targetRef&quot;:</span> &#123;</span><br><span class="line">          <span class="attr">&quot;kind&quot;:</span> <span class="string">&quot;Pod&quot;</span>,</span><br><span class="line">          <span class="attr">&quot;name&quot;:</span> <span class="string">&quot;coredns-565d847f94-rz4b6&quot;</span>,</span><br><span class="line">          <span class="attr">&quot;namespace&quot;:</span> <span class="string">&quot;kube-system&quot;</span>,</span><br><span class="line">          <span class="attr">&quot;uid&quot;:</span> <span class="string">&quot;c1b62754-4740-49ca-b506-3f40fb681778&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">&quot;ip&quot;:</span> <span class="string">&quot;192.169.203.46&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;nodeName&quot;:</span> <span class="string">&quot;k8s-control-3.lab.example.com&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;targetRef&quot;:</span> &#123;</span><br><span class="line">          <span class="attr">&quot;kind&quot;:</span> <span class="string">&quot;Pod&quot;</span>,</span><br><span class="line">          <span class="attr">&quot;name&quot;:</span> <span class="string">&quot;coredns-565d847f94-8xqxg&quot;</span>,</span><br><span class="line">          <span class="attr">&quot;namespace&quot;:</span> <span class="string">&quot;kube-system&quot;</span>,</span><br><span class="line">          <span class="attr">&quot;uid&quot;:</span> <span class="string">&quot;bec3ca63-f09a-4007-82e9-0e147e8587de&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">&quot;ports&quot;:</span> [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">&quot;name&quot;:</span> <span class="string">&quot;dns-tcp&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;port&quot;:</span> <span class="number">53</span>,</span><br><span class="line">        <span class="attr">&quot;protocol&quot;:</span> <span class="string">&quot;TCP&quot;</span></span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">&quot;name&quot;:</span> <span class="string">&quot;dns&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;port&quot;:</span> <span class="number">53</span>,</span><br><span class="line">        <span class="attr">&quot;protocol&quot;:</span> <span class="string">&quot;UDP&quot;</span></span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">&quot;name&quot;:</span> <span class="string">&quot;metrics&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;port&quot;:</span> <span class="number">9153</span>,</span><br><span class="line">        <span class="attr">&quot;protocol&quot;:</span> <span class="string">&quot;TCP&quot;</span></span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>您已经知道 CoreDNS 是什么以及已经解决的问题。是时候深入了解如何获取 CoreDNS 指标，以及如何配置 Prometheus 实例以开始抓取其指标。让我们开始吧！</p>
<h2 id="如何在-Kubernetes-中监控-CoreDNS？"><a href="#如何在-Kubernetes-中监控-CoreDNS？" class="headerlink" title="如何在 Kubernetes 中监控 CoreDNS？"></a>如何在 Kubernetes 中监控 CoreDNS？</h2><p>正如您刚刚看到的那样，CoreDNS 已经被检测并在每个 CoreDNS Pod 的端口 9153 上公开了 <code>/metrics</code> 端点。访问这个 <code>/metrics</code> 端点很简单，只需运行 curl 并立即开始提取 CoreDNS 指标！</p>
<h3 id="手动访问端点"><a href="#手动访问端点" class="headerlink" title="手动访问端点"></a>手动访问端点</h3><p>知道运行 CoreDNS 的端点或 IP 后，请尝试访问 9153 端口。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># curl http://192.169.203.46:9153/metrics</span></span><br><span class="line"><span class="comment"># HELP coredns_build_info A metric with a constant &#x27;1&#x27; value labeled by version, revision, and goversion from which CoreDNS was built.</span></span><br><span class="line"><span class="comment"># TYPE coredns_build_info gauge</span></span><br><span class="line"><span class="string">coredns_build_info&#123;goversion=&quot;go1.18.2&quot;,revision=&quot;45b0a11&quot;,version=&quot;1.9.3&quot;&#125;</span> <span class="number">1</span></span><br><span class="line"><span class="comment"># HELP coredns_cache_entries The number of elements in the cache.</span></span><br><span class="line"><span class="comment"># TYPE coredns_cache_entries gauge</span></span><br><span class="line"><span class="string">coredns_cache_entries&#123;server=&quot;dns://:53&quot;,type=&quot;denial&quot;,zones=&quot;.&quot;&#125;</span> <span class="number">46</span></span><br><span class="line"><span class="string">coredns_cache_entries&#123;server=&quot;dns://:53&quot;,type=&quot;success&quot;,zones=&quot;.&quot;&#125;</span> <span class="number">9</span></span><br><span class="line"><span class="comment"># HELP coredns_cache_hits_total The count of cache hits.</span></span><br><span class="line"><span class="comment"># TYPE coredns_cache_hits_total counter</span></span><br><span class="line"><span class="string">coredns_cache_hits_total&#123;server=&quot;dns://:53&quot;,type=&quot;denial&quot;,zones=&quot;.&quot;&#125;</span> <span class="number">6471</span></span><br><span class="line"><span class="string">coredns_cache_hits_total&#123;server=&quot;dns://:53&quot;,type=&quot;success&quot;,zones=&quot;.&quot;&#125;</span> <span class="number">6596</span></span><br><span class="line"><span class="comment"># HELP coredns_cache_misses_total The count of cache misses. Deprecated, derive misses from cache hits/requests counters.</span></span><br><span class="line"><span class="comment"># TYPE coredns_cache_misses_total counter</span></span><br><span class="line"><span class="string">coredns_cache_misses_total&#123;server=&quot;dns://:53&quot;,zones=&quot;.&quot;&#125;</span> <span class="number">1951</span></span><br><span class="line"><span class="comment"># HELP coredns_cache_requests_total The count of cache requests.</span></span><br><span class="line"><span class="comment"># TYPE coredns_cache_requests_total counter</span></span><br><span class="line"><span class="string">coredns_cache_requests_total&#123;server=&quot;dns://:53&quot;,zones=&quot;.&quot;&#125;</span> <span class="number">15018</span></span><br><span class="line"><span class="comment"># HELP coredns_dns_request_duration_seconds Histogram of the time (in seconds) each request took per zone.</span></span><br><span class="line"><span class="comment"># TYPE coredns_dns_request_duration_seconds histogram</span></span><br><span class="line"><span class="string">coredns_dns_request_duration_seconds_bucket&#123;server=&quot;dns://:53&quot;,zone=&quot;.&quot;,le=&quot;0.00025&quot;&#125;</span> <span class="number">14098</span></span><br><span class="line"><span class="string">coredns_dns_request_duration_seconds_bucket&#123;server=&quot;dns://:53&quot;,zone=&quot;.&quot;,le=&quot;0.0005&quot;&#125;</span> <span class="number">14836</span></span><br><span class="line"><span class="string">coredns_dns_request_duration_seconds_bucket&#123;server=&quot;dns://:53&quot;,zone=&quot;.&quot;,le=&quot;0.001&quot;&#125;</span> <span class="number">14850</span></span><br><span class="line"><span class="string">coredns_dns_request_duration_seconds_bucket&#123;server=&quot;dns://:53&quot;,zone=&quot;.&quot;,le=&quot;0.002&quot;&#125;</span> <span class="number">14856</span></span><br><span class="line"><span class="string">coredns_dns_request_duration_seconds_bucket&#123;server=&quot;dns://:53&quot;,zone=&quot;.&quot;,le=&quot;0.004&quot;&#125;</span> <span class="number">14857</span></span><br><span class="line"><span class="string">coredns_dns_request_duration_seconds_bucket&#123;server=&quot;dns://:53&quot;,zone=&quot;.&quot;,le=&quot;0.008&quot;&#125;</span> <span class="number">14870</span></span><br><span class="line"><span class="string">coredns_dns_request_duration_seconds_bucket&#123;server=&quot;dns://:53&quot;,zone=&quot;.&quot;,le=&quot;0.016&quot;&#125;</span> <span class="number">14879</span></span><br><span class="line"><span class="string">coredns_dns_request_duration_seconds_bucket&#123;server=&quot;dns://:53&quot;,zone=&quot;.&quot;,le=&quot;0.032&quot;&#125;</span> <span class="number">14883</span></span><br><span class="line"><span class="string">coredns_dns_request_duration_seconds_bucket&#123;server=&quot;dns://:53&quot;,zone=&quot;.&quot;,le=&quot;0.064&quot;&#125;</span> <span class="number">14884</span></span><br><span class="line"><span class="string">coredns_dns_request_duration_seconds_bucket&#123;server=&quot;dns://:53&quot;,zone=&quot;.&quot;,le=&quot;0.128&quot;&#125;</span> <span class="number">14884</span></span><br><span class="line"><span class="string">coredns_dns_request_duration_seconds_bucket&#123;server=&quot;dns://:53&quot;,zone=&quot;.&quot;,le=&quot;0.256&quot;&#125;</span> <span class="number">14885</span></span><br><span class="line"><span class="string">coredns_dns_request_duration_seconds_bucket&#123;server=&quot;dns://:53&quot;,zone=&quot;.&quot;,le=&quot;0.512&quot;&#125;</span> <span class="number">14886</span></span><br><span class="line"><span class="string">coredns_dns_request_duration_seconds_bucket&#123;server=&quot;dns://:53&quot;,zone=&quot;.&quot;,le=&quot;1.024&quot;&#125;</span> <span class="number">14887</span></span><br><span class="line"><span class="string">coredns_dns_request_duration_seconds_bucket&#123;server=&quot;dns://:53&quot;,zone=&quot;.&quot;,le=&quot;2.048&quot;&#125;</span> <span class="number">14903</span></span><br><span class="line"><span class="string">coredns_dns_request_duration_seconds_bucket&#123;server=&quot;dns://:53&quot;,zone=&quot;.&quot;,le=&quot;4.096&quot;&#125;</span> <span class="number">14911</span></span><br><span class="line"><span class="string">coredns_dns_request_duration_seconds_bucket&#123;server=&quot;dns://:53&quot;,zone=&quot;.&quot;,le=&quot;8.192&quot;&#125;</span> <span class="number">15018</span></span><br><span class="line"><span class="string">coredns_dns_request_duration_seconds_bucket&#123;server=&quot;dns://:53&quot;,zone=&quot;.&quot;,le=&quot;+Inf&quot;&#125;</span> <span class="number">15018</span></span><br><span class="line"><span class="string">coredns_dns_request_duration_seconds_sum&#123;server=&quot;dns://:53&quot;,zone=&quot;.&quot;&#125;</span> <span class="number">698.531992215999</span></span><br><span class="line"><span class="string">coredns_dns_request_duration_seconds_count&#123;server=&quot;dns://:53&quot;,zone=&quot;.&quot;&#125;</span> <span class="number">15018</span></span><br><span class="line"><span class="string">…</span></span><br><span class="line"><span class="string">(output</span> <span class="string">truncated)</span></span><br></pre></td></tr></table></figure>

<p>您还可以<code>/metrics</code>通过 Kubernetes 集群中默认公开的 CoreDNS Kubernetes 服务访问端点。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl get svc -n kube-system</span></span><br><span class="line">NAME       TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE</span><br><span class="line">kube-dns   ClusterIP   10.96.0.10   &lt;none&gt;        53/UDP,53/TCP,9153/TCP   129d</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl exec -it my-pod -n default -- /bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># curl http://kube-dns.kube-system.svc:9153/metrics</span></span><br></pre></td></tr></table></figure>

<h3 id="如何配置-Prometheus-以抓取-CoreDNS-指标"><a href="#如何配置-Prometheus-以抓取-CoreDNS-指标" class="headerlink" title="如何配置 Prometheus 以抓取 CoreDNS 指标"></a>如何配置 Prometheus 以抓取 CoreDNS 指标</h3><p>Prometheus 提供了一组角色来开始发现目标并从多个来源(如 Pods、 Kubernetes 节点和 Kubernetes 服务等)获取指标。当需要从嵌入在 Kubernetes 集群中的 CoreDNS 服务中获取指标时，您只需要使用适当的配置来配置 prometheus.yml 文件。这一次，您应该使用 <strong>endpoints role</strong>[3] 来发现这个目标。</p>
<p>编辑包含<code>prometheus.yml</code>配置文件的<code>ConfigMap</code>。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl edit cm prometheus-server -n monitoring -o yaml</span></span><br></pre></td></tr></table></figure>

<p>然后，在<code>scrape_configs</code>部分下添加下面的配置片段。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">honor_labels:</span> <span class="literal">true</span></span><br><span class="line">     <span class="attr">job_name:</span> <span class="string">kubernetes-service-endpoints</span></span><br><span class="line">     <span class="attr">kubernetes_sd_configs:</span></span><br><span class="line">     <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">endpoints</span></span><br><span class="line">     <span class="attr">relabel_configs:</span></span><br><span class="line">     <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">keep</span></span><br><span class="line">       <span class="attr">regex:</span> <span class="literal">true</span></span><br><span class="line">       <span class="attr">source_labels:</span></span><br><span class="line">       <span class="bullet">-</span> <span class="string">__meta_kubernetes_service_annotation_prometheus_io_scrape</span></span><br><span class="line">     <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">drop</span></span><br><span class="line">       <span class="attr">regex:</span> <span class="literal">true</span></span><br><span class="line">       <span class="attr">source_labels:</span></span><br><span class="line">       <span class="bullet">-</span> <span class="string">__meta_kubernetes_service_annotation_prometheus_io_scrape_slow</span></span><br><span class="line">     <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">replace</span></span><br><span class="line">       <span class="attr">regex:</span> <span class="string">(https?)</span></span><br><span class="line">       <span class="attr">source_labels:</span></span><br><span class="line">       <span class="bullet">-</span> <span class="string">__meta_kubernetes_service_annotation_prometheus_io_scheme</span></span><br><span class="line">       <span class="attr">target_label:</span> <span class="string">__scheme__</span></span><br><span class="line">     <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">replace</span></span><br><span class="line">       <span class="attr">regex:</span> <span class="string">(.+)</span></span><br><span class="line">       <span class="attr">source_labels:</span></span><br><span class="line">       <span class="bullet">-</span> <span class="string">__meta_kubernetes_service_annotation_prometheus_io_path</span></span><br><span class="line">       <span class="attr">target_label:</span> <span class="string">__metrics_path__</span></span><br><span class="line">     <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">replace</span></span><br><span class="line">       <span class="attr">regex:</span> <span class="string">(.+?)(?::\d+)?;(\d+)</span></span><br><span class="line">       <span class="attr">replacement:</span> <span class="string">$1:$2</span></span><br><span class="line">       <span class="attr">source_labels:</span></span><br><span class="line">       <span class="bullet">-</span> <span class="string">__address__</span></span><br><span class="line">       <span class="bullet">-</span> <span class="string">__meta_kubernetes_service_annotation_prometheus_io_port</span></span><br><span class="line">       <span class="attr">target_label:</span> <span class="string">__address__</span></span><br><span class="line">     <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span></span><br><span class="line">       <span class="attr">regex:</span> <span class="string">__meta_kubernetes_service_annotation_prometheus_io_param_(.+)</span></span><br><span class="line">       <span class="attr">replacement:</span> <span class="string">__param_$1</span></span><br><span class="line">     <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span></span><br><span class="line">       <span class="attr">regex:</span> <span class="string">__meta_kubernetes_service_label_(.+)</span></span><br><span class="line">     <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">replace</span></span><br><span class="line">       <span class="attr">source_labels:</span></span><br><span class="line">       <span class="bullet">-</span> <span class="string">__meta_kubernetes_namespace</span></span><br><span class="line">       <span class="attr">target_label:</span> <span class="string">namespace</span></span><br><span class="line">     <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">replace</span></span><br><span class="line">       <span class="attr">source_labels:</span></span><br><span class="line">       <span class="bullet">-</span> <span class="string">__meta_kubernetes_service_name</span></span><br><span class="line">       <span class="attr">target_label:</span> <span class="string">service</span></span><br><span class="line">     <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">replace</span></span><br><span class="line">       <span class="attr">source_labels:</span></span><br><span class="line">       <span class="bullet">-</span> <span class="string">__meta_kubernetes_pod_node_name</span></span><br><span class="line">       <span class="attr">target_label:</span> <span class="string">node</span></span><br></pre></td></tr></table></figure>

<p>此时，在重新部署 Prometheus Pod 后，您应该能够在 Prometheus 控制台中看到可用的 CoreDNS 指标端点（转到 Status -&gt; Targets）。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302071511104.png" alt="图片"></p>
<p>CoreDNS 指标从现在开始可用，并可从 Prometheus 控制台访问。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302071511078.png" alt="图片"></p>
<h2 id="应该检查哪些指标？"><a href="#应该检查哪些指标？" class="headerlink" title="应该检查哪些指标？"></a>应该检查哪些指标？</h2><p><em><strong>注意</strong>：CoreDNS 指标可能因 Kubernetes 版本和平台而异。在这里，我们使用了 Kubernetes 1.25 和 CoreDNS 1.9.3。您可以在 <strong>CoreDNS 存储库</strong>[4] 中检查适用于您的版本的指标。</em></p>
<p>首先，让我们谈谈可用性。集群中运行的 CoreDNS 副本数量可能会有所不同，因此最好进行监控，以防出现任何可能影响可用性和性能的变化。</p>
<ul>
<li>CoreDNS 副本数：如果您想监控在 Kubernetes 环境中运行的 CoreDNS 副本数，您可以通过计算<code>coredns_build_info metric</code>. 此指标提供有关在此类 Pod 上运行的 CoreDNS 构建的信息。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="built_in">count</span>(coredns_build_info)</span><br></pre></td></tr></table></figure>

<p>从现在开始，让我们遵循四个黄金信号方法。在本节中，您将学习如何从该角度监控 CoreDNS，测量错误、延迟、流量和饱和度。</p>
<h3 id="错误-Errors"><a href="#错误-Errors" class="headerlink" title="错误 Errors"></a>错误 Errors</h3><p>能够测量 CoreDNS 服务中的错误数量是更好地了解 Kubernetes 集群、应用程序和服务健康状况的关键。如果任何应用程序或内部 Kubernetes 组件从 DNS 服务收到意外错误响应，您可能会遇到严重的麻烦。当心 <strong><code>SERVFAIL</code></strong> 和 <strong><code>REFUSED</code></strong> 错误。在解析 Kubernetes 内部组件和应用程序的名称时，这些可能意味着问题。</p>
<ul>
<li><code>coredns_dns_responses_total</code>：此计数器提供有关 CoreDNS 响应代码、命名空间和 CoreDNS 实例的数量的信息。您可能希望获取每个响应代码的速率。它始终是测量 CoreDNS 实例中的错误率的有用方法。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sum</span>(rate(coredns_dns_responses_total&#123;instance<span class="operator">=</span><span class="operator">~</span>&quot;.*&quot;&#125;[<span class="number">2</span>m])) <span class="keyword">by</span> (rcode, instance)</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302071507622.png" alt="图片"></p>
<h3 id="延迟-Latency"><a href="#延迟-Latency" class="headerlink" title="延迟 Latency"></a>延迟 Latency</h3><p>测量延迟是确保 DNS 服务性能最佳以在 Kubernetes 中正常运行的关键。如果延迟很高或随着时间的推移而增加，则可能表示存在负载问题。如果 CoreDNS 实例过载，您可能会遇到 DNS 名称解析问题，并预计您的应用程序和 Kubernetes 内部服务会出现延迟甚至中断。</p>
<ul>
<li><code>coredns_dns_request_duration_seconds_bucket</code>：CoreDNS 请求持续时间（以秒为单位）。您可能想要计算第 99 个百分位数，以查看延迟在 CoreDNS 实例之间的分布情况。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">histogram_quantile(<span class="number">0.99</span>, <span class="built_in">sum</span>(rate(coredns_dns_request_duration_seconds_bucket&#123;instance<span class="operator">=</span><span class="operator">~</span>&quot;.*&quot;&#125;[<span class="number">2</span>m])) <span class="keyword">by</span> (server,zone,le,instance))</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302071507299.png" alt="图片"></p>
<h3 id="流量-Traffic"><a href="#流量-Traffic" class="headerlink" title="流量 Traffic"></a>流量 Traffic</h3><p>CoreDNS 服务正在处理的流量或请求量。监控 CoreDNS 中的流量非常重要，值得定期检查。观察流量是否有峰值或任何趋势变化是保证良好性能和避免问题的关键。</p>
<ul>
<li><code>coredns_dns_requests_total</code>：每个区域、协议和系列的 DNS 请求计数器。您可能希望按类型（A、AAAA）测量和监控 CoreDNS 请求的速率。<code>A</code> 代表 ipv4 查询，而 <code>AAAA</code> 是 ipv6 查询。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">(<span class="built_in">sum</span>(rate(coredns_dns_requests_total&#123;instance<span class="operator">=</span><span class="operator">~</span>&quot;.*&quot;&#125;[<span class="number">2</span>m])) <span class="keyword">by</span> (type,instance))</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302071508244.png" alt="图片"></p>
<h3 id="饱和度-Saturation"><a href="#饱和度-Saturation" class="headerlink" title="饱和度 Saturation"></a>饱和度 Saturation</h3><p>您可以使用系统资源消耗指标（例如 CoreDNS Pod 的 CPU、内存和网络使用情况）轻松监控 CoreDNS 饱和度。</p>
<h3 id="其他的"><a href="#其他的" class="headerlink" title="其他的"></a>其他的</h3><p>CoreDNS 实现了一种<strong>缓存机制</strong>[5]，允许 DNS 服务缓存记录长达 3600 秒。此缓存可以显着降低 CoreDNS 负载并提高性能。</p>
<ul>
<li><code>coredns_cache_hits_total</code>：缓存命中计数器。您可能希望通过运行以下查询来监视缓存命中率。多亏了这个 PromQL 查询，您可以轻松监控 CoreDNS 缓存命中的拒绝率和成功率。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sum</span>(rate(coredns_cache_hits_total&#123;instance<span class="operator">=</span><span class="operator">~</span>&quot;.*&quot;&#125;[<span class="number">2</span>m])) <span class="keyword">by</span> (type,instance)</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302071508936.png" alt="图片"></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>与 kube-dns 一起，CoreDNS 是可用于在 Kubernetes 环境中实施 DNS 服务的选择之一。DNS 是 Kubernetes 集群正常运行所必需的，而 CoreDNS 一直是大多数人的首选，因为它的灵活性以及与 kube-dns 相比它解决的问题数量。</p>
<p>如果您想确保您的 Kubernetes 基础设施健康且正常工作，您必须持续检查您的 DNS 服务。确保在每个应用程序、操作系统、IT 架构或云环境中正常运行是关键。</p>
<p>在本文中，您了解了如何提取 CoreDNS 指标以及如何配置您自己的 Prometheus 实例以从 CoreDNS 端点抓取指标。得益于 CoreDNS 的关键指标，您可以轻松地在任何 Kubernetes 环境中开始监控您自己的 CoreDNS。</p>
]]></content>
      <categories>
        <category>kubernetes</category>
        <category>CoreDns</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>CoreDns</tag>
      </tags>
  </entry>
  <entry>
    <title>Jenkins 自动化部署实例</title>
    <url>/2023/03/03/Jenkins%20%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2%E5%AE%9E%E4%BE%8B/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>你平常在做自己的项目时，是否有过部署项目太麻烦的想法？如果你是单体项目，可能没什么感触，但如果你是微服务项目，相信你应该是有过这种感触的。</p>
<p>这种情况下，我一般会劝你了解一下 Jenkins 这个玩意。</p>
<p>本文分为两部分：</p>
<ul>
<li>第一部分为 Jenkins 安装教程，会教你如何在 Linux 上安装 Jenkins。</li>
<li>第二部分为一个简单的 Jenkins 自动化构建部署实例讲解。</li>
</ul>
<p>你可以根据自己的意愿，选择性的跳过第一部分，因为第二部分才是重点。（通过目录可以快速翻到第二部分）</p>
<hr>
<h2 id="Jenkins-安装"><a href="#Jenkins-安装" class="headerlink" title="Jenkins 安装"></a>Jenkins 安装</h2><h3 id="当前环境"><a href="#当前环境" class="headerlink" title="当前环境"></a>当前环境</h3><ul>
<li>CentOS 7.8</li>
<li>Java 11（注意当前 jenkins 支持的 Java 版本最低为 Java11）</li>
<li>FinalShell 3.9（操作环境）</li>
</ul>
<h3 id="安装-Jenkins"><a href="#安装-Jenkins" class="headerlink" title="安装 Jenkins"></a>安装 Jenkins</h3><blockquote>
<p>PS：不建议使用 Docker 安装 Jenkins，因为使用 Jenkins 的时候一般会调用外部程序，比如 Maven、Docker、JDK、Nodejs 等，所以我们最好直接安装在本机上，以避免不必要的麻烦。</p>
</blockquote>
<h4 id="1-添加-Jenkins-源"><a href="#1-添加-Jenkins-源" class="headerlink" title="1. 添加 Jenkins 源"></a>1. 添加 Jenkins 源</h4><p>执行下面两条命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo --no-check-certificate</span><br><span class="line">sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031028625.jpeg" alt="图片"></p>
<h4 id="2-通过-yum-安装-Jenkins"><a href="#2-通过-yum-安装-Jenkins" class="headerlink" title="2. 通过 yum 安装 Jenkins"></a>2. 通过 yum 安装 Jenkins</h4><ul>
<li>yum -y install jenkins</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031028693.jpeg" alt="图片"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031028674.jpeg" alt="图片"></p>
<h4 id="3-修改-Jenkins-端口号"><a href="#3-修改-Jenkins-端口号" class="headerlink" title="3. 修改 Jenkins 端口号"></a>3. 修改 Jenkins 端口号</h4><ol>
<li>Jenkins 默认端口号为 8080，输入<code>vim /etc/sysconfig/jenkins</code>进行编辑，将 JENKINS_PORT 修改为自己想要的端口号，前提得保证修改后的这个端口没有被其他的进程占用。</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031028499.jpeg" alt="图片"></p>
<ol>
<li>这里修改了可能还不能生效，还需要修改另一个地方，输入以下指令进行编辑</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /usr/lib/systemd/system/jenkins.service</span><br><span class="line"><span class="comment"># 找到下面的文字</span></span><br><span class="line">Environment=<span class="string">&quot;JENKINS_PORT=8080&quot;</span> <span class="comment"># 修改为自己想要的端口号</span></span><br><span class="line"><span class="comment"># :wq退出</span></span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031028761.jpeg" alt="图片"></p>
<ol>
<li>修改完成后，重新加载配置文件，随后再重启 Jenkins，此时的启动端口应该已经变成你修改的端口号了。</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 重新加载配置文件</span></span><br><span class="line">systemctl daemon-reload</span><br><span class="line"><span class="comment"># 重启jenkins</span></span><br><span class="line">systemctl restart jenkins</span><br></pre></td></tr></table></figure>

<h3 id="启动-Jenkins"><a href="#启动-Jenkins" class="headerlink" title="启动 Jenkins"></a>启动 Jenkins</h3><blockquote>
<p>Jenkins 可以单独指定 Java 路径，在<code>/etc/init.d/jenkins</code>文件内大概一百行左右的位置，在最上面加上你的 java 路径即可：</p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031028223.jpeg" alt="图片"></p>
<blockquote>
<p>PS：当前 Jenkins 支持的最低 Java 版本为 11，如果机器上只有 Java8 的朋友需要先安装 Java11 或以上版本。Linux 下多版本 Java 建议通过系统自带的 <em>alternatives</em> 来管理，参考这篇文章外加自己琢磨搞定：<br>linux alternatives 命令详解：<br><a href="https://www.cnblogs.com/lpfuture/p/4638425.html">https://www.cnblogs.com/lpfuture/p/4638425.html</a></p>
</blockquote>
<ol>
<li><p>输入<code>service jenkins start</code>，会弹出提示：Starting jenkins (via systemctl):，意思是正在启动，第一次启动比较耗时，此时耐心等待。如果提示超时失败，没关系，jenkins 仍然在启动，只是第一次启动比较耗时。</p>
<p>如果提示内容不是超时失败，那大概率是你的 Java 没安装好或者版本不对。</p>
</li>
<li><p>放行刚刚配置的端口</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 放行15369端口</span></span><br><span class="line">firewall-cmd --zone=public --add-port=15369/tcp --permanent</span><br><span class="line"><span class="comment"># 重新加载防火墙</span></span><br><span class="line">firewall-cmd --reload</span><br><span class="line"><span class="comment"># 查看是否已经开启</span></span><br><span class="line">firewall-cmd --list-ports</span><br></pre></td></tr></table></figure>

<p>如果你是在阿里云腾讯云等类似服务器上的话，那你还需要去控制台防火墙或者安全组开放这个端口，像这样：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031029726.jpeg" alt="图片"></p>
<p>开放端口时记得设置授权 ip，建议你直接给自家 ip 地址授权全部端口号。</p>
<ol>
<li>在浏览器输入 ip+port，可以进入到 Jenkins 的初始化界面，第一次启动要等的比较久：</li>
</ol>
<blockquote>
<p>进入这个界面，说明你的 Jenkins 已经在启动中了。</p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031029332.jpeg" alt="图片"></p>
<h3 id="初始化配置-Jenkins"><a href="#初始化配置-Jenkins" class="headerlink" title="初始化配置 Jenkins"></a>初始化配置 Jenkins</h3><ol>
<li>系统启动完毕后，系统会提示你查看并输入管理员密码，根据中显示的密码位置，打开该文件并将密码复制粘贴即可：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在服务器查看密码文件</span></span><br><span class="line"><span class="built_in">cat</span> /var/lib/jenkins/secrets/initialAdminPassword</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031029360.jpeg" alt="图片"></p>
<ol>
<li>密码输入成功后，进入插件安装界面，如果你是新手，直接使用推荐安装的插件即可：</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031029450.jpeg" alt="图片"></p>
<ol>
<li>系统开始安装插件，需要等待系统安装完毕，这一步可能要比较久，耐心等待：</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031029651.jpeg" alt="图片"></p>
<p>安装过程中可能会出现部分插件安装失败的情况，没关系，全部处理完毕后可以选择重试。</p>
<ol>
<li>安装完毕后，系统会提示你创建第一个管理员账户：</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031029232.jpeg" alt="图片"></p>
<ol>
<li>配置 Jenkins 访问地址，便于一些插件使用，一般会有默认值：</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031029681.jpeg" alt="图片"></p>
<ol>
<li>配置完成，点击开始使用 Jenkins：</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031031641.jpeg" alt="图片"></p>
<p>随后就进入到 Jenkins 的管理界面了，不同版本的 Jenkins 界面可能会不一样：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031031749.jpeg" alt="图片"></p>
<p><strong>至此，Jenkins 安装完毕。</strong></p>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><p>如果你是使用 Jenkins 来对 Java 服务做持续集成的话，那么你还需要安装下面的插件：</p>
<ul>
<li>Maven Integration：Maven 集成管理插件。</li>
<li>Docker plugin：Docker 集成插件。</li>
<li>Publish Over SSH：远程文件发布插件。</li>
<li>SSH: 远程脚本执行插件。</li>
<li>GitLab：拉取远程仓库代码插件。</li>
</ul>
<p>安装插件在<code>系统管理 -&gt; 插件管理</code>里面</p>
<hr>
<h2 id="实例讲解"><a href="#实例讲解" class="headerlink" title="实例讲解"></a>实例讲解</h2><p>接下来，我会拿出我的用户微服务构建任务的实际配置来向你进行解读，当你了解了 Jenkins 自动化构建部署的工作原理后，你便可以很快的上手这个玩意，因为你会发现它是如此的简单。</p>
<blockquote>
<p>此实例是基于我的开源项目校园博客的 Jenkins 部分进行讲解的，如果你对我的项目感兴趣，欢迎访问项目的 GitHub 地址：stick-i&#x2F;scblogs: 🎉 校园博客，基于微服务架构且前后端分离的博客社区系统。项目后端技术栈：SpringBoot + SpringCloud + Mybatis-Plus + Nacos + MySQL + Redis + MQ + ElasticSearch + Docker。前端主要是基于 Vue2 和 ElementUI 进行开发的</p>
<p><a href="https://github.com/stick-i/scblogs">https://github.com/stick-i/scblogs</a></p>
</blockquote>
<h3 id="基本环境"><a href="#基本环境" class="headerlink" title="基本环境"></a>基本环境</h3><p>在此之前，我需要介绍一下我的基本环境：</p>
<ul>
<li>我的操作环境为 Windows，但是我要把微服务部署到一台 Linux 服务器上去，包括 Jenkins 也是安装在这个上面的。</li>
<li>服务器上安装了 Jenkins、Git、Docker、JDK、Maven、NodeJs，都是些拿来构建的东西，都是单独安装的，而不是跑在 Docker 上。</li>
<li>而项目服务都是跑在 Docker 上的，还有 Redis 这种轻量的中间件也跑在 Docker 上。</li>
<li>我的项目已经在 Git 仓库里放好了，放 github 或者 gitee 或者 gitlab 都行。</li>
</ul>
<h3 id="全局工具配置"><a href="#全局工具配置" class="headerlink" title="全局工具配置"></a>全局工具配置</h3><p>在 Jenkins 上，我已经配置好了这些构建工具的路径，以便于 Jenkins 可以直接调用到他们，在<code>系统管理 -&gt; 全局工具配置</code> 这个页面下，这张图有点长：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031031757.jpeg" alt="图片"></p>
<p>在这张图上，你可以看到其中有一部分的配置是有路径的，还有一部分配置是没有路径的，这是因为我把他们的命令路径加到了系统路径上，即使不添加完整路径，Jenkins 也可以调用到它们。</p>
<h3 id="创建任务"><a href="#创建任务" class="headerlink" title="创建任务"></a>创建任务</h3><p>好，现在我们已经准备好环境了，可以创建一个任务来试试水了，输入任务名称，然后选择<code>构建一个自由风格的软件项目</code>：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031031532.jpeg" alt="图片"></p>
<p>别问我在哪新建任务，请你返回首页好好看看：</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz/gIkzzLe4eUWiaLHC4ol02yOIIwfedd2qDHDxZWqkQ4UMaZZibkZmT7o2CeGEHvtLaNcVQKEjMW7AKibZgJibI5d3cg/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p>
<h3 id="任务配置"><a href="#任务配置" class="headerlink" title="任务配置"></a>任务配置</h3><h4 id="源码管理"><a href="#源码管理" class="headerlink" title="源码管理"></a>源码管理</h4><p>现在我们已经进入到任务配置界面了，往下划到源码管理的地方，选择 Git，然后填写仓库地址等信息：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031031960.jpeg" alt="图片"></p>
<p>添加 Credentials 的时候，如果你会使用 SSH 密钥的话，建议还是用这个，但你得在机器上进行格外的配置，这里我就不多说了，不会的话直接用账号密码也是可以的：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031031743.jpeg" alt="图片"></p>
<h4 id="构建步骤（Build-Steps）"><a href="#构建步骤（Build-Steps）" class="headerlink" title="构建步骤（Build Steps）"></a>构建步骤（Build Steps）</h4><h5 id="第一步：调用-Maven"><a href="#第一步：调用-Maven" class="headerlink" title="第一步：调用 Maven"></a>第一步：调用 Maven</h5><p>点击增加构建步骤，由于我们是 Maven 管理的项目，需要先使用 Maven 构建，所以第一步就用<code>调用顶层Maven目标</code>：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031031887.jpeg" alt="图片"></p>
<p>选择 maven 版本，然后 target 根据项目的实际情况编写，我的命令是这样的：</p>
<ol>
<li>先构建 jar 包，执行 install 的过程中会先执行 package 的，所以我直接 install。我的项目中单元测试是没怎么梳理的，所以我使用参数<code>-Dmaven.test.skip=true</code>跳过单元测试。</li>
<li>然后我得打包成 docker 镜像，我使用的是<code>dockerfile-maven-plugin</code>这个 Maven 插件，所以打包 docker 镜像的步骤就也放在 maven 里面了，构建 docker 镜像的信息都在项目的 pom 文件里面。</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">install -Dmaven.test.skip=<span class="literal">true</span></span><br><span class="line">dockerfile:build -f user-service/user-server/pom.xml</span><br></pre></td></tr></table></figure>

<p>构建完镜像了，接下来我们直接使用这个镜像创建容器然后运行就完事了。</p>
<h5 id="第二步：执行-shell-启动容器"><a href="#第二步：执行-shell-启动容器" class="headerlink" title="第二步：执行 shell 启动容器"></a>第二步：执行 shell 启动容器</h5><p>再添加一个构建步骤，正常情况下我们调用 docker 通过命令行调用就可以了，所以我们现在也添加一个<code>执行shell</code>的步骤即可。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031032697.jpeg" alt="图片"></p>
<p>具体的命令也很简单，就这么几步：</p>
<ol>
<li>清理之前的旧镜像。由于我们刚刚构建了一个新的镜像，新镜像和旧镜像的名称和版本我们是没有改的，所以旧的镜像就会自动变成<code>&lt;none&gt;</code>，使用命令<code>docker image prune -f</code> 就可以清理掉这部分镜像。</li>
<li>停止旧容器运行并删除旧容器。当然我们得先判断一下是否存在旧容器，使用容器名称来进行判断，这部分指令涉及到<code>shell</code>和<code>docker</code>的命令知识，看不懂没关系，可以直接 cv，注意修改容器名称就好。</li>
<li>调用 docker 启动容器，根据项目实际情况来设定不同的参数，我这里设置了网络模式为 host，并且映射了一个容器卷，用于读取 nacos 的地址，再指定容器名称为<code>user-service</code>，最后指定使用的镜像名称。</li>
</ol>
<p>大功告成！具体命令如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"> <span class="comment"># 清理镜像</span></span><br><span class="line">docker image prune -f</span><br><span class="line"></span><br><span class="line"><span class="comment"># 清理容器</span></span><br><span class="line"><span class="keyword">if</span> [ -n  <span class="string">&quot;<span class="subst">$(docker ps -a -f  name=user-service  --format &#x27;&#123;&#123;.ID&#125;&#125;&#x27; )</span>&quot;</span> ] <span class="keyword">then</span></span><br><span class="line"> <span class="comment">#停止容器运行</span></span><br><span class="line"> docker stop $(docker ps -a -f  name=user-service  --format <span class="string">&#x27;&#123;&#123;.ID&#125;&#125;&#x27;</span> )</span><br><span class="line"> <span class="comment">#删除之前的容器</span></span><br><span class="line"> docker <span class="built_in">rm</span> $(docker ps -a -f  name=user-service  --format <span class="string">&#x27;&#123;&#123;.ID&#125;&#125;&#x27;</span> )</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动容器</span></span><br><span class="line">docker run -d  --net=host  -v scblogs-config:/config -e PARAMS=<span class="string">&quot;<span class="variable">$params</span>&quot;</span>  --name  user-service  scblogs/user-server</span><br></pre></td></tr></table></figure>

<p>最后别忘了点击保存！</p>
<hr>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>经过上面这些步骤，我不仅安装好了 Jenkins，还完成了一个基本的自动化构建脚本，这个脚本会调用 maven 把我的项目打包，然后构建成一个 docker 镜像，再通过一段 shell 命令去启动这个程序。</p>
<p>如果你想尝试启动这个构建任务的话，你可以回到主页点击右边的绿色符号。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031032116.jpeg" alt="图片"></p>
<p>当然，你大概率是会构建失败的 😯。因为我的这份实例讲解并没有完全的讲清楚，甚至里面有很多步骤你都看不懂，是不是？</p>
<p>其实我并没有想写一份手把手的 Jenkins 使用教程，因为这要写的内容实在是太多了，我甚至可以因此写一本小册了！</p>
<p>还记得我在实例讲解的最开始写的吗？写这个构建案例的目的是让你了解 Jenkins 自动化构建的原理，如果你看到这里已经发现了，<strong>这自动化构建，其实就跟我们手动构建部署差不多！只不过是把手动操作的东西设定成了脚本</strong>，那你就已经有能力去自己摸索它了。</p>
<p>用用插件、写写脚本，就可以搞定自己项目的自动化部署啦。</p>
<p>实际情况是，我有一台服务器专门用于 Jenkins 自动化部署，还有一台服务器专门用于生产环境，这两台服务器都可以连接到外网，也可以互相访问到彼此。这是由于 Jenkins 构建时是会比较吃 CPU 的，为了不影响生产环境，所以我把它们分开了。当然，这种情况下，脚本也会稍微复杂一点，具体流程大概是下面这样的：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303031032080.jpeg" alt="图片"></p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>ETCD使用中需要注意的问题</title>
    <url>/2022/12/29/ETCD%E4%BD%BF%E7%94%A8%E4%B8%AD%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E9%97%AE%E9%A2%98--%E8%87%AA%E5%8A%A8%E5%8E%8B%E7%BC%A9--%E6%9C%80%E5%A4%A7%E5%AD%97%E8%8A%82%E6%95%B0--%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E5%A4%A7%E5%B0%8F/</url>
    <content><![CDATA[<h2 id="ETCD使用中需要注意的问题"><a href="#ETCD使用中需要注意的问题" class="headerlink" title="ETCD使用中需要注意的问题"></a>ETCD使用中需要注意的问题</h2><p>我们在实际生产中使用ETCD存储元数据，　起初集群规模不大的时候元数据信息不多没有发现什么问题。　随着集群规模越来越大问题逐渐暴露了</p>
<p>有些实际的配置还是需要在初始化的时候就研究确定</p>
<h3 id="1-自动压缩"><a href="#1-自动压缩" class="headerlink" title="1. 自动压缩"></a>1. 自动压缩</h3><p><code>--auto-compaction-retention</code></p>
<p>由于ETCD数据存储多版本数据，随着写入的主键增加历史版本需要定时清理，　默认的历史数据是不会清理的，数据达到2G就不能写入，必须要清理压缩历史数据才能继续写入；</p>
<p>所以根据业务需求，在上生产环境之前就提前确定，历史数据多长时间压缩一次；　我们的生产环境现在升级后是默认一小时压缩一次数据。这样可以极大的保证集群稳定，减少内存和磁盘占用</p>
<h3 id="2-最大字节数"><a href="#2-最大字节数" class="headerlink" title="2. 最大字节数"></a>2. 最大字节数</h3><p><code>--max-request-bytes</code><br>etcd Raft消息最大字节数，ETCD默认该值为1.5M; 但是很多业务场景发现同步数据的时候1.5M完全没法满足要求，所以提前确定初始值很重要；　由于1.5M导致我们线上的业务无法写入元数据的问题，</p>
<p>我们紧急升级之后把该值修改为默认32M,但是官方推荐的是10M(10485760byts)，大家可以根据业务情况自己调整</p>
<blockquote>
<p>最好按照官方的默认限制来储存，单个value不要超过10M，只要不超过10M生产环境就会很稳定，一旦超过10M集群就会变的不稳定；</p>
</blockquote>
<h3 id="3-存储数据大小"><a href="#3-存储数据大小" class="headerlink" title="3. 存储数据大小"></a>3. 存储数据大小</h3><p><code>--quota-backend-bytes</code></p>
<p>ETCDdb数据大小，默认是２G,当数据达到２G的时候就不允许写入，必须对历史数据进行压缩才能继续写入；　参加1里面说的，我们启动的时候就应该提前确定大小，官方推荐是8G,这里我们也使用8G的配置</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">＃ 启动命令</span><br><span class="line">/usr/bin/etcd --auto-compaction-retention <span class="string">&#x27;1&#x27;</span> --max-request-bytes <span class="string">&#x27;33554432&#x27;</span> --quota-backend-bytes <span class="string">&#x27;8589934592&#x27;</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kubernetes</category>
        <category>etcd</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>etcd</tag>
      </tags>
  </entry>
  <entry>
    <title>K8S OOM 和 CPU 节流</title>
    <url>/2023/02/07/K8S%20OOM%20%E5%92%8C%20CPU%20%E8%8A%82%E6%B5%81/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>使用 Kubernetes 时，内存不足 (OOM) 错误和 CPU 节流是云应用程序中资源处理的主要难题。</p>
<p>这是为什么？</p>
<p>云应用程序中的 CPU 和内存要求变得越来越重要，因为它们与您的云成本直接相关。</p>
<p>通过 limits 和 requests ，您可以配置 pod 应如何分配内存和 CPU 资源，以防止资源匮乏并调整云成本。</p>
<p>如果节点没有足够的资源， Pod 可能会通过抢占或节点压力被驱逐。</p>
<p>当一个进程运行内存不足 (OOM) 时，它会被终止，因为它没有所需的资源。</p>
<p>如果 CPU 消耗高于实际限制，进程将开始节流。</p>
<p>但是，如何主动监控 Kubernetes Pod 到达 OOM 和 CPU 节流的距离有多近？</p>
<h2 id="Kubernetes-OOM"><a href="#Kubernetes-OOM" class="headerlink" title="Kubernetes OOM"></a>Kubernetes OOM</h2><p>Pod 中的每个容器都需要内存才能运行。</p>
<p>Kubernetes limits 是在 Pod 定义或 Deployment 定义中为每个容器设置的。</p>
<p>所有现代 Unix 系统都有一种方法来终止进程，以防它们需要回收内存。这将被标记为错误 137 或<code>OOMKilled.</code></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">State:</span>          <span class="string">Running</span></span><br><span class="line">   <span class="attr">Started:</span>      <span class="string">Thu,</span> <span class="number">10</span> <span class="string">Oct</span> <span class="number">2019 11:14:13</span> <span class="string">+0200</span></span><br><span class="line"> <span class="attr">Last State:</span>     <span class="string">Terminated</span></span><br><span class="line">   <span class="attr">Reason:</span>       <span class="string">OOMKilled</span></span><br><span class="line">   <span class="attr">Exit Code:</span>    <span class="number">137</span></span><br><span class="line">   <span class="attr">Started:</span>      <span class="string">Thu,</span> <span class="number">10</span> <span class="string">Oct</span> <span class="number">2019 11:04:03</span> <span class="string">+0200</span></span><br><span class="line">   <span class="attr">Finished:</span>     <span class="string">Thu,</span> <span class="number">10</span> <span class="string">Oct</span> <span class="number">2019 11:14:11</span> <span class="string">+0200</span></span><br></pre></td></tr></table></figure>

<p>此退出代码 137 表示该进程使用的内存超过允许的数量，必须终止。</p>
<p>这是 Linux 中存在的一个特性，内核<code>oom_score</code>为系统中运行的进程设置一个值。此外，它允许设置一个名为 <code>oom_score_adj</code> 的值，Kubernetes 使用该值来允许服务质量。它还具有一个 <code>OOM Killer</code>功能，它将审查进程并终止那些使用比他们应该使用上限更多的内存的进程。</p>
<p>请注意，在 Kubernetes 中，进程可以达到以下任何限制：</p>
<ul>
<li>在容器上设置的 Kubernetes Limit。</li>
<li>在命名空间上设置的 Kubernetes ResourceQuota。</li>
<li>节点的实际内存大小。</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302071636097.png" alt="图片"></p>
<h3 id="内存过量使用"><a href="#内存过量使用" class="headerlink" title="内存过量使用"></a>内存过量使用</h3><p>Limits 可以高于 requests，因此所有限制的总和可以高于节点容量。这称为过度使用，这很常见。实际上，如果所有容器使用的内存都比请求的多，它可能会耗尽节点中的内存。这通常会导致一些 pod 被杀死以释放一些内存。</p>
<h3 id="监控-Kubernetes-OOM"><a href="#监控-Kubernetes-OOM" class="headerlink" title="监控 Kubernetes OOM"></a>监控 Kubernetes OOM</h3><p>在 Prometheus 中使用 node exporter 时，有一个指标称为<code>node_vmstat_oom_kill</code>. 跟踪 OOM 终止发生的时间很重要，但您可能希望在此类事件发生之前提前了解此类事件。</p>
<p>相反，您可以检查进程与 Kubernetes 限制的接近程度：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">(sum <span class="keyword">by</span> (namespace,pod,container)</span><br><span class="line">(rate(container_cpu_usage_seconds_total&#123;container<span class="operator">!=</span>&quot;&quot;&#125;[<span class="number">5</span>m])) <span class="operator">/</span> sum <span class="keyword">by</span></span><br><span class="line">(namespace,pod,container)</span><br><span class="line">(kube_pod_container_resource_limits&#123;resource<span class="operator">=</span>&quot;cpu&quot;&#125;)) <span class="operator">&gt;</span> <span class="number">0.8</span></span><br></pre></td></tr></table></figure>

<h2 id="Kubernetes-CPU-节流"><a href="#Kubernetes-CPU-节流" class="headerlink" title="Kubernetes CPU 节流"></a>Kubernetes CPU 节流</h2><p><strong>CPU 节流</strong> 是一种行为，当进程即将达到某些资源限制时，进程会变慢。</p>
<p>与内存情况类似，这些限制可能是：</p>
<ul>
<li>在容器上设置的 Kubernetes Limit。</li>
<li>在命名空间上设置的 Kubernetes ResourceQuota。</li>
<li>节点的实际内存大小。</li>
</ul>
<p>想想下面的类比。我们有一条有一些交通的高速公路，其中：</p>
<ul>
<li>CPU 就是路。</li>
<li>车辆代表进程，每个车辆都有不同的大小。</li>
<li>多条通道代表有多个核心。</li>
<li>一个 request 将是一条专用道路，如自行车道。</li>
</ul>
<p>这里的节流表现为交通堵塞：最终，所有进程都会运行，但一切都会变慢。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302071636818.gif" alt="图片"></p>
<h3 id="Kubernetes-中的-CPU-进程"><a href="#Kubernetes-中的-CPU-进程" class="headerlink" title="Kubernetes 中的 CPU 进程"></a>Kubernetes 中的 CPU 进程</h3><p>CPU 在 Kubernetes 中使用 <strong>shares</strong> 处理。每个 CPU 核心被分成 1024 份，然后使用 Linux 内核的 cgroups（控制组）功能在所有运行的进程之间分配。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302071636504.png" alt="图片"></p>
<p>如果 CPU 可以处理所有当前进程，则不需要任何操作。如果进程使用超过 100% 的 CPU，那么份额就会到位。与任何 Linux Kernel 一样，Kubernetes 使用 CFS（Completely Fair Scheduler）机制，因此拥有更多份额的进程将获得更多的 CPU 时间。</p>
<p>与内存不同，Kubernetes 不会因为节流而杀死 Pod。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302071636919.png" alt="图片"></p>
<blockquote>
<p>可以在 &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu&#x2F;cpu.stat 中查看 CPU 统计信息</p>
</blockquote>
<h3 id="CPU-过度使用"><a href="#CPU-过度使用" class="headerlink" title="CPU 过度使用"></a>CPU 过度使用</h3><p>正如我们在 限制和请求一文 中看到的，当我们想要限制进程的资源消耗时，设置限制或请求很重要。然而，请注意不要将请求总数设置为大于实际 CPU 大小，因为这意味着每个容器都应该有一定数量的 CPU。</p>
<h3 id="监控-Kubernetes-CPU-节流"><a href="#监控-Kubernetes-CPU-节流" class="headerlink" title="监控 Kubernetes CPU 节流"></a>监控 Kubernetes CPU 节流</h3><p>您可以检查进程与 Kubernetes 限制的接近程度：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">(sum <span class="keyword">by</span> (namespace,pod,container)(rate(container_cpu_usage_seconds_total</span><br><span class="line">&#123;container<span class="operator">!=</span>&quot;&quot;&#125;[<span class="number">5</span>m])) <span class="operator">/</span> sum <span class="keyword">by</span> (namespace,pod,container)</span><br><span class="line">(kube_pod_container_resource_limits&#123;resource<span class="operator">=</span>&quot;cpu&quot;&#125;)) <span class="operator">&gt;</span> <span class="number">0.8</span></span><br></pre></td></tr></table></figure>

<p>如果我们想跟踪集群中发生的节流量，cadvisor 提供<code>container_cpu_cfs_throttled_periods_total</code>和<code>container_cpu_cfs_periods_total</code>. 有了这两个，你就可以轻松计算出所有 CPU 周期的 throttling 百分比。</p>
<h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><h3 id="注意-limits-和-requests"><a href="#注意-limits-和-requests" class="headerlink" title="注意 limits 和 requests"></a>注意 limits 和 requests</h3><p>限制是在节点中设置最大资源上限的一种方法，但需要谨慎对待这些限制，因为您可能最终会遇到一个进程被限制或终止的情况。</p>
<h3 id="做好被驱逐的准备"><a href="#做好被驱逐的准备" class="headerlink" title="做好被驱逐的准备"></a>做好被驱逐的准备</h3><p>通过设置非常低的请求，您可能认为这会为您的进程授予最少的 CPU 或内存。但是<code>kubelet</code>会首先驱逐那些使用率高于请求的 Pod，因此您将它们标记为第一个被杀死！</p>
<p>如果您需要保护特定 Pod 免遭抢占（当<code>kube-scheduler</code>需要分配新 Pod 时），请为最重要的进程分配优先级。</p>
<h3 id="节流是无声的敌人"><a href="#节流是无声的敌人" class="headerlink" title="节流是无声的敌人"></a>节流是无声的敌人</h3><p>通过设置不切实际的限制或过度使用，您可能没有意识到您的进程正在受到限制，并且性能受到影响。主动监控您的 CPU 使用率并了解您在容器和命名空间中的实际限制。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这是 CPU 和内存的 Kubernetes 资源管理备忘单</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302071636134.png" alt="图片"></p>
]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>K8S 和 Docker容器中的退出状态码</title>
    <url>/2023/01/04/K8S%E5%92%8C%E5%AE%B9%E5%99%A8%E4%B8%AD%E7%9A%84%E9%80%80%E5%87%BA%E7%8A%B6%E6%80%81%E7%A0%81/</url>
    <content><![CDATA[<h2 id="什么是容器退出码"><a href="#什么是容器退出码" class="headerlink" title="什么是容器退出码"></a><strong>什么是容器退出码</strong></h2><p>当容器终止时，容器引擎使用退出码来报告容器终止的原因。如果您是 Kubernetes 用户，容器故障是 pod 异常最常见的原因之一，了解容器退出码可以帮助您在排查时找到 pod 故障的根本原因。</p>
<p>以下是容器使用的最常见的退出码：</p>
<table>
<thead>
<tr>
<th align="center">退出码</th>
<th align="center">名称</th>
<th align="center">含义</th>
</tr>
</thead>
<tbody><tr>
<td align="center">0</td>
<td align="center">正常退出</td>
<td align="center">开发者用来表明容器是正常退出</td>
</tr>
<tr>
<td align="center">1</td>
<td align="center">应用错误</td>
<td align="center">容器因应用程序错误或镜像规范中的错误引用而停止</td>
</tr>
<tr>
<td align="center">125</td>
<td align="center">容器未能运行</td>
<td align="center">docker run 命令没有执行成功</td>
</tr>
<tr>
<td align="center">126</td>
<td align="center">命令调用错误</td>
<td align="center">无法调用镜像中指定的命令</td>
</tr>
<tr>
<td align="center">127</td>
<td align="center">找不到文件或目录</td>
<td align="center">找不到镜像中指定的文件或目录</td>
</tr>
<tr>
<td align="center">128</td>
<td align="center">退出时使用的参数无效</td>
<td align="center">退出是用无效的退出码触发的（有效代码是 0-255 之间的整数）</td>
</tr>
<tr>
<td align="center">134</td>
<td align="center">异常终止 (SIGABRT)</td>
<td align="center">容器使用 abort() 函数自行中止</td>
</tr>
<tr>
<td align="center">137</td>
<td align="center">立即终止 (SIGKILL)</td>
<td align="center">容器被操作系统通过 SIGKILL 信号终止</td>
</tr>
<tr>
<td align="center">139</td>
<td align="center">分段错误 (SIGSEGV)</td>
<td align="center">容器试图访问未分配给它的内存并被终止</td>
</tr>
<tr>
<td align="center">143</td>
<td align="center">优雅终止 (SIGTERM)</td>
<td align="center">容器收到即将终止的警告，然后终止</td>
</tr>
<tr>
<td align="center">255</td>
<td align="center">退出状态超出范围</td>
<td align="center">容器退出，返回可接受范围之外的退出代码，表示错误原因未知</td>
</tr>
</tbody></table>
<p>下面我们将解释如何在宿主机和 Kubernetes 中对失败的容器进行故障排除，并提供有关上面列出的所有退出代码的更多详细信息。</p>
<h2 id="容器生命周期"><a href="#容器生命周期" class="headerlink" title="容器生命周期"></a><strong>容器生命周期</strong></h2><p>为了更好地理解容器故障的原因，让我们先讨论容器的生命周期。以 Docker 为例 —— 在任何给定时间，Docker 容器都会处于以下几种状态之一：</p>
<ul>
<li>Created：Docker 容器已创建但尚未启动（这是运行 <code>docker create</code> 后但实际运行容器之前的状态）</li>
<li>Up：Docker 容器当前正在运行。这意味着容器管理的操作系统进程正在运行。当您使用命令 <code>docker start</code> 或 <code>docker run</code> 时会发生这种情况，使用 <code>docker start</code> 或 <code>docker run</code> 可能会发生这种情况。</li>
<li>Paused：容器进程正在运行，但 Docker 暂停了容器。通常，当您运行 <code>docker pause</code> 命令时会发生这种情况</li>
<li>Exited：Docker 容器已经被终止，通常是因为容器的进程被杀死了</li>
</ul>
<p>当一个容器达到 Exited 状态时，Docker 会在日志中报告一个退出码，告诉你容器发生了什么导致它退出。</p>
<h2 id="了解容器退出码"><a href="#了解容器退出码" class="headerlink" title="了解容器退出码"></a><strong>了解容器退出码</strong></h2><p>下面我们将更详细地介绍每个退出码。</p>
<h3 id="退出码-0：正常退出"><a href="#退出码-0：正常退出" class="headerlink" title="退出码 0：正常退出"></a><strong>退出码 0：正常退出</strong></h3><p>退出代码 0 由开发人员在任务完成后故意停止容器时触发。从技术上讲，退出代码 0 意味着前台进程未附加到特定容器。</p>
<h4 id="如果容器以退出码-0-终止怎么办？"><a href="#如果容器以退出码-0-终止怎么办？" class="headerlink" title="如果容器以退出码 0 终止怎么办？"></a>如果容器以退出码 0 终止怎么办？</h4><ol>
<li>检查容器日志，确定哪个库导致容器退出；</li>
<li>查看现有库的代码，并确定它触发退出码 0 的原因，以及它是否正常运行。</li>
</ol>
<h3 id="退出码-1：应用错误"><a href="#退出码-1：应用错误" class="headerlink" title="退出码 1：应用错误"></a><strong>退出码 1：应用错误</strong></h3><p>退出代码 1 表示容器由于以下原因之一停止：</p>
<ol>
<li>应用程序错误：这可能是容器运行的代码中的简单编程错误，例如“除以零”，也可能是与运行时环境相关的高级错误，例如 Java、Python 等；</li>
<li>无效引用：这意味着镜像规范引用了容器镜像中不存在的文件。</li>
</ol>
<h4 id="如果容器以退出码-1-终止怎么办？"><a href="#如果容器以退出码-1-终止怎么办？" class="headerlink" title="如果容器以退出码 1 终止怎么办？"></a>如果容器以退出码 1 终止怎么办？</h4><ol>
<li>检查容器日志以查看是否找不到映像规范中列出的文件之一。如果这是问题所在，请更正镜像以指向正确的路径和文件名。</li>
<li>如果您找不到不正确的文件引用，请检查容器日志以查找应用程序错误，并调试导致错误的库。</li>
</ol>
<h3 id="退出码-125：容器未能运行"><a href="#退出码-125：容器未能运行" class="headerlink" title="退出码 125：容器未能运行"></a><strong>退出码 125：容器未能运行</strong></h3><p>退出码 125 表示该命令用于运行容器。例如 <code>docker run</code> 在 shell 中被调用但没有成功执行。以下是可能发生这种情况的常见原因：</p>
<ol>
<li>命令中使用了未定义的 flag，例如 <code>docker run --abcd</code>；</li>
<li>镜像中用户的定义命令在本机权限不足；</li>
<li>容器引擎与宿主机操作系统或硬件不兼容。</li>
</ol>
<h4 id="如果容器以退出码-125-终止怎么办？"><a href="#如果容器以退出码-125-终止怎么办？" class="headerlink" title="如果容器以退出码 125 终止怎么办？"></a>如果容器以退出码 125 终止怎么办？</h4><ol>
<li>检查运行容器的命令语法是否正确；</li>
<li>检查运行容器的用户，或者镜像中执行命令的上下文，是否有足够的权限在宿主机上创建容器；</li>
<li>如果您的容器引擎提供了运行容器的 option，请尝试它们。例如，在 Docker 中，尝试 <code>docker start</code> 而不是 <code>docker run</code>；</li>
<li>测试您是否能够使用相同的用户名或上下文在主机上运行其他容器。如果不能，重新安装容器引擎，或者解决容器引擎和主机设置之间的底层兼容性问题。</li>
</ol>
<h3 id="退出码-126：命令调用错误"><a href="#退出码-126：命令调用错误" class="headerlink" title="退出码 126：命令调用错误"></a><strong>退出码 126：命令调用错误</strong></h3><p>退出码 126 表示无法调用容器镜像中使用的命令。这通常是用于运行容器的持续集成脚本中缺少依赖项或错误的原因。</p>
<h4 id="如果容器以退出码-126-终止怎么办？"><a href="#如果容器以退出码-126-终止怎么办？" class="headerlink" title="如果容器以退出码 126 终止怎么办？"></a>如果容器以退出码 126 终止怎么办？</h4><ol>
<li>检查容器日志，查看无法调用哪个命令；</li>
<li>尝试在没有命令的情况下运行容器以确保隔离问题；</li>
<li>对命令进行故障排除以确保您使用正确的语法，并且所有依赖项都可用；</li>
<li>更正容器规范并重试运行容器。</li>
</ol>
<h3 id="退出码-127：找不到文件或目录"><a href="#退出码-127：找不到文件或目录" class="headerlink" title="退出码 127：找不到文件或目录"></a><strong>退出码 127：找不到文件或目录</strong></h3><p>退出码 127 表示容器中指定的命令引用了不存在的文件或目录。</p>
<h4 id="如果容器以退出码-127-终止怎么办？"><a href="#如果容器以退出码-127-终止怎么办？" class="headerlink" title="如果容器以退出码 127 终止怎么办？"></a>如果容器以退出码 127 终止怎么办？</h4><p>与退出码 126 相同，识别失败的命令，并确保容器镜像中引用的文件名或文件路径真实有效。</p>
<h3 id="退出码-128：退出时使用的参数无效"><a href="#退出码-128：退出时使用的参数无效" class="headerlink" title="退出码 128：退出时使用的参数无效"></a><strong>退出码 128：退出时使用的参数无效</strong></h3><p>退出码 128 表示容器内的代码触发了退出命令，但没有提供有效的退出码。Linux <code>exit</code> 命令只允许 0-255 之间的整数，因此如果进程以退出码 3.5 退出，则日志将报告退出代码 128。</p>
<h4 id="如果容器以退出码-128-终止怎么办？"><a href="#如果容器以退出码-128-终止怎么办？" class="headerlink" title="如果容器以退出码 128 终止怎么办？"></a>如果容器以退出码 128 终止怎么办？</h4><ol>
<li>检查容器日志以确定哪个库导致容器退出。</li>
<li>确定有问题的库在哪里使用了 <code>exit</code> 命令，并更正它以提供有效的退出代码。</li>
</ol>
<h3 id="退出码-134：异常终止-SIGABRT"><a href="#退出码-134：异常终止-SIGABRT" class="headerlink" title="退出码 134：异常终止 (SIGABRT)"></a><strong>退出码 134：异常终止 (SIGABRT)</strong></h3><p>退出码 134 表示容器自身异常终止，关闭进程并刷新打开的流。此操作是不可逆的，类似 <code>SIGKILL</code>（请参阅下面的退出码 137）。进程可以通过执行以下操作之一来触发 <code>SIGABRT</code>：</p>
<ul>
<li>调用 <code>libc</code> 库中的 <code>abort()</code> 函数；</li>
<li>调用 <code>assert()</code> 宏，用于调试。如果断言为假，则该过程中止。</li>
</ul>
<h4 id="如果容器以退出码-134-终止怎么办？"><a href="#如果容器以退出码-134-终止怎么办？" class="headerlink" title="如果容器以退出码 134 终止怎么办？"></a>如果容器以退出码 134 终止怎么办？</h4><ol>
<li>检查容器日志，查看哪个库触发了 <code>SIGABRT</code> 信号；</li>
<li>检查中止进程是否是预期内的（例如，因为库处于调试模式），如果不是，则对库进行故障排除，并修改以避免中止容器。</li>
</ol>
<h3 id="退出码-137：立即终止-SIGKILL"><a href="#退出码-137：立即终止-SIGKILL" class="headerlink" title="退出码 137：立即终止 (SIGKILL)"></a><strong>退出码 137：立即终止 (SIGKILL)</strong></h3><p>退出码 137 表示容器已收到来自主机操作系统的 <code>SIGKILL</code> 信号。该信号指示进程立即终止，没有宽限期。可能的原因是：</p>
<ul>
<li>当通过容器引擎杀死容器时触发，例如使用 <code>docker kill</code> 命令时；</li>
<li>由 Linux 用户向进程发送 <code>kill -9</code> 命令触发；</li>
<li>在尝试终止容器并等待 30 秒的宽限期后由 Kubernetes 触发（默认情况下）；</li>
<li>由主机自动触发，通常是由于内存不足。在这种情况下，<code>docker inspect</code> 命令将指示 <code>OOMKilled</code> 错误。</li>
</ul>
<h4 id="如果容器以退出码-137-终止怎么办？"><a href="#如果容器以退出码-137-终止怎么办？" class="headerlink" title="如果容器以退出码 137 终止怎么办？"></a>如果容器以退出码 137 终止怎么办？</h4><ol>
<li>检查主机上的日志，查看在容器终止之前发生了什么，以及在接收到 <code>SIGKILL</code> 之前是否之前收到过 <code>SIGTERM</code> 信号（优雅终止）；</li>
<li>如果之前有 <code>SIGTERM</code> 信号，请检查您的容器进程是否处理 <code>SIGTERM</code> 并能够正常终止；</li>
<li>如果没有 <code>SIGTERM</code> 并且容器报告了 <code>OOMKilled</code> 错误，则排查主机上的内存问题。</li>
</ol>
<h3 id="退出码-139：分段错误-SIGSEGV"><a href="#退出码-139：分段错误-SIGSEGV" class="headerlink" title="退出码 139：分段错误 (SIGSEGV)"></a><strong>退出码 139：分段错误 (SIGSEGV)</strong></h3><p>退出码 139 表示容器收到了来自操作系统的 <code>SIGSEGV</code> 信号。这表示分段错误 —— 内存违规，由容器试图访问它无权访问的内存位置引起。<code>SIGSEGV</code> 错误有三个常见原因：</p>
<ul>
<li>编码错误：容器进程没有正确初始化，或者它试图通过指向先前释放的内存的指针来访问内存</li>
<li>二进制文件和库之间不兼容：容器进程运行的二进制文件与共享库不兼容，因此可能会尝试访问不适当的内存地址</li>
<li>硬件不兼容或配置错误：如果您在多个库中看到多个分段错误，则主机上的内存子系统可能存在问题或系统配置问题</li>
</ul>
<h4 id="如果容器以退出码-139-终止怎么办？"><a href="#如果容器以退出码-139-终止怎么办？" class="headerlink" title="如果容器以退出码 139 终止怎么办？"></a>如果容器以退出码 139 终止怎么办？</h4><ol>
<li>检查容器进程是否处理 <code>SIGSEGV</code>。在 Linux 和 Windows 上，您都可以处理容器对分段错误的响应。例如，容器可以收集和报告堆栈跟踪；</li>
<li>如果您需要对 <code>SIGSEGV</code> 进行进一步的故障排除，您可能需要将操作系统设置为即使在发生分段错误后也允许程序运行，以便进行调查和调试。然后，尝试故意造成分段错误并调试导致问题的库；</li>
<li>如果您无法复现问题，请检查主机上的内存子系统并排除内存配置故障。</li>
</ol>
<h3 id="退出码-143：优雅终止-SIGTERM"><a href="#退出码-143：优雅终止-SIGTERM" class="headerlink" title="退出码 143：优雅终止 (SIGTERM)"></a><strong>退出码 143：优雅终止 (SIGTERM)</strong></h3><p>退出码 143 表示容器收到来自操作系统的 <code>SIGTERM</code> 信号，该信号要求容器正常终止，并且容器成功正常终止（否则您将看到退出码 137）。该退出码可能的原因是：</p>
<ul>
<li>容器引擎停止容器时触发，例如使用 <code>docker stop</code> 或 <code>docker-compose down</code> 命令时；</li>
<li>由 Kubernetes 将 Pod 设置为 Terminating 状态触发，并给容器 30 秒的时间以正常关闭。</li>
</ul>
<h4 id="如果容器以退出码-143-终止怎么办？"><a href="#如果容器以退出码-143-终止怎么办？" class="headerlink" title="如果容器以退出码 143 终止怎么办？"></a>如果容器以退出码 143 终止怎么办？</h4><p>检查主机日志，查看操作系统发送 <code>SIGTERM</code> 信号的上下文。如果您使用的是 Kubernetes，请检查 kubelet 日志，查看 pod 是否以及何时关闭。</p>
<p>一般来说，退出码 143 不需要故障排除。这意味着容器在主机指示后正确关闭。</p>
<h3 id="退出码-255：退出状态超出范围"><a href="#退出码-255：退出状态超出范围" class="headerlink" title="退出码 255：退出状态超出范围"></a><strong>退出码 255：退出状态超出范围</strong></h3><p>当您看到退出码 255 时，意味着容器的 entrypoint 以该状态停止。这意味着容器停止了，但不知道是什么原因。</p>
<h4 id="如果容器以退出码-255-终止怎么办？"><a href="#如果容器以退出码-255-终止怎么办？" class="headerlink" title="如果容器以退出码 255 终止怎么办？"></a>如果容器以退出码 255 终止怎么办？</h4><ol>
<li>如果容器在虚拟机中运行，首先尝试删除虚拟机上配置的 overlay 网络并重新创建它们。</li>
<li>如果这不能解决问题，请尝试删除并重新创建虚拟机，然后在其上重新运行容器。</li>
<li>如果上述操作失败，则 bash 进入容器并检查有关 entrypoint 进程及其失败原因的日志或其他线索。</li>
</ol>
<h2 id="哪些-Kubernetes-错误与容器退出代码有关？"><a href="#哪些-Kubernetes-错误与容器退出代码有关？" class="headerlink" title="哪些 Kubernetes 错误与容器退出代码有关？"></a><strong>哪些 Kubernetes 错误与容器退出代码有关？</strong></h2><p>每当 pod 中容器发生故障，或者 Kubernetes 指示 pod 出于任何原因终止时，容器将关闭并记录退出代码。识别退出代码可以帮助您了解 pod 异常的根本原因。</p>
<p>您可以使用以下命令查看 pod 错误：<code>kubectl describe pod [name]</code></p>
<p>结果将如下所示：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">Containers:</span></span><br><span class="line"><span class="attr">kubedns:</span></span><br><span class="line"><span class="attr">Container ID:</span> <span class="string">...</span></span><br><span class="line"><span class="attr">Image:</span> <span class="string">...</span></span><br><span class="line"><span class="attr">Image ID:</span> <span class="string">...</span></span><br><span class="line"><span class="attr">Ports:</span> <span class="string">...</span></span><br><span class="line"><span class="attr">Host Ports:</span> <span class="string">...</span></span><br><span class="line"><span class="attr">Args:</span> <span class="string">...</span></span><br><span class="line"><span class="attr">State:</span> <span class="string">Running</span></span><br><span class="line">   <span class="attr">Started:</span> <span class="string">Fri,</span> <span class="number">15</span> <span class="string">Oct</span> <span class="number">2021 12:06:01</span> <span class="string">+0800</span></span><br><span class="line"><span class="attr">Last State:</span> <span class="string">Terminated</span></span><br><span class="line">   <span class="attr">Reason:</span> <span class="string">Error</span></span><br><span class="line">   <span class="attr">Exit Code:</span> <span class="number">255</span></span><br><span class="line">   <span class="attr">Started:</span> <span class="string">Fri,</span> <span class="number">15</span> <span class="string">Oct</span> <span class="number">2021 11:43:42</span> <span class="string">+0800</span></span><br><span class="line">   <span class="attr">Finished:</span> <span class="string">Fri,</span> <span class="number">15</span> <span class="string">Oct</span> <span class="number">2021 12:05:17</span> <span class="string">+0800</span></span><br><span class="line"><span class="attr">Ready:</span> <span class="literal">True</span></span><br><span class="line"><span class="attr">Restart Count:</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>使用<code>kubectl</code>提供的退出代码解决问题：</p>
<ul>
<li><strong>如果退出代码为 0</strong>：容器正常退出，无需排查</li>
<li><strong>如果退出代码在 1-128 之间</strong>：容器因内部错误而终止，例如镜像规范中缺少或无效的命令</li>
<li><strong>如果退出代码在 129-255 之间</strong>：容器因操作信号而停止，例如 SIGKILL 或 SIGINT</li>
<li><strong>如果退出代码是</strong> <code>exit(-1)</code>或 0-255 范围之外的另一个值，<code>kubectl</code>将其转换为 0-255 范围内的值。</li>
</ul>
]]></content>
      <categories>
        <category>kubernetes</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>K8s 三种探针</title>
    <url>/2022/12/30/K8s%20%E4%B8%89%E7%A7%8D%E6%8E%A2%E9%92%88/</url>
    <content><![CDATA[<h2 id="▍POD-状态"><a href="#▍POD-状态" class="headerlink" title="▍POD 状态"></a><strong>▍POD 状态</strong></h2><h3 id="Pod-常见的状态"><a href="#Pod-常见的状态" class="headerlink" title="Pod 常见的状态"></a><strong>Pod 常见的状态</strong></h3><ul>
<li><strong>Pending</strong>：挂起，我们在请求创建 pod 时，条件不满足，调度没有完成，没有任何一个节点能满足调度条件。已经创建了但是没有适合它运行的节点叫做挂起，这其中也包含集群为容器创建网络，或者下载镜像的过程。</li>
<li><strong>Running</strong>：Pod 内所有的容器都已经被创建，且至少一个容器正在处于运行状态、正在启动状态或者重启状态。</li>
<li><strong>Succeeded</strong>：Pod 中所以容器都执行成功后退出，并且没有处于重启的容器。</li>
<li><strong>Failed</strong>：Pod 中所以容器都已退出，但是至少还有一个容器退出时为失败状态。</li>
<li><strong>Unknown</strong>：未知状态，所谓 pod 是什么状态是 apiserver 和运行在 pod 节点的 kubelet 进行通信获取状态信息的，如果节点之上的 kubelet 本身出故障，那么 apiserver 就连不上 kubelet，得不到信息了，就会看 Unknown。</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202212300819791.png" alt="图片"></p>
<h4 id="Pod-重启策略"><a href="#Pod-重启策略" class="headerlink" title="Pod 重启策略"></a><strong>Pod 重启策略</strong></h4><ul>
<li><strong>Always</strong>: 只要容器失效退出就重新启动容器。</li>
<li><strong>OnFailure</strong>: 当容器以非正常(异常)退出后才自动重新启动容器。</li>
<li><strong>Never</strong>: 无论容器状态如何，都不重新启动容器。</li>
</ul>
<h4 id="Pod-常见状态转换场景"><a href="#Pod-常见状态转换场景" class="headerlink" title="Pod 常见状态转换场景"></a><strong>Pod 常见状态转换场景</strong></h4><p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202212300819808.png" alt="图片"></p>
<h2 id="▍探针简介"><a href="#▍探针简介" class="headerlink" title="▍探针简介"></a><strong>▍探针简介</strong></h2><p>K8s提供了 3 种探针:</p>
<ul>
<li><strong>ReadinessProbe</strong></li>
<li><strong>LivenessProbe</strong></li>
<li><strong>StartupProbe</strong></li>
</ul>
<h3 id="探针存在的目的"><a href="#探针存在的目的" class="headerlink" title="探针存在的目的"></a><strong>探针存在的目的</strong></h3><p>在 Kubernetes 中 Pod 是最小的计算单元，而一个 Pod 又由多个容器组成，相当于每个容器就是一个应用，应用在运行期间，可能因为某也意外情况致使程序挂掉。</p>
<p>那么如何监控这些容器状态稳定性，保证服务在运行期间不会发生问题，发生问题后进行重启等机制，就成为了重中之重的事情，考虑到这点 kubernetes 推出了活性探针机制。</p>
<p>有了存活性探针能保证程序在运行中如果挂掉能够自动重启，但是还有个经常遇到的问题，比如说，在 Kubernetes 中启动 Pod，显示明明 Pod 已经启动成功，且能访问里面的端口，但是却返回错误信息。还有就是在执行滚动更新时候，总会出现一段时间，Pod 对外提供网络访问，但是访问却发生 404，这两个原因，都是因为 Pod 已经成功启动，但是 Pod 的的容器中应用程序还在启动中导致，考虑到这点 Kubernetes 推出了就绪性探针机制。</p>
<ol>
<li><strong>LivenessProbe</strong>：存活性探针，用于判断容器是不是健康，如果不满足健康条件，那么 Kubelet 将根据 Pod 中设置的 restartPolicy （重启策略）来判断，Pod 是否要进行重启操作。LivenessProbe 按照配置去探测 ( 进程、或者端口、或者命令执行后是否成功等等)，来判断容器是不是正常。如果探测不到，代表容器不健康（可以配置连续多少次失败才记为不健康），则 kubelet 会杀掉该容器，并根据容器的重启策略做相应的处理。如果未配置存活探针，则默认容器启动为通过（Success）状态。即探针返回的值永远是 Success。即 Success 后 pod 状态是 RUNING</li>
<li><strong>ReadinessProbe</strong>：就绪性探针，用于判断容器内的程序是否存活（或者说是否健康），只有程序(服务)正常， 容器开始对外提供网络访问（启动完成并就绪）。容器启动后按照 ReadinessProbe 配置进行探测，无问题后结果为成功即状态为 Success。pod 的 READY 状态为 true，从 0&#x2F;1 变为 1&#x2F;1。如果失败继续为 0&#x2F;1，状态为 false。若未配置就绪探针，则默认状态容器启动后为 Success。对于此 pod、此 pod 关联的 Service 资源、EndPoint 的关系也将基于 Pod 的 Ready 状态进行设置，如果 Pod 运行过程中 Ready 状态变为 false，则系统自动从 Service 资源 关联的 EndPoint 列表中去除此 pod，届时 service 资源接收到 GET 请求后，kube-proxy 将一定不会把流量引入此 pod 中，通过这种机制就能防止将流量转发到不可用的 Pod 上。如果 Pod 恢复为 Ready 状态。将再会被加回 Endpoint 列表。kube-proxy 也将有概率通过负载机制会引入流量到此 pod 中。</li>
<li><strong>StartupProbe</strong>: StartupProbe 探针，主要解决在复杂的程序中 ReadinessProbe、LivenessProbe 探针无法更好的判断程序是否启动、是否存活。进而引入 StartupProbe 探针为 ReadinessProbe、LivenessProbe 探针服务。</li>
</ol>
<h3 id="★-ReadinessProbe-与-LivenessProbe-的区别"><a href="#★-ReadinessProbe-与-LivenessProbe-的区别" class="headerlink" title="(★) ReadinessProbe 与 LivenessProbe 的区别"></a><strong>(★) ReadinessProbe 与 LivenessProbe 的区别</strong></h3><ul>
<li>ReadinessProbe 当检测失败后，将 Pod 的 IP:Port 从对应的 EndPoint 列表中删除。</li>
<li>LivenessProbe 当检测失败后，将杀死容器并根据 Pod 的重启策略来决定作出对应的措施。</li>
</ul>
<h3 id="★-StartupProbe-与-ReadinessProbe、LivenessProbe-的区别"><a href="#★-StartupProbe-与-ReadinessProbe、LivenessProbe-的区别" class="headerlink" title="(★) StartupProbe 与 ReadinessProbe、LivenessProbe 的区别"></a><strong>(★) StartupProbe 与 ReadinessProbe、LivenessProbe 的区别</strong></h3><p>如果三个探针同时存在，先执行 StartupProbe 探针，其他两个探针将会被暂时禁用，直到 pod 满足 StartupProbe 探针配置的条件，其他 2 个探针启动，如果不满足按照规则重启容器。</p>
<p>另外两种探针在容器启动后，会按照配置，直到容器消亡才停止探测，而 StartupProbe 探针只是在容器启动后按照配置满足一次后，不在进行后续的探测。</p>
<h3 id="正确的-ReadinessProbe-与-LivenessProbe-使用方式"><a href="#正确的-ReadinessProbe-与-LivenessProbe-使用方式" class="headerlink" title="正确的 ReadinessProbe 与 LivenessProbe 使用方式"></a><strong>正确的 ReadinessProbe 与 LivenessProbe 使用方式</strong></h3><p><strong>LivenessProbe 和 ReadinessProbe 两种探针都支持下面三种探测方法：</strong></p>
<ul>
<li><strong>ExecAction</strong>：在容器中执行指定的命令，如果执行成功，退出码为 0 则探测成功。</li>
<li><strong>HTTPGetAction</strong>：通过容器的 IP 地址、端口号及路径调用 HTTP Get 方法，如果响应的状态码大于等于 - 200 且小于 400，则认为容器 健康。</li>
<li><strong>TCPSocketAction</strong>：通过容器的 IP 地址和端口号执行 TCP 检 查，如果能够建立 TCP 连接，则表明容器健康。</li>
</ul>
<p><strong>探针探测结果有以下值：</strong></p>
<ul>
<li>Success：表示通过检测。</li>
<li>Failure：表示未通过检测。</li>
<li>Unknown：表示检测没有正常进行。</li>
</ul>
<p><strong>LivenessProbe 和 ReadinessProbe 两种探针的相关属性</strong>探针(Probe)有许多可选字段，可以用来更加精确的控制 Liveness 和 Readiness 两种探针的行为(Probe)：</p>
<ul>
<li><strong>initialDelaySeconds</strong>：容器启动后要等待多少秒后就探针开始工作，单位“秒”，默认是 0 秒，最小值是 0</li>
<li><strong>periodSeconds</strong>：执行探测的时间间隔（单位是秒），默认为 10s，单位“秒”，最小值是 1</li>
<li><strong>timeoutSeconds</strong>：探针执行检测请求后，等待响应的超时时间，默认为 1s，单位“秒”，最小值是 1</li>
<li><strong>successThreshold</strong>：探针检测失败后认为成功的最小连接成功次数，默认为 1s，在 Liveness 探针中必须为 1s，最小值为 1s。</li>
<li><strong>failureThreshold</strong>：探测失败的重试次数，重试一定次数后将认为失败，在 readiness 探针中，Pod 会被标记为未就绪，默认为 3s，最小值为 1s</li>
</ul>
<p><strong>Tips</strong>：initialDelaySeconds 在 ReadinessProbe 其实可以不用配置，不配置默认 pod 刚启动，开始进行 ReadinessProbe 探测，但那有怎么样，除了 StartupProbe，ReadinessProbe、LivenessProbe 运行在 pod 的整个生命周期，刚启动的时候 ReadinessProbe 检测失败了，只不过显示 READY 状态一直是 0&#x2F;1，ReadinessProbe 失败并不会导致重启 pod，只有 StartupProbe、LivenessProbe 失败才会重启 pod。而等到多少 s 后，真正服务启动后，检查 success 成功后，READY 状态自然正常</p>
<h3 id="正确的-StartupProbe-使用方式"><a href="#正确的-StartupProbe-使用方式" class="headerlink" title="正确的 StartupProbe 使用方式"></a><strong>正确的 StartupProbe 使用方式</strong></h3><p><strong>StartupProbe 探针支持下面三种探测方法：</strong></p>
<ul>
<li><p><strong>ExecAction</strong>：在容器中执行指定的命令，如果执行成功，退出码为 0 则探测成功。</p>
</li>
<li><p><strong>HTTPGetAction</strong>：通过容器的 IP 地址、端口号及路径调用 HTTP Get 方法，如果响应的状态码大于等于 200 且小于 400，则认为容器 健康。</p>
</li>
<li><p><strong>TCPSocketAction</strong>：通过容器的 IP 地址和端口号执行 TCP 检 查，如果能够建立 TCP 连接，则表明容器健康。</p>
</li>
</ul>
<p><strong>探针探测结果有以下值：</strong></p>
<ul>
<li><p>Success：表示通过检测。</p>
</li>
<li><p>Failure：表示未通过检测。</p>
</li>
<li><p>Unknown：表示检测没有正常进行。</p>
</li>
</ul>
<h3 id="StartupProbe-探针属性"><a href="#StartupProbe-探针属性" class="headerlink" title="StartupProbe 探针属性"></a><strong>StartupProbe 探针属性</strong></h3><ul>
<li><p><strong>initialDelaySeconds</strong>：容器启动后要等待多少秒后就探针开始工作，单位“秒”，默认是 0 秒，最小值是 0</p>
</li>
<li><p><strong>periodSeconds</strong>：执行探测的时间间隔（单位是秒），默认为 10s，单位“秒”，最小值是 1</p>
</li>
<li><p><strong>timeoutSeconds</strong>：探针执行检测请求后，等待响应的超时时间，默认为 1s，单位“秒”，最小值是 1</p>
</li>
<li><p><strong>successThreshold</strong>：探针检测失败后认为成功的最小连接成功次数，默认为 1s，在 Liveness 探针中必须为 1s，最小值为 1s。</p>
</li>
<li><p><strong>failureThreshold</strong>：探测失败的重试次数，重试一定次数后将认为失败，在 readiness 探针中，Pod 会被标记为未就绪，默认为 3s，最小值为 1s</p>
</li>
</ul>
<p><strong>Tips</strong>：在 StartupProbe 执行完之后，其他 2 种探针的所有配置才全部启动，相当于容器刚启动的时候，所以其他 2 种探针如果配置了 initialDelaySeconds，建议不要给太长。</p>
<h2 id="▍使用举例"><a href="#▍使用举例" class="headerlink" title="▍使用举例"></a><strong>▍使用举例</strong></h2><h3 id="LivenessProbe-探针使用示例"><a href="#LivenessProbe-探针使用示例" class="headerlink" title="LivenessProbe 探针使用示例"></a><strong>LivenessProbe 探针使用示例</strong></h3><h4 id="1-通过-exec-方式做健康探测"><a href="#1-通过-exec-方式做健康探测" class="headerlink" title="1. 通过 exec 方式做健康探测"></a><strong>1. 通过 exec 方式做健康探测</strong></h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># vim liveness-exec.yaml</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">liveness-exec</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">liveness</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">    <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">liveness</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">          <span class="attr">args:</span> <span class="comment">#创建测试探针探测的文件</span></span><br><span class="line">              <span class="bullet">-</span> <span class="string">/bin/sh</span></span><br><span class="line">              <span class="bullet">-</span> <span class="string">-c</span></span><br><span class="line">              <span class="bullet">-</span> <span class="string">touch</span> <span class="string">/tmp/healthy;</span> <span class="string">sleep</span> <span class="number">30</span><span class="string">;</span> <span class="string">rm</span> <span class="string">-rf</span> <span class="string">/tmp/healthy;</span> <span class="string">sleep</span> <span class="number">600</span></span><br><span class="line">          <span class="attr">LivenessProbe:</span></span><br><span class="line">              <span class="attr">initialDelaySeconds:</span> <span class="number">10</span> <span class="comment">#延迟检测时间</span></span><br><span class="line">              <span class="attr">periodSeconds:</span> <span class="number">5</span> <span class="comment">#检测时间间隔</span></span><br><span class="line">              <span class="attr">exec:</span> <span class="comment">#使用命令检查</span></span><br><span class="line">                  <span class="attr">command:</span> <span class="comment">#指令，类似于运行命令sh</span></span><br><span class="line">                      <span class="bullet">-</span> <span class="string">cat</span> <span class="comment">#sh 后的第一个内容，直到需要输入空格，变成下一行</span></span><br><span class="line">                      <span class="bullet">-</span> <span class="string">/tmp/healthy</span> <span class="comment">#由于不能输入空格，需要另外声明，结果为sh cat&quot;空格&quot;/tmp/healthy</span></span><br></pre></td></tr></table></figure>

<p><strong>思路整理：</strong></p>
<p>容器在初始化后，执行（&#x2F;bin&#x2F;sh -c “touch &#x2F;tmp&#x2F;healthy; sleep 30; rm -rf &#x2F;tmp&#x2F;healthy; sleep 600”）首先创建一个 &#x2F;tmp&#x2F;healthy 文件，然后执行睡眠命令，睡眠 30 秒，到时间后执行删除 &#x2F;tmp&#x2F;healthy 文件命令。</p>
<p>而设置的存活探针检检测方式为执行 shell 命令，用 cat 命令输出 healthy 文件的内容，如果能成功执行这条命令一次(默认 successThreshold:1)，存活探针就认为探测成功，由于没有配置(failureThreshold、timeoutSeconds)，所以执行（cat &#x2F;tmp&#x2F;healthy）并只等待 1s，如果 1s 内执行后返回失败，探测失败。</p>
<p>在前 30 秒内，由于文件存在，所以存活探针探测时执行 cat &#x2F;tmp&#x2F;healthy 命令成功执行。30 秒后 healthy 文件被删除，所以执行命令失败，Kubernetes 会根据 Pod 设置的重启策略来判断，是否重启 Pod。</p>
<h4 id="2-通过-HTTP-方式做健康探测"><a href="#2-通过-HTTP-方式做健康探测" class="headerlink" title="2. 通过 HTTP 方式做健康探测"></a><strong>2. 通过 HTTP 方式做健康探测</strong></h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># vi liveness-http.yaml</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">liveness-http</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">  <span class="attr">test:</span> <span class="string">liveness</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">liveness</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">test.com/test-http-prober:v0.0.1</span></span><br><span class="line">    <span class="attr">LivenessProbe:</span></span><br><span class="line">      <span class="attr">failureThreshold:</span> <span class="number">5</span> <span class="comment">#检测失败5次表示未就绪</span></span><br><span class="line">      <span class="attr">initialDelaySeconds:</span> <span class="number">20</span> <span class="comment">#延迟加载时间</span></span><br><span class="line">      <span class="attr">periodSeconds:</span> <span class="number">10</span> <span class="comment">#重试时间间隔</span></span><br><span class="line">      <span class="attr">timeoutSeconds:</span> <span class="number">5</span> <span class="comment">#超时时间设置</span></span><br><span class="line">      <span class="attr">successThreshold:</span> <span class="number">2</span> <span class="comment">#检查成功为2次表示就绪</span></span><br><span class="line">      <span class="attr">httpGet:</span></span><br><span class="line">        <span class="attr">scheme:</span> </span><br><span class="line">        <span class="attr">HTTPport:</span> <span class="number">8081</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/ping</span></span><br></pre></td></tr></table></figure>

<p><strong>思路整理：</strong></p>
<p>在 pod 启动后，初始化等待 20s 后，LivenessProbe 开始工作，去请求 <code>http://Pod_IP:8081/ping</code> 接口，类似于 curl -I <code>http://Pod_IP:8081/ping</code> 接口,考虑到请求会有延迟(curl -I 后一直出现假死状态)，所以给这次请求操作一直持续 5s，如果 5s 内访问返回数值在&gt;&#x3D;200 且&lt;&#x3D;400 代表第一次检测 success，如果是其他的数值，或者 5s 后还是假死状态，执行类似（ctrl+c）中断，并反回 failure 失败。</p>
<p>等待 10s 后，再一次的去请求 <code>http://Pod_IP:8081/ping</code> 接口。如果有连续的 2 次都是 success，代表无问题。如果期间有连续的 5 次都是 failure，代表有问题，直接重启 pod，此操作会伴随 pod 的整个生命周期。</p>
<blockquote>
<p>Tips</p>
</blockquote>
<p>Http Get 探测方式有如下可选的控制字段:</p>
<ul>
<li>scheme: 用于连接 host 的协议，默认为 HTTP。</li>
<li>host：要连接的主机名，默认为 Pod IP，可以在 Http Request headers 中设置 host 头部。</li>
<li>port：容器上要访问端口号或名称。</li>
<li>path：http 服务器上的访问 URI。</li>
<li>httpHeaders：自定义 HTTP 请求 headers，HTTP 允许重复 headers。</li>
</ul>
<h4 id="3-通过-TCP-方式做健康探测"><a href="#3-通过-TCP-方式做健康探测" class="headerlink" title="3. 通过 TCP 方式做健康探测"></a><strong>3. 通过 TCP 方式做健康探测</strong></h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># vi liveness-tcp.yaml</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">liveness-tcp</span></span><br><span class="line"><span class="attr">labels:</span></span><br><span class="line"><span class="attr">app:</span> <span class="string">liveness</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">containers:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">liveness</span></span><br><span class="line"><span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">LivenessProbe:</span></span><br><span class="line"><span class="attr">initialDelaySeconds:</span> <span class="number">15</span></span><br><span class="line"><span class="attr">periodSeconds:</span> <span class="number">20</span></span><br><span class="line"><span class="attr">tcpSocket:</span></span><br><span class="line"><span class="attr">port:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p><strong>思路整理：</strong></p>
<p>TCP 检查方式和 HTTP 检查方式非常相似，在容器启动 initialDelaySeconds 参数设定的时间后，kubelet 将发送第一个 LivenessProbe 探针，尝试连接容器的 80 端口，类似于 telnet 80 端口。每隔 20 秒(periodSeconds)做探测，如果连接失败则将杀死 Pod 重启容器。</p>
<h2 id="ReadinessProbe-探针使用示例"><a href="#ReadinessProbe-探针使用示例" class="headerlink" title="ReadinessProbe 探针使用示例"></a><strong>ReadinessProbe 探针使用示例</strong></h2><p>ReadinessProbe 探针使用方式和 LivenessProbe 探针探测方法一样，也是支持三种，只是一个是用于探测应用的存活，一个是判断是否对外提供流量的条件。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># vim readiness-exec.yaml</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">readiness-exec</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">readiness-exec</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">    <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">readiness-exec</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">          <span class="attr">args:</span> <span class="comment">#创建测试探针探测的文件</span></span><br><span class="line">              <span class="bullet">-</span> <span class="string">/bin/sh</span></span><br><span class="line">              <span class="bullet">-</span> <span class="string">-c</span></span><br><span class="line">              <span class="bullet">-</span> <span class="string">touch</span> <span class="string">/tmp/healthy;</span> <span class="string">sleep</span> <span class="number">30</span><span class="string">;</span> <span class="string">rm</span> <span class="string">-rf</span> <span class="string">/tmp/healthy;</span> <span class="string">sleep</span> <span class="number">600</span></span><br><span class="line">          <span class="attr">LivenessProbe:</span></span><br><span class="line">              <span class="attr">initialDelaySeconds:</span> <span class="number">10</span></span><br><span class="line">              <span class="attr">periodSeconds:</span> <span class="number">5</span></span><br><span class="line">              <span class="attr">exec:</span></span><br><span class="line">                  <span class="attr">command:</span></span><br><span class="line">                      <span class="bullet">-</span> <span class="string">cat</span></span><br><span class="line">                      <span class="bullet">-</span> <span class="string">/tmp/healthy</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">readiness-http</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">readiness-http</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">    <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">readiness-http</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">test.com/test-http-prober:v0.0.1</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">server</span></span><br><span class="line">                <span class="attr">containerPort:</span> <span class="number">8080</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">management</span></span><br><span class="line">                <span class="attr">containerPort:</span> <span class="number">8081</span></span><br><span class="line">          <span class="attr">ReadinessProbe:</span></span><br><span class="line">              <span class="attr">initialDelaySeconds:</span> <span class="number">20</span></span><br><span class="line">              <span class="attr">periodSeconds:</span> <span class="number">5</span></span><br><span class="line">              <span class="attr">timeoutSeconds:</span> <span class="number">10</span></span><br><span class="line">              <span class="attr">httpGet:</span></span><br><span class="line">                  <span class="attr">scheme:</span> <span class="string">HTTP</span></span><br><span class="line">                  <span class="attr">port:</span> <span class="number">8081</span></span><br><span class="line">                  <span class="attr">path:</span> <span class="string">/ping</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">readiness-tcp</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">readiness-tcp</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">    <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">readiness-tcp</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">          <span class="attr">LivenessProbe:</span></span><br><span class="line">              <span class="attr">initialDelaySeconds:</span> <span class="number">15</span></span><br><span class="line">              <span class="attr">periodSeconds:</span> <span class="number">20</span></span><br><span class="line">              <span class="attr">tcpSocket:</span></span><br><span class="line">                  <span class="attr">port:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<h3 id="这里说说-terminationGracePeriodSeconds"><a href="#这里说说-terminationGracePeriodSeconds" class="headerlink" title="这里说说 terminationGracePeriodSeconds"></a>这里说说 <strong>terminationGracePeriodSeconds</strong></h3><p>terminationGracePeriodSeconds 这个参数非常的重要，具体讲解。请参考我的另外一篇文章《详细解读 Kubernetes 中 Pod 优雅退出，帮你解决大问题》, 里面有详细的解释，我这里说下其他的内容。</p>
<p><strong>Tips</strong>: terminationGracePeriodSeconds 不能用于 ReadinessProbe，如果将它应用于 ReadinessProbe 将会被 apiserver 接口所拒绝</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">LivenessProbe:</span></span><br><span class="line"><span class="attr">httpGet:</span></span><br><span class="line"><span class="attr">path:</span> <span class="string">/ping</span></span><br><span class="line"><span class="attr">port:</span> <span class="string">liveness-port</span></span><br><span class="line"><span class="attr">failureThreshold:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">periodSeconds:</span> <span class="number">30</span></span><br><span class="line"><span class="attr">terminationGracePeriodSeconds:</span> <span class="number">30</span> <span class="comment"># 宽限时间30s</span></span><br></pre></td></tr></table></figure>

<h2 id="▍StartupProbe-探针使用示例"><a href="#▍StartupProbe-探针使用示例" class="headerlink" title="▍StartupProbe 探针使用示例"></a><strong>▍StartupProbe 探针使用示例</strong></h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># vim startup.yaml</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">startup</span></span><br><span class="line"><span class="attr">labels:</span></span><br><span class="line"><span class="attr">app:</span> <span class="string">startup</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">containers:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">startup</span></span><br><span class="line"><span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">StartupProbe:</span></span><br><span class="line"><span class="attr">failureThreshold:</span> <span class="number">3</span> <span class="comment"># 失败阈值，连续几次失败才算真失败</span></span><br><span class="line"><span class="attr">initialDelaySeconds:</span> <span class="number">5</span> <span class="comment"># 指定的这个秒以后才执行探测</span></span><br><span class="line"><span class="attr">timeoutSeconds:</span> <span class="number">10</span> <span class="comment"># 探测超时，到了超时时间探测还没返回结果说明失败</span></span><br><span class="line"><span class="attr">periodSeconds:</span> <span class="number">5</span> <span class="comment"># 每隔几秒来运行这个</span></span><br><span class="line"><span class="attr">httpGet:</span></span><br><span class="line"><span class="attr">path:</span> <span class="string">/test</span></span><br><span class="line"><span class="attr">prot:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p><strong>思路整理：</strong></p>
<p>在容器启动 initialDelaySeconds (5 秒) 参数设定的时间后，kubelet 将发送第一个 StartupProbe 探针，尝试连接容器的 80 端口。如果连续探测失败没有超过 3 次 (failureThreshold) ，且每次探测间隔为 5 秒 (periodSeconds) 和探测执行时间不超过超时时间 10 秒&#x2F;每次 (timeoutSeconds)，则认为探测成功，反之探测失败，kubelet 直接杀死 Pod。</p>
]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes 的 hostNetwork 和 NetworkPolicy (网络策略)</title>
    <url>/2022/12/29/Kubernetes%20%E7%9A%84%20hostNetwork%20%E5%92%8C%20NetworkPolicy%20(%E7%BD%91%E7%BB%9C%E7%AD%96%E7%95%A5)/</url>
    <content><![CDATA[<h2 id="1-hostNetwork-介绍"><a href="#1-hostNetwork-介绍" class="headerlink" title="1. hostNetwork 介绍"></a>1. hostNetwork 介绍</h2><blockquote>
<p>在 k8s 中，若 <strong>pod 使用主机网络</strong>，也就是<code>hostNetwork=true</code>。则该pod会使用主机的dns以及所有网络配置，<strong>默认情况下是无法使用 k8s 自带的 dns 解析服务</strong>，但是可以修改 DNS 策略或者修改主机上的域名解析（<code>/etc/resolv.conf</code>），使主机可以用 k8s 自身的 dns 服务。一般通过 DNS 策略（<code>ClusterFirstWithHostNet</code>）来使用 k8s DNS 内部域名解析，k8s DNS 策略如下：</p>
</blockquote>
<ul>
<li><code>Default</code>：继承 Pod 所在宿主机的 DNS 设置，hostNetwork 的默认策略。</li>
<li><code>ClusterFirst（默认DNS策略）</code>：优先使用 kubernetes 环境的 dns 服务，将无法解析的域名转发到从宿主机继承的 dns 服务器。</li>
<li><code>ClusterFirstWithHostNet</code>：和 ClusterFirst 类似，对于以 <code>hostNetwork</code> 模式运行的 Pod 应明确知道使用该策略。也是可以同时解析内部和外部的域名。</li>
<li><code>None</code>：忽略 kubernetes 环境的 dns 配置，通过 spec.dnsConfig 自定义 DNS 配置。</li>
</ul>
<p>一般使用主机网络就增加如下几行即可：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">dnsPolicy:</span> <span class="string">&quot;ClusterFirstWithHostNet&quot;</span></span><br></pre></td></tr></table></figure>

<p><strong>『示例』：<code>hostNetwork.yaml</code></strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="comment"># 使用主机网络</span></span><br><span class="line">      <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line">      <span class="comment"># 该设置是使POD使用k8s的dns，dns配置在/etc/resolv.conf文件中</span></span><br><span class="line">      <span class="comment"># 如果不加，pod默认使用所在宿主主机使用的DNS，这样会导致容器</span></span><br><span class="line">      <span class="comment"># 内不能通过service name访问k8s集群中其他POD</span></span><br><span class="line">      <span class="attr">dnsPolicy:</span> <span class="string">ClusterFirstWithHostNet</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.7.9</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">metrics</span></span><br><span class="line">          <span class="comment"># 如果hostNetwork: true，hostPort必须跟containerPort一样，所以hostPort一般不写，端口也是占用宿主机上的端口。</span></span><br><span class="line">          <span class="attr">hostPort:</span> <span class="number">80</span></span><br><span class="line">          <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">nodePort:</span> <span class="number">31280</span></span><br></pre></td></tr></table></figure>

<p><strong>hostPort 和 NodePort的区别：</strong></p>
<blockquote>
<p><code>hostPort</code> 只会在运行机器上开启端口， <code>NodePort</code> 是所有 Node 上都会开启端口。</p>
</blockquote>
<ul>
<li>hostPort 是由 portmap 这个 cni 提供 portMapping 能力，同时如果想使用这个能力，在配置文件中一定需要开启 portmap。</li>
<li>使用 hostPort 后，会在 iptables 的 nat 链中插入相应的规则，而且这些规则是在 KUBE-SERVICES 规则之前插入的，也就是说会优先匹配 hostPort 的规则，我们常用的 NodePort 规则其实是在 KUBE-SERVICES 之中，也排在其后。</li>
<li>hostport 可以通过 iptables 命令查看到， 但是无法在 ipvsadm 中查看到。</li>
<li>使用 lsof&#x2F;netstat 也查看不到这个端口,这是因为 hostport 是通过 iptables 对请求中的目的端口进行转发的，并不是在主机上通过端口监听。</li>
<li><strong>在生产环境中不建议使用 hostPort</strong>。</li>
</ul>
<h2 id="2-K8s-网络策略-NetworkPolicy"><a href="#2-K8s-网络策略-NetworkPolicy" class="headerlink" title="2. K8s 网络策略 NetworkPolicy"></a>2. K8s 网络策略 NetworkPolicy</h2><p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202212290837401.png" alt="p"></p>
<blockquote>
<p>如果你希望在 IP 地址或端口层面（OSI 第 3 层或第 4 层）控制网络流量， 则你可以考虑为集群中特定应用使用 Kubernetes 网络策略（<code>NetworkPolicy</code>）。**<code>NetworkPolicy</code> 是一种以应用为中心的结构，允许你设置如何允许 Pod 与网络上的各类网络“实体”** 通信。官方文档</p>
</blockquote>
<p>网络策略是通过<strong>网络插件</strong>来实现，常用的网络插件<code>Flannel</code>和<code>Calico</code>：</p>
<ul>
<li><code>Flannel</code>：只能提供网络通讯，<strong>不提供网络策略</strong>，如果需要使用网络策略，建议使用下面的 Calico，关于 Flannel 更详细的介绍和安装可以参考我这篇文章：Kubernetes（k8s）CNI（flannel）网络模型原理。</li>
<li><code>Calico</code>：<strong>支持丰富的网络策略</strong>，Calico以其性能、灵活性而闻名。后面也会出相关文章详细介绍 Calico。</li>
</ul>
<p>更多了解更多的网络策略，可以参考<a href="https://kubernetes.io/docs/concepts/cluster-administration/addons/">官方文档</a></p>
<p>Pod 可以通信的 Pod 是通过如下三个标识符的组合来辩识的：</p>
<ul>
<li>其他被允许的 Pods（例外：Pod 无法阻塞对自身的访问）</li>
<li>被允许的名字空间</li>
<li>IP 组块（例外：与 Pod 运行所在的节点的通信总是被允许的， 无论 Pod 或节点的 IP 地址）</li>
</ul>
<h2 id="3-Pod-隔离的两种类型"><a href="#3-Pod-隔离的两种类型" class="headerlink" title="3. Pod 隔离的两种类型"></a>3. Pod 隔离的两种类型</h2><p>Pod 有两种隔离: <strong>出口的隔离</strong>和<strong>入口的隔离</strong>。默认情况下，出口和入口都是非隔离的。</p>
<ul>
<li><strong>网络策略是相加的</strong>，所以不会产生冲突。如果策略适用于 Pod 某一特定方向的流量， Pod 在对应方向所允许的连接是适用的网络策略所允许的集合。因此，评估的顺序不影响策略的结果。</li>
<li>要允许从源 Pod 到目的 Pod 的连接，源 Pod 的出口策略和目的 Pod 的入口策略都需要允许连接。如果任何一方不允许连接，建立连接将会失败。</li>
</ul>
<h2 id="4-NetworkPolicy-资源"><a href="#4-NetworkPolicy-资源" class="headerlink" title="4. NetworkPolicy 资源"></a>4. NetworkPolicy 资源</h2><h3 id="4-1-NetworkPolicy-示例演示"><a href="#4-1-NetworkPolicy-示例演示" class="headerlink" title="4.1 NetworkPolicy 示例演示"></a>4.1 NetworkPolicy 示例演示</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">NetworkPolicy</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-network-policy</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">podSelector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">role:</span> <span class="string">db</span></span><br><span class="line">  <span class="attr">policyTypes:</span></span><br><span class="line"> <span class="bullet">-</span> <span class="string">Ingress</span></span><br><span class="line"> <span class="bullet">-</span> <span class="string">Egress</span></span><br><span class="line">  <span class="attr">ingress:</span></span><br><span class="line"> <span class="bullet">-</span> <span class="attr">from:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">ipBlock:</span></span><br><span class="line">        <span class="attr">cidr:</span> <span class="number">172.17</span><span class="number">.0</span><span class="number">.0</span><span class="string">/16</span></span><br><span class="line">        <span class="attr">except:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="number">172.17</span><span class="number">.1</span><span class="number">.0</span><span class="string">/24</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">namespaceSelector:</span></span><br><span class="line">        <span class="attr">matchLabels:</span></span><br><span class="line">          <span class="attr">project:</span> <span class="string">myproject</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">podSelector:</span></span><br><span class="line">        <span class="attr">matchLabels:</span></span><br><span class="line">          <span class="attr">role:</span> <span class="string">frontend</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">6379</span></span><br><span class="line">  <span class="attr">egress:</span></span><br><span class="line"> <span class="bullet">-</span> <span class="attr">to:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">ipBlock:</span></span><br><span class="line">        <span class="attr">cidr:</span> <span class="number">10.0</span><span class="number">.0</span><span class="number">.0</span><span class="string">/24</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">5978</span></span><br></pre></td></tr></table></figure>

<p>必需字段：与所有其他的 Kubernetes 配置一样，NetworkPolicy 需要 apiVersion、 kind 和 metadata 字段。关于配置文件操作的一般信息， 请参考配置 Pod 以使用 ConfigMap 和对象管理。</p>
<ul>
<li><code>spec</code>：NetworkPolicy 规约 中包含了在一个名字空间中定义特定网络策略所需的所有信息。</li>
<li><code>podSelector</code>：每个 NetworkPolicy 都包括一个 podSelector， 它对该策略所适用的一组 Pod 进行选择。示例中的策略选择带有 “role&#x3D;db” 标签的 Pod。空的 podSelector 选择名字空间下的所有 Pod。</li>
<li><code>policyTypes</code>：每个 NetworkPolicy 都包含一个 policyTypes 列表，其中包含 Ingress 或 Egress 或两者兼具。policyTypes 字段表示给定的策略是应用于进入所选 Pod 的入站流量还是来自所选 Pod 的出站流量，或两者兼有。如果 NetworkPolicy 未指定 policyTypes 则默认情况下始终设置 Ingress；如果 NetworkPolicy 有任何出口规则的话则设置 Egress。</li>
<li><code>ingress</code>：每个 NetworkPolicy 可包含一个 ingress 规则的白名单列表。每个规则都允许同时匹配 from 和 ports 部分的流量。示例策略中包含一条简单的规则：它匹配某个特定端口，来自三个来源中的一个，第一个通过 ipBlock 指定，第二个通过 namespaceSelector 指定，第三个通过 podSelector 指定。</li>
<li><code>egress</code>：每个 NetworkPolicy 可包含一个 egress 规则的白名单列表。每个规则都允许匹配 to 和 port 部分的流量。该示例策略包含一条规则， 该规则将指定端口上的流量匹配到 10.0.0.0&#x2F;24 中的任何目的地。</li>
</ul>
<p>所以，该网络策略示例:</p>
<ul>
<li><p>隔离 “default” 名字空间下 “role&#x3D;db” 的 Pod （如果它们不是已经被隔离的话）。</p>
</li>
<li><p>（Ingress 规则）允许以下 Pod 连接到 “default” 名字空间下的带有 “role&#x3D;db” 标签的所有 Pod 的 6379 TCP 端口：</p>
<ul>
<li>“default” 名字空间下带有 “role&#x3D;frontend” 标签的所有 Pod</li>
<li>带有 “project&#x3D;myproject” 标签的所有名字空间中的 Pod</li>
<li>IP 地址范围为 172.17.0.0–172.17.0.255 和 172.17.2.0–172.17.255.255 （即，除了 172.17.1.0&#x2F;24 之外的所有 172.17.0.0&#x2F;16）</li>
</ul>
</li>
<li><p>（Egress 规则）允许 “default” 命名空间中任何带有标签 “role&#x3D;db” 的 Pod 到 CIDR 10.0.0.0&#x2F;24 下 5978 TCP 端口的连接。</p>
</li>
</ul>
<h3 id="4-2-选择器-to-和-from-的行为"><a href="#4-2-选择器-to-和-from-的行为" class="headerlink" title="4.2 选择器 to 和 from 的行为"></a>4.2 选择器 to 和 from 的行为</h3><p>可以在 ingress 的 from 部分或 egress 的 to 部分中指定四种选择器：</p>
<ul>
<li><code>podSelector</code>：此选择器将在与 NetworkPolicy 相同的名字空间中选择特定的 Pod，应将其允许作为入站流量来源或出站流量目的地。</li>
<li><code>namespaceSelector</code>：此选择器将选择特定的名字空间，应将所有 Pod 用作其入站流量来源或出站流量目的地。</li>
<li><code>namespaceSelector</code> 和 <code>podSelector</code>：一个指定 namespaceSelector 和 podSelector 的 to&#x2F;from 条目选择特定名字空间中的特定 Pod。注意使用正确的 YAML 语法；下面的策略：</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">ingress:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">from:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">namespaceSelector:</span></span><br><span class="line">      <span class="attr">matchLabels:</span></span><br><span class="line">        <span class="attr">user:</span> <span class="string">alice</span></span><br><span class="line">    <span class="attr">podSelector:</span></span><br><span class="line">      <span class="attr">matchLabels:</span></span><br><span class="line">        <span class="attr">role:</span> <span class="string">client</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure>

<p>在 from 数组中仅包含一个元素，只允许来自标有 role&#x3D;client 的 Pod 且该 Pod 所在的名字空间中标有 user&#x3D;alice 的连接。但是 这项 策略：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"> <span class="attr">ingress:</span></span><br><span class="line"> <span class="bullet">-</span> <span class="attr">from:</span></span><br><span class="line">   <span class="bullet">-</span> <span class="attr">namespaceSelector:</span></span><br><span class="line">       <span class="attr">matchLabels:</span></span><br><span class="line">         <span class="attr">user:</span> <span class="string">alice</span></span><br><span class="line">   <span class="bullet">-</span> <span class="attr">podSelector:</span></span><br><span class="line">       <span class="attr">matchLabels:</span></span><br><span class="line">         <span class="attr">role:</span> <span class="string">client</span></span><br><span class="line"> <span class="string">...</span></span><br></pre></td></tr></table></figure>

<p>这里只是把官网的摘了一部分，官网介绍的比较清楚，这里就不粘贴复制了，可以参考<a href="https://kubernetes.io/zh-cn/docs/concepts/services-networking/network-policies/">官方文档</a></p>
<h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5.总结"></a>5.总结</h2><ul>
<li>在 k8s 上网络策略是<strong>白名单机制</strong>，所谓白名单机制是指，只有明确定义的策略才会被允许放行，默认没有指定的规则就是拒绝的，即条件不匹配的都会被拒绝。</li>
<li>其次对于 ingress 或 egress 来说，对应的 <code>from</code> 或 <code>to</code> 都是用来指定访问端或被访问端的信息。</li>
<li>如果我们在对应的字段中<strong>没有定义 namespaceSelector 字段</strong>，<strong>默认 ingress 或 egrss 会匹配当前 netpol 所在名称空间</strong>，即在没有明确指定 namespaceSelector 字段时，对应的其他条件都是针对当前 netpol 所在名称空间。</li>
<li><strong>多个条件组合</strong>使用，如果多个条件都在一个列表中，则表示多个条件间是与关系，即指定的条件需要同时满足对应策略才会放行。</li>
<li>如果<strong>多个条件不再同一个列表中</strong>，则多个条件之间是或关系，即满足其中一个条件都会被对应策略放行。</li>
</ul>
]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Prometheus 自定义告警规则</title>
    <url>/2023/01/04/Prometheus%20%E8%87%AA%E5%AE%9A%E4%B9%89%E5%91%8A%E8%AD%A6%E8%A7%84%E5%88%99/</url>
    <content><![CDATA[<h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><blockquote>
<p>通过创建 Prometheus 监控告警规则，您可以制定针对特定 Prometheus 实例的告警规则。当告警规则设置的条件满足后，系统会产生对应的告警事件。如果想要收到通知，需要进一步配置对应的通知策略以生成告警并且以短信、邮件、电话、钉群机器人、企业微信机器人或者 Webhook 等方式发送通知。</p>
</blockquote>
<p>从 Prometheus server 端接收到 alerts 后，会基于 PromQL 的告警规则 分析数据，如果满足 PromQL 定义的规则，则会产生一条告警，并发送告警信息到 Alertmanager，Alertmanager 则是根据配置处理告警信息并发送。所以 Prometheus 的告警配置依赖于<code>PromQL</code>与<code>AlertManager</code>，关于这两个介绍可以参考以下文章：</p>
<ul>
<li><strong>Prometheus AlertManager 实战</strong>[1]</li>
<li><strong>Prometheus PromQL 实战</strong>[2]</li>
<li><strong>Prometheus Pushgetway 实战</strong>[3]</li>
<li><a href="https://prometheus.io/docs/alerting/latest/overview/">官方文档</a></li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202212220942871.png" alt="图片"></p>
<h2 id="二、告警实现流程"><a href="#二、告警实现流程" class="headerlink" title="二、告警实现流程"></a>二、告警实现流程</h2><p>设置警报和通知的主要步骤是：</p>
<ol>
<li>在 Prometheus 中配置告警规则。</li>
<li>配置 Prometheus 与 AlertManager 关联。</li>
<li>配置 AlertManager 告警通道。</li>
</ol>
<h2 id="三、告警规则"><a href="#三、告警规则" class="headerlink" title="三、告警规则"></a>三、告警规则</h2><p><a href="https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/">官方文档</a></p>
<h3 id="1）告警规则配置"><a href="#1）告警规则配置" class="headerlink" title="1）告警规则配置"></a>1）告警规则配置</h3><p>在 Prometheus 配置（<code>prometheus.yml</code>）中添加报警规则配置，配置文件中 <code>rule_files</code> 就是用来指定报警规则文件的，如下配置即指定存放报警规则的目录为&#x2F;etc&#x2F;prometheus，规则文件为 rules.yml：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">rule_files:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">/etc/prometheus/rules.yml</span></span><br></pre></td></tr></table></figure>

<p><strong>设置报警规则：</strong></p>
<p>警报规则允许基于 Prometheus 表达式语言的表达式来定义报警报条件的，并在触发警报时发送通知给外部的接收者（Alertmanager），一条警报规则主要由以下几部分组成：</p>
<ul>
<li><code>alert</code>——告警规则的名称。</li>
<li><code>expr</code>——是用于进行报警规则 PromQL 查询语句。</li>
<li><code>for</code>——评估告警的等待时间（Pending Duration）。</li>
<li><code>labels</code>——自定义标签，允许用户指定额外的标签列表，把它们附加在告警上。</li>
<li><code>annotations</code>——用于存储一些额外的信息，用于报警信息的展示之类的。</li>
</ul>
<p>rules.yml 示例如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">groups:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">example</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">alert:</span> <span class="string">high_memory</span></span><br><span class="line">    <span class="comment"># 当内存占有率超过10%，持续1min,则触发告警</span></span><br><span class="line">    <span class="attr">expr:</span> <span class="number">100</span> <span class="bullet">-</span> <span class="string">((node_memory_MemAvailable_bytes&#123;instance=&quot;192.168.182.110:9100&quot;,job=&quot;node_exporter&quot;&#125;</span> <span class="string">*</span> <span class="number">100</span><span class="string">)</span> <span class="string">/</span> <span class="string">node_memory_MemTotal_bytes&#123;instance=&quot;192.168.182.110:9100&quot;,job=&quot;node_exporter&quot;&#125;)</span> <span class="string">&gt;</span> <span class="number">90</span></span><br><span class="line">    <span class="attr">for:</span> <span class="string">1m</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">severity:</span> <span class="string">page</span></span><br><span class="line">    <span class="attr">annotations:</span></span><br><span class="line">      <span class="attr">summary:</span> <span class="string">spike</span> <span class="string">memeory</span></span><br></pre></td></tr></table></figure>

<h3 id="1）监控服务器是否在线"><a href="#1）监控服务器是否在线" class="headerlink" title="1）监控服务器是否在线"></a>1）监控服务器是否在线</h3><p>对于被 Prometheus 监控的服务器，我们都有一个 up 指标，可以知道该服务是否在线。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">up</span> <span class="string">==</span> <span class="number">0</span>  <span class="comment">#服务下线了。</span></span><br><span class="line"><span class="string">up</span> <span class="string">==</span> <span class="number">1</span> <span class="comment">#服务在线。</span></span><br></pre></td></tr></table></figure>

<p>【示例】</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">groups:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Test-Group-001</span> <span class="comment"># 组的名字，在这个文件中必须要唯一</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">alert:</span> <span class="string">InstanceDown</span> <span class="comment"># 告警的名字，在组中需要唯一</span></span><br><span class="line">    <span class="attr">expr:</span> <span class="string">up</span> <span class="string">==</span> <span class="number">0</span> <span class="comment"># 表达式, 执行结果为true: 表示需要告警</span></span><br><span class="line">    <span class="attr">for:</span> <span class="string">1m</span> <span class="comment"># 超过多少时间才认为需要告警(即up==0需要持续的时间)</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">severity:</span> <span class="string">warning</span> <span class="comment"># 定义标签</span></span><br><span class="line">    <span class="attr">annotations:</span></span><br><span class="line">      <span class="attr">summary:</span> <span class="string">&quot;服务 <span class="template-variable">&#123;&#123; $labels.instance &#125;&#125;</span> 下线了&quot;</span></span><br><span class="line">      <span class="attr">description:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; $labels.instance &#125;&#125;</span> of job <span class="template-variable">&#123;&#123; $labels.job &#125;&#125;</span> has been down for more than 1 minutes.&quot;</span></span><br></pre></td></tr></table></figure>

<p>注意：</p>
<ul>
<li><code>for</code> 指定达到告警阈值之后，一致要持续多长时间，才发送告警数据。</li>
<li><code>labels</code> 中可以指定自定义的标签，如果定义的标签已经存在，则会被覆盖。可以使用模板。</li>
<li><code>annotations</code> 中的数据，可以使用模板，<code>$labels</code>表示告警<strong>数据的标签</strong>，<code>&#123;&#123;$value&#125;&#125;</code>表示<strong>时间序列的值</strong>。</li>
</ul>
<h3 id="3）告警数据的状态"><a href="#3）告警数据的状态" class="headerlink" title="3）告警数据的状态"></a>3）告警数据的状态</h3><ul>
<li><code>Inactive</code>——表示没有达到告警的阈值，即 expr 表达式不成立。</li>
<li><code>Pending</code>——表示达到了告警的阈值，即 expr 表达式成立了，但是未满足告警的持续时间，即 for 的值。</li>
<li><code>Firing</code>——已经达到阈值，且满足了告警的持续时间。</li>
</ul>
<blockquote>
<p><em>【温馨提示】经测试发现，如果同一个告警数据达到了 Firing，那么不会再次产生一个告警数据，除非该告警解决了。</em></p>
</blockquote>
<h2 id="四、实战操作"><a href="#四、实战操作" class="headerlink" title="四、实战操作"></a>四、实战操作</h2><p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202212220941947.png" alt="图片"></p>
<h3 id="1）下载-node-exporter"><a href="#1）下载-node-exporter" class="headerlink" title="1）下载 node_exporter"></a>1）下载 node_exporter</h3><blockquote>
<p><em>node-exporter 用于采集 node 的运行指标，包括 node 的 cpu、load、filesystem、meminfo、network 等基础监控指标，类似于 zabbix 监控系统的的 zabbix-agent。</em></p>
</blockquote>
<p><a href="https://github.com/prometheus/node_exporter/releases/">下载地址</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://github.com/prometheus/node_exporter/releases/download/v1.5.0/node_exporter-1.5.0.linux-amd64.tar.gz</span><br><span class="line">tar -xzf node_exporter-1.5.0.linux-amd64.tar.gz</span><br></pre></td></tr></table></figure>

<h3 id="2）启动-node-exporter"><a href="#2）启动-node-exporter" class="headerlink" title="2）启动 node_exporter"></a>2）启动 node_exporter</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ln</span> -s /opt/prometheus/exporter/node_exporter/node_exporter-1.5.0.linux-amd64/node_exporter  /usr/local/bin/node_exporter</span><br><span class="line"><span class="comment"># 指定端口启动，默认端口：9100</span></span><br><span class="line">node_exporter --web.listen-address=<span class="string">&quot;:9100&quot;</span></span><br></pre></td></tr></table></figure>

<p>配置<code>node_exporter.service</code>启动</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 默认端口9100</span></span><br><span class="line"><span class="built_in">cat</span> &gt;/usr/lib/systemd/system/node_exporter.service&lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">[Unit]</span></span><br><span class="line"><span class="string">Description=node_exporter</span></span><br><span class="line"><span class="string">After=network.target</span></span><br><span class="line"><span class="string"> #可以创建相应的用户和组 启动</span></span><br><span class="line"><span class="string">#User=prometheus</span></span><br><span class="line"><span class="string">#Group=prometheus</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">ExecStart=/opt/prometheus/exporter/node_exporter/node_exporter-1.5.0.linux-amd64/node_exporter --web.listen-address=:9100</span></span><br><span class="line"><span class="string">[Install]</span></span><br><span class="line"><span class="string">WantedBy=multi-user.target</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>启动服务</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start node_exporter</span><br><span class="line">systemctl status node_exporter</span><br><span class="line">systemctl <span class="built_in">enable</span> node_exporter</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202212220941957.png" alt="图片">检查</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl http://localhost:9100/metrics</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202212220941163.png" alt="图片"></p>
<h3 id="3）配置-Prometheus-加载-node-exporter"><a href="#3）配置-Prometheus-加载-node-exporter" class="headerlink" title="3）配置 Prometheus 加载 node_exporter"></a>3）配置 Prometheus 加载 node_exporter</h3><p>添加或修改配置 <code>prometheus.yml</code><br><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202212220943146.png" alt="图片"></p>
<p>重启加载配置</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl restart prometheus</span><br><span class="line"><span class="comment"># 1、 kill方式</span></span><br><span class="line"><span class="comment">#kill -HUP pid</span></span><br><span class="line"><span class="comment"># 2、curl方式（推荐）</span></span><br><span class="line"><span class="comment">#curl -X POST http://IP/-/reload</span></span><br><span class="line"><span class="comment"># 【注意】需要在启动的命令行增加参数： --web.enable-lifecycle</span></span><br><span class="line">curl -X POST http://192.168.182.110:9090/-/reload</span><br><span class="line"><span class="comment"># 3、重启（不推荐，重启会导致所有的连接短暂性中断）</span></span><br><span class="line">systemctl restart prometheus</span><br></pre></td></tr></table></figure>

<p>检查<br>web：<code>http://ip:9090/targets</code><br><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202212220941014.png" alt="图片"></p>
<h3 id="4）告警规则配置"><a href="#4）告警规则配置" class="headerlink" title="4）告警规则配置"></a>4）告警规则配置</h3><p>在 Prometheus 配置文件<code>rometheus.yml</code> 中配置如下：<br><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202212220943663.png" alt="图片"><br>在<code>/etc/prometheus/rule.yml</code>配置如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">groups:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Test-Group-001</span> <span class="comment"># 组的名字，在这个文件中必须要唯一</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">alert:</span> <span class="string">InstanceDown</span> <span class="comment"># 告警的名字，在组中需要唯一</span></span><br><span class="line">    <span class="attr">expr:</span> <span class="string">up</span> <span class="string">==</span> <span class="number">0</span> <span class="comment"># 表达式, 执行结果为true: 表示需要告警</span></span><br><span class="line">    <span class="attr">for:</span> <span class="string">1m</span> <span class="comment"># 超过多少时间才认为需要告警(即up==0需要持续的时间)</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">severity:</span> <span class="string">warning</span> <span class="comment"># 定义标签</span></span><br><span class="line">    <span class="attr">annotations:</span></span><br><span class="line">      <span class="attr">summary:</span> <span class="string">&quot;服务 <span class="template-variable">&#123;&#123; $labels.instance &#125;&#125;</span> 下线了&quot;</span></span><br><span class="line">      <span class="attr">description:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; $labels.instance &#125;&#125;</span> of job <span class="template-variable">&#123;&#123; $labels.job &#125;&#125;</span> has been down for more than 1 minutes.&quot;</span></span><br></pre></td></tr></table></figure>

<p>重新加载</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -X POST http://localhost:9090/-/reload</span><br></pre></td></tr></table></figure>

<p>在 web 上就可以看到一个告警规则。<br><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202212220941350.png" alt="图片"></p>
<h3 id="5）模拟告警"><a href="#5）模拟告警" class="headerlink" title="5）模拟告警"></a>5）模拟告警</h3><p>手动关机</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo shutdown -h now</span><br></pre></td></tr></table></figure>

<p>过了一段时间告警状态就变成<code>Pending</code><br><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202212220943160.png" alt="图片"><br>再过一段时间告警就变成了<code>Firing</code><br><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202212220941009.png" alt="图片"></p>
<h3 id="6）配置告警通道"><a href="#6）配置告警通道" class="headerlink" title="6）配置告警通道"></a>6）配置告警通道</h3><p>这里以有邮件告警为示例，其它的也差不多。修改配置之前最好先备份一下之前的配置</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cp</span> alertmanager.yml alertmanager.bak</span><br></pre></td></tr></table></figure>

<p>【1】配置 <code>alertmanager.yml</code></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">global:</span></span><br><span class="line">  <span class="attr">resolve_timeout:</span> <span class="string">5m</span></span><br><span class="line">  <span class="comment">## 这里为qq邮箱 SMTP 服务地址，官方地址为 smtp.qq.com 端口为 465 或 587，同时要设置开启 POP3/SMTP 服务。</span></span><br><span class="line">  <span class="attr">smtp_smarthost:</span> <span class="string">&#x27;smtp.qq.com:465&#x27;</span></span><br><span class="line">  <span class="attr">smtp_from:</span> <span class="string">&#x27;xxxxxxxx@qq.com&#x27;</span></span><br><span class="line">  <span class="attr">smtp_auth_username:</span> <span class="string">&#x27;xxxxxxxx@qq.com&#x27;</span></span><br><span class="line">  <span class="comment">#授权码，不是密码,在 QQ 邮箱服务端设置开启 POP3/SMTP 服务时会提示</span></span><br><span class="line">  <span class="attr">smtp_auth_password:</span> <span class="string">&#x27;xxxxxxxx&#x27;</span></span><br><span class="line">  <span class="attr">smtp_require_tls:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#1、模板</span></span><br><span class="line"><span class="attr">templates:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&#x27;/opt/prometheus/alertmanager/alertmanager-0.24.0.linux-amd64/templates/email.tmpl&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#2、路由</span></span><br><span class="line"><span class="attr">route:</span></span><br><span class="line">  <span class="attr">group_by:</span> [<span class="string">&#x27;alertname&#x27;</span>]</span><br><span class="line">  <span class="attr">group_wait:</span> <span class="string">10s</span></span><br><span class="line">  <span class="attr">group_interval:</span> <span class="string">10s</span></span><br><span class="line">  <span class="attr">repeat_interval:</span> <span class="string">1h</span></span><br><span class="line">  <span class="comment">#邮箱</span></span><br><span class="line">  <span class="attr">receiver:</span> <span class="string">&#x27;email&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">receivers:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&#x27;email&#x27;</span></span><br><span class="line">  <span class="attr">email_configs:</span></span><br><span class="line">  <span class="comment">## 接收警报的email（这里是引用模板文件中定义的变量）</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">to:</span> <span class="string">&#x27;<span class="template-variable">&#123;&#123; template &quot;email.to&quot;&#125;&#125;</span>&#x27;</span></span><br><span class="line">    <span class="comment">## 发送邮件的内容（调用模板文件中的）</span></span><br><span class="line">    <span class="attr">html:</span> <span class="string">&#x27;<span class="template-variable">&#123;&#123; template &quot;email.to.html&quot; .&#125;&#125;</span>&#x27;</span></span><br><span class="line">    <span class="attr">send_resolved:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 抑制器配置</span></span><br><span class="line"><span class="attr">inhibit_rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">source_match:</span></span><br><span class="line">      <span class="attr">severity:</span> <span class="string">&#x27;critical&#x27;</span></span><br><span class="line">    <span class="attr">target_match:</span></span><br><span class="line">      <span class="attr">severity:</span> <span class="string">&#x27;warning&#x27;</span></span><br><span class="line">    <span class="comment">#确保这个配置下的标签内容相同才会抑制，也就是说警报中必须有这三个标签值才会被抑制。</span></span><br><span class="line">    <span class="attr">equal:</span> [<span class="string">&#x27;alertname&#x27;</span>, <span class="string">&#x27;dev&#x27;</span>, <span class="string">&#x27;instance&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p>【2】模板 <code>alert.tmpl</code></p>
<p>模板文件配置了<code>email.from</code>、<code>email.to</code>、<code>email.to.html</code> 三种模板变量，可以在 <code>alertmanager.yml</code> 文件中直接配置引用。这里 <code>email.to.html</code> 就是要发送的邮件内容，<strong>支持 Html 和 Text 格式</strong>，这里为了显示好看，采用 Html 格式简单显示信息。下边  是个循环语法，用于循环获取匹配的 Alerts 的信息。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> define <span class="string">&quot;email.from&quot;</span> <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span>xxxxxxxx@qq.com<span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> end <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> define <span class="string">&quot;email.to&quot;</span> <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span>xxxxxxxx@<span class="number">163.</span>com<span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> end <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> define <span class="string">&quot;email.to.html&quot;</span> <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> range .Alerts <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">=========start==========&lt;br&gt;</span><br><span class="line">告警程序<span class="punctuation">:</span> prometheus_alert &lt;br&gt;</span><br><span class="line">告警级别<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .Labels.severity <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span> 级 &lt;br&gt;</span><br><span class="line">告警类型<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .Labels.alertname <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span> &lt;br&gt;</span><br><span class="line">故障主机<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .Labels.instance <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span> &lt;br&gt;</span><br><span class="line">告警主题<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .Annotations.summary <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span> &lt;br&gt;</span><br><span class="line">告警详情<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .Annotations.description <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span> &lt;br&gt;</span><br><span class="line">触发时间<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .StartsAt.Format <span class="string">&quot;2019-08-04 16:58:15&quot;</span> <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span> &lt;br&gt;</span><br><span class="line">=========end==========&lt;br&gt;</span><br><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> end <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> end <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p><em>【温馨提示】这里记得换成自己的邮箱地址！！！</em></p>
</blockquote>
<p>重启 alertmanager</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl restart alertmanager</span><br></pre></td></tr></table></figure>

<p>在 web 上就可以看到对应的告警信息了。<br><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202212220944402.png" alt="图片"><br>接下来就静待告警了。<br><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202212220941740.png" alt="图片"><br>一整套流程到这里就全部跑通了，告警规则、告警指标、告警通道根据自己的场景来定</p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><blockquote>
<p>[1] <a href="https://www.cnblogs.com/liugp/p/16974615.htmla">Prometheus AlertManager 实战</a><br>[2] <a href="https://www.cnblogs.com/liugp/p/16977340.html">Prometheus PromQL 实战</a><br>[3] <a href="https://www.cnblogs.com/liugp/p/16973756.html">Prometheus Pushgetway 实战</a></p>
</blockquote>
]]></content>
      <categories>
        <category>kubernetes</category>
        <category>Prometheus</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>Prometheus</tag>
      </tags>
  </entry>
  <entry>
    <title>Tempo - 分布式Loki链路追踪利器</title>
    <url>/2023/03/22/Tempo-%E5%88%86%E5%B8%83%E5%BC%8FLoki%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%E5%88%A9%E5%99%A8/</url>
    <content><![CDATA[<p><code>Tempo</code>是Grafana Labs在<code>ObservabilityCON 2020</code>大会上新开源的一个用于做分布式式追踪的后端服务。它和Cortex、Loki一样，Tempo也是一个兼备<code>高扩展</code>和<code>低成本</code>效应的系统。</p>
<h2 id="关于Tempo"><a href="#关于Tempo" class="headerlink" title="关于Tempo"></a>关于Tempo</h2><p>Tempo本质上来说还是一个存储系统，它兼容一些开源的trace协议（包含Jaeger、Zipkin和OpenCensus等），将他们存在廉价的S3存储中，并利用TraceID与其他监控系统（比如Loki、Prometheus）进行协同工作。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303220944179.png" alt="图片"></p>
<p>可以看到Tempo的架构仍然分为<code>distributor</code>、<code>ingester</code>、<code>querier</code>、<code>tempo-query</code>、<code>compactor</code>这几个架构，熟悉Loki和Cortex的朋友可能光看名字就知道他们大概是做什么的。不熟悉的同学也没关系，下面简单说下各模块的作用：</p>
<ul>
<li>distributor</li>
</ul>
<p>监听多个端口，分别接受来自Jaeger、Zipkin和OpenCensus协议的数据，按照TraceID进行哈希并映射到哈希环上，并交由ingester进行存储处理。当前distributor支持的trace协议如下：</p>
<table>
<thead>
<tr>
<th align="left">Protocol</th>
<th align="left">Port</th>
</tr>
</thead>
<tbody><tr>
<td align="left">OpenTelemetry</td>
<td align="left">55680</td>
</tr>
<tr>
<td align="left">Jaeger - Thrift Compact</td>
<td align="left">6831</td>
</tr>
<tr>
<td align="left">Jaeger - Thrift Binary</td>
<td align="left">6832</td>
</tr>
<tr>
<td align="left">Jaeger - Thrift HTTP</td>
<td align="left">14268</td>
</tr>
<tr>
<td align="left">Jaeger - GRPC</td>
<td align="left">14250</td>
</tr>
<tr>
<td align="left">Zipkin</td>
<td align="left">9411</td>
</tr>
</tbody></table>
<ul>
<li>ingester</li>
</ul>
<p>具体负责trace数据的块存储（memcache、GCS、S3）、缓存（Memcache）和索引的处理</p>
<ul>
<li>querier</li>
</ul>
<p>负责从ingester和后端存储里面捞取trace数据，并提供api给查询者</p>
<ul>
<li>compactor</li>
</ul>
<p>负责后端存储块的压缩，减少数据块数量</p>
<ul>
<li>tempo-query</li>
</ul>
<p>tempo的一个可视化界面，用的<code>jaeger query</code>，可以在上面查询tempo的trace数据。</p>
<h2 id="Loki链路跟踪"><a href="#Loki链路跟踪" class="headerlink" title="Loki链路跟踪"></a>Loki链路跟踪</h2><blockquote>
<p>要体验的同学，可以先下载在GitHub上的Docker-Compose，推荐配合本篇内容一起实践<br><a href="https://github.com/CloudXiaobai/loki-cluster-deploy/tree/master/demo/docker-compose-with-tempo">https://github.com/CloudXiaobai/loki-cluster-deploy/tree/master/demo/docker-compose-with-tempo</a></p>
</blockquote>
<h3 id="Loki方面"><a href="#Loki方面" class="headerlink" title="Loki方面"></a>Loki方面</h3><p>在做之前我们先看下Loki的文档是怎么描述的:</p>
<p><em>The tracing_config block configures tracing for Jaeger. Currently limited to disable auto-configuration per environment variables only.</em></p>
<p>可以看到当前Loki对于Trace的支持集中在Jaeger，而且配置是默认开启的，并且只能在环境变量里面读取jaeger的信息。docker-compose下的案例如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">querier-frontend:</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">grafana/loki:1.6.1</span></span><br><span class="line">  <span class="attr">runtime:</span> <span class="string">runc</span></span><br><span class="line">  <span class="attr">scale:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">environment:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">JAEGER_AGENT_HOST=tempo</span>    <span class="string">\\tempo的地址</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">JAEGER_ENDPOINT=http://tempo:14268/api/traces</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">JAEGER_SAMPLER_TYPE=const</span>   <span class="string">\\采样率类型</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">JAEGER_SAMPLER_PARAM=100</span>    <span class="string">\\采样率100</span></span><br></pre></td></tr></table></figure>

<h3 id="API网关方面"><a href="#API网关方面" class="headerlink" title="API网关方面"></a>API网关方面</h3><p>API网关并不是Loki的原生组件，而是在Loki分布式部署的情况下，需要有一个统一的入口对Loki API进行路由。之前用的Nginx，但是<code>原生的Nginx并不支持OpenTracing</code>。根据nginx1.14版本做了一个带jaeger模块的镜像用于Loki入口的trace生成和日志采集。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">gateway:</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">quay.io/cloudxiaobai/nginx-jaeger:1.14.0</span></span><br><span class="line">  <span class="attr">runtime:</span> <span class="string">runc</span></span><br><span class="line">  <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="number">3100</span><span class="string">:3100</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">./nginx.conf:/etc/nginx/nginx.conf</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">./jaeger-config.json:/etc/jaeger-config.json</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;gateway_trace_log:/var/log/nginx/&#x27;</span></span><br></pre></td></tr></table></figure>

<p>对于支持OpenTracing的Nginx，我们需要修改nginx.conf配置文件如下：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">#加载opentracing库</span><br><span class="line">load_module modules/ngx_http_opentracing_module.so;</span><br><span class="line">http <span class="punctuation">&#123;</span></span><br><span class="line"> </span><br><span class="line">  #启用opentracing</span><br><span class="line">  opentracing on;</span><br><span class="line"> </span><br><span class="line">  #加载jaeger库</span><br><span class="line">  opentracing_load_tracer /usr/local/lib/libjaegertracing_plugin.so /etc/jaeger-config.json;</span><br><span class="line"> </span><br><span class="line">  #日志格式，打印traceid</span><br><span class="line">  log_format opentracing &#x27;<span class="attr">&quot;traceID&quot;</span><span class="punctuation">:</span><span class="string">&quot;$opentracing_context_uber_trace_id&quot;</span>&#x27;;</span><br><span class="line"> </span><br><span class="line">  server <span class="punctuation">&#123;</span></span><br><span class="line">    listen               <span class="number">3100</span> default_server;</span><br><span class="line">    location = / <span class="punctuation">&#123;</span></span><br><span class="line">      #向upstream转发时带上trace的头信息</span><br><span class="line">      opentracing_operation_name $uri;</span><br><span class="line">      opentracing_trace_locations off;</span><br><span class="line">      opentracing_propagate_context;</span><br><span class="line">      proxy_pass      http<span class="punctuation">:</span><span class="comment">//querier:3100/ready;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>以上只截取了Nginx部分配置，完整的要参考docker-compose里的nginx.conf</p>
</blockquote>
<p>此外，nginx还需要一个jaeger-config.json，用于将trace数据转给agent处理。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;service_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gateway&quot;</span><span class="punctuation">,</span> \\服务名</span><br><span class="line">  <span class="attr">&quot;diabled&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;reporter&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;logSpans&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;localAgentHostPort&quot;</span><span class="punctuation">:</span> <span class="string">&quot;jaeger-agent:6831&quot;</span>  \\jaeger-agent地址</span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;sampler&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;const&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;param&quot;</span><span class="punctuation">:</span> <span class="string">&quot;100&quot;</span>  \\采样率</span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>为了方便演示，配置的采样率均为100%</p>
</blockquote>
<p>最后，我们为API网关启用一个Jaeger-agent用于收集trace信息并转给Tempo，它的配置如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">jaeger-agent:</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">jaegertracing/jaeger-agent:1.20</span></span><br><span class="line">  <span class="attr">runtime:</span> <span class="string">runc</span></span><br><span class="line">  <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">  <span class="comment"># 转发给tempo</span></span><br><span class="line">  <span class="attr">command:</span> [<span class="string">&quot;--reporter.grpc.host-port=tempo:14250&quot;</span>]</span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;5775:5775/udp&quot;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;6831:6831/udp&quot;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;6832:6832/udp&quot;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;5778:5778&quot;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>为什么API网关不直接发给Tempo要经过Jaeger-agent转发一下，认为用agent的方式更加灵活一些。</p>
</blockquote>
<p>以上，我们就完成了Loki分布式追踪的配置部分，接下来我们用<code>docker-compose up -d</code>将服务都运行起来。</p>
<h3 id="Grafana方面"><a href="#Grafana方面" class="headerlink" title="Grafana方面"></a>Grafana方面</h3><p>当docker的所有服务运行正常后，我们访问grafana并添加两个数据源</p>
<ul>
<li>添加tempo数据源</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303220945671.png" alt="图片"></p>
<ul>
<li>添加Loki数据源，并解析API网关TraceID</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303220945435.png" alt="图片"><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303220945856.png" alt="图片"></p>
<blockquote>
<p>Loki提取TraceID的正则部分是从API网关的日志中匹配</p>
</blockquote>
<h2 id="体验Tempo"><a href="#体验Tempo" class="headerlink" title="体验Tempo"></a>体验Tempo</h2><p>数据源设置OK后，我们进入Explore选择loki查询trace.log就可以得到API网关的日志了。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303220945290.png" alt="图片">从Parsed Fields里面我们就可以看到，Grafana从API网关的日志里面提取了16位字符串作为TraceID了，而它关联了Tempo的数据源，我们点击<code>Tempo</code>按钮就可以直接切到Trace的信息如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303220945854.png" alt="图片"></p>
<p>展开Trace信息，我们可以看到Loki的一次查询的链路会经过下面几个部分</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">flowchart LR</span><br><span class="line">gateway -&gt; query-frontend -&gt; querier -&gt; ingester</span><br><span class="line">                                    |-&gt; SeriesStore.GetChunkRefs</span><br></pre></td></tr></table></figure>

<p>并且得出结论，本次查询的耗时主要落在Ingeter上，原因是查询的日志还没被flush到存储当中，querier需从ingester中取日志的数据。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303220946802.png" alt="图片"></p>
<p>我们再来看一个Loki接收日志的案例：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303220946291.png" alt="图片"></p>
<p>从trace的链路来看，当日志采集端往Loki Post日志时，请求的链路会经过如下部分：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">flowchart LR</span><br><span class="line">gateway -&gt; distributor -&gt; ingester</span><br></pre></td></tr></table></figure>

<p>同时，我们还看到了这次的提交的日志流经过两个ingester实例的处理，且处理时间没有明显差异。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>关于<code>Logging</code>和<code>Tracing</code>两部分在Grafana上的展示还没有达到ObservabilityCON 2020上的流畅度，不过根据会上的消息，更精细话的<code>trace &lt;--&gt; log</code>、<code>metrics &lt;--&gt; trace</code>和<code>metrics &lt;--&gt; log</code>这三部分互相协作部分应该很快会发布。届时Grafana将是云上可观测性应用系统里的王者级产品（虽然有额外的各种查询语句学习成本）</p>
]]></content>
      <categories>
        <category>kubernetes</category>
        <category>Grafana</category>
        <category>Tempo</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>Grafana</tag>
        <tag>Tempo</tag>
      </tags>
  </entry>
  <entry>
    <title>etcd 备份还原</title>
    <url>/2022/12/29/etcd%E5%A4%87%E4%BB%BD%E8%BF%98%E5%8E%9F/</url>
    <content><![CDATA[<h2 id="containerd"><a href="#containerd" class="headerlink" title="containerd"></a>containerd</h2><h3 id="etcd-备份还原"><a href="#etcd-备份还原" class="headerlink" title="etcd 备份还原"></a>etcd 备份还原</h3><h4 id="还原"><a href="#还原" class="headerlink" title="还原"></a>还原</h4><p>每台的master节点 IP 和主机名需要修改<br>停止集群<br>mv   &#x2F;etc&#x2F;kubernetes&#x2F;manifests.bak</p>
<h2 id="备份原有etcd数据"><a href="#备份原有etcd数据" class="headerlink" title="备份原有etcd数据"></a>备份原有etcd数据</h2><p>mv &#x2F;u01&#x2F;local&#x2F;kube-system&#x2F;etcd &#x2F;u01&#x2F;local&#x2F;kube-system&#x2F;etcd-<code>date &#39;+%Y%m%d-%H:%M:%S&#39;</code><br>​</p>
<h3 id="还原第一台master"><a href="#还原第一台master" class="headerlink" title="还原第一台master"></a>还原第一台master</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nerdctl  -n k8s.io run --<span class="built_in">rm</span> \</span><br><span class="line">-v <span class="string">&#x27;/tmp\:/tmp&#x27;</span> \</span><br><span class="line">-v <span class="string">&#x27;/u01/local/kube-system:/u01/local/kube-system&#x27;</span> \</span><br><span class="line">-v <span class="string">&#x27;/etc/kubernetes/pki/etcd:/etc/kubernetes/pki/etcd&#x27;</span> \</span><br><span class="line">--<span class="built_in">env</span> ETCDCTL\_API=3 \</span><br><span class="line"><span class="string">&#x27;docker.kedacom.com:15000/etcd:3.5.0-0&#x27;</span> \</span><br><span class="line">/bin/sh -c <span class="string">&quot;etcdctl snapshot restore \</span></span><br><span class="line"><span class="string">/tmp/etcd-snapshot-.db \</span></span><br><span class="line"><span class="string">--name node-9xct \</span></span><br><span class="line"><span class="string">--endpoints=10.165.124.13:2379 \</span></span><br><span class="line"><span class="string">--cert=/etc/kubernetes/pki/etcd/server.crt \</span></span><br><span class="line"><span class="string">--key=/etc/kubernetes/pki/etcd/server.key \</span></span><br><span class="line"><span class="string">--cacert=/etc/kubernetes/pki/etcd/ca.crt \</span></span><br><span class="line"><span class="string">--initial-advertise-peer-urls=&lt;https://10.165.124.13:2380&gt; \</span></span><br><span class="line"><span class="string">--initial-cluster=node-9xct=&lt;https://10.165.124.13:2380,node-dfkb=https://10.165.124.14:2380,node-24ge=https://10.165.124.15:2380&gt; \</span></span><br><span class="line"><span class="string">--data-dir=/u01/local/kube-system/etcd \</span></span><br><span class="line"><span class="string">--skip-hash-check=true&quot;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nerdctl  -n k8s.io run --<span class="built_in">rm</span> \</span><br><span class="line">-v <span class="string">&#x27;/tmp\:/tmp&#x27;</span> \</span><br><span class="line">-v <span class="string">&#x27;/u01/local/kube-system:/u01/local/kube-system&#x27;</span> \</span><br><span class="line">-v <span class="string">&#x27;/etc/kubernetes/pki/etcd:/etc/kubernetes/pki/etcd&#x27;</span> \</span><br><span class="line">--<span class="built_in">env</span> ETCDCTL\_API=3 \</span><br><span class="line"><span class="string">&#x27;docker.kedacom.com:15000/etcd:3.5.0-0&#x27;</span> \</span><br><span class="line">/bin/sh -c <span class="string">&quot;etcdctl snapshot restore \</span></span><br><span class="line"><span class="string">/tmp/etcd-snapshot-.db \</span></span><br><span class="line"><span class="string">--name node-dfkb \</span></span><br><span class="line"><span class="string">--endpoints=10.165.124.14:2379 \</span></span><br><span class="line"><span class="string">--cert=/etc/kubernetes/pki/etcd/server.crt \</span></span><br><span class="line"><span class="string">--key=/etc/kubernetes/pki/etcd/server.key \</span></span><br><span class="line"><span class="string">--cacert=/etc/kubernetes/pki/etcd/ca.crt \</span></span><br><span class="line"><span class="string">--initial-advertise-peer-urls=&lt;https://10.165.124.14:2380&gt; \</span></span><br><span class="line"><span class="string">--initial-cluster=node-9xct=&lt;https://10.165.124.13:2380,node-dfkb=https://10.165.124.14:2380,node-24ge=https://10.165.124.15:2380&gt; \</span></span><br><span class="line"><span class="string">--data-dir=/u01/local/kube-system/etcd \</span></span><br><span class="line"><span class="string">--skip-hash-check=true&quot;</span></span><br></pre></td></tr></table></figure>

<p>​</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nerdctl  -n k8s.io run --<span class="built_in">rm</span> \</span><br><span class="line">-v <span class="string">&#x27;/tmp\:/tmp&#x27;</span> \</span><br><span class="line">-v <span class="string">&#x27;/u01/local/kube-system:/u01/local/kube-system&#x27;</span> \</span><br><span class="line">-v <span class="string">&#x27;/etc/kubernetes/pki/etcd:/etc/kubernetes/pki/etcd&#x27;</span> \</span><br><span class="line">--<span class="built_in">env</span> ETCDCTL\_API=3 \</span><br><span class="line"><span class="string">&#x27;docker.kedacom.com:15000/etcd:3.5.0-0&#x27;</span> \</span><br><span class="line">/bin/sh -c <span class="string">&quot;etcdctl snapshot restore \</span></span><br><span class="line"><span class="string">/tmp/etcd-snapshot-.db \</span></span><br><span class="line"><span class="string">--name node-24ge \</span></span><br><span class="line"><span class="string">--endpoints=10.165.124.15:2379 \</span></span><br><span class="line"><span class="string">--cert=/etc/kubernetes/pki/etcd/server.crt \</span></span><br><span class="line"><span class="string">--key=/etc/kubernetes/pki/etcd/server.key \</span></span><br><span class="line"><span class="string">--cacert=/etc/kubernetes/pki/etcd/ca.crt \</span></span><br><span class="line"><span class="string">--initial-advertise-peer-urls=&lt;https://10.165.124.15:2380&gt; \</span></span><br><span class="line"><span class="string">--initial-cluster=node-9xct=&lt;https://10.165.124.13:2380,node-dfkb=https://10.165.124.14:2380,node-24ge=https://10.165.124.15:2380&gt; \</span></span><br><span class="line"><span class="string">--data-dir=/u01/local/kube-system/etcd \</span></span><br><span class="line"><span class="string">--skip-hash-check=true&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="恢复集群"><a href="#恢复集群" class="headerlink" title="恢复集群"></a>恢复集群</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mv</span> /etc/kubernetes/manifests.bak /etc/kubernetes/manifests</span><br></pre></td></tr></table></figure>

<h4 id="备份"><a href="#备份" class="headerlink" title="备份"></a>备份</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nerdctl  -n k8s.io run --<span class="built_in">rm</span> \</span><br><span class="line">\-v <span class="string">&#x27;/tmp\:/tmp&#x27;</span> \</span><br><span class="line">\-v <span class="string">&#x27;/etc/kubernetes/pki/etcd:/etc/kubernetes/pki/etcd&#x27;</span> \</span><br><span class="line">\--<span class="built_in">env</span> ETCDCTL\_API=3 \</span><br><span class="line"><span class="string">&#x27;docker.kedacom.com:15000/etcd:3.5.0-0&#x27;</span> \</span><br><span class="line">/bin/sh -c <span class="string">&quot;etcdctl snapshot save \</span></span><br><span class="line"><span class="string">/tmp/etcd-snapshot-134.db \</span></span><br><span class="line"><span class="string">\--endpoints=10.165.24.181:2379 \</span></span><br><span class="line"><span class="string">\--cert=/etc/kubernetes/pki/etcd/server.crt \</span></span><br><span class="line"><span class="string">\--key=/etc/kubernetes/pki/etcd/server.key \</span></span><br><span class="line"><span class="string">\--cacert=/etc/kubernetes/pki/etcd/ca.crt&quot;</span></span><br></pre></td></tr></table></figure>

<p>docker<br>备份</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run --<span class="built_in">rm</span> -e ETCDCTL\_API=3 -v /etc/kubernetes/pki/etcd:/etc/kubernetes/pki/etcd -v /data/etcd\_backup\:/data/etcd\_backup registry.cn-hangzhou.aliyuncs.com/google\_containers/etcd:3.4.13-0 sh -c <span class="string">&quot;etcdctl --endpoints=&lt;https://11.1.100.194:2379&gt; --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/healthcheck-client.crt --key=/etc/kubernetes/pki/etcd/healthcheck-client.key snapshot save /data/etcd\_backup/etcd-snapshot-\$(date +%Y-%m-%d\_%H:%M:%S\_%Z).db&quot;</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kubernetes</category>
        <category>etcd</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>etcd</tag>
      </tags>
  </entry>
  <entry>
    <title>harbor对接minio和NFS</title>
    <url>/2023/01/04/harbor%E5%AF%B9%E6%8E%A5minio%E5%92%8CNFS/</url>
    <content><![CDATA[<h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a><strong>一、前言</strong></h2><p>Harbor 的部署可以使用 NFS 存储，虽然可以使用 rsync+inotify 做数据同步做解决单点问题，但是 NFS 效率&#x2F;性能有限，没有对象存储那么强大，所以一般使用对象存储居多，这里选用 <code>MinIO</code> 对象存储软件，当然也可以使用<code>Ceph</code>或者其它对象存储。都部署在 k8s 集群上，k8s 基础环境部署可以参考文章：<a href="https://blog.kkun.site/2022/12/29/%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2%E4%B8%80%E5%A5%97%E5%AE%8C%E6%95%B4%E7%9A%84%E4%BC%81%E4%B8%9A%E7%BA%A7K8s%E9%9B%86%E7%BE%A4/">二进制部署一套完整的企业级K8s集群</a></p>
<h2 id="二、MinIO-on-K8S-部署"><a href="#二、MinIO-on-K8S-部署" class="headerlink" title="二、MinIO on K8S 部署"></a><strong>二、MinIO on K8S 部署</strong></h2><p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640.png" alt="图片"></p>
<p>MinIO 的介绍可以参考这篇文章：高性能分布式对象存储 MinIO 部署</p>
<p>这里使用 Helm 部署 MinIO ，关于 Helm 的介绍可以参考官方文档</p>
<blockquote>
<p>官方文档：<a href="https://helm.sh/zh/docs/">https://helm.sh/zh/docs/</a></p>
</blockquote>
<p>部署步骤如下：</p>
<h3 id="1）下载安装-MinIO-包"><a href="#1）下载安装-MinIO-包" class="headerlink" title="1）下载安装 MinIO 包"></a><strong>1）下载安装 MinIO 包</strong></h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /opt/k8s/bigdata/minio;<span class="built_in">cd</span> /opt/k8s/bigdata/minio</span><br><span class="line"><span class="comment"># 添加数据源</span></span><br><span class="line">helm repo add bitnami https://charts.bitnami.com/bitnami</span><br><span class="line"><span class="comment"># 下载</span></span><br><span class="line">helm pull bitnami/minio</span><br><span class="line"><span class="comment"># 解压部署包</span></span><br><span class="line">tar -xf minio-11.9.2.tgz</span><br></pre></td></tr></table></figure>

<h3 id="2）修改配置"><a href="#2）修改配置" class="headerlink" title="2）修改配置"></a><strong>2）修改配置</strong></h3><p>添加文件<code>minio/templates/storage-class.yaml</code>，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">minio-local-storage</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">kubernetes.io/no-provisioner</span></span><br><span class="line"><span class="attr">volumeBindingMode:</span> <span class="string">WaitForFirstConsumer</span></span><br></pre></td></tr></table></figure>

<p>添加 pv 配置 <code>minio/templates/pv.yaml</code></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">&#123;&#123;<span class="bullet">-</span> <span class="string">range</span> <span class="string">.Values.persistence.local</span> &#125;&#125;</span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> &#123;&#123; <span class="string">.name</span> &#125;&#125;</span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> &#123;&#123; <span class="string">.size</span> &#125;&#125;</span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Retain</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">minio-local-storage</span></span><br><span class="line">  <span class="attr">local:</span></span><br><span class="line">    <span class="attr">path:</span> &#123;&#123; <span class="string">.path</span> &#125;&#125;</span><br><span class="line">  <span class="attr">nodeAffinity:</span></span><br><span class="line">    <span class="attr">required:</span></span><br><span class="line">      <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">kubernetes.io/hostname</span></span><br><span class="line">          <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">          <span class="attr">values:</span></span><br><span class="line">          <span class="bullet">-</span> &#123;&#123; <span class="string">.host</span> &#125;&#125;</span><br><span class="line"> <span class="string">---</span></span><br><span class="line">&#123;&#123;<span class="bullet">-</span> <span class="string">end</span> &#125;&#125;</span><br></pre></td></tr></table></figure>

<p>修改配置<code>minio/values.yaml</code></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">service:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">nodePorts:</span></span><br><span class="line">    <span class="attr">api:</span> <span class="string">&quot;30900&quot;</span></span><br><span class="line">    <span class="attr">console:</span> <span class="string">&quot;30901&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ---</span></span><br><span class="line"><span class="comment"># 这里先部署单节点，后面会详细讲在k8s中部署分布式minio，这里的重点是Harbor对接minio</span></span><br><span class="line"><span class="attr">mode:</span> <span class="string">standalone</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ---</span></span><br><span class="line"><span class="attr">statefulset:</span></span><br><span class="line">  <span class="attr">replicaCount:</span> <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ---</span></span><br><span class="line"><span class="string">persistence</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">storageClass:</span> <span class="string">minio-local-storage</span></span><br><span class="line">  <span class="attr">size:</span> <span class="string">1Gi</span></span><br><span class="line">  <span class="attr">local:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">minio-pv-0</span></span><br><span class="line">      <span class="attr">size:</span> <span class="string">1Gi</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/opt/k8s/bigdata/minio/data</span></span><br><span class="line">      <span class="attr">host:</span> <span class="string">local-168-182-110</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>【温馨提示】需要提前在对应的节点上创建对应的目录。</p>
</blockquote>
<h3 id="3）开始部署"><a href="#3）开始部署" class="headerlink" title="3）开始部署"></a><strong>3）开始部署</strong></h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/k8s/bigdata/minio</span><br><span class="line">helm install minio ./minio \</span><br><span class="line">  --namespace=minio \</span><br><span class="line">  --create-namespace</span><br></pre></td></tr></table></figure>

<p>回显如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">NAME: minio</span><br><span class="line">LAST DEPLOYED: Sun Aug 28 09:13:06 2022</span><br><span class="line">NAMESPACE: minio</span><br><span class="line">STATUS: deployed</span><br><span class="line">REVISION: 1</span><br><span class="line">TEST SUITE: None</span><br><span class="line">NOTES:</span><br><span class="line">CHART NAME: minio</span><br><span class="line">CHART VERSION: 11.9.2</span><br><span class="line">APP VERSION: 2022.8.22</span><br><span class="line"></span><br><span class="line">** Please be patient <span class="keyword">while</span> the chart is being deployed **</span><br><span class="line"></span><br><span class="line">MinIO&amp;reg; can be accessed via port  on the following DNS name from within your cluster:</span><br><span class="line"></span><br><span class="line">   minio.minio.svc.cluster.local</span><br><span class="line"></span><br><span class="line">To get your credentials run:</span><br><span class="line"></span><br><span class="line">   <span class="built_in">export</span> ROOT_USER=$(kubectl get secret --namespace minio minio -o jsonpath=<span class="string">&quot;&#123;.data.root-user&#125;&quot;</span> | <span class="built_in">base64</span> -d)</span><br><span class="line">   <span class="built_in">export</span> ROOT_PASSWORD=$(kubectl get secret --namespace minio minio -o jsonpath=<span class="string">&quot;&#123;.data.root-password&#125;&quot;</span> | <span class="built_in">base64</span> -d)</span><br><span class="line"></span><br><span class="line">To connect to your MinIO&amp;reg; server using a client:</span><br><span class="line"></span><br><span class="line">- Run a MinIO&amp;reg; Client pod and append the desired <span class="built_in">command</span> (e.g. <span class="string">&#x27;admin info&#x27;</span>):</span><br><span class="line"></span><br><span class="line">   kubectl run --namespace minio minio-client \</span><br><span class="line">     --<span class="built_in">rm</span> --<span class="built_in">tty</span> -i --restart=<span class="string">&#x27;Never&#x27;</span> \</span><br><span class="line">     --<span class="built_in">env</span> MINIO_SERVER_ROOT_USER=<span class="variable">$ROOT_USER</span> \</span><br><span class="line">     --<span class="built_in">env</span> MINIO_SERVER_ROOT_PASSWORD=<span class="variable">$ROOT_PASSWORD</span> \</span><br><span class="line">     --<span class="built_in">env</span> MINIO_SERVER_HOST=minio \</span><br><span class="line">     --image docker.io/bitnami/minio-client:2022.8.11-debian-11-r3 -- admin info minio</span><br><span class="line"></span><br><span class="line">To access the MinIO&amp;reg; web UI:</span><br><span class="line"></span><br><span class="line">- Get the MinIO&amp;reg; URL:</span><br><span class="line"></span><br><span class="line">   <span class="built_in">export</span> NODE_PORT=$(kubectl get --namespace minio -o jsonpath=<span class="string">&quot;&#123;.spec.ports[0].nodePort&#125;&quot;</span> services minio)</span><br><span class="line">   <span class="built_in">export</span> NODE_IP=$(kubectl get nodes --namespace minio -o jsonpath=<span class="string">&quot;&#123;.items[0].status.addresses[0].address&#125;&quot;</span>)</span><br><span class="line">   <span class="built_in">echo</span> <span class="string">&quot;MinIO&amp;reg; web URL: http://<span class="variable">$NODE_IP</span>:<span class="variable">$NODE_PORT</span>/minio&quot;</span></span><br></pre></td></tr></table></figure>

<p>查看</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pods,svc -n minio -owide</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901102456926.png" alt="图片"></p>
<p>webUI 登录：<br><a href="http://local-168-182-110:30901/">http://local-168-182-110:30901</a><br>账号密码通过以下方式查询：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> ROOT_USER=$(kubectl get secret --namespace minio minio -o jsonpath=<span class="string">&quot;&#123;.data.root-user&#125;&quot;</span> | <span class="built_in">base64</span> -d)</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$ROOT_USER</span></span><br><span class="line"><span class="built_in">export</span> ROOT_PASSWORD=$(kubectl get secret --namespace minio minio -o jsonpath=<span class="string">&quot;&#123;.data.root-password&#125;&quot;</span> | <span class="built_in">base64</span> -d)</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$ROOT_PASSWORD</span></span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901102506506.png" alt="图片"><br><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901102630617.png" alt="图片"></p>
<h3 id="4）安装-mc-测试"><a href="#4）安装-mc-测试" class="headerlink" title="4）安装 mc 测试"></a><strong>4）安装 mc 测试</strong></h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/k8s/bigdata/minio</span><br><span class="line">wget https://dl.min.io/client/mc/release/linux-amd64/mc</span><br><span class="line"><span class="built_in">chmod</span> +x mc</span><br><span class="line"><span class="built_in">ln</span> -s /opt/k8s/bigdata/minio/mc /usr/bin/mc</span><br><span class="line">mc --<span class="built_in">help</span></span><br></pre></td></tr></table></figure>

<p>添加 MinIO 存储服务</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mc config host add minio http://local-168-182-110:30900 admin Kgb4zZT1cU</span><br><span class="line">mc admin info minio</span><br><span class="line"><span class="comment"># 并创建bucket harbor</span></span><br><span class="line">mc mb minio/harbor</span><br><span class="line">mc <span class="built_in">ls</span> minio</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901102432573.png" alt="图片"></p>
<p>常用命令参数：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ls</span>       列出文件和文件夹。</span><br><span class="line">mb       创建一个存储桶或一个文件夹。</span><br><span class="line"><span class="built_in">cat</span>      显示文件和对象内容。</span><br><span class="line">pipe     将一个STDIN重定向到一个对象或者文件或者STDOUT。</span><br><span class="line">share    生成用于共享的URL。</span><br><span class="line"><span class="built_in">cp</span>       拷贝文件和对象。</span><br><span class="line">mirror   给存储桶和文件夹做镜像。</span><br><span class="line">find     基于参数查找文件。</span><br><span class="line">diff     对两个文件夹或者存储桶比较差异。</span><br><span class="line"><span class="built_in">rm</span>       删除文件和对象。</span><br><span class="line">events   管理对象通知。</span><br><span class="line">watch    监听文件和对象的事件。</span><br><span class="line">policy   管理访问策略。</span><br><span class="line">session  为<span class="built_in">cp</span>命令管理保存的会话。</span><br><span class="line">config   管理mc配置文件。</span><br><span class="line">update   检查软件更新。</span><br><span class="line">version  输出版本信息。</span><br></pre></td></tr></table></figure>

<h3 id="5）卸载"><a href="#5）卸载" class="headerlink" title="5）卸载"></a><strong>5）卸载</strong></h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm uninstall minio -n minio</span><br><span class="line">kubectl delete ns minio --force</span><br></pre></td></tr></table></figure>

<h2 id="三、Harbor-on-K8S-部署"><a href="#三、Harbor-on-K8S-部署" class="headerlink" title="三、Harbor on K8S 部署"></a><strong>三、Harbor on K8S 部署</strong></h2><p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901102432588.png" alt="图片"></p>
<h3 id="1）创建-stl-证书"><a href="#1）创建-stl-证书" class="headerlink" title="1）创建 stl 证书"></a><strong>1）创建 stl 证书</strong></h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /opt/k8s/bigdata/harbor/stl &amp;&amp; <span class="built_in">cd</span> /opt/k8s/bigdata/harbor/stl</span><br><span class="line"><span class="comment"># 生成 CA 证书私钥</span></span><br><span class="line">openssl genrsa -out ca.key 4096</span><br><span class="line"><span class="comment"># 生成 CA 证书</span></span><br><span class="line">openssl req -x509 -new -nodes -sha512 -days 3650 \</span><br><span class="line"> -subj <span class="string">&quot;/C=CN/ST=Guangdong/L=Shenzhen/O=harbor/OU=harbor/CN=myharbor-minio.com&quot;</span> \</span><br><span class="line"> -key ca.key \</span><br><span class="line"> -out ca.crt</span><br><span class="line"><span class="comment"># 创建域名证书，生成私钥</span></span><br><span class="line">openssl genrsa -out myharbor-minio.com.key 4096</span><br><span class="line"><span class="comment"># 生成证书签名请求 CSR</span></span><br><span class="line">openssl req -sha512 -new \</span><br><span class="line">    -subj <span class="string">&quot;/C=CN/ST=Guangdong/L=Shenzhen/O=harbor/OU=harbor/CN=myharbor-minio.com&quot;</span> \</span><br><span class="line">    -key myharbor-minio.com.key \</span><br><span class="line">    -out myharbor-minio.com.csr</span><br><span class="line"><span class="comment"># 生成 x509 v3 扩展</span></span><br><span class="line"><span class="built_in">cat</span> &gt; v3.ext &lt;&lt;-<span class="string">EOF</span></span><br><span class="line"><span class="string">authorityKeyIdentifier=keyid,issuer</span></span><br><span class="line"><span class="string">basicConstraints=CA:FALSE</span></span><br><span class="line"><span class="string">keyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment</span></span><br><span class="line"><span class="string">extendedKeyUsage = serverAuth</span></span><br><span class="line"><span class="string">subjectAltName = @alt_names</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[alt_names]</span></span><br><span class="line"><span class="string">DNS.1=myharbor-minio.com</span></span><br><span class="line"><span class="string">DNS.2=*.myharbor-minio.com</span></span><br><span class="line"><span class="string">DNS.3=hostname</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="comment">#创建 Harbor 访问证书</span></span><br><span class="line">openssl x509 -req -sha512 -days 3650 \</span><br><span class="line">    -extfile v3.ext \</span><br><span class="line">    -CA ca.crt -CAkey ca.key -CAcreateserial \</span><br><span class="line">    -<span class="keyword">in</span> myharbor-minio.com.csr \</span><br><span class="line">    -out myharbor-minio.com.crt</span><br></pre></td></tr></table></figure>

<h3 id="2）创建-secret"><a href="#2）创建-secret" class="headerlink" title="2）创建 secret"></a><strong>2）创建 secret</strong></h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create ns harbor-minio</span><br><span class="line">kubectl create secret tls myharbor-minio.com --key myharbor-minio.com.key --cert myharbor-minio.com.crt -n harbor-minio</span><br><span class="line">kubectl get secret myharbor-minio.com -n harbor-minio</span><br></pre></td></tr></table></figure>

<h3 id="3）下载-harbor-安装包"><a href="#3）下载-harbor-安装包" class="headerlink" title="3）下载 harbor 安装包"></a><strong>3）下载 harbor 安装包</strong></h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/k8s/bigdata/harbor</span><br><span class="line">helm repo add harbor https://helm.goharbor.io</span><br><span class="line">helm pull harbor/harbor</span><br><span class="line">tar -xf harbor-1.9.3.tgz</span><br></pre></td></tr></table></figure>

<h3 id="4）配置-minio-存储"><a href="#4）配置-minio-存储" class="headerlink" title="4）配置 minio 存储"></a><strong>4）配置 minio 存储</strong></h3><p>这里存储镜像和 Chart 使用<code>minio</code>。</p>
<blockquote>
<p>persistence 是默认 enabled 的，StorageClass 是默认的 在 k8s 集群中需要使用，来动态地提供卷。在”StorageClass”中指定另一个 StorageClass 或设置”existingClaim” ，如果您已经使用了现有的持久卷。<br>对于存储镜像和 Chart，你也可以使用“azure”，“gcs”，“s3”，“swift”或“oss”。在“imageChartStorage”部分设置它。<br>即 registry 和 chartmuseum 使用 minio 存储。</p>
</blockquote>
<p>具体参考：<a href="https://github.com/goharbor/harbor-helm">https://github.com/goharbor/harbor-helm</a></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">persistence:</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">imageChartStorage:</span></span><br><span class="line">    <span class="attr">disableredirect:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">s3</span></span><br><span class="line">    <span class="attr">filesystem:</span></span><br><span class="line">      <span class="attr">rootdirectory:</span> <span class="string">/storage</span></span><br><span class="line">      <span class="comment">#maxthreads: 100</span></span><br><span class="line">    <span class="attr">s3:</span></span><br><span class="line">      <span class="comment"># region描述的是服务器的物理位置，默认是us-east-1(美国东区1),这也是亚马逊S3的默认区域</span></span><br><span class="line">      <span class="attr">region:</span> <span class="string">us-west-1</span></span><br><span class="line">      <span class="attr">bucket:</span> <span class="string">harbor</span></span><br><span class="line">      <span class="comment"># 账号，密码</span></span><br><span class="line">      <span class="attr">accesskey:</span> <span class="string">admin</span></span><br><span class="line">      <span class="attr">secretkey:</span> <span class="string">Kgb4zZT1cU</span></span><br><span class="line">      <span class="comment"># 这里minio.minion是&lt;service-name&gt;.&lt;namespace-name&gt;</span></span><br><span class="line">      <span class="attr">regionendpoint:</span> <span class="string">http://minio.minio:9000</span></span><br><span class="line">      <span class="attr">encrypt:</span> <span class="literal">false</span></span><br><span class="line">      <span class="attr">secure:</span> <span class="literal">false</span></span><br><span class="line">      <span class="attr">v4auth:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">chunksize:</span> <span class="string">&quot;5242880&quot;</span></span><br><span class="line">      <span class="attr">rootdirectory:</span> <span class="string">/</span></span><br><span class="line">      <span class="attr">redirect:</span></span><br><span class="line">        <span class="attr">disabled:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">maintenance:</span></span><br><span class="line">      <span class="attr">uploadpurging:</span></span><br><span class="line">        <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">delete:</span></span><br><span class="line">      <span class="attr">enabled:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<h3 id="6）安装-nfs-（harbor-本身服务存储）"><a href="#6）安装-nfs-（harbor-本身服务存储）" class="headerlink" title="6）安装 nfs （harbor 本身服务存储）"></a><strong>6）安装 nfs （harbor 本身服务存储）</strong></h3><p>harbor 本身服务的存储这里使用 nfs。</p>
<blockquote>
<p>即 Redis、Postgresql 数据库、JobService 和 trivy 使用 nfs。</p>
</blockquote>
<h4 id="1、所有节点安装-nfs"><a href="#1、所有节点安装-nfs" class="headerlink" title="1、所有节点安装 nfs"></a>1、所有节点安装 nfs</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum -y install  nfs-utils rpcbind</span><br></pre></td></tr></table></figure>

<h4 id="2、在-master-节点创建共享目录并授权"><a href="#2、在-master-节点创建共享目录并授权" class="headerlink" title="2、在 master 节点创建共享目录并授权"></a>2、在 master 节点创建共享目录并授权</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /opt/nfsdata</span><br><span class="line"><span class="comment"># 授权共享目录</span></span><br><span class="line"><span class="built_in">chmod</span> 666 /opt/nfsdata</span><br></pre></td></tr></table></figure>

<h4 id="3、配置-exports-文件"><a href="#3、配置-exports-文件" class="headerlink" title="3、配置 exports 文件"></a>3、配置 exports 文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/exports&lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">/opt/nfsdata *(rw,no_root_squash,no_all_squash,sync)</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="comment"># 配置生效</span></span><br><span class="line">exportfs -r</span><br></pre></td></tr></table></figure>

<h4 id="4、启动-rpc-和-nfs（客户端只需要启动-rpc-服务）（注意顺序）"><a href="#4、启动-rpc-和-nfs（客户端只需要启动-rpc-服务）（注意顺序）" class="headerlink" title="4、启动 rpc 和 nfs（客户端只需要启动 rpc 服务）（注意顺序）"></a>4、启动 rpc 和 nfs（客户端只需要启动 rpc 服务）（注意顺序）</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start rpcbind</span><br><span class="line">systemctl start nfs-server</span><br><span class="line">systemctl <span class="built_in">enable</span> rpcbind</span><br><span class="line">systemctl <span class="built_in">enable</span> nfs-server</span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">showmount -e</span><br><span class="line">showmount -e 192.168.182.110</span><br></pre></td></tr></table></figure>

<h4 id="5、客户端"><a href="#5、客户端" class="headerlink" title="5、客户端"></a>5、客户端</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装</span></span><br><span class="line">yum -y install  nfs-utils rpcbind</span><br><span class="line"><span class="comment"># 启动rpc服务</span></span><br><span class="line">systemctl start rpcbind</span><br><span class="line">systemctl <span class="built_in">enable</span> rpcbind</span><br><span class="line"><span class="comment"># 创建挂载目录</span></span><br><span class="line"><span class="built_in">mkdir</span> /mnt/nfsdata</span><br><span class="line"><span class="comment"># 挂载</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;192.168.182.110:/opt/nfsdata /mnt/nfsdata     nfs    defaults  0 1&quot;</span>&gt;&gt; /etc/fstab</span><br><span class="line">mount -a</span><br></pre></td></tr></table></figure>

<h4 id="6、创建-nfs-provisioner-和持久化存储-SC"><a href="#6、创建-nfs-provisioner-和持久化存储-SC" class="headerlink" title="6、创建 nfs provisioner 和持久化存储 SC"></a>6、创建 nfs provisioner 和持久化存储 SC</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 添加数据源</span></span><br><span class="line">helm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始安装</span></span><br><span class="line">helm install nfs-subdir-external-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \</span><br><span class="line">  --namespace=nfs-provisioner \</span><br><span class="line">  --create-namespace \</span><br><span class="line">  --<span class="built_in">set</span> image.repository=willdockerhub/nfs-subdir-external-provisioner \</span><br><span class="line">  --<span class="built_in">set</span> image.tag=v4.0.2 \</span><br><span class="line">  --<span class="built_in">set</span> replicaCount=2 \</span><br><span class="line">  --<span class="built_in">set</span> storageClass.name=nfs-client \</span><br><span class="line">  --<span class="built_in">set</span> storageClass.defaultClass=<span class="literal">true</span> \</span><br><span class="line">  --<span class="built_in">set</span> nfs.server=192.168.182.110 \</span><br><span class="line">  --<span class="built_in">set</span> nfs.path=/opt/nfsdata</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">kubectl get pods,deploy,sc -n nfs-provisioner</span><br></pre></td></tr></table></figure>

<h3 id="7）开始安装"><a href="#7）开始安装" class="headerlink" title="7）开始安装"></a><strong>7）开始安装</strong></h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/k8s/bigdata/harbor</span><br><span class="line">helm install myharbor-minio --namespace harbor-minio ./harbor \</span><br><span class="line">  --<span class="built_in">set</span> expose.ingress.hosts.core=myharbor-minio.com \</span><br><span class="line">  --<span class="built_in">set</span> expose.ingress.hosts.notary=notary.myharbor-minio.com \</span><br><span class="line">  --set-string expose.ingress.annotations.<span class="string">&#x27;nginx\.org/client-max-body-size&#x27;</span>=<span class="string">&quot;1024m&quot;</span> \</span><br><span class="line">  --<span class="built_in">set</span> persistence.persistentVolumeClaim.registry.storageClass=nfs-client</span><br><span class="line">  --<span class="built_in">set</span> persistence.persistentVolumeClaim.jobservice.storageClass=nfs-client \</span><br><span class="line">  --<span class="built_in">set</span> persistence.persistentVolumeClaim.database.storageClass=nfs-client \</span><br><span class="line">  --<span class="built_in">set</span> persistence.persistentVolumeClaim.redis.storageClass=nfs-client \</span><br><span class="line">  --<span class="built_in">set</span> persistence.persistentVolumeClaim.trivy.storageClass=nfs-client \</span><br><span class="line">  --<span class="built_in">set</span> persistence.persistentVolumeClaim.chartmuseum.storageClass=nfs-client \</span><br><span class="line">  --<span class="built_in">set</span> persistence.enabled=<span class="literal">true</span> \</span><br><span class="line">  --<span class="built_in">set</span> expose.tls.secretName=myharbor-minio.com \</span><br><span class="line">  --<span class="built_in">set</span> externalURL=https://myharbor-minio.com \</span><br><span class="line">  --<span class="built_in">set</span> harborAdminPassword=xxxxxxxxx</span><br></pre></td></tr></table></figure>

<blockquote>
<p>这里虽然给 chartmuseum 和 registry 指定了 storageClass 为 nfs-client，但最终不会创建 pvc，因为只要<code>persistence.imageChartStorage.type</code>设置为<code>filesystem</code>，就不会创建 pvc，具体可以查看 <code>templates/registry/registry-pvc.yaml</code> 和 <code>templates/chartmuseum/chartmuseum-pvc.yaml</code> 查看创建 pvc 的条件。<br>即 registry 和 chartmuseum 还是使用上面指定的 minio 存储。</p>
</blockquote>
<p>回显如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">NAME:</span> <span class="string">myharbor</span></span><br><span class="line"><span class="attr">LAST DEPLOYED:</span> <span class="string">Sun</span> <span class="string">Aug</span> <span class="number">28</span> <span class="number">11</span><span class="string">:27:47</span> <span class="number">2022</span></span><br><span class="line"><span class="attr">NAMESPACE:</span> <span class="string">harbor-minio</span></span><br><span class="line"><span class="attr">STATUS:</span> <span class="string">deployed</span></span><br><span class="line"><span class="attr">REVISION:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">TEST SUITE:</span> <span class="string">None</span></span><br><span class="line"><span class="attr">NOTES:</span></span><br><span class="line"><span class="string">Please</span> <span class="string">wait</span> <span class="string">for</span> <span class="string">several</span> <span class="string">minutes</span> <span class="string">for</span> <span class="string">Harbor</span> <span class="string">deployment</span> <span class="string">to</span> <span class="string">complete.</span></span><br><span class="line"><span class="string">Then</span> <span class="string">you</span> <span class="string">should</span> <span class="string">be</span> <span class="string">able</span> <span class="string">to</span> <span class="string">visit</span> <span class="string">the</span> <span class="string">Harbor</span> <span class="string">portal</span> <span class="string">at</span> <span class="string">https://myharbor-minio.com</span></span><br><span class="line"><span class="string">For</span> <span class="string">more</span> <span class="string">details,</span> <span class="string">please</span> <span class="string">visit</span> <span class="string">https://github.com/goharbor/harbor</span></span><br></pre></td></tr></table></figure>

<p>查看</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">pods,svc,ingress</span> <span class="string">-n</span>  <span class="string">harbor-minio</span></span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901102432612.png" alt="图片"><br>配置<code>/etc/hosts</code>，如果有域名解析就可忽略</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">192.168.182.110 myharbor-minio.com</span><br><span class="line">192.168.182.111 myharbor-minio.com</span><br><span class="line">192.168.182.112 myharbor-minio.com</span><br></pre></td></tr></table></figure>

<p>Harbor web：<a href="https://myharbor-minio.com/">https://myharbor-minio.com</a><br><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901102730348.png" alt="图片"><br><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901102432648.png" alt="图片"></p>
<h3 id="8）Containerd-配置-Harbor"><a href="#8）Containerd-配置-Harbor" class="headerlink" title="8）Containerd 配置 Harbor"></a><strong>8）Containerd 配置 Harbor</strong></h3><p>以前使用 docker-engine 的时候，只需要修改&#x2F;etc&#x2F;docker&#x2F;daemon.json 就行，但是新版的 k8s 已经使用 containerd 了，所以这里需要做相关配置，要不然 containerd 会失败。证书（ca.crt）可以在页面上下载：<br><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901102725115.png" alt="图片"><br>创建域名目录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /etc/containerd/myharbor-minio.com</span><br><span class="line"><span class="built_in">cp</span> ca.crt /etc/containerd/myharbor-minio.com/</span><br></pre></td></tr></table></figure>

<p>配置文件：<code>/etc/containerd/config.toml</code></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">[</span>plugins.<span class="string">&quot;io.containerd.grpc.v1.cri&quot;</span>.registry<span class="punctuation">]</span></span><br><span class="line">      config_path = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">      <span class="punctuation">[</span>plugins.<span class="string">&quot;io.containerd.grpc.v1.cri&quot;</span>.registry.auths<span class="punctuation">]</span></span><br><span class="line"></span><br><span class="line">      <span class="punctuation">[</span>plugins.<span class="string">&quot;io.containerd.grpc.v1.cri&quot;</span>.registry.configs<span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">[</span>plugins.<span class="string">&quot;io.containerd.grpc.v1.cri&quot;</span>.registry.configs.<span class="string">&quot;myharbor-minio.com&quot;</span>.tls<span class="punctuation">]</span></span><br><span class="line">          insecure_skip_verify = <span class="literal"><span class="keyword">true</span></span>  #跳过认证</span><br><span class="line">          ca_file = <span class="string">&quot;/etc/containerd/myharbor-minio.com/ca.crt&quot;</span></span><br><span class="line">        <span class="punctuation">[</span>plugins.<span class="string">&quot;io.containerd.grpc.v1.cri&quot;</span>.registry.configs.<span class="string">&quot;myharbor-minio.com&quot;</span>.auth<span class="punctuation">]</span></span><br><span class="line">          username = <span class="string">&quot;admin&quot;</span></span><br><span class="line">          password(删掉这里) = <span class="string">&quot;xxxxxxxxx&quot;</span></span><br><span class="line"></span><br><span class="line">      <span class="punctuation">[</span>plugins.<span class="string">&quot;io.containerd.grpc.v1.cri&quot;</span>.registry.headers<span class="punctuation">]</span></span><br><span class="line"></span><br><span class="line">      <span class="punctuation">[</span>plugins.<span class="string">&quot;io.containerd.grpc.v1.cri&quot;</span>.registry.mirrors<span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">[</span>plugins.<span class="string">&quot;io.containerd.grpc.v1.cri&quot;</span>.registry.mirrors.<span class="string">&quot;myharbor-minio.com&quot;</span><span class="punctuation">]</span></span><br><span class="line">          endpoint = <span class="punctuation">[</span><span class="string">&quot;https://myharbor-minio.com&quot;</span><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901102432680.png" alt="图片"></p>
<p>重启 containerd</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#重新加载配置</span></span><br><span class="line">systemctl daemon-reload</span><br><span class="line"><span class="comment">#重启containerd</span></span><br><span class="line">systemctl restart containerd</span><br></pre></td></tr></table></figure>

<h3 id="9）测试验证"><a href="#9）测试验证" class="headerlink" title="9）测试验证"></a><strong>9）测试验证</strong></h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># tag</span></span><br><span class="line"><span class="comment"># ctr 有命名空间 namespace 来指定类似于工作空间的隔离区域。使用方法 ctr -n default images ls 来查看 default 命名空间的镜像，不加 -n 参数，默认也是使用default的命名空间。i：images</span></span><br><span class="line">ctr -n k8s.io i tag docker.io/bitnami/minio:2022.8.22-debian-11-r0 myharbor-minio.com/bigdata/minio:2022.8.22-debian-11-r0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 推送镜像到harbor</span></span><br><span class="line">ctr --namespace=k8s.io images push myharbor-minio.com/bigdata/minio:2022.8.22-debian-11-r0 --skip-verify --user admin:xxxxxxxxx</span><br><span class="line"></span><br><span class="line"><span class="comment"># --namespace=k8s.io 指定命名空间，不是必须，根据环境而定</span></span><br><span class="line"><span class="comment"># --skip-verify 跳过认证</span></span><br><span class="line"><span class="comment"># --user 指定harbor用户名及密码</span></span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901102432694.png" alt="图片"><br><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901102716000.png" alt="图片"></p>
<p>查看 minio ：<br><a href="http://local-168-182-110:30901/">http://local-168-182-110:30901/</a></p>
<blockquote>
<p>查看 minio 中 harbor bucket 是否存在 docker 目录。如果存在说明成功。</p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901102432733.png" alt="图片"><br><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901102432749.png" alt="图片"></p>
<h3 id="10）卸载"><a href="#10）卸载" class="headerlink" title="10）卸载"></a><strong>10）卸载</strong></h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm uninstall myharbor-minio -n harbor-minio</span><br></pre></td></tr></table></figure>

<p>镜像仓库 <code>Harbor</code> 对接 <code>MinIO</code> 对象存储就到了，有疑问的小伙伴欢迎留言哦</p>
]]></content>
      <categories>
        <category>kubernetes</category>
        <category>Harbor</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>Harbor</tag>
        <tag>Minio</tag>
        <tag>NFS</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker 实用工具 gosu 和 su-exec</title>
    <url>/2023/02/20/docker%20%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7%20gosu%20%E5%92%8C%20su-exec/</url>
    <content><![CDATA[<h2 id="volume-的权限问题"><a href="#volume-的权限问题" class="headerlink" title="volume 的权限问题"></a>volume 的权限问题</h2><p>在 Docker 中，需要把 host 的目录挂载到 container 中作为 volume 使用时，往往会发生文件权限问题。常见的现象是，container 对该路径并无写权限，以致其中服务的各种千奇百怪的问题。</p>
<p>导致这类问题的原因，是 container 内外的 UID 不同。比如，host 当前使用 docker 的用户 UID 是 1000（这是默认第一个用户的 UID）。如果 container 内的 UID 是 2000，那么 host 创建的目录对 container 来说就并非 owner，默认情况下不可写入。</p>
<p>此外还有一种情况，那就是挂载前，host 上不存在被挂载的目录。Docker 会以 root 权限，先创建该目录，再挂载。这就导致，即使 host 与 container 的 UID 都是 1000，也会出现无写权限的情况。这种现象，只会在初始化时出现，但也足够令新手困惑，令老手厌烦。</p>
<p>为什么在 Dockerfile 中不能把 volume 的权限配置好？因为 Dockerfile 是对 image 的描述，而 volume 则是 container 的内容。Dockerfile 中做出的权限配置，对非 volume 来说是可以生效的，而对 volume 则不然。本质上，host 挂载到 volume 上的目录，是属于 host 的。Dockerfile 是在<code>docker build</code>期间执行，而 volume 则是在<code>docker run</code>的时候产生。</p>
<p>其实，Docker 在自动创建 volume 路径时，应该再自动地把它修改为 container 内前台进程的 user:group。然而 Docker 目前并无此类机制，俺们这些用户就只能另谋出路。</p>
<p>一般的临时方案，都是去手动修改权限。要么通过 chown，把 owner 改成 container 内用户的 UID；要么通过 chmod 777，搞成所有用户通用。这些当然不是什么好的长期方案，也违背了 Docker 方便部署的初衷。</p>
<p>目前看来，最好的方案，还是定制 Dockerfile 的 ENTRYPOINT。</p>
<h2 id="ENTRYPOINT"><a href="#ENTRYPOINT" class="headerlink" title="ENTRYPOINT"></a>ENTRYPOINT</h2><p>ENTRYPOINT 有以下几个重点：</p>
<ul>
<li>ENTRYPOINT 指定镜像的默认入口命令，该入口命令会在启动容器时作为根命令执行，所有其他传入值作为该命令的参数。</li>
<li>ENTRYPOINT 的值可以通过<code>docker run --entrypoint</code>来覆盖掉。</li>
<li>只有 Dockerfile 中的最后一条 ENTRYPOINT 指令会起作用。</li>
</ul>
<p>当指定了 ENTRYPOINT 后，CMD 的含义就发生了改变，不再是直接的运行其命令，而是将 CMD 的内容作为参数传给 ENTRYPOINT 指令。换句话说实际执行时，会变成<code>&lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot;</code>。</p>
<p>所以在 dockerfile 中 ENTRYPOINT 里编写一个入口脚本<code>entrypoint.sh</code>或<code>docker-entrypoint.sh</code>。在容器运行的时候通过 ENTRYPOINT 来做一些操作，比如把 volume 挂载的目录权限给改正确，然后再切换普通用户运行正常的程序进程。</p>
<h2 id="gosu-和-su-exec"><a href="#gosu-和-su-exec" class="headerlink" title="gosu 和 su-exec"></a>gosu 和 su-exec</h2><p>gosu 的 github 仓库地址：</p>
<blockquote>
<p><a href="https://github.com/tianon/gosu">https://github.com/tianon/gosu</a></p>
</blockquote>
<p>用法：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ gosu</span><br><span class="line">Usage: ./gosu user-spec <span class="built_in">command</span> [args]</span><br><span class="line">   eg: ./gosu tianon bash</span><br><span class="line">       ./gosu nobody:root bash -c <span class="string">&#x27;whoami &amp;&amp; id&#x27;</span></span><br><span class="line">       ./gosu 1000:1 <span class="built_in">id</span></span><br><span class="line"></span><br><span class="line">./gosu version: 1.1 (go1.3.1 on linux/amd64; gc)</span><br></pre></td></tr></table></figure>

<p>文档中的简单例子：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker run -it --<span class="built_in">rm</span> ubuntu:trusty su -c <span class="string">&#x27;exec ps aux&#x27;</span></span><br><span class="line">USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</span><br><span class="line">root         1  0.0  0.0  46636  2688 ?        Ss+  02:22   0:00 su -c <span class="built_in">exec</span> ps a</span><br><span class="line">root         6  0.0  0.0  15576  2220 ?        Rs   02:22   0:00 ps aux</span><br><span class="line">$ docker run -it --<span class="built_in">rm</span> ubuntu:trusty sudo ps aux</span><br><span class="line">USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</span><br><span class="line">root         1  3.0  0.0  46020  3144 ?        Ss+  02:22   0:00 sudo ps aux</span><br><span class="line">root         7  0.0  0.0  15576  2172 ?        R+   02:22   0:00 ps aux</span><br><span class="line">$ docker run -it --<span class="built_in">rm</span> -v <span class="variable">$PWD</span>/gosu-amd64:/usr/local/bin/gosu:ro ubuntu:trusty gosu root ps aux</span><br><span class="line">USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</span><br><span class="line">root         1  0.0  0.0   7140   768 ?        Rs+  02:22   0:00 ps aux</span><br></pre></td></tr></table></figure>

<p>不管是<code>su</code>还是<code>sudo</code>，他们在执行<code>ps aux</code>命令的 PID 编号都不为 1。在容器中虽然可以，但是这不是一个好的方案，容器里面 PID&#x3D;1 的进程就是应用本身。因此可以使用<code>gosu</code>命令来切换用户执行命令。</p>
<p>对于 debian 安装方法如下：</p>
<h3 id="Debian-9（“Debian-Stretch”）或更新的版本"><a href="#Debian-9（“Debian-Stretch”）或更新的版本" class="headerlink" title="Debian 9（“Debian Stretch”）或更新的版本"></a>Debian 9（“Debian Stretch”）或更新的版本</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">RUN <span class="built_in">set</span> -eux; \</span><br><span class="line"> apt-get update; \</span><br><span class="line"> apt-get install -y gosu; \</span><br><span class="line"> <span class="built_in">rm</span> -rf /var/lib/apt/lists/*; \</span><br><span class="line"><span class="comment"># verify that the binary works</span></span><br><span class="line"> gosu nobody <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<h3 id="较旧的-Debian-版本（或较新的-gosu-版本）"><a href="#较旧的-Debian-版本（或较新的-gosu-版本）" class="headerlink" title="较旧的 Debian 版本（或较新的 gosu 版本）"></a>较旧的 Debian 版本（或较新的 gosu 版本）</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ENV GOSU_VERSION 1.16</span><br><span class="line">RUN <span class="built_in">set</span> -eux; \</span><br><span class="line"><span class="comment"># save list of currently installed packages for later so we can clean up</span></span><br><span class="line"> savedAptMark=<span class="string">&quot;<span class="subst">$(apt-mark showmanual)</span>&quot;</span>; \</span><br><span class="line"> apt-get update; \</span><br><span class="line"> apt-get install -y --no-install-recommends ca-certificates wget; \</span><br><span class="line"> <span class="keyword">if</span> ! <span class="built_in">command</span> -v gpg; <span class="keyword">then</span> \</span><br><span class="line">  apt-get install -y --no-install-recommends gnupg2 dirmngr; \</span><br><span class="line"> <span class="keyword">elif</span> gpg --version | grep -q <span class="string">&#x27;^gpg (GnuPG) 1\.&#x27;</span>; <span class="keyword">then</span> \</span><br><span class="line"><span class="comment"># &quot;This package provides support for HKPS keyservers.&quot; (GnuPG 1.x only)</span></span><br><span class="line">  apt-get install -y --no-install-recommends gnupg-curl; \</span><br><span class="line"> <span class="keyword">fi</span>; \</span><br><span class="line"> <span class="built_in">rm</span> -rf /var/lib/apt/lists/*; \</span><br><span class="line"> \</span><br><span class="line"> dpkgArch=<span class="string">&quot;<span class="subst">$(dpkg --print-architecture | awk -F- &#x27;&#123; print $NF &#125;&#x27;)</span>&quot;</span>; \</span><br><span class="line"> wget -O /usr/local/bin/gosu <span class="string">&quot;https://github.com/tianon/gosu/releases/download/<span class="variable">$GOSU_VERSION</span>/gosu-<span class="variable">$dpkgArch</span>&quot;</span>; \</span><br><span class="line"> wget -O /usr/local/bin/gosu.asc <span class="string">&quot;https://github.com/tianon/gosu/releases/download/<span class="variable">$GOSU_VERSION</span>/gosu-<span class="variable">$dpkgArch</span>.asc&quot;</span>; \</span><br><span class="line"> \</span><br><span class="line"><span class="comment"># verify the signature</span></span><br><span class="line"> <span class="built_in">export</span> GNUPGHOME=<span class="string">&quot;<span class="subst">$(mktemp -d)</span>&quot;</span>; \</span><br><span class="line"> gpg --batch --keyserver hkps://keys.openpgp.org --recv-keys B42F6819007F00F88E364FD4036A9C25BF357DD4; \</span><br><span class="line"> gpg --batch --verify /usr/local/bin/gosu.asc /usr/local/bin/gosu; \</span><br><span class="line"> <span class="built_in">command</span> -v gpgconf &amp;&amp; gpgconf --<span class="built_in">kill</span> all || :; \</span><br><span class="line"> <span class="built_in">rm</span> -rf <span class="string">&quot;<span class="variable">$GNUPGHOME</span>&quot;</span> /usr/local/bin/gosu.asc; \</span><br><span class="line"> \</span><br><span class="line"><span class="comment"># clean up fetch dependencies</span></span><br><span class="line"> apt-mark auto <span class="string">&#x27;.*&#x27;</span> &gt; /dev/null; \</span><br><span class="line"> [ -z <span class="string">&quot;<span class="variable">$savedAptMark</span>&quot;</span> ] || apt-mark manual <span class="variable">$savedAptMark</span>; \</span><br><span class="line"> apt-get purge -y --auto-remove -o APT::AutoRemove::RecommendsImportant=<span class="literal">false</span>; \</span><br><span class="line"> \</span><br><span class="line"> <span class="built_in">chmod</span> +x /usr/local/bin/gosu; \</span><br><span class="line"><span class="comment"># verify that the binary works</span></span><br><span class="line"> gosu --version; \</span><br><span class="line"> gosu nobody <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<h3 id="对于-alpine-3-7"><a href="#对于-alpine-3-7" class="headerlink" title="对于 alpine (3.7+)"></a>对于 alpine (3.7+)</h3><p>当使用 Alpine 时，可能也值得检查一下<code>su-exec</code>（<code>apk add --no-cache su-exec</code>），自从 0.2 版以来，它完全与<code>gosu</code>兼容，文件大小只有几分之一。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ENV GOSU_VERSION 1.16</span><br><span class="line">RUN <span class="built_in">set</span> -eux; \</span><br><span class="line"> \</span><br><span class="line"> apk add --no-cache --virtual .gosu-deps \</span><br><span class="line">  ca-certificates \</span><br><span class="line">  dpkg \</span><br><span class="line">  gnupg \</span><br><span class="line"> ; \</span><br><span class="line"> \</span><br><span class="line"> dpkgArch=<span class="string">&quot;<span class="subst">$(dpkg --print-architecture | awk -F- &#x27;&#123; print $NF &#125;&#x27;)</span>&quot;</span>; \</span><br><span class="line"> wget -O /usr/local/bin/gosu <span class="string">&quot;https://github.com/tianon/gosu/releases/download/<span class="variable">$GOSU_VERSION</span>/gosu-<span class="variable">$dpkgArch</span>&quot;</span>; \</span><br><span class="line"> wget -O /usr/local/bin/gosu.asc <span class="string">&quot;https://github.com/tianon/gosu/releases/download/<span class="variable">$GOSU_VERSION</span>/gosu-<span class="variable">$dpkgArch</span>.asc&quot;</span>; \</span><br><span class="line"> \</span><br><span class="line"><span class="comment"># verify the signature</span></span><br><span class="line"> <span class="built_in">export</span> GNUPGHOME=<span class="string">&quot;<span class="subst">$(mktemp -d)</span>&quot;</span>; \</span><br><span class="line"> gpg --batch --keyserver hkps://keys.openpgp.org --recv-keys B42F6819007F00F88E364FD4036A9C25BF357DD4; \</span><br><span class="line"> gpg --batch --verify /usr/local/bin/gosu.asc /usr/local/bin/gosu; \</span><br><span class="line"> <span class="built_in">command</span> -v gpgconf &amp;&amp; gpgconf --<span class="built_in">kill</span> all || :; \</span><br><span class="line"> <span class="built_in">rm</span> -rf <span class="string">&quot;<span class="variable">$GNUPGHOME</span>&quot;</span> /usr/local/bin/gosu.asc; \</span><br><span class="line"> \</span><br><span class="line"><span class="comment"># clean up fetch dependencies</span></span><br><span class="line"> apk del --no-network .gosu-deps; \</span><br><span class="line"> \</span><br><span class="line"> <span class="built_in">chmod</span> +x /usr/local/bin/gosu; \</span><br><span class="line"><span class="comment"># verify that the binary works</span></span><br><span class="line"> gosu --version; \</span><br><span class="line"> gosu nobody <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<h3 id="entrypoint-脚本文件"><a href="#entrypoint-脚本文件" class="headerlink" title="entrypoint 脚本文件"></a>entrypoint 脚本文件</h3><p>脚本例 1：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"><span class="built_in">set</span> -e</span><br><span class="line"><span class="built_in">ls</span> <span class="variable">$&#123;LOG_PATH&#125;</span> &gt; /dev/null 2&gt;&amp;1 || <span class="built_in">mkdir</span> -p <span class="variable">$&#123;LOG_PATH&#125;</span></span><br><span class="line"><span class="built_in">chown</span> -R www-data <span class="variable">$&#123;LOG_PATH&#125;</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -gt 0 ];<span class="keyword">then</span></span><br><span class="line">    <span class="comment">#su $&#123;USERNAME&#125; -c &quot;exec $@&quot;</span></span><br><span class="line">    <span class="built_in">exec</span> su-exec www-data <span class="variable">$@</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="comment">#su $&#123;USERNAME&#125; -c &quot;exec uwsgi --ini uwsgi.ini --http=0.0.0.0:$&#123;DJANGO_PORT&#125;&quot;</span></span><br><span class="line">    <span class="built_in">exec</span> su-exec www-data uwsgi --ini uwsgi.ini --http=0.0.0.0:<span class="variable">$&#123;DJANGO_PORT&#125;</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>

<p>脚本说明：</p>
<ul>
<li><code>set -e</code>：如果出现命令执行失败，那么就应该退出脚本不继续往下执行，避免失败对后续有影响。可以避免操作失败还继续往下执行的问题。</li>
<li><code>exec</code>：系统调用<code>exec</code>是以新的进程去代替原来的进程，但进程的 PID 保持不变，可以保证容器的主程序 PID&#x3D;1。</li>
</ul>
<p>脚本例 2：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"><span class="built_in">set</span> -e</span><br><span class="line"><span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$1</span>&quot;</span> = <span class="string">&#x27;uwsgi&#x27;</span> -a <span class="string">&quot;<span class="subst">$(id -u)</span>&quot;</span> = <span class="string">&#x27;0&#x27;</span> ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    <span class="built_in">ls</span> <span class="variable">$&#123;LOG_PATH&#125;</span> &gt; /dev/null 2&gt;&amp;1 || <span class="built_in">mkdir</span> -p <span class="variable">$&#123;LOG_PATH&#125;</span></span><br><span class="line">    <span class="built_in">chown</span> -R www-data <span class="variable">$&#123;LOG_PATH&#125;</span></span><br><span class="line">    <span class="built_in">exec</span> su-exec www-data <span class="string">&quot;<span class="variable">$0</span>&quot;</span> <span class="string">&quot;<span class="variable">$@</span>&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">exec</span> <span class="string">&quot;<span class="variable">$@</span>&quot;</span></span><br></pre></td></tr></table></figure>

<p>脚本说明：</p>
<ul>
<li>当前用户是 root 的话, 那么创建和修改 LOG_PATH 目录权限，并切换到 www-data 的身份，带上剩余的参数，再次运行 docker-entrypoint.sh 文件（<code>&quot;$0&quot;</code>表示 docker-entrypoint.sh 本身，<code>&quot;$@&quot;</code>表示剩余的参数）。如果此脚本其他位置还有需要由 www-data 用户执行的代码，则可以一并执行。</li>
<li>当再次执行该脚本时由于已经不是 root 用户了, 会直接执行<code>exec &quot;$@&quot;</code>, 于是直接执行带的参数,即 CMD 定义的脚本。</li>
</ul>
<p>在 Dockerfile 中添加 docker-entrypoint.sh 脚本，并且需要注意<code>x</code>执行权限，否则将无权限执行。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">COPY docker-entrypoint.sh /usr/local/bin/</span><br><span class="line">ENTRYPOINT [<span class="string">&quot;docker-entrypoint.sh&quot;</span>]</span><br></pre></td></tr></table></figure>

<p>通过此 docker-entrypoint.sh 脚本，可以在容器运行时强制把目录权限修改成需要的权限，即使 docker 通过 root 用户初始化创建的 volume 挂载目录。如此一来，就可以通过容器中的普通用户来运行程序，并在这个普通的权限的目录中写入文件。</p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Helm基础使用及语法</title>
    <url>/2022/12/29/helm%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8%E5%8F%8A%E8%AF%AD%E6%B3%95/</url>
    <content><![CDATA[<h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><blockquote>
<p>我们可以将 Helm 看作 Kubernetes 下的 apt-get&#x2F;yum。Helm 是 kubernetes 的包管理器，helm 仓库里面只有配置清单文件,而没有镜像,镜像还是由镜像仓库来提供,比如 hub.docker.com、私有仓库。</p>
</blockquote>
<p>官方文档：</p>
<blockquote>
<p><a href="https://v3.helm.sh/zh/docs/">https://v3.helm.sh/zh/docs/</a></p>
</blockquote>
<h2 id="二、Helm-架构"><a href="#二、Helm-架构" class="headerlink" title="二、Helm 架构"></a>二、Helm 架构</h2><p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202209071137580.png" alt="图片"></p>
<h2 id="三、Helm-安装"><a href="#三、Helm-安装" class="headerlink" title="三、Helm 安装"></a>三、Helm 安装</h2><p>下载地址：</p>
<blockquote>
<p><a href="https://github.com/helm/helm/releases">https://github.com/helm/helm/releases</a></p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 下载包</span></span><br><span class="line">$  wget https://get.helm.sh/helm-v3.9.4-linux-amd64.tar.gz</span><br><span class="line"><span class="comment"># 解压压缩包</span></span><br><span class="line">$ tar -xf helm-v3.9.4-linux-amd64.tar.gz</span><br><span class="line"><span class="comment"># 制作软连接</span></span><br><span class="line">$ <span class="built_in">ln</span> -s /opt/helm/linux-amd64/helm /usr/local/bin/helm</span><br><span class="line"><span class="comment"># 验证</span></span><br><span class="line">$ helm version</span><br><span class="line">$ helm <span class="built_in">help</span></span><br></pre></td></tr></table></figure>

<h2 id="四、Helm-组件及相关术语"><a href="#四、Helm-组件及相关术语" class="headerlink" title="四、Helm 组件及相关术语"></a>四、Helm 组件及相关术语</h2><ul>
<li><code>Helm</code>——Helm 是一个命令行下的<strong>客户端工具</strong>。主要用于 Kubernetes 应用程序 Chart 的创建、打包、发布以及创建和管理本地和远程的 Chart 仓库。</li>
<li><code>Chart</code>——Chart 代表着 <strong>Helm 包</strong>。它包含在 Kubernetes 集群内部运行应用程序，工具或服务所需的所有资源定义。你可以把它看作是 Homebrew formula，Apt dpkg，或 Yum RPM 在 Kubernetes 中的等价物。</li>
<li><code>Release</code>——Release 是运行在 Kubernetes 集群中的 <strong>chart 的实例</strong>。一个 chart 通常可以在同一个集群中安装多次。每一次安装都会创建一个新的 release。</li>
<li><code>Repoistory</code>——Repository（<strong>仓库</strong>） 是用来存放和共享 charts 的地方。它就像 Perl 的 CPAN 档案库网络 或是 Fedora 的 软件包仓库，只不过它是供 Kubernetes 包所使用的。</li>
</ul>
<h2 id="五、Helm-Chart-详解"><a href="#五、Helm-Chart-详解" class="headerlink" title="五、Helm Chart 详解"></a>五、Helm Chart 详解</h2><h3 id="1）Chart-目录结构"><a href="#1）Chart-目录结构" class="headerlink" title="1）Chart 目录结构"></a>1）Chart 目录结构</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 通过helm create命令创建一个新的chart包</span></span><br><span class="line">helm create nginx</span><br><span class="line">tree nginx</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202209071137553.png" alt="图片"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nginx/</span><br><span class="line">├── charts  <span class="comment">#依赖其他包的charts文件</span></span><br><span class="line">├── Chart.yaml <span class="comment"># 该chart的描述文件,包括ico地址,版本信息等</span></span><br><span class="line">├── templates  <span class="comment"># #存放k8s模板文件目录</span></span><br><span class="line">│   ├── deployment.yaml <span class="comment"># 创建k8s资源的yaml 模板</span></span><br><span class="line">│   ├── _helpers.tpl <span class="comment"># 下划线开头的文件,可以被其他模板引用</span></span><br><span class="line">│   ├── hpa.yaml <span class="comment"># 弹性扩缩容，配置服务资源CPU 内存</span></span><br><span class="line">│   ├── ingress.yaml <span class="comment"># ingress 配合service域名访问的配置</span></span><br><span class="line">│   ├── NOTES.txt <span class="comment"># 说明文件,helm install之后展示给用户看的内容</span></span><br><span class="line">│   ├── serviceaccount.yaml <span class="comment"># 服务账号配置</span></span><br><span class="line">│   ├── service.yaml <span class="comment"># kubernetes Serivce yaml 模板</span></span><br><span class="line">│   └── tests <span class="comment"># 测试模块</span></span><br><span class="line">│       └── test-connection.yaml</span><br><span class="line">└── values.yaml <span class="comment"># 给模板文件使用的变量</span></span><br></pre></td></tr></table></figure>

<p>可能有写包还会有以下几个目录：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wordpress/</span><br><span class="line">...</span><br><span class="line">  LICENSE             <span class="comment"># 可选: 包含chart许可证的纯文本文件</span></span><br><span class="line">  README.md           <span class="comment"># 可选: 可读的README文件</span></span><br><span class="line">  values.schema.json  <span class="comment"># 可选: 一个使用JSON结构的values.yaml文件</span></span><br><span class="line">  charts/             <span class="comment"># 包含chart依赖的其他chart</span></span><br><span class="line">  crds/               <span class="comment"># 自定义资源的定义</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h3 id="2）Chart-yaml-文件"><a href="#2）Chart-yaml-文件" class="headerlink" title="2）Chart.yaml 文件"></a>2）Chart.yaml 文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: chart API 版本 （必需）</span><br><span class="line">name: chart名称 （必需）</span><br><span class="line">version: chart 版本，语义化2 版本（必需）</span><br><span class="line">kubeVersion: 兼容Kubernetes版本的语义化版本（可选）</span><br><span class="line">description: 一句话对这个项目的描述（可选）</span><br><span class="line"><span class="built_in">type</span>: chart类型 （可选）</span><br><span class="line">keywords:</span><br><span class="line">  - 关于项目的一组关键字（可选）</span><br><span class="line">home: 项目home页面的URL （可选）</span><br><span class="line">sources:</span><br><span class="line">  - 项目源码的URL列表（可选）</span><br><span class="line">dependencies: <span class="comment"># chart 必要条件列表 （可选）</span></span><br><span class="line">  - name: chart名称 (nginx)</span><br><span class="line">    version: chart版本 (<span class="string">&quot;1.2.3&quot;</span>)</span><br><span class="line">    repository: （可选）仓库URL (<span class="string">&quot;https://example.com/charts&quot;</span>) 或别名 (<span class="string">&quot;@repo-name&quot;</span>)</span><br><span class="line">    condition: （可选） 解析为布尔值的yaml路径，用于启用/禁用chart (e.g. subchart1.enabled )</span><br><span class="line">    tags: <span class="comment"># （可选）</span></span><br><span class="line">      - 用于一次启用/禁用 一组chart的tag</span><br><span class="line">    import-values: <span class="comment"># （可选）</span></span><br><span class="line">      - ImportValue 保存源值到导入父键的映射。每项可以是字符串或者一对子/父列表项</span><br><span class="line">    <span class="built_in">alias</span>: （可选） chart中使用的别名。当你要多次添加相同的chart时会很有用</span><br><span class="line">maintainers: <span class="comment"># （可选）</span></span><br><span class="line">  - name: 维护者名字 （每个维护者都需要）</span><br><span class="line">    email: 维护者邮箱 （每个维护者可选）</span><br><span class="line">    url: 维护者URL （每个维护者可选）</span><br><span class="line">icon: 用做icon的SVG或PNG图片URL （可选）</span><br><span class="line">appVersion: 包含的应用版本（可选）。不需要是语义化，建议使用引号</span><br><span class="line">deprecated: 不被推荐的chart （可选，布尔值）</span><br><span class="line">annotations:</span><br><span class="line">  example: 按名称输入的批注列表 （可选）.</span><br></pre></td></tr></table></figure>

<ul>
<li>从 v3.3.2，不再允许额外的字段。推荐的方法是在 <code>annotations</code> 中添加自定义元数据。</li>
<li>每个 chart 都必须有个版本号（<code>version</code>）。版本必须遵循 语义化版本 2 标准。不像经典 Helm， Helm v2 以及后续版本会使用版本号作为发布标记。仓库中的包通过名称加版本号标识。</li>
</ul>
<p>比如 nginx chart 的版本字段 version: 1.2.3 按照名称被设置为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nginx-1.2.3.tgz</span><br></pre></td></tr></table></figure>

<blockquote>
<p>【温馨提示】<code>appVersion</code>字段与<code>version</code>字段并不相关。这是指定应用版本的一种方式。比如，这个 drupal chart 可能有一个 appVersion: “8.2.1”，表示包含在 chart（默认）的 Drupal 的版本是 8.2.1。</p>
</blockquote>
<h3 id="3）Chart-依赖管理（dependencies）"><a href="#3）Chart-依赖管理（dependencies）" class="headerlink" title="3）Chart 依赖管理（dependencies）"></a>3）Chart 依赖管理（dependencies）</h3><p>当前 chart 依赖的其他 chart 会在 dependencies 字段定义为一个列表。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">dependencies:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">apache</span></span><br><span class="line">    <span class="attr">version:</span> <span class="number">1.2</span><span class="number">.3</span></span><br><span class="line">    <span class="attr">repository:</span> <span class="string">https://example.com/charts</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mysql</span></span><br><span class="line">    <span class="attr">version:</span> <span class="number">3.2</span><span class="number">.1</span></span><br><span class="line">    <span class="attr">repository:</span> <span class="string">https://another.example.com/charts</span></span><br></pre></td></tr></table></figure>

<ul>
<li>name 字段是你需要的 chart 的名称</li>
<li>version 字段是你需要的 chart 的版本</li>
<li>repository 字段是 chart 仓库的完整 URL。注意你必须使用 helm repo add 在本地添加仓库</li>
<li>你可以使用仓库的名称代替 URL</li>
</ul>
<p>示例演示：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm repo add bitnami https://charts.bitnami.com/bitnami</span><br><span class="line">helm pull bitnami/wordpress</span><br><span class="line">tar -xf wordpress</span><br><span class="line"><span class="built_in">cat</span> wordpress/Chart.yaml</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202212291124189.png" alt="图片"><br>一旦你定义好了依赖，运行 <code>helm dependency update</code> 就会使用你的依赖文件下载所有你指定的 chart 到你的 charts&#x2F;目录。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm dependency update ./wordpress</span><br></pre></td></tr></table></figure>

<p>当 helm dependency update 拉取 chart 时，会在 charts&#x2F;目录中形成一个 chart 包。因此对于上面的示例，会在 chart 目录中期望看到以下文件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wordpress/charts/</span><br><span class="line">├── common</span><br><span class="line">├── common-2.0.1.tgz</span><br><span class="line">├── mariadb</span><br><span class="line">├── mariadb-11.2.2.tgz</span><br><span class="line">├── memcached</span><br><span class="line">└── memcached-6.2.3.tgz</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/645.png" alt="图片"></p>
<p>依赖中的tag和条件字段</p>
<blockquote>
<p>除了上面的其他字段外，每个需求项可以包含可选字段 <code>tags</code> 和 <code>condition</code>。<strong>所有的 chart 会默认加载</strong>。如果存在 tags 或者 condition 字段，它们将被评估并用于控制它们应用的 chart 的加载。</p>
</blockquote>
<ul>
<li><code>Condition</code> ——<strong>条件字段</strong>field 包含一个或多个 YAML 路径（用逗号分隔）。如果这个路径在上层 values 中已存在并解析为布尔值，chart 会基于布尔值启用或禁用 chart。只会使用列表中找到的第一个有效路径，如果路径为未找到则条件无效。</li>
<li><code>Tags</code> ——<code>tag</code>字段是与 chart 关联的 YAML 格式的标签列表。在顶层 value 中，通过指定 tag 和布尔值，可以启用或禁用所有的带 tag 的 chart。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># parentchart/Chart.yaml</span></span><br><span class="line"></span><br><span class="line">dependencies:</span><br><span class="line">  - name: subchart1</span><br><span class="line">    repository: http://localhost:10191</span><br><span class="line">    version: 0.1.0</span><br><span class="line">    condition: subchart1.enabled, global.subchart1.enabled</span><br><span class="line">    tags:</span><br><span class="line">      - front-end</span><br><span class="line">      - subchart1</span><br><span class="line">  - name: subchart2</span><br><span class="line">    repository: http://localhost:10191</span><br><span class="line">    version: 0.1.0</span><br><span class="line">    condition: subchart2.enabled,global.subchart2.enabled</span><br><span class="line">    tags:</span><br><span class="line">      - back-end</span><br><span class="line">      - subchart2</span><br><span class="line"><span class="comment"># parentchart/values.yaml</span></span><br><span class="line"></span><br><span class="line">subchart1:</span><br><span class="line">  enabled: <span class="literal">true</span></span><br><span class="line">tags:</span><br><span class="line">  front-end: <span class="literal">false</span></span><br><span class="line">  back-end: <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<ul>
<li>在上面的例子中，所有带 front-end tag 的 chart 都会被禁用，但只要上层的 value 中 <code>subchart1.enabled</code> 路径被设置为 <code>&#39;true&#39;</code>，<strong>该条件会覆盖 front-end 标签且 subchart1 会被启用</strong>。</li>
<li>一旦 subchart2 使用了 back-end 标签并被设置为了 true，subchart2 就会被启用。也要注意尽管 subchart2 指定了一个条件字段， 但是上层 value 没有相应的路径和 value，因此这个条件不会生效。</li>
</ul>
<p><code>--set</code> 参数可以用来设置标签和条件值。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm install --<span class="built_in">set</span> tags.front-end=<span class="literal">true</span> --<span class="built_in">set</span> subchart2.enabled=<span class="literal">false</span></span><br></pre></td></tr></table></figure>

<p>标签和条件的解析：</p>
<ul>
<li>条件 （当设置在 value 中时）总是会覆盖标签 第一个 chart 条件路径存在时会忽略后面的路径。</li>
<li>标签被定义为 ‘如果任意的 chart 标签是 true，chart 就可以启用’。</li>
<li>标签和条件值必须被设置在顶层 value 中。</li>
<li>value 中的 tags:键必须是顶层键。</li>
</ul>
<h3 id="4）通过依赖导入子-Value"><a href="#4）通过依赖导入子-Value" class="headerlink" title="4）通过依赖导入子 Value"></a>4）通过依赖导入子 Value</h3><ul>
<li>在某些情况下，<strong>允许子 chart 的值作为公共默认传递到父 chart 中</strong>是值得的。使用 <code>exports</code>格式的额外好处是它可是将来的工具可以自检用户可设置的值。</li>
<li>被导入的包含值的 key 可以在父 chart 的 dependencies 中的 <code>import-values</code>字段以 YAML 列表形式指定。列表中的每一项是从子 chart 中 exports 字段导入的 key。</li>
<li>导入 exports key 中未包含的值，使用 <strong>子-父格式</strong>。两种格式的示例如下所述。</li>
</ul>
<p>使用导出格式：<br>如果子 chart 的 values.yaml 文件中在根节点包含了 exports 字段，它的内容可以通过指定的可以被直接导入到父 chart 的 value 中， 如下所示：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># parent&#x27;s Chart.yaml file</span></span><br><span class="line"></span><br><span class="line">dependencies:</span><br><span class="line">  - name: subchart</span><br><span class="line">    repository: http://localhost:10191</span><br><span class="line">    version: 0.1.0</span><br><span class="line">    import-values:</span><br><span class="line">      - data</span><br><span class="line"><span class="comment"># child&#x27;s values.yaml file</span></span><br><span class="line"></span><br><span class="line">exports:</span><br><span class="line">  data:</span><br><span class="line">    myint: 99</span><br></pre></td></tr></table></figure>

<blockquote>
<p>只要我们再导入列表中指定了键 data，Helm 就会在子 chart 的 exports 字段查找 data 键并导入它的内容。</p>
</blockquote>
<p>最终的父级 value 会包含我们的导出字段：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># parent&#x27;s values</span></span><br><span class="line"></span><br><span class="line">myint: 99</span><br></pre></td></tr></table></figure>

<blockquote>
<p>【注意】父级键 data 没有包含在父级最终的 value 中，如果想指定这个父级键，要使用<code>&#39;子-父&#39; 格式</code>。</p>
</blockquote>
<p>下面示例中的<code>import-values</code> 指示 Helm 去拿到能再 child:路径中找到的任何值，并拷贝到 parent:的指定路径。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># parent&#x27;s Chart.yaml file</span></span><br><span class="line"></span><br><span class="line">dependencies:</span><br><span class="line">  - name: subchart1</span><br><span class="line">    repository: http://localhost:10191</span><br><span class="line">    version: 0.1.0</span><br><span class="line">    ...</span><br><span class="line">    import-values:</span><br><span class="line">      - child: default.data</span><br><span class="line">        parent: myimports</span><br></pre></td></tr></table></figure>

<p>上面的例子中，在 subchart1 里面找到的 default.data 的值会被导入到父 chart 的 myimports 键中，细节如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># parent&#x27;s values.yaml file</span></span><br><span class="line"></span><br><span class="line">myimports:</span><br><span class="line">  myint: 0</span><br><span class="line">  mybool: <span class="literal">false</span></span><br><span class="line">  mystring: <span class="string">&quot;helm rocks!&quot;</span></span><br><span class="line"><span class="comment"># subchart1&#x27;s values.yaml file</span></span><br><span class="line"></span><br><span class="line">default:</span><br><span class="line">  data:</span><br><span class="line">    myint: 999</span><br><span class="line">    mybool: <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p>父 chart 的结果值将会是这样：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># parent&#x27;s final values</span></span><br><span class="line"></span><br><span class="line">myimports:</span><br><span class="line">  myint: 999</span><br><span class="line">  mybool: <span class="literal">true</span></span><br><span class="line">  mystring: <span class="string">&quot;helm rocks!&quot;</span></span><br></pre></td></tr></table></figure>

<h2 id="六、Templates-and-Values"><a href="#六、Templates-and-Values" class="headerlink" title="六、Templates and Values"></a>六、Templates and Values</h2><h3 id="1）Templates-and-Values-简介"><a href="#1）Templates-and-Values-简介" class="headerlink" title="1）Templates and Values 简介"></a>1）Templates and Values 简介</h3><ul>
<li>Helm Chart 模板是按照 Go 模板语言书写， 增加了 50 个左右的附加模板函数 来自 Sprig 库 和一些其他 指定的函数。</li>
<li>所有模板文件存储在 chart 的 <code>templates/</code> 文件夹。当 Helm 渲染 chart 时，它会通过模板引擎遍历目录中的每个文件。</li>
</ul>
<p>模板的 Value 通过两种方式提供：</p>
<ul>
<li>Chart 开发者可以在 chart 中提供一个命名为 <code>values.yaml</code> 的文件。这个文件包含了默认值。</li>
<li>Chart 用户可以提供一个包含了 value 的 YAML 文件。可以在命令行使用 helm install 命令时通过<code>-f</code>指定 value 文件。</li>
</ul>
<p>模板示例</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicationController</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">deis-database</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">deis</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/managed-by:</span> <span class="string">deis</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">deis-database</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/name:</span> <span class="string">deis-database</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">serviceAccount:</span> <span class="string">deis-database</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">deis-database</span></span><br><span class="line">          <span class="attr">image:</span> &#123;&#123; <span class="string">.Values.imageRegistry</span> &#125;&#125;<span class="string">/postgres:&#123;&#123;</span> <span class="string">.Values.dockerTag</span> <span class="string">&#125;&#125;</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> &#123;&#123; <span class="string">.Values.pullPolicy</span> &#125;&#125;</span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">5432</span></span><br><span class="line">          <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">DATABASE_STORAGE</span></span><br><span class="line">              <span class="attr">value:</span> &#123;&#123; <span class="string">default</span> <span class="string">&quot;minio&quot;</span> <span class="string">.Values.storage</span> &#125;&#125;</span><br></pre></td></tr></table></figure>

<p>上面的例子，松散地基于</p>
<blockquote>
<p><a href="https://github.com/deis/charts">https://github.com/deis/charts</a></p>
</blockquote>
<p>是一个 Kubernetes 副本控制器的模板。可以使用下面四种模板值（一般被定义在 values.yaml 文件）：</p>
<ul>
<li>imageRegistry: Docker 镜像的源注册表</li>
<li>dockerTag: Docker 镜像的 tag</li>
<li>pullPolicy: Kubernetes 的拉取策略</li>
<li>storage: 后台存储，默认设置为”minio”</li>
</ul>
<h3 id="2）预定义的-Values"><a href="#2）预定义的-Values" class="headerlink" title="2）预定义的 Values"></a>2）预定义的 Values</h3><blockquote>
<p>Values 通过模板中.Values 对象可访问的 values.yaml 文件（或者通过 –set 参数)提供， 但可以模板中访问其他预定义的数据片段。</p>
</blockquote>
<p>以下值是预定义的，对每个模板都有效，并且可以被覆盖。和所有值一样，名称 区分大小写。</p>
<ul>
<li><code>Release.Name</code>: 版本名称(非 chart 的)</li>
<li><code>Release.Namespace</code>: 发布的 chart 版本的命名空间</li>
<li><code>Release.Service</code>: 组织版本的服务</li>
<li><code>Release.IsUpgrade</code>: 如果当前操作是升级或回滚，设置为 true</li>
<li><code>Release.IsInstall</code>: 如果当前操作是安装，设置为 true</li>
<li><code>Chart</code>: <code>Chart.yaml</code>的内容。因此，chart 的版本可以从 Chart.Version 获得， 并且维护者在 Chart.Maintainers 里。</li>
<li><code>Files</code>: chart 中的包含了非特殊文件的类图对象。这将不允许您访问模板， 但是可以访问现有的其他文件（除非被.helmignore 排除在外）。使用<code>&#123;&#123; index .Files "file.name" &#125;&#125;</code>可以访问文件或者使用<code>&#123;&#123;.Files.Get name &#125;&#125;</code>功能。您也可以使用<code>&#123;&#123; .Files.GetBytes &#125;&#125;</code>作为[]byte 访问文件内容。</li>
<li><code>Capabilities</code>: 包含了 Kubernetes 版本信息的类图对象。<code>&#123;&#123; .Capabilities.KubeVersion &#125;&#125;</code> 和支持的 Kubernetes API 版本<code>&#123;&#123; .Capabilities.APIVersions.Has "batch/v1" &#125;&#125;</code></li>
</ul>
<p>考虑到前面部分的模板，<code>values.yaml</code>文件提供的必要值如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">imageRegistry: <span class="string">&quot;quay.io/deis&quot;</span></span><br><span class="line">dockerTag: <span class="string">&quot;latest&quot;</span></span><br><span class="line">pullPolicy: <span class="string">&quot;Always&quot;</span></span><br><span class="line">storage: <span class="string">&quot;s3&quot;</span></span><br></pre></td></tr></table></figure>

<p>values 文件被定义为 YAML 格式。chart 会包含一个默认的 values.yaml 文件。Helm 安装命令允许用户使用附加的 YAML values 覆盖这个 values：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm install --generate-name --values=myvals.yaml wordpress</span><br></pre></td></tr></table></figure>

<h3 id="3）范围，依赖和值"><a href="#3）范围，依赖和值" class="headerlink" title="3）范围，依赖和值"></a>3）范围，依赖和值</h3><p><strong>Values 文件</strong>可以声明顶级 chart 的值，以及<code>charts/</code>目录中包含的其他任意 chart。或者换个说法，<strong>values 文件可以为 chart 及其任何依赖项提供值</strong>。比如，上面示范的 WordPress chart 同时有 mysql 和 apache 作为依赖。values 文件可以为以下所有这些组件提供依赖：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">title: <span class="string">&quot;My WordPress Site&quot;</span> <span class="comment"># Sent to the WordPress template</span></span><br><span class="line"></span><br><span class="line">mysql:</span><br><span class="line">  max_connections: 100 <span class="comment"># Sent to MySQL</span></span><br><span class="line">  password: <span class="string">&quot;secret&quot;</span></span><br><span class="line"></span><br><span class="line">apache:</span><br><span class="line">  port: 8080 <span class="comment"># Passed to Apache</span></span><br></pre></td></tr></table></figure>

<p>更<strong>高阶的 chart 可以访问下面定义的所有变量</strong>。因此<strong>WordPress chart 可以用.Values.mysql.password 访问 MySQL 密码</strong>。但是<strong>低阶的 chart 不能访问父级 chart</strong>，所以 MySQL 无法访问 title 属性。同样也无法访问 apache.port。</p>
<h3 id="4）全局-Values"><a href="#4）全局-Values" class="headerlink" title="4）全局 Values"></a>4）全局 Values</h3><p>从 2.0.0-Alpha.2 开始，Helm 支持特殊的”global”值。设想一下前面的示例中的修改版本：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">title: <span class="string">&quot;My WordPress Site&quot;</span> <span class="comment"># Sent to the WordPress template</span></span><br><span class="line"></span><br><span class="line">global:</span><br><span class="line">  app: MyWordPress</span><br><span class="line"></span><br><span class="line">mysql:</span><br><span class="line">  max_connections: 100 <span class="comment"># Sent to MySQL</span></span><br><span class="line">  password: <span class="string">&quot;secret&quot;</span></span><br><span class="line"></span><br><span class="line">apache:</span><br><span class="line">  port: 8080 <span class="comment"># Passed to Apache</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>面添加了 global 部分和一个值 app: MyWordPress。这个值以<code>.Values.global.app</code>在 <strong>所有 chart 中有效</strong>。</p>
</blockquote>
<p>比如，mysql 模板可以以<code>&#123;&#123;.Values.global.app&#125;&#125;</code>访问 app，同样 apache chart 也可以访问。实际上，上面的 values 文件会重新生成为这样：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">title: <span class="string">&quot;My WordPress Site&quot;</span> <span class="comment"># Sent to the WordPress template</span></span><br><span class="line"></span><br><span class="line">global:</span><br><span class="line">  app: MyWordPress</span><br><span class="line"></span><br><span class="line">mysql:</span><br><span class="line">  global:</span><br><span class="line">    app: MyWordPress</span><br><span class="line">  max_connections: 100 <span class="comment"># Sent to MySQL</span></span><br><span class="line">  password: <span class="string">&quot;secret&quot;</span></span><br><span class="line"></span><br><span class="line">apache:</span><br><span class="line">  global:</span><br><span class="line">    app: MyWordPress</span><br><span class="line">  port: 8080 <span class="comment"># Passed to Apache</span></span><br></pre></td></tr></table></figure>

<h2 id="七、Helm-资源安装顺序"><a href="#七、Helm-资源安装顺序" class="headerlink" title="七、Helm 资源安装顺序"></a>七、Helm 资源安装顺序</h2><ul>
<li>Namespace</li>
<li>NetworkPolicy</li>
<li>ResourceQuota</li>
<li>LimitRange</li>
<li>PodSecurityPolicy</li>
<li>PodDisruptionBudget</li>
<li>ServiceAccount</li>
<li>Secret</li>
<li>SecretList</li>
<li>ConfigMap</li>
<li>StorageClass</li>
<li>PersistentVolume</li>
<li>PersistentVolumeClaim</li>
<li>CustomResourceDefinition</li>
<li>ClusterRole</li>
<li>ClusterRoleList</li>
<li>ClusterRoleBinding</li>
<li>ClusterRoleBindingList</li>
<li>Role</li>
<li>RoleList</li>
<li>RoleBinding</li>
<li>RoleBindingList</li>
<li>Service</li>
<li>DaemonSet</li>
<li>Pod</li>
<li>ReplicationController</li>
<li>ReplicaSet</li>
<li>Deployment</li>
<li>HorizontalPodAutoscaler</li>
<li>StatefulSet</li>
<li>Job</li>
<li>CronJob</li>
<li>Ingress</li>
<li>APIService</li>
</ul>
<h2 id="八、Helm-安装-Chart-包的三种方式"><a href="#八、Helm-安装-Chart-包的三种方式" class="headerlink" title="八、Helm 安装 Chart 包的三种方式"></a>八、Helm 安装 Chart 包的三种方式</h2><p>Helm 自带一个强大的搜索命令，可以用来从两种来源中进行搜索：</p>
<ul>
<li><code>helm search hub</code> 从 Artifact Hub <code>https://artifacthub.io/</code> 中查找并列出 helm charts。Artifact Hub 中存放了大量不同的仓库。</li>
<li><code>helm search repo</code> 从你添加（使用 <code>helm repo add</code>）到本地 helm 客户端中的仓库中进行查找。该命令基于本地数据进行搜索，无需连接互联网。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 添加bitnami仓库源</span></span><br><span class="line">helm repo add bitnami https://charts.bitnami.com/bitnami</span><br><span class="line"><span class="comment"># 从bitnami源查找所有chart包，不指定具体源的话，会查找本地添加的所有源地址的所有chart包</span></span><br><span class="line">helm search repo bitnami</span><br></pre></td></tr></table></figure>

<h3 id="1）values-传参"><a href="#1）values-传参" class="headerlink" title="1）values 传参"></a>1）values 传参</h3><p>安装过程中有两种方式传递配置数据：</p>
<ul>
<li><code>--values (或 -f)</code>：使用 YAML 文件覆盖配置。可以指定多次，优先使用最右边的文件。</li>
<li><code>--set</code>：通过命令行的方式对指定项进行覆盖。</li>
</ul>
<p>如果同时使用两种方式，则 –set 中的值会被合并到 –values 中，但是 <code>--set</code> 中的值<strong>优先级更高</strong>。在–set 中覆盖的内容会被被保存在 ConfigMap 中。可以通过 <code>helm get values &lt;release-name&gt;</code> 来<strong>查看指定 release 中 –set 设置的值</strong>。也可以通过运行 helm upgrade 并指定 –reset-values 字段来清除 –set 中设置的值。示例如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;&#123;mariadb.auth.database: user0db, mariadb.auth.username: user0&#125;&#x27;</span> &gt; values.yaml</span><br><span class="line">helm install -f values.yaml bitnami/wordpress --generate-name</span><br></pre></td></tr></table></figure>

<h3 id="2）【第一种方式】直接在线-安装不需要先下载包到本地"><a href="#2）【第一种方式】直接在线-安装不需要先下载包到本地" class="headerlink" title="2）【第一种方式】直接在线 安装不需要先下载包到本地"></a>2）【第一种方式】直接在线 安装不需要先下载包到本地</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm install mysql bitnami/mysql</span><br><span class="line">helm list</span><br></pre></td></tr></table></figure>

<h3 id="3）【第二种方式】离线安装-直接通过安装包安装"><a href="#3）【第二种方式】离线安装-直接通过安装包安装" class="headerlink" title="3）【第二种方式】离线安装 直接通过安装包安装"></a>3）【第二种方式】离线安装 直接通过安装包安装</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 先删除</span></span><br><span class="line">helm uninstall mysql</span><br><span class="line"><span class="comment"># 拉包到本地</span></span><br><span class="line">helm pull bitnami/mysql</span><br><span class="line"><span class="comment"># 不解压直接安装</span></span><br><span class="line">helm install mysql ./mysql-9.3.1.tgz</span><br><span class="line">helm list</span><br></pre></td></tr></table></figure>

<h3 id="4）【第三种方式】离线安装-解压包再安装"><a href="#4）【第三种方式】离线安装-解压包再安装" class="headerlink" title="4）【第三种方式】离线安装 解压包再安装"></a>4）【第三种方式】离线安装 解压包再安装</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 拉包到本地</span></span><br><span class="line">helm pull bitnami/mysql</span><br><span class="line"><span class="comment"># 解压安装</span></span><br><span class="line">tar -xf mysql-9.3.1.tgz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始安装</span></span><br><span class="line">helm install mysql ./mysql \</span><br><span class="line">--namespace=mysql \</span><br><span class="line">--create-namespace \</span><br><span class="line">--<span class="built_in">set</span> image.registry=myharbor.com \</span><br><span class="line">--<span class="built_in">set</span> image.repository=bigdata/mysql \</span><br><span class="line">--<span class="built_in">set</span> image.tag=8.0.30 \</span><br><span class="line">--<span class="built_in">set</span> primary.service.type=NodePort \</span><br><span class="line">--<span class="built_in">set</span> service.nodePorts.mysql=30306</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看在运行的Release</span></span><br><span class="line">helm list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 卸载</span></span><br><span class="line">helm uninstall mysql -n mysql</span><br></pre></td></tr></table></figure>

<h2 id="九、Helm-基础语法"><a href="#九、Helm-基础语法" class="headerlink" title="九、Helm 基础语法"></a>九、Helm 基础语法</h2><h3 id="1）变量"><a href="#1）变量" class="headerlink" title="1）变量"></a>1）变量</h3><p>模板（<code>templates/</code>）中的<strong>变量</strong>都放在<code>&#123;&#123;&#125;&#125;</code>中，比如：<code>&#123;&#123; .Values.images &#125;&#125;</code> 表示 <code>Values 对象</code>下的 images 字段。Values 来源于<code>values.yaml</code>文件或者<code>-f</code>指定的 yaml 文件，或者<code>--set</code>设置的变量。</p>
<blockquote>
<p>【温馨提示】使用<code>-</code>删除空格和换行符，要想删除那行其他的空格和换行符可以用<code>&#123;&#123;-`或者`-&#125;&#125;</code>，**一个是删除左边的<code>空格</code>和<code>换行符</code><strong>，</strong>一个是删除右边的<code>空格</code>和<code>换行符</code>**。</p>
</blockquote>
<h3 id="2）内置对象"><a href="#2）内置对象" class="headerlink" title="2）内置对象"></a>2）内置对象</h3><ul>
<li><p><code>Release</code>：Release 对象描述了版本发布本身。包含了以下对象：</p>
</li>
<li><ul>
<li><code>Release.Name</code>：release 名称；</li>
<li><code>Release.Namespace</code>：版本中包含的命名空间(如果 manifest 没有覆盖的话)；</li>
<li><code>Release.IsUpgrade</code>：如果当前操作是升级或回滚的话，该值将被设置为 true</li>
<li><code>Release.IsInstall</code>：如果当前操作是安装的话，该值将被设置为 true</li>
<li><code>Release.Revision</code>：此次修订的版本号。安装时是 1，每次升级或回滚都会自增；</li>
<li><code>Release.Service</code>：该 service 用来渲染当前模板。Helm 里始终 Helm。</li>
</ul>
</li>
<li><p><code>Values</code>：Values 对象是从<code>values.yaml</code>文件和用户提供的文件传进模板的。默认为空</p>
</li>
<li><p><code>Chart</code>：<code>Chart.yaml</code>文件内容。Chart.yaml 里的所有数据在这里都可以可访问的。比如 <code>&#123;&#123; .Chart.Name &#125;&#125;-&#123;&#123; .Chart.Version &#125;&#125;</code> 会打印出 mychart-0.1.0。</p>
</li>
<li><p><code>Template</code>：包含当前被执行的当前模板信息</p>
</li>
<li><ul>
<li><code>Template.Name</code>: 当前模板的命名空间文件路径 (e.g. mychart&#x2F;templates&#x2F;mytemplate.yaml)；</li>
<li><code>Template.BasePath</code>: 当前 chart 模板目录的路径 (e.g. mychart&#x2F;templates)。</li>
</ul>
</li>
</ul>
<h3 id="3）常用的内置函数"><a href="#3）常用的内置函数" class="headerlink" title="3）常用的内置函数"></a>3）常用的内置函数</h3><h4 id="1、quote-and-squote"><a href="#1、quote-and-squote" class="headerlink" title="1、quote and squote"></a>1、quote and squote</h4><p>该函数将值转<strong>换成字符串</strong>用<strong>双引号(<code>quote</code>)</strong> 或者**单引号(<code>squote</code>)**括起来。示例如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> &#123;&#123; <span class="string">.Release.Name</span> &#125;&#125;<span class="string">-configmap</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">myvalue:</span> <span class="string">&quot;Hello World&quot;</span></span><br><span class="line">  <span class="attr">drink:</span> &#123;&#123; <span class="string">.Values.favorite.drink</span> <span class="string">|</span> <span class="string">quote</span> &#125;&#125;</span><br><span class="line">  <span class="attr">food:</span> &#123;&#123; <span class="string">.Values.favorite.food</span> <span class="string">|</span> <span class="string">upper</span> <span class="string">|</span> <span class="string">quote</span> &#125;&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>倒置命令是模板中的常见做法。可以经常看到 <code>.val | quote</code> 而不是 <code>quote .val</code>。实际上两种操作都是可以的。</p>
</blockquote>
<h4 id="2、default"><a href="#2、default" class="headerlink" title="2、default"></a>2、default</h4><p>这个函数允许你在模板中指定一个默认值，以防这个值被忽略。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 如果.Values.favorite.drink是非空值，则使用它，否则会返回tea。</span></span><br><span class="line">drink: &#123;&#123; .Values.favorite.drink | default <span class="string">&quot;tea&quot;</span> | quote &#125;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 还可以这样写，如果.Bar是非空值，则使用它，否则会返回foo。</span></span><br><span class="line">default <span class="string">&quot;foo&quot;</span> .Bar</span><br></pre></td></tr></table></figure>

<p>“空”定义取决于以下类型：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">整型: 0</span><br><span class="line">字符串: &quot;&quot;</span><br><span class="line">列表: []</span><br><span class="line">字典: &#123;&#125;</span><br><span class="line">布尔: false</span><br><span class="line">以及所有的nil (或 null)</span><br></pre></td></tr></table></figure>

<h4 id="3、print"><a href="#3、print" class="headerlink" title="3、print"></a>3、print</h4><p>返回各部分组合的字符串，非字符串类型会被转换成字符串。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span> <span class="string">&quot;Matt has &quot;</span> .Dogs <span class="string">&quot; dogs&quot;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>【温馨提示】当相邻两个参数不是字符串时会在它们之间添加一个空格。</p>
</blockquote>
<h4 id="4、println"><a href="#4、println" class="headerlink" title="4、println"></a>4、println</h4><p>和 print 效果一样，但会在末尾新添加一行。</p>
<h4 id="5、printf"><a href="#5、printf" class="headerlink" title="5、printf"></a>5、printf</h4><p>返回参数按顺序传递的格式化字符串。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">printf</span> <span class="string">&quot;%s has %d dogs.&quot;</span> .Name .NumberDogs</span><br><span class="line">&#123;&#123;- <span class="built_in">printf</span> <span class="string">&quot;%d&quot;</span> (.Values.externalCache.port | int ) -&#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="built_in">printf</span> <span class="string">&quot;%s&quot;</span> .Values.existingSecret -&#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123;- <span class="built_in">printf</span> <span class="string">&quot;%v&quot;</span> .context.Values.redis.enabled -&#125;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># %s 字符串占位符，未解析的二进制字符串或切片</span></span><br><span class="line"><span class="comment"># %d 数字占位符，十进制</span></span><br><span class="line"><span class="comment"># %v 默认格式的值，当打印字典时，加号参数(%+v)可以添加字段名称</span></span><br></pre></td></tr></table></figure>

<p>更多占位符的使用，可以参考官方文档：</p>
<blockquote>
<p><a href="https://helm.sh/zh/docs/chart_template_guide/function_list/">https://helm.sh/zh/docs/chart_template_guide/function_list/</a></p>
</blockquote>
<h4 id="6、trim"><a href="#6、trim" class="headerlink" title="6、trim"></a>6、trim</h4><p>trim 行数移除字符串两边的空格：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">trim <span class="string">&quot;   hello    &quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="7、trimAll"><a href="#7、trimAll" class="headerlink" title="7、trimAll"></a>7、trimAll</h4><p>从字符串中移除给定的字符：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">trimAll <span class="string">&quot;$&quot;</span> <span class="string">&quot;<span class="variable">$5</span>.00&quot;</span></span><br></pre></td></tr></table></figure>

<p>上述结果为：5.00 (作为一个字符串)。</p>
<h4 id="8、lower"><a href="#8、lower" class="headerlink" title="8、lower"></a>8、lower</h4><p>将整个字符串转换成小写：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lower <span class="string">&quot;HELLO&quot;</span></span><br></pre></td></tr></table></figure>

<p>上述结果为：hello</p>
<h4 id="9、upper"><a href="#9、upper" class="headerlink" title="9、upper"></a>9、upper</h4><p>将整个字符串转换成大写：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">upper <span class="string">&quot;hello&quot;</span></span><br></pre></td></tr></table></figure>

<p>上述结果为：HELLO</p>
<h4 id="10、title"><a href="#10、title" class="headerlink" title="10、title"></a>10、title</h4><p>首字母转换成大写：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">title <span class="string">&quot;hello world&quot;</span></span><br></pre></td></tr></table></figure>

<p>上述结果为：Hello World</p>
<h4 id="11、substr"><a href="#11、substr" class="headerlink" title="11、substr"></a>11、substr</h4><p>获取字符串的子串，有三个参数：</p>
<ul>
<li>start (int)</li>
<li>end (int)</li>
<li>string (string)</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">substr 0 5 <span class="string">&quot;hello world&quot;</span></span><br></pre></td></tr></table></figure>

<p>上述结果为：hello</p>
<h4 id="12、abbrev"><a href="#12、abbrev" class="headerlink" title="12、abbrev"></a>12、abbrev</h4><p>用省略号截断字符串 (…)</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">abbrev 5 <span class="string">&quot;hello world&quot;</span></span><br><span class="line"><span class="comment"># 第一个参数：最大长度</span></span><br><span class="line"><span class="comment"># 第二个参数：字符串</span></span><br></pre></td></tr></table></figure>

<p>上述结果为：he…， 因为将省略号算进了长度中。</p>
<h4 id="13、contains"><a href="#13、contains" class="headerlink" title="13、contains"></a>13、contains</h4><p>测试字符串是否包含在另一个字符串中：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">contains <span class="string">&quot;cat&quot;</span> <span class="string">&quot;catch&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="14、cat"><a href="#14、cat" class="headerlink" title="14、cat"></a>14、cat</h4><p>cat 函数将多个字符串合并成一个，用空格分隔：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> <span class="string">&quot;hello&quot;</span> <span class="string">&quot;beautiful&quot;</span> <span class="string">&quot;world&quot;</span></span><br></pre></td></tr></table></figure>

<p>上述结果为：hello beautiful world</p>
<h4 id="15、indent"><a href="#15、indent" class="headerlink" title="15、indent"></a>15、indent</h4><p>indent 以<strong>指定长度缩进</strong>给定字符串所在行，在对齐多行字符串时很有用：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">indent 4 <span class="variable">$lots_of_text</span></span><br></pre></td></tr></table></figure>

<p>上述结果会将每行缩进 4 个空格。</p>
<h4 id="16、nindent"><a href="#16、nindent" class="headerlink" title="16、nindent"></a>16、nindent</h4><p>nindent 函数和 indent 函数一样，但可以在字符串开头添加新行。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nindent 4 <span class="variable">$lots_of_text</span></span><br></pre></td></tr></table></figure>

<p>上述结果会在字符串所在行缩进 4 个字符，并且在开头新添加一行。</p>
<h4 id="17、replace"><a href="#17、replace" class="headerlink" title="17、replace"></a>17、replace</h4><p>执行简单的字符串替换。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 下面两行等价</span></span><br><span class="line">replace <span class="string">&quot; &quot;</span> <span class="string">&quot;-&quot;</span> <span class="string">&quot;I Am Henry VIII&quot;</span></span><br><span class="line"><span class="string">&quot;I Am Henry VIII&quot;</span> | replace <span class="string">&quot; &quot;</span> <span class="string">&quot;-&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数1：待替换字符串</span></span><br><span class="line"><span class="comment"># 参数2：要替换字符串</span></span><br><span class="line"><span class="comment"># 参数3：源字符串</span></span><br></pre></td></tr></table></figure>

<p>上述结果为：I-Am-Henry-VIII</p>
<h4 id="18、date"><a href="#18、date" class="headerlink" title="18、date"></a>18、date</h4><p>date 函数格式化日期，日期格式化为 YEAR-MONTH-DAY：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">now | <span class="built_in">date</span> <span class="string">&quot;2006-01-02&quot;</span></span><br></pre></td></tr></table></figure>

<p>想了解更多内置函数，可以参考官方文档：</p>
<blockquote>
<p><a href="https://helm.sh/zh/docs/chart_template_guide/function_list/">https://helm.sh/zh/docs/chart_template_guide/function_list/</a></p>
</blockquote>
<h3 id="4）类型转换函数"><a href="#4）类型转换函数" class="headerlink" title="4）类型转换函数"></a>4）类型转换函数</h3><p>Helm 提供了以下类型转换函数：</p>
<ul>
<li><code>atoi</code>: 字符串转换成整型。</li>
<li><code>float64</code>: 转换成 float64。</li>
<li><code>int</code>: 按系统整型宽度转换成 int。</li>
<li><code>int64</code>: 转换成 int64。</li>
<li><code>toDecimal</code>: 将 unix 八进制转换成 int64。</li>
<li><code>toString</code>: 转换成字符串。</li>
<li><code>toStrings</code>: 将列表、切片或数组转换成字符串列表。</li>
<li><code>toJson (mustToJson)</code>: 将列表、切片、数组、字典或对象转换成 JSON。</li>
<li><code>toPrettyJson (mustToPrettyJson)</code>: 将列表、切片、数组、字典或对象转换成格式化 JSON。</li>
<li><code>toRawJson (mustToRawJson)</code>: 将列表、切片、数组、字典或对象转换成 HTML 字符未转义的 JSON。</li>
</ul>
<h3 id="5）正则表达式（Regular-Expressions）"><a href="#5）正则表达式（Regular-Expressions）" class="headerlink" title="5）正则表达式（Regular Expressions）"></a>5）正则表达式（Regular Expressions）</h3><p>Helm 包含以下正则表达式函数</p>
<ul>
<li>regexFind(mustRegexFind)</li>
<li>regexFindAll(mustRegexFindAll)</li>
<li>regexMatch (mustRegexMatch)</li>
<li>regexReplaceAll (mustRegexReplaceAll)</li>
<li>regexReplaceAllLiteral(mustRegexReplaceAllLiteral)</li>
<li>regexSplit (mustRegexSplit)</li>
</ul>
<h3 id="6）编码和解码函数"><a href="#6）编码和解码函数" class="headerlink" title="6）编码和解码函数"></a>6）编码和解码函数</h3><p>Helm 有以下编码和解码函数：</p>
<ul>
<li>b64enc&#x2F;b64dec: 编码或解码 Base64</li>
<li>b32enc&#x2F;b32dec: 编码或解码 Base32</li>
</ul>
<h3 id="7）Dictionaries-and-Dict-Functions"><a href="#7）Dictionaries-and-Dict-Functions" class="headerlink" title="7）Dictionaries and Dict Functions"></a>7）Dictionaries and Dict Functions</h3><blockquote>
<p>Helm 提供了一个 key&#x2F;value 存储类型称为 dict（”dictionary”的简称，Python 中也有）。dict 是无序类型。<strong>字典的 key 必须是字符串</strong>。<strong>但值可以是任意类型，甚至是另一个 dict 或 list</strong>。</p>
</blockquote>
<h4 id="1、创建字典（dict）"><a href="#1、创建字典（dict）" class="headerlink" title="1、创建字典（dict）"></a>1、创建字典（dict）</h4><p>下面是创建三个键值对的字典：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$myDict</span> := dict <span class="string">&quot;name1&quot;</span> <span class="string">&quot;value1&quot;</span> <span class="string">&quot;name2&quot;</span> <span class="string">&quot;value2&quot;</span> <span class="string">&quot;name3&quot;</span> <span class="string">&quot;value 3&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="2、获取值（get）"><a href="#2、获取值（get）" class="headerlink" title="2、获取值（get）"></a>2、获取值（get）</h4><p>给定一个映射和一个键，从映射中获取值。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">get <span class="variable">$myDict</span> <span class="string">&quot;name1&quot;</span></span><br></pre></td></tr></table></figure>

<p>上述结果为：”value1”</p>
<blockquote>
<p>注意如果没有找到，会简单返回””。不会生成 error。</p>
</blockquote>
<h4 id="3、添加键值对（set）"><a href="#3、添加键值对（set）" class="headerlink" title="3、添加键值对（set）"></a>3、添加键值对（set）</h4><p>使用 set 给字典添加一个键值对。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$_</span> := <span class="built_in">set</span> <span class="variable">$myDict</span> <span class="string">&quot;name4&quot;</span> <span class="string">&quot;value4&quot;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意 set 返回字典 (Go 模板函数的一个要求)，因此你可能需要像上面那样使用使用<code>$_</code>赋值来获取值。</p>
</blockquote>
<h4 id="4、删除（unset）"><a href="#4、删除（unset）" class="headerlink" title="4、删除（unset）"></a>4、删除（unset）</h4><p>给定一个映射和 key，从映射中删除这个 key。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$_</span> := <span class="built_in">unset</span> <span class="variable">$myDict</span> <span class="string">&quot;name4&quot;</span></span><br></pre></td></tr></table></figure>

<p>和 set 一样，需要返回字典。</p>
<h4 id="5、判断-key（hasKey）"><a href="#5、判断-key（hasKey）" class="headerlink" title="5、判断 key（hasKey）"></a>5、判断 key（hasKey）</h4><p>hasKey 函数会在给定字典中包含了给定 key 时返回 true。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hasKey <span class="variable">$myDict</span> <span class="string">&quot;name1&quot;</span></span><br></pre></td></tr></table></figure>

<p>如果 key 没找到，会返回 false。</p>
<h4 id="6、pluck"><a href="#6、pluck" class="headerlink" title="6、pluck"></a>6、pluck</h4><p>pluck 函数给定一个键和多个映射，并获得所有匹配项的列表：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pluck <span class="string">&quot;name1&quot;</span> <span class="variable">$myDict</span> <span class="variable">$myOtherDict</span></span><br></pre></td></tr></table></figure>

<p>上述会返回的 list 包含了每个找到的值([value1 otherValue1])。</p>
<h4 id="7、合并-dict（merge-mustMerge）"><a href="#7、合并-dict（merge-mustMerge）" class="headerlink" title="7、合并 dict（merge, mustMerge）"></a>7、合并 dict（merge, mustMerge）</h4><p>将两个或多个字典合并为一个， 目标字典优先：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$newdict</span> := merge <span class="variable">$dest</span> <span class="variable">$source1</span> <span class="variable">$source2</span></span><br></pre></td></tr></table></figure>

<h4 id="8、获取所有-keys"><a href="#8、获取所有-keys" class="headerlink" title="8、获取所有 keys"></a>8、获取所有 keys</h4><p>keys 函数会返回一个或多个 dict 类型中所有的 key 的 list。由于字典是 无序的，key 不会有可预料的顺序。可以使用 sortAlpha 存储。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">keys <span class="variable">$myDict</span> | sortAlpha</span><br></pre></td></tr></table></figure>

<blockquote>
<p>当提供了多个词典时，key 会被串联起来。使用<code>uniq</code>函数和<code>sortAlpha</code>获取一个唯一有序的键列表。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">keys <span class="variable">$myDict</span> <span class="variable">$myOtherDict</span> | <span class="built_in">uniq</span> | sortAlpha</span><br></pre></td></tr></table></figure>

<h4 id="9、获取所有-values"><a href="#9、获取所有-values" class="headerlink" title="9、获取所有 values"></a>9、获取所有 values</h4><p>values 函数类似于 keys，返回一个新的 list 包含源字典中所有的 value(只支持一个字典)。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$vals</span> := values <span class="variable">$myDict</span></span><br></pre></td></tr></table></figure>

<p>上述结果为：list[“value1”, “value2”, “value 3”]。</p>
<blockquote>
<p>注意 values 不能保证结果的顺序；如果你需要顺序， 请使用<code>sortAlpha</code>。</p>
</blockquote>
<h3 id="8）Lists-and-List-Functions"><a href="#8）Lists-and-List-Functions" class="headerlink" title="8）Lists and List Functions"></a>8）Lists and List Functions</h3><blockquote>
<p>Helm 提供了一个简单的 list 类型，包含任意顺序的列表。类似于数组或切片，但列表是被设计用于不可变数据类型。</p>
</blockquote>
<h4 id="1、创建列表"><a href="#1、创建列表" class="headerlink" title="1、创建列表"></a>1、创建列表</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$myList</span> := list 1 2 3 4 5</span><br></pre></td></tr></table></figure>

<p>上述会生成一个列表 [1 2 3 4 5]。</p>
<h4 id="2、获取列表第一项（first-mustFirst）"><a href="#2、获取列表第一项（first-mustFirst）" class="headerlink" title="2、获取列表第一项（first, mustFirst）"></a>2、获取列表第一项（first, mustFirst）</h4><p>获取列表中的第一项，使用 first。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">first <span class="variable">$myList</span></span><br><span class="line"><span class="comment"># 返回 1</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>first 有问题时会出错，mustFirst 有问题时会向模板引擎返回错误。</p>
</blockquote>
<h4 id="3、获取列表的尾部内容（rest-mustRest）"><a href="#3、获取列表的尾部内容（rest-mustRest）" class="headerlink" title="3、获取列表的尾部内容（rest, mustRest）"></a>3、获取列表的尾部内容（rest, mustRest）</h4><p>获取列表的尾部内容(除了第一项外的所有内容)，使用 rest。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rest <span class="variable">$myList</span></span><br><span class="line"><span class="comment"># 返回 [2 3 4 5]</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>rest 有问题时会出错，mustRest 有问题时会向模板引擎返回错误。</p>
</blockquote>
<h4 id="4、获取列表的最后一项（last-mustLast）"><a href="#4、获取列表的最后一项（last-mustLast）" class="headerlink" title="4、获取列表的最后一项（last, mustLast）"></a>4、获取列表的最后一项（last, mustLast）</h4><p>使用 last 获取列表的最后一项：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">last <span class="variable">$myList</span></span><br><span class="line"><span class="comment"># 返回 5。这大致类似于反转列表然后调用first。</span></span><br></pre></td></tr></table></figure>

<h4 id="5、获取列表所有内容（initial-mustInitial）"><a href="#5、获取列表所有内容（initial-mustInitial）" class="headerlink" title="5、获取列表所有内容（initial, mustInitial）"></a>5、获取列表所有内容（initial, mustInitial）</h4><p>通过返回所有元素 但 除了最后一个元素。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">initial <span class="variable">$myList</span></span><br><span class="line"><span class="comment"># 返回 [1 2 3 4]。</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>initial 有问题时会出错，但是 mustInitial 有问题时会向模板引擎返回错误。</p>
</blockquote>
<h4 id="6、末尾添加元素（append-mustAppend）"><a href="#6、末尾添加元素（append-mustAppend）" class="headerlink" title="6、末尾添加元素（append, mustAppend）"></a>6、末尾添加元素（append, mustAppend）</h4><p>在已有列表中追加一项，创建一个新的列表。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$new</span> = append <span class="variable">$myList</span> 6</span><br></pre></td></tr></table></figure>

<p>上述语句会设置 为。myList 会保持不变。</p>
<blockquote>
<p>append 有问题时会出错，但 mustAppend 有问题时会向模板引擎返回错误。</p>
</blockquote>
<h4 id="7、前面添加元素（prepend-mustPrepend）"><a href="#7、前面添加元素（prepend-mustPrepend）" class="headerlink" title="7、前面添加元素（prepend, mustPrepend）"></a>7、前面添加元素（prepend, mustPrepend）</h4><p>将元素添加到列表的前面，生成一个新的列表。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">prepend <span class="variable">$myList</span> 0</span><br></pre></td></tr></table></figure>

<p>上述语句会生成 [0 1 2 3 4 5]。$myList 会保持不变。</p>
<blockquote>
<p>prepend 有问题时会出错，但 mustPrepend 有问题时会向模板引擎返回错误。</p>
</blockquote>
<h4 id="8、多列表连接（concat）"><a href="#8、多列表连接（concat）" class="headerlink" title="8、多列表连接（concat）"></a>8、多列表连接（concat）</h4><p>将任意数量的列表串联成一个。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">concat <span class="variable">$myList</span> ( list 6 7 ) ( list 8 )</span><br></pre></td></tr></table></figure>

<p>上述语句会生成 [1 2 3 4 5 6 7 8]。$myList 会保持不变。</p>
<h4 id="9、反转（reverse-mustReverse）"><a href="#9、反转（reverse-mustReverse）" class="headerlink" title="9、反转（reverse, mustReverse）"></a>9、反转（reverse, mustReverse）</h4><p>反转给定的列表生成一个新列表。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">reverse <span class="variable">$myList</span></span><br></pre></td></tr></table></figure>

<p>上述语句会生成一个列表：[5 4 3 2 1]。</p>
<blockquote>
<p>reverse 有问题时会出错，但 mustReverse 有问题时会向模板引擎返回错误。</p>
</blockquote>
<h4 id="10、去重（uniq-mustUniq）"><a href="#10、去重（uniq-mustUniq）" class="headerlink" title="10、去重（uniq, mustUniq）"></a>10、去重（uniq, mustUniq）</h4><p>生成一个移除重复项的列表。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">list 1 1 1 2 | <span class="built_in">uniq</span></span><br></pre></td></tr></table></figure>

<p>上述语句会生成 [1 2]</p>
<blockquote>
<p>uniq 有问题时会出错，但 mustUniq 有问题时会向模板引擎返回错误。</p>
</blockquote>
<h4 id="11、过滤（without-mustWithout）"><a href="#11、过滤（without-mustWithout）" class="headerlink" title="11、过滤（without, mustWithout）"></a>11、过滤（without, mustWithout）</h4><p>without 函数从列表中过滤内容。<br>    without $myList 3<br>    # 上述语句会生成 [1 2 4 5]</p>
<p>一个过滤器可以过滤多个元素：<br>    without $myList 1 3 5<br>    # 这样会得到： [2 4]</p>
<blockquote>
<p>without 有问题时会出错，但 mustWithout 有问题时会向模板引擎返回错误。</p>
</blockquote>
<h4 id="12、判断元素是否存在（has-mustHas）"><a href="#12、判断元素是否存在（has-mustHas）" class="headerlink" title="12、判断元素是否存在（has, mustHas）"></a>12、判断元素是否存在（has, mustHas）</h4><p>验证列表是否有特定元素。<br>    has 4 $myList</p>
<p>上述语句会返回 true, 但 has “hello” $myList 就会返回 false。</p>
<blockquote>
<p>has 有问题时会出错，但 mustHas 有问题时会向模板引擎返回错误。</p>
</blockquote>
<h4 id="13、删除空项（compact-mustCompact）"><a href="#13、删除空项（compact-mustCompact）" class="headerlink" title="13、删除空项（compact, mustCompact）"></a>13、删除空项（compact, mustCompact）</h4><p>接收一个列表并删除空值项。<br>    $list :&#x3D; list 1 “a” “foo” “”<br>    $copy :&#x3D; compact $list</p>
<p>compact 会返回一个移除了空值(比如， “”)的新列表。</p>
<blockquote>
<p>compact 有问题时会出错，但 mustCompact 有问题时会向模板引擎返回错误。</p>
</blockquote>
<h4 id="14、index"><a href="#14、index" class="headerlink" title="14、index"></a>14、index</h4><p>使用 index list [n]获取列表的第 n 个元素。使用 index list [n] [m] …获取多位列表元素。</p>
<ul>
<li>index $myList 0 返回 1，同 myList[0]</li>
<li>index $myList 0 1 同 myList[0][1]</li>
</ul>
<h4 id="15、获取部分元素（slice-mustSlice）"><a href="#15、获取部分元素（slice-mustSlice）" class="headerlink" title="15、获取部分元素（slice, mustSlice）"></a>15、获取部分元素（slice, mustSlice）</h4><p>从列表中获取部分元素，使用 slice list [n] [m]。等同于 list[n:m].</p>
<ul>
<li>slice $myList 返回 [1 2 3 4 5]。等同于 myList[:]。</li>
<li>slice $myList 3 返回 [4 5]等同于 myList[3:]。</li>
<li>slice $myList 1 3 返回 [2 3]等同于 myList[1:3]。</li>
<li>slice $myList 0 3 返回 [1 2 3]等同于 myList[:3]。</li>
</ul>
<blockquote>
<p>slice 有问题时会出错，但 mustSlice 有问题时会向模板引擎返回错误。</p>
</blockquote>
<h4 id="16、构建一个整数列表（until）"><a href="#16、构建一个整数列表（until）" class="headerlink" title="16、构建一个整数列表（until）"></a>16、构建一个整数列表（until）</h4><p>until 函数构建一个整数范围。<br>    until 5</p>
<p>上述语句会生成一个列表：[0, 1, 2, 3, 4]。</p>
<p>对循环语句很有用：range e :&#x3D; until 5。</p>
<h4 id="17、seq"><a href="#17、seq" class="headerlink" title="17、seq"></a>17、seq</h4><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">seq <span class="number">5</span>       =&gt; <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span></span><br><span class="line">seq <span class="number">-3</span>      =&gt; <span class="number">1</span> <span class="number">0</span> <span class="number">-1</span> <span class="number">-2</span> <span class="number">-3</span></span><br><span class="line">seq <span class="number">0</span> <span class="number">2</span>     =&gt; <span class="number">0</span> <span class="number">1</span> <span class="number">2</span></span><br><span class="line">seq <span class="number">2</span> <span class="number">-2</span>    =&gt; <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">-1</span> <span class="number">-2</span></span><br><span class="line">seq <span class="number">0</span> <span class="number">2</span> <span class="number">10</span>  =&gt; <span class="number">0</span> <span class="number">2</span> <span class="number">4</span> <span class="number">6</span> <span class="number">8</span> <span class="number">10</span></span><br><span class="line">seq <span class="number">0</span> <span class="number">-2</span> <span class="number">-5</span> =&gt; <span class="number">0</span> <span class="number">-2</span> <span class="number">-4</span></span><br></pre></td></tr></table></figure>

<h3 id="9）数学函数（Math-Functions）"><a href="#9）数学函数（Math-Functions）" class="headerlink" title="9）数学函数（Math Functions）"></a>9）数学函数（Math Functions）</h3><h4 id="1、求和（add）"><a href="#1、求和（add）" class="headerlink" title="1、求和（add）"></a>1、求和（add）</h4><p>使用 add 求和。接受两个或多个输入。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">add <span class="number">1</span> <span class="number">2</span> <span class="number">3</span></span><br></pre></td></tr></table></figure>

<h4 id="2、自加-1（add1）"><a href="#2、自加-1（add1）" class="headerlink" title="2、自加 1（add1）"></a>2、自加 1（add1）</h4><p>自增加 1，使用 add1。</p>
<h4 id="3、相减（sub）"><a href="#3、相减（sub）" class="headerlink" title="3、相减（sub）"></a>3、相减（sub）</h4><p>相减使用 sub。</p>
<h4 id="4、除（div）"><a href="#4、除（div）" class="headerlink" title="4、除（div）"></a>4、除（div）</h4><p>整除使用 div。</p>
<h4 id="5、取模（mod）"><a href="#5、取模（mod）" class="headerlink" title="5、取模（mod）"></a>5、取模（mod）</h4><p>取模使用 mod。</p>
<h4 id="6、相乘（mul）"><a href="#6、相乘（mul）" class="headerlink" title="6、相乘（mul）"></a>6、相乘（mul）</h4><p>相乘使用 mul。接受两个或多个输入。<br>    mul 1 2 3</p>
<h4 id="7、获取最大值（max）"><a href="#7、获取最大值（max）" class="headerlink" title="7、获取最大值（max）"></a>7、获取最大值（max）</h4><p>返回一组整数中最大的整数。<br>    max 1 2 3<br>    # 返回 3</p>
<h4 id="8、获取最小值（min）"><a href="#8、获取最小值（min）" class="headerlink" title="8、获取最小值（min）"></a>8、获取最小值（min）</h4><p>返回一组数中最小的数。<br>    min 1 2 3<br>    # 会返回 1。</p>
<h4 id="9、获取长度（len）"><a href="#9、获取长度（len）" class="headerlink" title="9、获取长度（len）"></a>9、获取长度（len）</h4><p>以整数返回参数的长度。<br>    len .Arg</p>
<h4 id="10、Network-Functions"><a href="#10、Network-Functions" class="headerlink" title="10、Network Functions"></a>10、Network Functions</h4><p>Helm 提供了几个网络函数：</p>
<ul>
<li><code>getHostByName</code>接收一个域名返回 IP 地址。</li>
<li><code>getHostByName</code> “<a href="http://www.google.com"会返回对应的/">www.google.com"会返回对应的</a> <a href="http://www.google.com/">www.google.com</a> 的地址。</li>
</ul>
<h3 id="10）条件语句"><a href="#10）条件语句" class="headerlink" title="10）条件语句"></a>10）条件语句</h3><p><strong>运算符：</strong></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">eq<span class="punctuation">:</span> 等于（equal to）</span><br><span class="line">ne<span class="punctuation">:</span> 不等于（not equal to）</span><br><span class="line">lt<span class="punctuation">:</span> 小于（less than）</span><br><span class="line">le<span class="punctuation">:</span> 小于等于（less than or equal to）</span><br><span class="line">gt<span class="punctuation">:</span> 大于（greater than）</span><br><span class="line">ge<span class="punctuation">:</span> 大于等于（greater than or equal to）</span><br></pre></td></tr></table></figure>

<p><strong>if&#x2F;else 用法：</strong></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">    <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>if 命令<span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">    …</span><br><span class="line">    <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>else if 命令<span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">    …</span><br><span class="line">    <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>else<span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">    …</span><br><span class="line">    <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>end<span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line">如果是以下值时，管道会被设置为 <span class="literal"><span class="keyword">false</span></span>：</span><br><span class="line">    布尔<span class="literal"><span class="keyword">false</span></span></span><br><span class="line">    数字<span class="number">0</span></span><br><span class="line">    空字符串</span><br><span class="line">    nil (空或<span class="literal"><span class="keyword">null</span></span>)</span><br><span class="line">    空集合(map<span class="punctuation">,</span> slice<span class="punctuation">,</span> tuple<span class="punctuation">,</span> dict<span class="punctuation">,</span> array)</span><br><span class="line"></span><br><span class="line">【示例】</span><br><span class="line">    apiVersion<span class="punctuation">:</span> v1</span><br><span class="line">    kind<span class="punctuation">:</span> ConfigMap</span><br><span class="line">    metadata<span class="punctuation">:</span></span><br><span class="line">      name<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .Release.Name <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span>-configmap</span><br><span class="line">    data<span class="punctuation">:</span></span><br><span class="line">      myvalue<span class="punctuation">:</span> <span class="string">&quot;Hello World&quot;</span></span><br><span class="line">      drink<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .Values.favorite.drink | default <span class="string">&quot;tea&quot;</span> | quote <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">      food<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .Values.favorite.food | upper | quote <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">      <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> if eq .Values.favorite.drink <span class="string">&quot;coffee&quot;</span> <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span>mug<span class="punctuation">:</span> <span class="string">&quot;true&quot;</span><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> end <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<h3 id="11）变更作用域-with"><a href="#11）变更作用域-with" class="headerlink" title="11）变更作用域 with"></a>11）变更作用域 with</h3><blockquote>
<p>下一个控制结构是<code>with</code>操作。这个用来<strong>控制变量范围</strong>。回想一下，<code>.</code>是对 当前作用域 的引用。因此 <code>.Values</code>就是告诉模板在当前作用域查找 Values 对象。</p>
</blockquote>
<p>with 的语法与 if 语句类似：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> with PIPELINE <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">  # restricted scope</span><br><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> end <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>作用域可以被改变。with 允许你为特定对象设定当前作用域(<code>.</code>)。比如，我们已经在使用.Values.favorite。修改配置映射中的.的作用域指向.Values.favorite：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">apiVersion<span class="punctuation">:</span> v1</span><br><span class="line">kind<span class="punctuation">:</span> ConfigMap</span><br><span class="line">metadata<span class="punctuation">:</span></span><br><span class="line">  name<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .Release.Name <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span>-configmap</span><br><span class="line">data<span class="punctuation">:</span></span><br><span class="line">  myvalue<span class="punctuation">:</span> <span class="string">&quot;Hello World&quot;</span></span><br><span class="line">  <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- with .Values.favorite <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">  drink<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .drink | default <span class="string">&quot;tea&quot;</span> | quote <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">  food<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .food | upper | quote <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- end <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>但是这里有个注意事项，在限定的作用域内，<strong>无法使用.访问父作用域</strong>的对象。错误示例如下：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- with .Values.favorite <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">drink<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .drink | default <span class="string">&quot;tea&quot;</span> | quote <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">food<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .food | upper | quote <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">release<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .Release.Name <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- end <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>这样会报错因为<code>Release.Name</code><strong>不在<code>.</code>限定的作用域内</strong>。但是如果对调最后两行就是正常的， 因为在之后作用域被重置了。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- with .Values.favorite <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">drink<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .drink | default <span class="string">&quot;tea&quot;</span> | quote <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">food<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .food | upper | quote <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- end <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">release<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .Release.Name <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>或者，我们可以使用<code>$$</code><strong>从父作用域中访问 Release.Name 对象</strong>。当模板开始执行后<code>$$</code>会被映射到<strong>根作用域</strong>，且执行过程中不会更改。下面这种方式也可以正常工作：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- with .Values.favorite <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">drink<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .drink | default <span class="string">&quot;tea&quot;</span> | quote <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">food<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .food | upper | quote <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">release<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> $.Release.Name <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- end <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>也可以在外边定义变量，遵循<code>$name变量</code>的格式且指定了一个特殊的赋值运算符：<code>:=</code>。我们可以使用针对 Release.Name 的变量重写上述内容。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> &#123;&#123; <span class="string">.Release.Name</span> &#125;&#125;<span class="string">-configmap</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">myvalue:</span> <span class="string">&quot;Hello World&quot;</span></span><br><span class="line">  &#123;&#123;<span class="bullet">-</span> <span class="string">$relname</span> <span class="string">:=</span> <span class="string">.Release.Name</span> <span class="string">-</span>&#125;&#125;</span><br><span class="line">  &#123;&#123;<span class="bullet">-</span> <span class="string">with</span> <span class="string">.Values.favorite</span> &#125;&#125;</span><br><span class="line">  <span class="attr">drink:</span> &#123;&#123; <span class="string">.drink</span> <span class="string">|</span> <span class="string">default</span> <span class="string">&quot;tea&quot;</span> <span class="string">|</span> <span class="string">quote</span> &#125;&#125;</span><br><span class="line">  <span class="attr">food:</span> &#123;&#123; <span class="string">.food</span> <span class="string">|</span> <span class="string">upper</span> <span class="string">|</span> <span class="string">quote</span> &#125;&#125;</span><br><span class="line">  <span class="attr">release:</span> &#123;&#123; <span class="string">$relname</span> &#125;&#125;</span><br><span class="line">  &#123;&#123;<span class="bullet">-</span> <span class="string">end</span> &#125;&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意在 with 块开始之前，赋值<code>$relname := .Release.Name</code>。现在在 with 块中，$relname 变量仍会执行版本名称。</p>
</blockquote>
<h3 id="12）rang-循环语句"><a href="#12）rang-循环语句" class="headerlink" title="12）rang 循环语句"></a>12）rang 循环语句</h3><p>很多编程语言支持使用 for 循环，foreach 循环，或者类似的方法机制。在 Helm 的模板语言中，在一个集合中迭代的方式是使用<code>range</code>操作符。</p>
<p>定义 values<br>    favorite:<br>      drink: coffee<br>      food: pizza<br>    pizzaToppings:<br>      - mushrooms<br>      - cheese<br>      - peppers<br>      - onions</p>
<p>现在我们有了一个 pizzaToppings 列表（模板中称为切片）。修改模板把这个列表打印到配置映射中：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> &#123;&#123; <span class="string">.Release.Name</span> &#125;&#125;<span class="string">-configmap</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">myvalue:</span> <span class="string">&quot;Hello World&quot;</span></span><br><span class="line">  &#123;&#123;<span class="bullet">-</span> <span class="string">with</span> <span class="string">.Values.favorite</span> &#125;&#125;</span><br><span class="line">  <span class="attr">drink:</span> &#123;&#123; <span class="string">.drink</span> <span class="string">|</span> <span class="string">default</span> <span class="string">&quot;tea&quot;</span> <span class="string">|</span> <span class="string">quote</span> &#125;&#125;</span><br><span class="line">  <span class="attr">food:</span> &#123;&#123; <span class="string">.food</span> <span class="string">|</span> <span class="string">upper</span> <span class="string">|</span> <span class="string">quote</span> &#125;&#125;</span><br><span class="line">  &#123;&#123;<span class="bullet">-</span> <span class="string">end</span> &#125;&#125;</span><br><span class="line">  <span class="attr">toppings:</span> <span class="string">|-</span></span><br><span class="line"><span class="string">    &#123;&#123;- range .Values.pizzaToppings &#125;&#125;</span></span><br><span class="line"><span class="string">    - &#123;&#123; . | title | quote &#125;&#125;</span></span><br><span class="line"><span class="string">    &#123;&#123;- end &#125;&#125;</span></span><br></pre></td></tr></table></figure>

<p>有时能在模板中快速创建列表然后迭代很有用，Helm 模板的 tuple 可以很容易实现该功能。在计算机科学中， 元组表示一个有固定大小的类似列表的集合，但可以是任意数据类型。这大致表达了<code>tuple</code>的用法。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">sizes<span class="punctuation">:</span> |-</span><br><span class="line">  <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- range tuple <span class="string">&quot;small&quot;</span> <span class="string">&quot;medium&quot;</span> <span class="string">&quot;large&quot;</span> <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">  - <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> . <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- end <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>上述模板会生成以下内容：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">sizes<span class="punctuation">:</span> |-</span><br><span class="line">  - small</span><br><span class="line">  - medium</span><br><span class="line">  - large</span><br></pre></td></tr></table></figure>

<h3 id="13）命名模板"><a href="#13）命名模板" class="headerlink" title="13）命名模板"></a>13）命名模板</h3><blockquote>
<p>此时需要越过模板，开始创建其他内容了。该部分我们会看到如何在一个文件中定义 命名模板，并在其他地方使用。<strong>命名模板</strong> (有时称作一个 部分 或一个 子模板)仅仅是在文件内部定义的模板，并使用了一个名字。有两种创建方式和几种不同的使用方法。</p>
</blockquote>
<ul>
<li>三种声明和管理模板的方法：<code>define</code>，<code>template</code>，和<code>block</code>，在这部分，我们将使用这三种操作并介绍一种特殊用途的 <code>include</code>方法，类似于 template 操作。</li>
<li>命名模板时要记住一个重要细节：<strong>模板名称是全局的</strong>。如果您想声明两个相同名称的模板，<strong>哪个最后加载就使用哪个</strong>。因为在子 chart 中的模板和顶层模板一起编译，命名时要注意 chart 特定名称。</li>
<li>一个常见的命名惯例是用 chart 名称作为模板前缀：<code>&#123;&#123; define "mychart.labels" &#125;&#125;</code>。使用<strong>特定 chart 名称作为前缀</strong>可以<strong>避免可能因为 两个不同 chart 使用了相同名称的模板</strong>而引起的冲突。</li>
</ul>
<p>在编写模板细节之前，文件的命名惯例需要注意：</p>
<ul>
<li>templates&#x2F;中的大多数文件被视为包含 Kubernetes 清单</li>
<li>NOTES.txt 是个例外</li>
<li>命名以下划线(<code>_</code>)开始的文件则假定 没有 包含清单内容。这些文件不会渲染为 Kubernetes 对象定义，但在其他 chart 模板中都可用。</li>
</ul>
<blockquote>
<p>这些文件用来存储局部和辅助对象，实际上当我们第一次创建 mychart 时，会看到一个名为<code>_helpers.tpl</code>的文件，这个文件是<strong>模板局部的默认位置</strong>。</p>
</blockquote>
<h4 id="1、用-define-和-template-声明和使用模板"><a href="#1、用-define-和-template-声明和使用模板" class="headerlink" title="1、用 define 和 template 声明和使用模板"></a>1、用 define 和 template 声明和使用模板</h4><p>define 操作允许我们在模板文件中创建一个命名模板，<strong>语法</strong>如下：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- define <span class="string">&quot;MY.NAME&quot;</span> <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">  # body of template here</span><br><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- end <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>比如我们可以定义一个模板封装 Kubernetes 的标签：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- define <span class="string">&quot;mychart.labels&quot;</span> <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">  labels<span class="punctuation">:</span></span><br><span class="line">    generator<span class="punctuation">:</span> helm</span><br><span class="line">    date<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> now | htmlDate <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- end <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>现在我们将模板嵌入到了已有的配置映射中，然后使用<code>template</code>包含进来：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- define <span class="string">&quot;mychart.labels&quot;</span> <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">  labels<span class="punctuation">:</span></span><br><span class="line">    generator<span class="punctuation">:</span> helm</span><br><span class="line">    date<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> now | htmlDate <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- end <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">apiVersion<span class="punctuation">:</span> v1</span><br><span class="line">kind<span class="punctuation">:</span> ConfigMap</span><br><span class="line">metadata<span class="punctuation">:</span></span><br><span class="line">  name<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .Release.Name <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span>-configmap</span><br><span class="line">  <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- template <span class="string">&quot;mychart.labels&quot;</span> <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">data<span class="punctuation">:</span></span><br><span class="line">  myvalue<span class="punctuation">:</span> <span class="string">&quot;Hello World&quot;</span></span><br><span class="line">  <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- range $key<span class="punctuation">,</span> $val <span class="punctuation">:</span>= .Values.favorite <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> $key <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> $val | quote <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- end <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>当模板引擎读取该文件时，它会存储 mychart.labels 的引用直到 template “mychart.labels”被调用。然后会按行渲染模板，因此结果类似这样：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Source: mychart/templates/configmap.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">running-panda-configmap</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">generator:</span> <span class="string">helm</span></span><br><span class="line">    <span class="attr">date:</span> <span class="number">2022-09-04</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">myvalue:</span> <span class="string">&quot;Hello World&quot;</span></span><br><span class="line">  <span class="attr">drink:</span> <span class="string">&quot;coffee&quot;</span></span><br><span class="line">  <span class="attr">food:</span> <span class="string">&quot;pizza&quot;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：define 不会有输出，除非像本示例一样用模板调用它。</p>
</blockquote>
<p>按照惯例，Helm chart 将这些模板放置在局部文件中，一般是<code>_helpers.tpl</code>。把这个方法移到那里：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span><span class="comment">/* Generate basic labels */</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- define <span class="string">&quot;mychart.labels&quot;</span> <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">  labels<span class="punctuation">:</span></span><br><span class="line">    generator<span class="punctuation">:</span> helm</span><br><span class="line">    date<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> now | htmlDate <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- end <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<h4 id="2、设置模板范围"><a href="#2、设置模板范围" class="headerlink" title="2、设置模板范围"></a>2、设置模板范围</h4><p>在上面定义的模板中，我们没有使用任何对象，仅仅使用了方法。修改定义好的模板让其包含 chart 名称和版本号：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span><span class="comment">/* Generate basic labels */</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- define <span class="string">&quot;mychart.labels&quot;</span> <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">  labels<span class="punctuation">:</span></span><br><span class="line">    generator<span class="punctuation">:</span> helm</span><br><span class="line">    date<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> now | htmlDate <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">    chart<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .Chart.Name <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">    version<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .Chart.Version <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- end <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<h4 id="3、include-方法"><a href="#3、include-方法" class="headerlink" title="3、include 方法"></a>3、include 方法</h4><p>假设定义了一个简单模板如下：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- define <span class="string">&quot;mychart.app&quot;</span> -<span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">app_name<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .Chart.Name <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">app_version<span class="punctuation">:</span> <span class="string">&quot;&#123;&#123; .Chart.Version &#125;&#125;&quot;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>- end -<span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>现在假设我想把这个插入到模板的 labels:部分和 data:部分：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> &#123;&#123; <span class="string">.Release.Name</span> &#125;&#125;<span class="string">-configmap</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    &#123;&#123; <span class="string">template</span> <span class="string">&quot;mychart.app&quot;</span> <span class="string">.</span> &#125;&#125;</span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">myvalue:</span> <span class="string">&quot;Hello World&quot;</span></span><br><span class="line">  &#123;&#123;<span class="bullet">-</span> <span class="string">range</span> <span class="string">$key</span>, <span class="string">$val</span> <span class="string">:=</span> <span class="string">.Values.favorite</span> &#125;&#125;</span><br><span class="line">  &#123;&#123; <span class="string">$key</span> &#125;&#125;<span class="string">:</span> &#123;&#123; <span class="string">$val</span> <span class="string">|</span> <span class="string">quote</span> &#125;&#125;</span><br><span class="line">  &#123;&#123;<span class="bullet">-</span> <span class="string">end</span> &#125;&#125;</span><br><span class="line">&#123;&#123; <span class="string">template</span> <span class="string">&quot;mychart.app&quot;</span> <span class="string">.</span> &#125;&#125;</span><br></pre></td></tr></table></figure>

<p>如果渲染这个，会得到以下错误：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ helm install --dry-run measly-whippet ./mychart</span><br><span class="line">Error: unable to build kubernetes objects from release manifest: error validating <span class="string">&quot;&quot;</span>: error validating data: [ValidationError(ConfigMap): unknown field <span class="string">&quot;app_name&quot;</span> <span class="keyword">in</span> io.k8s.api.core.v1.ConfigMap, ValidationError(ConfigMap): unknown field <span class="string">&quot;app_version&quot;</span> <span class="keyword">in</span> io.k8s.api.core.v1.ConfigMap]</span><br></pre></td></tr></table></figure>

<p>要查看渲染了什么，可以用<code>--disable-openapi-validation</code>参数重新执行：<code>helm install --dry-run --disable-openapi-validation measly-whippet ./mychart</code>。输入不是我们想要的：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Source: mychart/templates/configmap.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">measly-whippet-configmap</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app_name:</span> <span class="string">mychart</span></span><br><span class="line"><span class="attr">app_version:</span> <span class="string">&quot;0.1.0&quot;</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">myvalue:</span> <span class="string">&quot;Hello World&quot;</span></span><br><span class="line">  <span class="attr">drink:</span> <span class="string">&quot;coffee&quot;</span></span><br><span class="line">  <span class="attr">food:</span> <span class="string">&quot;pizza&quot;</span></span><br><span class="line"><span class="attr">app_name:</span> <span class="string">mychart</span></span><br><span class="line"><span class="attr">app_version:</span> <span class="string">&quot;0.1.0&quot;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意两处的<strong>app_version 缩进都不对</strong>，为啥？因为被替换的模板中文本是左对齐的。由于<code>template</code>是一个行为，<strong>不是方法</strong>，<strong>无法将 <code>template</code>调用的输出传给其他方法，数据只是简单地按行插入</strong>。</p>
</blockquote>
<p>为了处理这个问题，Helm 提供了一个<code>include</code>，可以将模板内容导入当前管道，然后传递给管道中的其他方法。下面这个示例，使用<code>indent</code>正确地缩进了 mychart.app 模板：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> &#123;&#123; <span class="string">.Release.Name</span> &#125;&#125;<span class="string">-configmap</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">&#123;&#123; <span class="string">include</span> <span class="string">&quot;mychart.app&quot;</span> <span class="string">.</span> <span class="string">|</span> <span class="string">indent</span> <span class="number">4</span> &#125;&#125;</span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">myvalue:</span> <span class="string">&quot;Hello World&quot;</span></span><br><span class="line">  &#123;&#123;<span class="bullet">-</span> <span class="string">range</span> <span class="string">$key</span>, <span class="string">$val</span> <span class="string">:=</span> <span class="string">.Values.favorite</span> &#125;&#125;</span><br><span class="line">  &#123;&#123; <span class="string">$key</span> &#125;&#125;<span class="string">:</span> &#123;&#123; <span class="string">$val</span> <span class="string">|</span> <span class="string">quote</span> &#125;&#125;</span><br><span class="line">  &#123;&#123;<span class="bullet">-</span> <span class="string">end</span> &#125;&#125;</span><br><span class="line">&#123;&#123; <span class="string">include</span> <span class="string">&quot;mychart.app&quot;</span> <span class="string">.</span> <span class="string">|</span> <span class="string">indent</span> <span class="number">2</span> &#125;&#125;</span><br></pre></td></tr></table></figure>

<p>现在生成的 YAML 每一部分都可以正确缩进了：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Source: mychart/templates/configmap.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">edgy-mole-configmap</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app_name:</span> <span class="string">mychart</span></span><br><span class="line">    <span class="attr">app_version:</span> <span class="string">&quot;0.1.0&quot;</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">myvalue:</span> <span class="string">&quot;Hello World&quot;</span></span><br><span class="line">  <span class="attr">drink:</span> <span class="string">&quot;coffee&quot;</span></span><br><span class="line">  <span class="attr">food:</span> <span class="string">&quot;pizza&quot;</span></span><br><span class="line">  <span class="attr">app_name:</span> <span class="string">mychart</span></span><br><span class="line">  <span class="attr">app_version:</span> <span class="string">&quot;0.1.0&quot;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p><code>include</code> 相较于使用 template，在 helm 中<strong>使用 include 被认为是更好的方式</strong> 只是为了更好地处理 YAML 文档的输出格式。</p>
</blockquote>
<h3 id="14）NOTES-txt-文件"><a href="#14）NOTES-txt-文件" class="headerlink" title="14）NOTES.txt 文件"></a>14）NOTES.txt 文件</h3><blockquote>
<p>该部分会<strong>介绍为 chart 用户提供说明的 Helm 工具</strong>。在 helm install 或 helm upgrade 命令的最后，<strong>Helm 会打印出对用户有用的信息</strong>。使用模板可以高度自定义这部分信息。</p>
</blockquote>
<p>要在 chart 添加安装说明，只需创建<code>templates/NOTES.txt</code>文件即可。<strong>该文件是纯文本，但会像模板一样处理</strong>， 所有正常的模板函数和对象都是可用的。让我们创建一个简单的 NOTES.txt 文件：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">Thank you for installing <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .Chart.Name <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span>.</span><br><span class="line"></span><br><span class="line">Your release is named <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .Release.Name <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span>.</span><br><span class="line"></span><br><span class="line">To learn more about the release<span class="punctuation">,</span> try<span class="punctuation">:</span></span><br><span class="line"></span><br><span class="line">  $ helm status <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .Release.Name <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">  $ helm get all <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .Release.Name <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>现在如果我们执行 helm install rude-cardinal .&#x2F;mychart 会在底部看到：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">RESOURCES:</span><br><span class="line">==&gt; v1/Secret</span><br><span class="line">NAME                   TYPE      DATA      AGE</span><br><span class="line">rude-cardinal-secret   Opaque    1         0s</span><br><span class="line"></span><br><span class="line">==&gt; v1/ConfigMap</span><br><span class="line">NAME                      DATA      AGE</span><br><span class="line">rude-cardinal-configmap   3         0s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">NOTES:</span><br><span class="line">Thank you <span class="keyword">for</span> installing mychart.</span><br><span class="line"></span><br><span class="line">Your release is named rude-cardinal.</span><br><span class="line"></span><br><span class="line">To learn more about the release, try:</span><br><span class="line"></span><br><span class="line">  $ helm status rude-cardinal</span><br><span class="line">  $ helm get all rude-cardinal</span><br></pre></td></tr></table></figure>

<blockquote>
<p>使用 NOTES.txt 这种方式是给用户提供关于如何使用新安装的 chart 细节信息的好方法。尽管并不是必需的，<strong>强烈建议创建一个<code>NOTES.txt</code>文件</strong>。</p>
</blockquote>
<h3 id="15）模板调试"><a href="#15）模板调试" class="headerlink" title="15）模板调试"></a>15）模板调试</h3><p>调试模板可能很棘手，因为渲染后的模板发送给了 Kubernetes API server，可能会以格式化以外的原因拒绝 YAML 文件。以下命令有助于调试：</p>
<ul>
<li><code>helm lint</code> 是验证 chart 是否遵循最佳实践的首选工具</li>
<li><code>helm install --dry-run --debug</code> 或 <code>helm template --debug</code>：我们已经看过这个技巧了， 这是让服务器渲染模板的好方法，然后返回生成的清单文件。</li>
<li><code>helm get manifest</code>: 这是查看安装在服务器上的模板的好方法。</li>
</ul>
<p>当你的 YAML 文件解析失败，但你想知道生成了什么，检索 YAML 一个简单的方式是<strong>注释掉模板中有问题的部分</strong>， 然后重新运行 <code>helm install --dry-run --debug</code>：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">apiVersion<span class="punctuation">:</span> v2</span><br><span class="line"># some<span class="punctuation">:</span> problem section</span><br><span class="line"># <span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> .Values.foo | quote <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>以上内容会被渲染同时返回完整的注释：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v2</span></span><br><span class="line"><span class="comment"># some: problem section</span></span><br><span class="line"><span class="comment">#  &quot;bar&quot;</span></span><br></pre></td></tr></table></figure>

<p>其实这里主要是正对官方文档进行整理，列出了常见的使用语法，想了解更多，可以参考官方文档，</p>
]]></content>
      <categories>
        <category>kubernetes</category>
        <category>Helm</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>Helm</tag>
      </tags>
  </entry>
  <entry>
    <title>Helm进阶使用</title>
    <url>/2022/12/29/helm%E8%BF%9B%E9%98%B6%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><p>Helm 针对 Kubernetes 的 Helm 包管理器。Helm 的一般操作：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 搜索 chart</span></span><br><span class="line">helm search: </span><br><span class="line"><span class="comment"># 下载 chart 到本地目录查看</span></span><br><span class="line">helm pull:    </span><br><span class="line"><span class="comment"># 上传 chart 到 Kubernetes</span></span><br><span class="line">helm install: </span><br><span class="line"><span class="comment"># 列出已发布的 chart</span></span><br><span class="line">helm list:      </span><br><span class="line"><span class="comment"># 查看帮助</span></span><br><span class="line">helm --<span class="built_in">help</span></span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220909090236244.png" alt="图片"><br>官方文档：<a href="https://helm.sh/zh/docs/helm/helm/">https://helm.sh/zh/docs/helm/helm/</a><br><a href="https://blog.kkun.site/2022/12/29/helm%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8%E5%8F%8A%E8%AF%AD%E6%B3%95/">Helm 架构和基础语法讲解可以参考这篇文章</a></p>
<h2 id="二、Helm-仓库（helm-repo）"><a href="#二、Helm-仓库（helm-repo）" class="headerlink" title="二、Helm 仓库（helm repo）"></a>二、Helm 仓库（helm repo）</h2><blockquote>
<p><a href="https://blog.kkun.site/2022/12/29/helm%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8%E5%8F%8A%E8%AF%AD%E6%B3%95/">添加、列出、删除、更新和索引 chart 仓库。</a></p>
</blockquote>
<h3 id="1）添加-chart-仓库"><a href="#1）添加-chart-仓库" class="headerlink" title="1）添加 chart 仓库"></a>1）添加 chart 仓库</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm repo add bitnami https://charts.bitnami.com/bitnami</span><br></pre></td></tr></table></figure>

<h3 id="2）列出已添加的仓库"><a href="#2）列出已添加的仓库" class="headerlink" title="2）列出已添加的仓库"></a>2）列出已添加的仓库</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm repo list</span><br></pre></td></tr></table></figure>

<h3 id="3）从-chart-仓库中更新本地可用-chart-的信息"><a href="#3）从-chart-仓库中更新本地可用-chart-的信息" class="headerlink" title="3）从 chart 仓库中更新本地可用 chart 的信息"></a>3）从 chart 仓库中更新本地可用 chart 的信息</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm repo update bitnami</span><br></pre></td></tr></table></figure>

<h3 id="4）删除一个或多个仓库"><a href="#4）删除一个或多个仓库" class="headerlink" title="4）删除一个或多个仓库"></a>4）删除一个或多个仓库</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm repo remove bitnami</span><br></pre></td></tr></table></figure>

<h2 id="三、创建-chart（helm-create）"><a href="#三、创建-chart（helm-create）" class="headerlink" title="三、创建 chart（helm create）"></a>三、创建 chart（helm create）</h2><blockquote>
<p>使用给定名称创建新的 chart，该命令创建 chart 目录和 chart 用到的公共文件目录。</p>
</blockquote>
<p>比如’helm create foo’会创建一个目录结构看起来像这样：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ helm create foo</span><br><span class="line">foo/</span><br><span class="line">├── .helmignore   <span class="comment"># Contains patterns to ignore when packaging Helm charts.</span></span><br><span class="line">├── Chart.yaml    <span class="comment"># Information about your chart</span></span><br><span class="line">├── values.yaml   <span class="comment"># The default values for your templates</span></span><br><span class="line">├── charts/       <span class="comment"># Charts that this chart depends on</span></span><br><span class="line">└── templates/    <span class="comment"># The template files</span></span><br><span class="line">    └── tests/    <span class="comment"># The test files</span></span><br></pre></td></tr></table></figure>

<h2 id="四、chart-包安装（helm-install）"><a href="#四、chart-包安装（helm-install）" class="headerlink" title="四、chart 包安装（helm install）"></a>四、chart 包安装（helm install）</h2><blockquote>
<p>该命令用于<strong>安装 chart 包</strong>。安装参数必须是 chart 的引用，一个<strong>打包后的 chart 路径</strong>，<strong>未打包的 chart 目录或者是一个 URL</strong>。</p>
</blockquote>
<p>要重写 chart 中的值，使用<code>--values</code>参数传递一个文件或者使用<code>--set</code>参数在命令行传递配置，强制使用字符串要用<code>--set-string</code>。当值本身对于命令行太长或者是动态生成的时候，可以使用<code>--set-file</code>设置独立的值。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm install -f myvalues.yaml myredis ./redis</span><br><span class="line"></span><br><span class="line">helm install --<span class="built_in">set</span> name=prod myredis ./redis</span><br><span class="line"></span><br><span class="line">helm install --set-string long_int=1234567890 myredis ./redis</span><br><span class="line"></span><br><span class="line">helm install --set-file my_script=dothings.sh myredis ./redis</span><br></pre></td></tr></table></figure>

<h2 id="五、管理-chart-依赖（helm-dependency）"><a href="#五、管理-chart-依赖（helm-dependency）" class="headerlink" title="五、管理 chart 依赖（helm dependency）"></a>五、管理 chart 依赖（helm dependency）</h2><ul>
<li><a href="https://blog.kkun.site/2022/12/29/helm%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8%E5%8F%8A%E8%AF%AD%E6%B3%95/">Helm chart 将依赖存储在’charts&#x2F;‘。对于 chart 开发者，管理依赖比声明了所有依赖的’Chart.yaml’文件更容易。</a></li>
<li><a href="https://blog.kkun.site/2022/12/29/helm%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8%E5%8F%8A%E8%AF%AD%E6%B3%95/">依赖命令对该文件进行操作，使得存储在’charts&#x2F;‘目录的需要的依赖和实际依赖之间同步变得很容易。</a></li>
</ul>
<p><a href="https://blog.kkun.site/2022/12/29/helm%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8%E5%8F%8A%E8%AF%AD%E6%B3%95/">比如 Chart.yaml 声明了两个依赖：</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Chart.yaml</span></span><br><span class="line">dependencies:</span><br><span class="line">- name: nginx</span><br><span class="line">    version: <span class="string">&quot;1.2.3&quot;</span></span><br><span class="line">    repository: <span class="string">&quot;https://example.com/charts&quot;</span></span><br><span class="line">- name: memcached</span><br><span class="line">    version: <span class="string">&quot;3.2.1&quot;</span></span><br><span class="line">    repository: <span class="string">&quot;https://another.example.com/charts&quot;</span></span><br></pre></td></tr></table></figure>

<ul>
<li><code>name</code> 是 chart 名称，<strong>必须匹配<code>Chart.yaml</code>文件中名称</strong>。</li>
<li><code>version</code> 字段应该包含一个语义化的版本或版本范围。</li>
</ul>
<p>从 2.2.0 开始，仓库可以被定义为本地存储的依赖 chart 的目录路径。路径应该以”file:&#x2F;&#x2F;“前缀开头，比如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Chart.yaml</span></span><br><span class="line">dependencies:</span><br><span class="line">- name: nginx</span><br><span class="line">    version: <span class="string">&quot;1.2.3&quot;</span></span><br><span class="line">    repository: <span class="string">&quot;file://../dependency_chart/nginx&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="1）列举指定-chart-的依赖"><a href="#1）列举指定-chart-的依赖" class="headerlink" title="1）列举指定 chart 的依赖"></a>1）列举指定 chart 的依赖</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># helm dependency list CHART</span></span><br><span class="line">helm dependency list wordpress</span><br></pre></td></tr></table></figure>

<h3 id="2）依赖升级"><a href="#2）依赖升级" class="headerlink" title="2）依赖升级"></a>2）依赖升级</h3><p>基于 Chart.yaml 内容升级 charts&#x2F;</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># helm dependency update CHART [flags]</span></span><br><span class="line">helm dependency update wordpress</span><br></pre></td></tr></table></figure>

<h2 id="六、Helm-列表（helm-list）"><a href="#六、Helm-列表（helm-list）" class="headerlink" title="六、Helm 列表（helm list）"></a>六、Helm 列表（helm list）</h2><ul>
<li><strong>列举发布版本</strong>，该命令会列举出指定命名空间的所有发布版本，(如果没有指定命名空间，会使用当前命名空间)。</li>
<li><strong>默认</strong>情况下，只会<strong>列举出部署的或者失败的发布</strong>，像<code>--uninstalled</code>或者<code>--all</code>会修改默认行为。这些参数可以组合使用：<code>--uninstalled --failed</code>。</li>
<li>默认情况下，最多返回<code>256</code>项，使用<code>--max</code>限制数量，<code>--max</code>设置为<strong>0 不会返回所有结果</strong>，而是返回服务器默认值，可能要比 256 更多。同时使用<code>--max</code>和<code>--offset</code>参数可以<strong>翻页</strong>显示。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -A显示所有</span></span><br><span class="line">helm list --max=10 --offset=2 -A</span><br></pre></td></tr></table></figure>

<h2 id="七、升级版本（helm-upgrade）"><a href="#七、升级版本（helm-upgrade）" class="headerlink" title="七、升级版本（helm upgrade）"></a>七、升级版本（helm upgrade）</h2><blockquote>
<p>该命令将发布升级到新版的 chart。升级参数必须是发布和 chart。chart 参数可以是：<code>chart引用(&#39;example/mariadb&#39;)</code>，<code>chart目录路径</code>，打包的 chart 或者完整 URL。对于 chart 引用，除非使用’–version’参数指定，否则会使用最新版本。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm upgrade --<span class="built_in">set</span> foo=bar --<span class="built_in">set</span> foo=newbar redis ./redis</span><br></pre></td></tr></table></figure>

<h2 id="八、发布历史（helm-history）"><a href="#八、发布历史（helm-history）" class="headerlink" title="八、发布历史（helm history）"></a>八、发布历史（helm history）</h2><blockquote>
<p>检索发布历史，打印给定版本的历史修订。<strong>默认</strong>会返回最大的<code>256</code>个历史版本。设置<code>--max</code>配置返回历史列表的最大长度。</p>
</blockquote>
<p>历史发布集合会被打印成格式化的表格，例如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ helm <span class="built_in">history</span> angry-bird</span><br><span class="line">REVISION    UPDATED                     STATUS          CHART             APP VERSION     DESCRIPTION</span><br><span class="line">1           Mon Oct 3 10:15:13 2016     superseded      alpine-0.1.0      1.0             Initial install</span><br><span class="line">2           Mon Oct 3 10:15:13 2016     superseded      alpine-0.1.0      1.0             Upgraded successfully</span><br><span class="line">3           Mon Oct 3 10:15:13 2016     superseded      alpine-0.1.0      1.0             Rolled back to 2</span><br><span class="line">4           Mon Oct 3 10:15:13 2016     deployed        alpine-0.1.0      1.0             Upgraded successfully</span><br></pre></td></tr></table></figure>

<h2 id="九、回滚版本（helm-rollback）"><a href="#九、回滚版本（helm-rollback）" class="headerlink" title="九、回滚版本（helm rollback）"></a>九、回滚版本（helm rollback）</h2><blockquote>
<p>回滚发布到上一个版本，回滚命令的第一个参数是发布的名称，第二是修订（版本）号，如果省略此参数，会回滚到上一个版本。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># helm rollback &lt;RELEASE&gt; [REVISION] [flags]</span></span><br><span class="line"><span class="comment"># 先查看历史版本</span></span><br><span class="line">helm <span class="built_in">history</span> myharbor -n harbor</span><br><span class="line"><span class="comment"># 不指定版本就回退上个版本</span></span><br><span class="line">helm rollback myharbor 1 -n harbor</span><br><span class="line">helm rollback myharbor -n harbor</span><br></pre></td></tr></table></figure>

<h2 id="十、展示-chart（helm-show）"><a href="#十、展示-chart（helm-show）" class="headerlink" title="十、展示 chart（helm show）"></a>十、展示 chart（helm show）</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># helm show all [CHART] [flags]</span></span><br><span class="line"><span class="comment"># 该命令检查chart(目录、文件或URL)并显示所有的内容（values.yaml, Chart.yaml, README）</span></span><br><span class="line">helm show all mysql</span><br><span class="line"></span><br><span class="line"><span class="comment"># helm show values [CHART] [flags]</span></span><br><span class="line"><span class="comment"># 该命令检查chart(目录、文件或URL)并显示values.yaml文件的内容</span></span><br><span class="line">helm show values mysql</span><br></pre></td></tr></table></figure>

<h2 id="十一、拉取-chart（helm-pull）"><a href="#十一、拉取-chart（helm-pull）" class="headerlink" title="十一、拉取 chart（helm pull）"></a>十一、拉取 chart（helm pull）</h2><p>从仓库下载并（可选）在本地目录解压。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># helm pull [chart URL | repo/chartname] [...] [flags]</span></span><br><span class="line"><span class="comment"># 仅下载</span></span><br><span class="line">helm pull bitnami/redis</span><br><span class="line"><span class="comment"># 下载并解压到当前目录</span></span><br><span class="line">helm pull bitnami/redis --untar</span><br></pre></td></tr></table></figure>

<h2 id="十二、Helm-打包（helm-package）"><a href="#十二、Helm-打包（helm-package）" class="headerlink" title="十二、Helm 打包（helm package）"></a>十二、Helm 打包（helm package）</h2><ul>
<li><strong>将 chart 目录打包到 chart 归档中</strong>，该命令将 chart 打包成一个 chart 版本包文件。如果给定路径，就会在该路径中查找 chart（必须包含 Chart.yaml 文件）然后将目录打包。</li>
<li>要签名一个 chart，使用<code>--sign</code>参数，在大多数场景中，也要提供<code>--keyring path/to/secret/keys</code>和<code>--key keyname</code>。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm package mysql/</span><br><span class="line"><span class="comment"># Successfully packaged chart and saved it to: /opt/k8s/helm/mysql-9.3.1.tgz</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果<strong>想忽略 helm 中的文件</strong>，可以在<code>.helmignore</code>进行匹配，该.helmignore 文件支持 Unix shell 全局匹配，相对路径匹配和否定（以！前缀反向匹配）。每行仅考虑一种模式。示例如下：</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># .helmignore</span></span><br><span class="line">.git</span><br><span class="line">*/temp*</span><br><span class="line">*/*/temp*</span><br><span class="line">temp?</span><br></pre></td></tr></table></figure>

<h2 id="十三、推送-chart-到-harbor（helm-cm-push）"><a href="#十三、推送-chart-到-harbor（helm-cm-push）" class="headerlink" title="十三、推送 chart 到 harbor（helm cm-push）"></a>十三、推送 chart 到 harbor（helm cm-push）</h2><blockquote>
<p>将 chart 推送到远程。</p>
</blockquote>
<h3 id="1）在线安装"><a href="#1）在线安装" class="headerlink" title="1）在线安装"></a>1）在线安装</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm plugin install https://github.com/chartmuseum/helm-push</span><br></pre></td></tr></table></figure>

<h3 id="2）离线安装"><a href="#2）离线安装" class="headerlink" title="2）离线安装"></a>2）离线安装</h3><p>下载地址：<a href="https://github.com/chartmuseum/helm-push/tags">https://github.com/chartmuseum/helm-push/tags</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1、下载安装包</span></span><br><span class="line">wget https://github.com/chartmuseum/helm-push/releases/tag/v0.10.3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、查看helm的plugin路径：helm env</span></span><br><span class="line">helm <span class="built_in">env</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、在该路径下创建helm-push文件夹，并将安装包拷贝到该文件夹下解压即可</span></span><br><span class="line"><span class="built_in">mkdir</span> /root/.local/share/helm/plugins/helm-push</span><br><span class="line"></span><br><span class="line">wget https://github.com/chartmuseum/helm-push/releases/download/v0.10.3/helm-push_0.10.3_linux_amd64.tar.gz</span><br><span class="line"></span><br><span class="line">tar zxvf /root/.local/share/helm/plugins/helm-push/helm-push_0.10.3_linux_amd64.tar.gz -C /root/.local/share/helm/plugins/helm-push</span><br></pre></td></tr></table></figure>

<p>查看插件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm plugin list</span><br></pre></td></tr></table></figure>

<h3 id="3）helm-增加-harbor-repo"><a href="#3）helm-增加-harbor-repo" class="headerlink" title="3）helm 增加 harbor repo"></a>3）helm 增加 harbor repo</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># chartrepo，固定参数，bigdata自定义项目</span></span><br><span class="line">helm repo add local-harbor --username=admin --password=Harbor12345 https://myharbor.com/chartrepo/bigdata/ --ca-file /opt/k8s/helm/ca.crt</span><br></pre></td></tr></table></figure>

<p>证书直接在 harbor 上下载<br><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220909085720442.png" alt="图片"></p>
<h3 id="4）示例演示"><a href="#4）示例演示" class="headerlink" title="4）示例演示"></a>4）示例演示</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看帮助</span></span><br><span class="line">helm cm-push --<span class="built_in">help</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 推送，接【目录】</span></span><br><span class="line">helm cm-push mysql/ local-harbor --ca-file /opt/k8s/helm/ca.crt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 推送，接【压缩包】</span></span><br><span class="line">helm cm-push wordpress-15.1.5.tgz local-harbor --ca-file /opt/k8s/helm/ca.crt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 推送，指定版本，--version</span></span><br><span class="line">helm cm-push mychart/ --version=<span class="string">&quot;1.2.3&quot;</span> local-harbor --ca-file /opt/k8s/helm/ca.crt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 强制推送，--force</span></span><br><span class="line">helm cm-push --force mychart-0.3.2.tgz local-harbor</span><br></pre></td></tr></table></figure>

<p>查看<br><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220909090058216.png" alt="图片"></p>
<h2 id="十四、搜索-hub（helm-search-hub）"><a href="#十四、搜索-hub（helm-search-hub）" class="headerlink" title="十四、搜索 hub（helm search hub）"></a>十四、搜索 hub（helm search hub）</h2><p>在Artifact Hub或自己的 hub 实例中搜索 chart。</p>
<p><code>Artifact Hub</code> 是<strong>基于 web 页面的应用</strong>，支持 CNCF 项目的查找、安装和发布包及配置项，包括了公开发布的 Helm chart。它是 CNCF 的沙盒项目。可以访问<a href="https://artifacthub.io/">https://artifacthub.io/</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 不带参数，列出所有</span></span><br><span class="line">helm search hub</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定chart</span></span><br><span class="line">helm search hub mysql</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220909085720501.png" alt="图片"></p>
<h2 id="十五、搜索仓库（helm-search-repo）"><a href="#十五、搜索仓库（helm-search-repo）" class="headerlink" title="十五、搜索仓库（helm search repo）"></a>十五、搜索仓库（helm search repo）</h2><blockquote>
<p>用 chart 中关键字搜索仓库，搜索会读取系统上配置的所有仓库，并查找匹配。搜索这些仓库会使用存储在系统中的元数据。它会展示找到<strong>最新稳定版本的 chart</strong>。如果指定了<code>--devel</code>参数，输出会包括预发布版本。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Search for stable release versions matching the keyword &quot;nginx&quot;</span></span><br><span class="line">$ helm search repo nginx</span><br><span class="line"></span><br><span class="line"><span class="comment"># Search for release versions matching the keyword &quot;nginx&quot;, including pre-release versions</span></span><br><span class="line">$ helm search repo nginx --devel</span><br><span class="line"></span><br><span class="line"><span class="comment"># Search for the latest stable release for nginx-ingress with a major version of 1</span></span><br><span class="line">$ helm search repo nginx-ingress --version ^1.0.0</span><br></pre></td></tr></table></figure>

<h2 id="十六、验证-chart（helm-lint）"><a href="#十六、验证-chart（helm-lint）" class="headerlink" title="十六、验证 chart（helm lint）"></a>十六、验证 chart（helm lint）</h2><blockquote>
<p>该命令使用一个 chart 路径并运行一系列的<strong>测试来验证 chart 的格式是否正确</strong>。如果遇到引起 chart 安装失败的情况，会触发[ERROR]信息，如果遇到违反惯例或建议的问题，会触发[WARNING]。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># helm lint PATH [flags]</span></span><br><span class="line">helm lint ./mysql</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220909085720509.png" alt="图片"><br><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202212291321175.png" alt="图片"></p>
<h2 id="十七、常用命令总结"><a href="#十七、常用命令总结" class="headerlink" title="十七、常用命令总结"></a>十七、常用命令总结</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm version                            // 查看helm版本</span><br><span class="line">helm create xxx                         // 创建一个xxx charts</span><br><span class="line">helm lint ./xxx                         // 检查包的格式或信息是否有问题</span><br><span class="line">helm install xxx1 ./xxx                 // 部署安装xxx，设置名称为xxx1</span><br><span class="line">helm list                               // 列出已经部署的charts</span><br><span class="line">helm <span class="built_in">history</span>                            // 发布历史</span><br><span class="line">helm upgrade                            // 更新版本</span><br><span class="line">helm rollback                           // 回滚版本</span><br><span class="line">helm package ./xxx                      // 打包charts</span><br><span class="line">helm repo add --username admin --password password myharbor xxx  // 增加repo</span><br><span class="line">helm uninstall xxx1                     // 卸载删除xxx1</span><br><span class="line">helm pull                                // 拉取chart包</span><br><span class="line">helm cm-push                            // 推送chart包</span><br><span class="line">helm repo update                        // 更新仓库资源</span><br><span class="line">helm search hub                         // 从 Artifact Hub 中查找并列出 helm charts。Artifact Hub中存放了大量不同的仓库</span><br><span class="line">helm search repo                        // 从你添加（使用 helm repo add）到本地 helm 客户端中的仓库中进行查找。该命令基于本地数据进行搜索，无需连接互联网</span><br></pre></td></tr></table></figure>

<p>Helm 常用命令（chart 安装、升级、回滚、卸载等操作）就先到这里，</p>
]]></content>
      <categories>
        <category>kubernetes</category>
        <category>Helm</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>Helm</tag>
      </tags>
  </entry>
  <entry>
    <title>ingress 兼容旧版tls</title>
    <url>/2023/01/04/ingress%20%E5%85%BC%E5%AE%B9%E6%97%A7%E7%89%88tls/</url>
    <content><![CDATA[<h2 id="Ingress支持哪些SSL-x2F-TLS版本？"><a href="#Ingress支持哪些SSL-x2F-TLS版本？" class="headerlink" title="Ingress支持哪些SSL&#x2F;TLS版本？"></a>Ingress支持哪些SSL&#x2F;TLS版本？</h2><p>Ingress-Nginx默认支持TLS V1.2及V1.3版本，对于部分旧版本的浏览器，或者移动客户端TLS版本低于1.2时，会导致客户端在与Ingress-Nginx服务SSL版本协商时报错。</p>
<p>修改kube-system&#x2F;nginx-configuration configmap添加以下配置，为Ingress-Nginx开启支持更多TLS版本的功能。具体操作，请参见<a href="https://kubernetes.github.io/ingress-nginx/user-guide/tls/?spm=a2c4g.11186623.0.0.3ecd1606Njfrf3#default-tls-version-and-ciphers">TLS&#x2F;HTTPS</a>。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">ssl-ciphers:</span> <span class="string">&quot;ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA:ECDHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES256-SHA256:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:DES-CBC3-SHA&quot;</span></span><br><span class="line"><span class="attr">ssl-protocols:</span> <span class="string">&quot;TLSv1 TLSv1.1 TLSv1.2 TLSv1.3&quot;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果使用crt证书还是提示不安全，就使用带认证机构的pem证书。<br>示例如下</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">-----BEGIN CERTIFICATE-----</span><br><span class="line">          ······</span><br><span class="line">-----END CERTIFICATE-----</span><br><span class="line">-----BEGIN CERTIFICATE-----</span><br><span class="line">MIIFUTCCBDmgAwIBAgIQB5g2A63jmQghnKAMJ7yKbDANBgkqhkiG9w0BAQsFADBh</span><br><span class="line">MQswCQYDVQQGEwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5jMRkwFwYDVQQLExB3</span><br><span class="line">d3cuZGlnaWNlcnQuY29tMSAwHgYDVQQDExdEaWdpQ2VydCBHbG9iYWwgUm9vdCBD</span><br><span class="line">QTAeFw0yMDA3MTYxMjI1MjdaFw0yMzA1MzEyMzU5NTlaMFkxCzAJBgNVBAYTAlVT</span><br><span class="line">MRUwEwYDVQQKEwxEaWdpQ2VydCBJbmMxMzAxBgNVBAMTKlJhcGlkU1NMIFRMUyBE</span><br><span class="line">ViBSU0EgTWl4ZWQgU0hBMjU2IDIwMjAgQ0EtMTCCASIwDQYJKoZIhvcNAQEBBQAD</span><br><span class="line">ggEPADCCAQoCggEBANpuQ1VVmXvZlaJmxGVYotAMFzoApohbJAeNpzN+49LbgkrM</span><br><span class="line">Lv2tblII8H43vN7UFumxV7lJdPwLP22qa0sV9cwCr6QZoGEobda+4pufG0aSfHQC</span><br><span class="line">QhulaqKpPcYYOPjTwgqJA84AFYj8l/IeQ8n01VyCurMIHA478ts2G6GGtEx0ucnE</span><br><span class="line">fV2QHUL64EC2yh7ybboo5v8nFWV4lx/xcfxoxkFTVnAIRgHrH2vUdOiV9slOix3z</span><br><span class="line">5KPs2rK2bbach8Sh5GSkgp2HRoS/my0tCq1vjyLJeP0aNwPd3rk5O8LiffLev9j+</span><br><span class="line">UKZo0tt0VvTLkdGmSN4h1mVY6DnGfOwp1C5SK0MCAwEAAaOCAgswggIHMB0GA1Ud</span><br><span class="line">DgQWBBSkjeW+fHnkcCNtLik0rSNY3PUxfzAfBgNVHSMEGDAWgBQD3lA1VtFMu2bw</span><br><span class="line">o+IbG8OXsj3RVTAOBgNVHQ8BAf8EBAMCAYYwHQYDVR0lBBYwFAYIKwYBBQUHAwEG</span><br><span class="line">CCsGAQUFBwMCMBIGA1UdEwEB/wQIMAYBAf8CAQAwNAYIKwYBBQUHAQEEKDAmMCQG</span><br><span class="line">CCsGAQUFBzABhhhodHRwOi8vb2NzcC5kaWdpY2VydC5jb20wewYDVR0fBHQwcjA3</span><br><span class="line">oDWgM4YxaHR0cDovL2NybDMuZGlnaWNlcnQuY29tL0RpZ2lDZXJ0R2xvYmFsUm9v</span><br><span class="line">dENBLmNybDA3oDWgM4YxaHR0cDovL2NybDQuZGlnaWNlcnQuY29tL0RpZ2lDZXJ0</span><br><span class="line">R2xvYmFsUm9vdENBLmNybDCBzgYDVR0gBIHGMIHDMIHABgRVHSAAMIG3MCgGCCsG</span><br><span class="line">AQUFBwIBFhxodHRwczovL3d3dy5kaWdpY2VydC5jb20vQ1BTMIGKBggrBgEFBQcC</span><br><span class="line">AjB+DHxBbnkgdXNlIG9mIHRoaXMgQ2VydGlmaWNhdGUgY29uc3RpdHV0ZXMgYWNj</span><br><span class="line">ZXB0YW5jZSBvZiB0aGUgUmVseWluZyBQYXJ0eSBBZ3JlZW1lbnQgbG9jYXRlZCBh</span><br><span class="line">dCBodHRwczovL3d3dy5kaWdpY2VydC5jb20vcnBhLXVhMA0GCSqGSIb3DQEBCwUA</span><br><span class="line">A4IBAQAi49xtSOuOygBycy50quCThG45xIdUAsQCaXFVRa9asPaB/jLINXJL3qV9</span><br><span class="line">J0Gh2bZM0k4yOMeAMZ57smP6JkcJihhOFlfQa18aljd+xNc6b+GX6oFcCHGr+gsE</span><br><span class="line">yPM8qvlKGxc5T5eHVzV6jpjpyzl6VEKpaxH6gdGVpQVgjkOR9yY9XAUlFnzlOCpq</span><br><span class="line">sm7r2ZUKpDfrhUnVzX2nSM15XSj48rVBBAnGJWkLPijlACd3sWFMVUiKRz1C5PZy</span><br><span class="line">el2l7J/W4d99KFLSYgoy5GDmARpwLc//fXfkr40nMY8ibCmxCsjXQTe0fJbtrrLL</span><br><span class="line">yWQlk9VDV296EI/kQOJNLVEkJ54P</span><br><span class="line">-----END CERTIFICATE-----</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kubernetes</category>
        <category>ingress</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>ingress</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes入门教程</title>
    <url>/2022/12/29/k8s%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="第一章-kubernetes介绍"><a href="#第一章-kubernetes介绍" class="headerlink" title="第一章 kubernetes介绍"></a>第一章 kubernetes介绍</h2><p>本章节主要介绍应用程序在服务器上部署方式演变以及kubernetes的概念、组件和工作原理。</p>
<h3 id="应用部署方式演变"><a href="#应用部署方式演变" class="headerlink" title="应用部署方式演变"></a>应用部署方式演变</h3><p>在部署应用程序的方式上，主要经历了三个时代：</p>
<ul>
<li><p><strong>传统部署</strong>：互联网早期，会直接将应用程序部署在物理机上</p>
<blockquote>
<p>优点：简单，不需要其它技术的参与</p>
<p>缺点：不能为应用程序定义资源使用边界，很难合理地分配计算资源，而且程序之间容易产生影响</p>
</blockquote>
</li>
<li><p><strong>虚拟化部署</strong>：可以在一台物理机上运行多个虚拟机，每个虚拟机都是独立的一个环境</p>
<blockquote>
<p>优点：程序环境不会相互产生影响，提供了一定程度的安全性</p>
<p>缺点：增加了操作系统，浪费了部分资源</p>
</blockquote>
</li>
<li><p><strong>容器化部署</strong>：与虚拟化类似，但是共享了操作系统</p>
<blockquote>
<p>优点：</p>
<p>可以保证每个容器拥有自己的文件系统、CPU、内存、进程空间等</p>
<p>运行应用程序所需要的资源都被容器包装，并和底层基础架构解耦</p>
<p>容器化的应用程序可以跨云服务商、跨Linux操作系统发行版进行部署</p>
</blockquote>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200505183738289.png" alt="image-20200505183738289"></p>
<p>容器化部署方式给带来很多的便利，但是也会出现一些问题，比如说：</p>
<ul>
<li>一个容器故障停机了，怎么样让另外一个容器立刻启动去替补停机的容器</li>
<li>当并发访问量变大的时候，怎么样做到横向扩展容器数量</li>
</ul>
<p>这些容器管理的问题统称为<strong>容器编排</strong>问题，为了解决这些容器编排问题，就产生了一些容器编排的软件：</p>
<ul>
<li><strong>Swarm</strong>：Docker自己的容器编排工具</li>
<li><strong>Mesos</strong>：Apache的一个资源统一管控的工具，需要和Marathon结合使用</li>
<li><strong>Kubernetes</strong>：Google开源的的容器编排工具</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200524150339551.png" alt="image-20200524150339551" style />

<h2 id="kubernetes简介"><a href="#kubernetes简介" class="headerlink" title="kubernetes简介"></a>kubernetes简介</h2><p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200406232838722.png" alt="image-20200406232838722"></p>
<p>​</p>
<pre><code>kubernetes，是一个全新的基于容器技术的分布式架构领先方案，是谷歌严格保密十几年的秘密武器----Borg系统的一个开源版本，于2014年9月发布第一个版本，2015年7月发布第一个正式版本。

kubernetes的本质是**一组服务器集群**，它可以在集群的每个节点上运行特定的程序，来对节点中的容器进行管理。目的是实现资源管理的自动化，主要提供了如下的主要功能：
</code></pre>
<ul>
<li><strong>自我修复</strong>：一旦某一个容器崩溃，能够在1秒中左右迅速启动新的容器</li>
<li><strong>弹性伸缩</strong>：可以根据需要，自动对集群中正在运行的容器数量进行调整</li>
<li><strong>服务发现</strong>：服务可以通过自动发现的形式找到它所依赖的服务</li>
<li><strong>负载均衡</strong>：如果一个服务起动了多个容器，能够自动实现请求的负载均衡</li>
<li><strong>版本回退</strong>：如果发现新发布的程序版本有问题，可以立即回退到原来的版本</li>
<li><strong>存储编排</strong>：可以根据容器自身的需求自动创建存储卷</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200526203726071.png" alt="image-20200526203726071"></p>
<h2 id="kubernetes组件"><a href="#kubernetes组件" class="headerlink" title="kubernetes组件"></a>kubernetes组件</h2><p>一个kubernetes集群主要是由**控制节点(master)**、**工作节点(node)**构成，每个节点上都会安装不同的组件。</p>
<p><strong>master：集群的控制平面，负责集群的决策  (  管理  )</strong></p>
<blockquote>
<p><strong>ApiServer</strong> : 资源操作的唯一入口，接收用户输入的命令，提供认证、授权、API注册和发现等机制</p>
<p><strong>Scheduler</strong> : 负责集群资源调度，按照预定的调度策略将Pod调度到相应的node节点上</p>
<p><strong>ControllerManager</strong> : 负责维护集群的状态，比如程序部署安排、故障检测、自动扩展、滚动更新等</p>
<p>**Etcd **：负责存储集群中各种资源对象的信息</p>
</blockquote>
<p>**node：集群的数据平面，负责为容器提供运行环境 ( 干活 ) **</p>
<blockquote>
<p><strong>Kubelet</strong> : 负责维护容器的生命周期，即通过控制docker，来创建、更新、销毁容器</p>
<p><strong>KubeProxy</strong> : 负责提供集群内部的服务发现和负载均衡</p>
<p><strong>Docker</strong> : 负责节点上容器的各种操作</p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200406184656917.png" alt="image-20200406184656917"></p>
<p>下面，以部署一个nginx服务来说明kubernetes系统各个组件调用关系：</p>
<ol>
<li><p>首先要明确，一旦kubernetes环境启动之后，master和node都会将自身的信息存储到etcd数据库中</p>
</li>
<li><p>一个nginx服务的安装请求会首先被发送到master节点的apiServer组件</p>
</li>
<li><p>apiServer组件会调用scheduler组件来决定到底应该把这个服务安装到哪个node节点上</p>
<p> 在此时，它会从etcd中读取各个node节点的信息，然后按照一定的算法进行选择，并将结果告知apiServer</p>
</li>
<li><p>apiServer调用controller-manager去调度Node节点安装nginx服务</p>
</li>
<li><p>kubelet接收到指令后，会通知docker，然后由docker来启动一个nginx的pod</p>
<p> pod是kubernetes的最小操作单元，容器必须跑在pod中至此，</p>
</li>
<li><p>一个nginx服务就运行了，如果需要访问nginx，就需要通过kube-proxy来对pod产生访问的代理</p>
<pre><code> 这样，外界用户就可以访问集群中的nginx服务了
</code></pre>
</li>
</ol>
<h2 id="kubernetes概念"><a href="#kubernetes概念" class="headerlink" title="kubernetes概念"></a>kubernetes概念</h2><p><strong>Master</strong>：集群控制节点，每个集群需要至少一个master节点负责集群的管控</p>
<p><strong>Node</strong>：工作负载节点，由master分配容器到这些node工作节点上，然后node节点上的docker负责容器的运行</p>
<p><strong>Pod</strong>：kubernetes的最小控制单元，容器都是运行在pod中的，一个pod中可以有1个或者多个容器</p>
<p><strong>Controller</strong>：控制器，通过它来实现对pod的管理，比如启动pod、停止pod、伸缩pod的数量等等</p>
<p><strong>Service</strong>：pod对外服务的统一入口，下面可以维护者同一类的多个pod</p>
<p><strong>Label</strong>：标签，用于对pod进行分类，同一类pod会拥有相同的标签</p>
<p><strong>NameSpace</strong>：命名空间，用来隔离pod的运行环境</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200403224313355.png" alt="image-20200403224313355"></p>
<h1 id="第二章-集群环境搭建"><a href="#第二章-集群环境搭建" class="headerlink" title="第二章 集群环境搭建"></a>第二章 集群环境搭建</h1><p>本章节主要介绍如何搭建kubernetes的集群环境</p>
<h2 id="环境规划"><a href="#环境规划" class="headerlink" title="环境规划"></a>环境规划</h2><h3 id="集群类型"><a href="#集群类型" class="headerlink" title="集群类型"></a>集群类型</h3><p>kubernetes集群大体上分为两类：<strong>一主多从</strong>和<strong>多主多从</strong>。</p>
<ul>
<li>一主多从：一台Master节点和多台Node节点，搭建简单，但是有单机故障风险，适合用于测试环境</li>
<li>多主多从：多台Master节点和多台Node节点，搭建麻烦，安全性高，适合用于生产环境</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200404094800622.png" alt="image-20200404094800622"></p>
<blockquote>
<p><code>说明：为了测试简单，本次搭建的是  一主两从   类型的集群</code></p>
</blockquote>
<h3 id="安装方式"><a href="#安装方式" class="headerlink" title="安装方式"></a>安装方式</h3><p>kubernetes有多种部署方式，目前主流的方式有kubeadm、minikube、二进制包</p>
<ul>
<li>minikube：一个用于快速搭建单节点kubernetes的工具</li>
<li>kubeadm：一个用于快速搭建kubernetes集群的工具</li>
<li>二进制包 ：从官网下载每个组件的二进制包，依次去安装，此方式对于理解kubernetes组件更加有效</li>
</ul>
<blockquote>
<p><code>说明：现在需要安装kubernetes的集群环境，但是又不想过于麻烦，所以选择使用kubeadm方式</code></p>
</blockquote>
<h3 id="主机规划"><a href="#主机规划" class="headerlink" title="主机规划"></a>主机规划</h3><table>
<thead>
<tr>
<th>作用</th>
<th>IP地址</th>
<th>操作系统</th>
<th>配置</th>
</tr>
</thead>
<tbody><tr>
<td>Master</td>
<td>192.168.109.101</td>
<td>Centos7.5    基础设施服务器</td>
<td>2颗CPU  2G内存   50G硬盘</td>
</tr>
<tr>
<td>Node1</td>
<td>192.168.109.102</td>
<td>Centos7.5    基础设施服务器</td>
<td>2颗CPU  2G内存   50G硬盘</td>
</tr>
<tr>
<td>Node2</td>
<td>192.168.109.103</td>
<td>Centos7.5    基础设施服务器</td>
<td>2颗CPU  2G内存   50G硬盘</td>
</tr>
</tbody></table>
<h2 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h2><pre><code>本次环境搭建需要安装三台Centos服务器（一主二从），然后在每台服务器中分别安装docker（18.06.3），kubeadm（1.17.4）、kubelet（1.17.4）、kubectl（1.17.4）程序。
</code></pre>
<h3 id="主机安装"><a href="#主机安装" class="headerlink" title="主机安装"></a>主机安装</h3><p>安装虚拟机过程中注意下面选项的设置：</p>
<ul>
<li><p>操作系统环境：CPU（2C）    内存（2G）   硬盘（50G）</p>
</li>
<li><p>语言选择：中文简体</p>
</li>
<li><p>软件选择：基础设施服务器</p>
</li>
<li><p>分区选择：自动分区</p>
</li>
<li><p>网络配置：按照下面配置网路地址信息</p>
  <figure class="highlight md"><table><tr><td class="code"><pre><span class="line">网络地址：192.168.109.100  （每台主机都不一样  分别为100、101、102）</span><br><span class="line">子网掩码：255.255.255.0</span><br><span class="line">默认网关：192.168.109.2</span><br><span class="line">DNS：    223.5.5.5</span><br></pre></td></tr></table></figure>

<p>  <img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200505213817934.png" alt="image-20200505213817934"></p>
</li>
<li><p>主机名设置：按照下面信息设置主机名</p>
  <figure class="highlight md"><table><tr><td class="code"><pre><span class="line">master节点： master</span><br><span class="line">node节点：   node1</span><br><span class="line">node节点：   node2</span><br></pre></td></tr></table></figure>

<p>  <img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200505214156148.png" alt="image-20200505214156148"></p>
</li>
</ul>
<h3 id="环境初始化"><a href="#环境初始化" class="headerlink" title="环境初始化"></a>环境初始化</h3><ol>
<li>检查操作系统的版本</li>
</ol>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 此方式下安装kubernetes集群要求Centos版本要在7.5或之上</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># cat /etc/redhat-release</span></span><br><span class="line">CentOS Linux release <span class="number">7.5</span>.<span class="number">1804</span> (Core)</span><br></pre></td></tr></table></figure>

<p>2） 主机名解析</p>
<p>为了方便后面集群节点间的直接调用，在这配置一下主机名解析，企业中推荐使用内部DNS服务器</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 主机名成解析 编辑三台服务器的/etc/hosts文件，添加下面内容</span></span><br><span class="line"><span class="number">192.168</span>.<span class="number">109.100</span>  master</span><br><span class="line"><span class="number">192.168</span>.<span class="number">109.101</span>  node1</span><br><span class="line"><span class="number">192.168</span>.<span class="number">109.102</span>  node2</span><br></pre></td></tr></table></figure>

<p>3） 时间同步</p>
<p>kubernetes要求集群中的节点时间必须精确一致，这里直接使用chronyd服务从网络同步时间。</p>
<p>企业中建议配置内部的时间同步服务器</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 启动chronyd服务</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># systemctl start chronyd</span></span><br><span class="line"><span class="comment"># 设置chronyd服务开机自启</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># systemctl enable chronyd</span></span><br><span class="line"><span class="comment"># chronyd服务启动稍等几秒钟，就可以使用date命令验证时间了</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># date</span></span><br></pre></td></tr></table></figure>

<p>4） 禁用iptables和firewalld服务</p>
<p>kubernetes和docker在运行中会产生大量的iptables规则，为了不让系统规则跟它们混淆，直接关闭系统的规则</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1 关闭firewalld服务</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># systemctl stop firewalld</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># systemctl disable firewalld</span></span><br><span class="line"><span class="comment"># 2 关闭iptables服务</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># systemctl stop iptables</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># systemctl disable iptables</span></span><br></pre></td></tr></table></figure>

<p>5） 禁用selinux</p>
<p>selinux是linux系统下的一个安全服务，如果不关闭它，在安装集群中会产生各种各样的奇葩问题</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 编辑 /etc/selinux/config 文件，修改SELINUX的值为disabled</span></span><br><span class="line"><span class="comment"># 注意修改完毕之后需要重启linux服务</span></span><br><span class="line">SELINUX=disabled</span><br></pre></td></tr></table></figure>

<p>6） 禁用swap分区</p>
<p>swap分区指的是虚拟内存分区，它的作用是在物理内存使用完之后，将磁盘空间虚拟成内存来使用</p>
<p>启用swap设备会对系统的性能产生非常负面的影响，因此kubernetes要求每个节点都要禁用swap设备</p>
<p>但是如果因为某些原因确实不能关闭swap分区，就需要在集群安装过程中通过明确的参数进行配置说明</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 编辑分区配置文件/etc/fstab，注释掉swap分区一行</span></span><br><span class="line"><span class="comment"># 注意修改完毕之后需要重启linux服务</span></span><br><span class="line"> UUID=<span class="number">455</span>cc753<span class="literal">-7a60-4c17-a424-7741728c44a1</span> /boot    xfs     defaults        <span class="number">0</span> <span class="number">0</span></span><br><span class="line"> /dev/mapper/centos<span class="literal">-home</span> /home                      xfs     defaults        <span class="number">0</span> <span class="number">0</span></span><br><span class="line"><span class="comment"># /dev/mapper/centos-swap swap                      swap    defaults        0 0</span></span><br></pre></td></tr></table></figure>

<p>7）修改linux的内核参数</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 修改linux的内核参数，添加网桥过滤和地址转发功能</span></span><br><span class="line"><span class="comment"># 编辑/etc/sysctl.d/kubernetes.conf文件，添加如下配置:</span></span><br><span class="line">net.bridge.bridge<span class="literal">-nf-call-ip6tables</span> = <span class="number">1</span></span><br><span class="line">net.bridge.bridge<span class="literal">-nf-call-iptables</span> = <span class="number">1</span></span><br><span class="line">net.ipv4.ip_forward = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新加载配置</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># sysctl -p</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载网桥过滤模块</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># modprobe br_netfilter</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看网桥过滤模块是否加载成功</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># lsmod | grep br_netfilter</span></span><br></pre></td></tr></table></figure>

<p>8）配置ipvs功能</p>
<p>在kubernetes中service有两种代理模型，一种是基于iptables的，一种是基于ipvs的</p>
<p>两者比较的话，ipvs的性能明显要高一些，但是如果要使用它，需要手动载入ipvs模块</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1 安装ipset和ipvsadm</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># yum install ipset ipvsadmin -y</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2 添加需要加载的模块写入脚本文件</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># cat &lt;&lt;EOF &gt;  /etc/sysconfig/modules/ipvs.modules</span></span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line">modprobe <span class="literal">--</span> ip_vs</span><br><span class="line">modprobe <span class="literal">--</span> ip_vs_rr</span><br><span class="line">modprobe <span class="literal">--</span> ip_vs_wrr</span><br><span class="line">modprobe <span class="literal">--</span> ip_vs_sh</span><br><span class="line">modprobe <span class="literal">--</span> nf_conntrack_ipv4</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3 为脚本文件添加执行权限</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># chmod +x /etc/sysconfig/modules/ipvs.modules</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4 执行脚本文件</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># /bin/bash /etc/sysconfig/modules/ipvs.modules</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5 查看对应的模块是否加载成功</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># lsmod | grep -e ip_vs -e nf_conntrack_ipv4</span></span><br></pre></td></tr></table></figure>

<p>9） 重启服务器</p>
<p>上面步骤完成之后，需要重新启动linux系统</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># reboot</span></span><br></pre></td></tr></table></figure>

<h3 id="安装docker"><a href="#安装docker" class="headerlink" title="安装docker"></a>安装docker</h3><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1 切换镜像源</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2 查看当前镜像源中支持的docker版本</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># yum list docker-ce --showduplicates</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3 安装特定版本的docker-ce</span></span><br><span class="line"><span class="comment"># 必须指定--setopt=obsoletes=0，否则yum会自动安装更高版本</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># yum install --setopt=obsoletes=0 docker-ce-18.06.3.ce-3.el7 -y</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4 添加一个配置文件</span></span><br><span class="line"><span class="comment"># Docker在默认情况下使用的Cgroup Driver为cgroupfs，而kubernetes推荐使用systemd来代替cgroupfs</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># mkdir /etc/docker</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># cat &lt;&lt;EOF &gt;  /etc/docker/daemon.json</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;exec-opts&quot;</span>: [<span class="string">&quot;native.cgroupdriver=systemd&quot;</span>],</span><br><span class="line">  <span class="string">&quot;registry-mirrors&quot;</span>: [<span class="string">&quot;https://kn0t2bca.mirror.aliyuncs.com&quot;</span>]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5 启动docker</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># systemctl restart docker</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># systemctl enable docker</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 6 检查docker状态和版本</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># docker version</span></span><br></pre></td></tr></table></figure>

<h3 id="安装kubernetes组件"><a href="#安装kubernetes组件" class="headerlink" title="安装kubernetes组件"></a>安装kubernetes组件</h3><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 由于kubernetes的镜像源在国外，速度比较慢，这里切换成国内的镜像源</span></span><br><span class="line"><span class="comment"># 编辑/etc/yum.repos.d/kubernetes.repo，添加下面的配置 </span></span><br><span class="line">[<span class="type">kubernetes</span>]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes<span class="literal">-el7-x86_64</span></span><br><span class="line">enabled=<span class="number">1</span></span><br><span class="line">gpgcheck=<span class="number">0</span></span><br><span class="line">repo_gpgcheck=<span class="number">0</span></span><br><span class="line">gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum<span class="literal">-key</span>.gpg</span><br><span class="line">       http://mirrors.aliyun.com/kubernetes/yum/doc/rpm<span class="literal">-package-key</span>.gpg</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装kubeadm、kubelet和kubectl</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># yum install --setopt=obsoletes=0 kubeadm-1.17.4-0 kubelet-1.17.4-0 kubectl-1.17.4-0 -y</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置kubelet的cgroup</span></span><br><span class="line"><span class="comment"># 编辑/etc/sysconfig/kubelet，添加下面的配置</span></span><br><span class="line">KUBELET_CGROUP_ARGS=<span class="string">&quot;--cgroup-driver=systemd&quot;</span></span><br><span class="line">KUBE_PROXY_MODE=<span class="string">&quot;ipvs&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4 设置kubelet开机自启</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># systemctl enable kubelet</span></span><br></pre></td></tr></table></figure>

<h3 id="准备集群镜像"><a href="#准备集群镜像" class="headerlink" title="准备集群镜像"></a>准备集群镜像</h3><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在安装kubernetes集群之前，必须要提前准备好集群需要的镜像，所需镜像可以通过下面命令查看</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubeadm config images list</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载镜像</span></span><br><span class="line"><span class="comment"># 此镜像在kubernetes的仓库中,由于网络原因,无法连接，下面提供了一种替代方案</span></span><br><span class="line">images=(</span><br><span class="line">    kube<span class="literal">-apiserver</span>:v1.<span class="number">17.4</span></span><br><span class="line">    kube<span class="literal">-controller-manager</span>:v1.<span class="number">17.4</span></span><br><span class="line">    kube<span class="literal">-scheduler</span>:v1.<span class="number">17.4</span></span><br><span class="line">    kube<span class="literal">-proxy</span>:v1.<span class="number">17.4</span></span><br><span class="line">    pause:<span class="number">3.1</span></span><br><span class="line">    etcd:<span class="number">3.4</span>.<span class="number">3</span><span class="literal">-0</span></span><br><span class="line">    coredns:<span class="number">1.6</span>.<span class="number">5</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> imageName <span class="keyword">in</span> <span class="variable">$</span>&#123;images[<span class="selector-tag">@</span>]&#125; ; <span class="keyword">do</span></span><br><span class="line"> docker pull registry.cn<span class="literal">-hangzhou</span>.aliyuncs.com/google_containers/<span class="variable">$imageName</span></span><br><span class="line"> docker tag registry.cn<span class="literal">-hangzhou</span>.aliyuncs.com/google_containers/<span class="variable">$imageName</span>   k8s.gcr.io/<span class="variable">$imageName</span></span><br><span class="line"> docker rmi registry.cn<span class="literal">-hangzhou</span>.aliyuncs.com/google_containers/<span class="variable">$imageName</span></span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h3 id="集群初始化"><a href="#集群初始化" class="headerlink" title="集群初始化"></a>集群初始化</h3><p>下面开始对集群进行初始化，并将node节点加入到集群中</p>
<blockquote>
<p>下面的操作只需要在<code>master</code>节点上执行即可</p>
</blockquote>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建集群</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubeadm init \</span></span><br><span class="line"> <span class="literal">--kubernetes-version</span>=v1.<span class="number">17.4</span> \</span><br><span class="line">    <span class="literal">--pod-network-cidr</span>=<span class="number">10.244</span>.<span class="number">0.0</span>/<span class="number">16</span> \</span><br><span class="line">    <span class="literal">--service-cidr</span>=<span class="number">10.96</span>.<span class="number">0.0</span>/<span class="number">12</span> \</span><br><span class="line">    <span class="literal">--apiserver-advertise-address</span>=<span class="number">192.168</span>.<span class="number">109.100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建必要文件</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># mkdir -p $HOME/.kube</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># sudo chown $(id -u):$(id -g) $HOME/.kube/config</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>下面的操作只需要在<code>node</code>节点上执行即可</p>
</blockquote>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将node节点加入集群</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubeadm join 192.168.109.100:6443 \ </span></span><br><span class="line"> <span class="literal">--token</span> <span class="number">8507</span>uc.o0knircuri8etnw2 \</span><br><span class="line"> <span class="literal">--discovery-token-ca-cert-hash</span> \</span><br><span class="line"> sha256:acc37967fb5b0acf39d7598f8a439cc7dc88f439a3f4d0c9cae88e7901b9d3f</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 查看集群状态 此时的集群状态为NotReady，这是因为还没有配置网络插件</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get nodes</span></span><br><span class="line">NAME     STATUS     ROLES    AGE     VERSION</span><br><span class="line">master   NotReady   master   <span class="number">6</span>m43s   v1.<span class="number">17.4</span></span><br><span class="line">node1    NotReady   &lt;none&gt;   <span class="number">22</span>s     v1.<span class="number">17.4</span></span><br><span class="line">node2    NotReady   &lt;none&gt;   <span class="number">19</span>s     v1.<span class="number">17.4</span></span><br></pre></td></tr></table></figure>

<h3 id="安装网络插件"><a href="#安装网络插件" class="headerlink" title="安装网络插件"></a>安装网络插件</h3><p>kubernetes支持多种网络插件，比如flannel、calico、canal等等，任选一种使用即可，本次选择flannel</p>
<blockquote>
<p>下面操作依旧只在<code>master</code>节点执行即可，插件使用的是DaemonSet的控制器，它会在每个节点上都运行</p>
</blockquote>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 获取fannel的配置文件</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改文件中quay.io仓库为quay-mirror.qiniu.com</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用配置文件启动fannel</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl apply -f kube-flannel.yml</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 稍等片刻，再次查看集群节点的状态</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get nodes</span></span><br><span class="line">NAME     STATUS   ROLES    AGE     VERSION</span><br><span class="line">master   Ready    master   <span class="number">15</span>m     v1.<span class="number">17.4</span></span><br><span class="line">node1    Ready    &lt;none&gt;   <span class="number">8</span>m53s   v1.<span class="number">17.4</span></span><br><span class="line">node2    Ready    &lt;none&gt;   <span class="number">8</span>m50s   v1.<span class="number">17.4</span></span><br></pre></td></tr></table></figure>

<p>至此，kubernetes的集群环境搭建完成</p>
<h2 id="服务部署"><a href="#服务部署" class="headerlink" title="服务部署"></a>服务部署</h2><p>接下来在kubernetes集群中部署一个nginx程序，测试下集群是否在正常工作。</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 部署nginx</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create deployment nginx --image=nginx:1.14-alpine</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 暴露端口</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl expose deployment nginx --port=80 --type=NodePort</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看服务状态</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods,service</span></span><br><span class="line">NAME                         READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/nginx<span class="literal">-86c57db685-fdc2k</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">18</span>m</span><br><span class="line"></span><br><span class="line">NAME                 <span class="built_in">TYPE</span>        CLUSTER<span class="literal">-IP</span>      EXTERNAL<span class="literal">-IP</span>   PORT(S)        AGE</span><br><span class="line">service/kubernetes   ClusterIP   <span class="number">10.96</span>.<span class="number">0.1</span>       &lt;none&gt;        <span class="number">443</span>/TCP        <span class="number">82</span>m</span><br><span class="line">service/nginx        NodePort    <span class="number">10.104</span>.<span class="number">121.45</span>   &lt;none&gt;        <span class="number">80</span>:<span class="number">30073</span>/TCP   <span class="number">17</span>m</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4 最后在电脑上访问下部署的nginx服务</span></span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200405142656921.png" alt="image-20200405142656921"></p>
<h1 id="第三章-资源管理"><a href="#第三章-资源管理" class="headerlink" title="第三章 资源管理"></a>第三章 资源管理</h1><p>本章节主要介绍yaml语法和kubernetes的资源管理方式</p>
<h2 id="资源管理介绍"><a href="#资源管理介绍" class="headerlink" title="资源管理介绍"></a>资源管理介绍</h2><p>在kubernetes中，所有的内容都抽象为资源，用户需要通过操作资源来管理kubernetes。</p>
<blockquote>
<p>kubernetes的本质上就是一个集群系统，用户可以在集群中部署各种服务，所谓的部署服务，其实就是在kubernetes集群中运行一个个的容器，并将指定的程序跑在容器中。</p>
<p>kubernetes的最小管理单元是pod而不是容器，所以只能将容器放在<code>Pod</code>中，而kubernetes一般也不会直接管理Pod，而是通过<code>Pod控制器</code>来管理Pod的。</p>
<p>Pod可以提供服务之后，就要考虑如何访问Pod中服务，kubernetes提供了<code>Service</code>资源实现这个功能。</p>
<p>当然，如果Pod中程序的数据需要持久化，kubernetes还提供了各种<code>存储</code>系统。</p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200406225334627.png" alt="image-20200406225334627"></p>
<blockquote>
<p>学习kubernetes的核心，就是学习如何对集群上的<code>Pod、Pod控制器、Service、存储</code>等各种资源进行操作</p>
</blockquote>
<h2 id="YAML语言介绍"><a href="#YAML语言介绍" class="headerlink" title="YAML语言介绍"></a>YAML语言介绍</h2><pre><code>YAML是一个类似 XML、JSON 的标记性语言。它强调以**数据**为中心，并不是以标识语言为重点。因而YAML本身的定义比较简单，号称&quot;一种人性化的数据格式语言&quot;。
</code></pre>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">heima</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">age</span>&gt;</span>15<span class="tag">&lt;/<span class="name">age</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">address</span>&gt;</span>Beijing<span class="tag">&lt;/<span class="name">address</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">heima</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">heima:</span></span><br><span class="line">  <span class="attr">age:</span> <span class="number">15</span></span><br><span class="line">  <span class="attr">address:</span> <span class="string">Beijing</span></span><br></pre></td></tr></table></figure>

<p>YAML的语法比较简单，主要有下面几个：</p>
<ul>
<li>大小写敏感</li>
<li>使用缩进表示层级关系</li>
<li>缩进不允许使用tab，只允许空格( 低版本限制 )</li>
<li>缩进的空格数不重要，只要相同层级的元素左对齐即可</li>
<li>‘#’表示注释</li>
</ul>
<p>YAML支持以下几种数据类型：</p>
<ul>
<li>纯量：单个的、不可再分的值</li>
<li>对象：键值对的集合，又称为映射（mapping）&#x2F; 哈希（hash） &#x2F; 字典（dictionary）</li>
<li>数组：一组按次序排列的值，又称为序列（sequence） &#x2F; 列表（list）</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 纯量, 就是指的一个简单的值，字符串、布尔值、整数、浮点数、Null、时间、日期</span></span><br><span class="line"><span class="comment"># 1 布尔类型</span></span><br><span class="line"><span class="attr">c1:</span> <span class="literal">true</span> <span class="string">(或者True)</span></span><br><span class="line"><span class="comment"># 2 整型</span></span><br><span class="line"><span class="attr">c2:</span> <span class="number">234</span></span><br><span class="line"><span class="comment"># 3 浮点型</span></span><br><span class="line"><span class="attr">c3:</span> <span class="number">3.14</span></span><br><span class="line"><span class="comment"># 4 null类型 </span></span><br><span class="line"><span class="attr">c4:</span> <span class="string">~</span>  <span class="comment"># 使用~表示null</span></span><br><span class="line"><span class="comment"># 5 日期类型</span></span><br><span class="line"><span class="attr">c5:</span> <span class="number">2018-02-17</span>    <span class="comment"># 日期必须使用ISO 8601格式，即yyyy-MM-dd</span></span><br><span class="line"><span class="comment"># 6 时间类型</span></span><br><span class="line"><span class="attr">c6:</span> <span class="number">2018-02-17T15:02:31+08:00</span>  <span class="comment"># 时间使用ISO 8601格式，时间和日期之间使用T连接，最后使用+代表时区</span></span><br><span class="line"><span class="comment"># 7 字符串类型</span></span><br><span class="line"><span class="attr">c7:</span> <span class="string">heima</span>     <span class="comment"># 简单写法，直接写值 , 如果字符串中间有特殊字符，必须使用双引号或者单引号包裹 </span></span><br><span class="line"><span class="attr">c8:</span> <span class="string">line1</span></span><br><span class="line">    <span class="string">line2</span>     <span class="comment"># 字符串过多的情况可以拆成多行，每一行会被转化成一个空格</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对象</span></span><br><span class="line"><span class="comment"># 形式一(推荐):</span></span><br><span class="line"><span class="attr">heima:</span></span><br><span class="line">  <span class="attr">age:</span> <span class="number">15</span></span><br><span class="line">  <span class="attr">address:</span> <span class="string">Beijing</span></span><br><span class="line"><span class="comment"># 形式二(了解):</span></span><br><span class="line"><span class="attr">heima:</span> &#123;<span class="attr">age:</span> <span class="number">15</span>,<span class="attr">address:</span> <span class="string">Beijing</span>&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数组</span></span><br><span class="line"><span class="comment"># 形式一(推荐):</span></span><br><span class="line"><span class="attr">address:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">顺义</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">昌平</span></span><br><span class="line"><span class="comment"># 形式二(了解):</span></span><br><span class="line"><span class="attr">address:</span> [<span class="string">顺义</span>,<span class="string">昌平</span>]</span><br></pre></td></tr></table></figure>

<blockquote>
<p>小提示：</p>
<p>1  书写yaml切记<code>:</code> 后面要加一个空格</p>
<p>2  如果需要将多段yaml配置放在一个文件中，中间要使用<code>---</code>分隔</p>
<p>3 下面是一个yaml转json的网站，可以通过它验证yaml是否书写正确</p>
<p><a href="https://www.json2yaml.com/convert-yaml-to-json">https://www.json2yaml.com/convert-yaml-to-json</a></p>
</blockquote>
<h2 id="资源管理方式"><a href="#资源管理方式" class="headerlink" title="资源管理方式"></a>资源管理方式</h2><ul>
<li><p>命令式对象管理：直接使用命令去操作kubernetes资源</p>
<p>  <code>kubectl run nginx-pod --image=nginx:1.17.1 --port=80</code></p>
</li>
<li><p>命令式对象配置：通过命令配置和配置文件去操作kubernetes资源</p>
<p>  <code>kubectl create/patch -f nginx-pod.yaml</code></p>
</li>
<li><p>声明式对象配置：通过apply命令和配置文件去操作kubernetes资源</p>
<p>  <code>kubectl apply -f nginx-pod.yaml</code></p>
</li>
</ul>
<table>
<thead>
<tr>
<th>类型</th>
<th>操作对象</th>
<th>适用环境</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody><tr>
<td>命令式对象管理</td>
<td>对象</td>
<td>测试</td>
<td>简单</td>
<td>只能操作活动对象，无法审计、跟踪</td>
</tr>
<tr>
<td>命令式对象配置</td>
<td>文件</td>
<td>开发</td>
<td>可以审计、跟踪</td>
<td>项目大时，配置文件多，操作麻烦</td>
</tr>
<tr>
<td>声明式对象配置</td>
<td>目录</td>
<td>开发</td>
<td>支持目录操作</td>
<td>意外情况下难以调试</td>
</tr>
</tbody></table>
<h3 id="命令式对象管理"><a href="#命令式对象管理" class="headerlink" title="命令式对象管理"></a>命令式对象管理</h3><p><strong>kubectl命令</strong></p>
<p><code>kubectl</code>是kubernetes集群的命令行工具，通过它能够对集群本身进行管理，并能够在集群上进行容器化应用的安装部署。kubectl命令的语法如下：</p>
<figure class="highlight md"><table><tr><td class="code"><pre><span class="line">kubectl [command] [type] [name] [flags]</span><br></pre></td></tr></table></figure>

<p><strong>comand</strong>：指定要对资源执行的操作，例如create、get、delete</p>
<p><strong>type</strong>：指定资源类型，比如deployment、pod、service</p>
<p><strong>name</strong>：指定资源的名称，名称大小写敏感</p>
<p><strong>flags</strong>：指定额外的可选参数</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看所有pod</span></span><br><span class="line">kubectl get pod </span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看某个pod</span></span><br><span class="line">kubectl get pod pod_name</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看某个pod,以yaml格式展示结果</span></span><br><span class="line">kubectl get pod pod_name <span class="literal">-o</span> yaml</span><br></pre></td></tr></table></figure>

<p><strong>资源类型</strong></p>
<p><code>kubernetes</code>中所有的内容都抽象为资源，可以通过下面的命令进行查看:</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">kubectl api<span class="literal">-resources</span></span><br></pre></td></tr></table></figure>

<p>经常使用的资源有下面这些：</p>
<table>
 <tr>
     <th>资源分类</th>
     <th>资源名称</th>
  <th>缩写</th>
  <th>资源作用</th>
 </tr>
 <tr>
     <td rowspan="2">集群级别资源</td>
        <td>nodes</td>
     <td>no</td>
  <td>集群组成部分</td>
 </tr>
 <tr>
  <td>namespaces</td>
     <td>ns</td>
  <td>隔离Pod</td>
 </tr>
 <tr>
  <td>pod资源</td>
     <td>pods</td>
     <td>po</td>
  <td>装载容器</td>
 </tr>
 <tr>
  <td rowspan="8">pod资源控制器</td>
     <td>replicationcontrollers</td>
     <td>rc</td>
  <td>控制pod资源</td>
 </tr>
 <tr>
     <td>replicasets</td>
     <td>rs</td>
  <td>控制pod资源</td>
 </tr>
 <tr>
     <td>deployments</td>
     <td>deploy</td>
  <td>控制pod资源</td>
 </tr>
 <tr>
     <td>daemonsets</td>
     <td>ds</td>
  <td>控制pod资源</td>
 </tr>
 <tr>
     <td>jobs</td>
     <td></td>
  <td>控制pod资源</td>
 </tr> 
 <tr>
     <td>cronjobs</td>
     <td>cj</td>
  <td>控制pod资源</td>
 </tr> 
 <tr>
     <td>horizontalpodautoscalers</td>
     <td>hpa</td>
  <td>控制pod资源</td>
 </tr> 
 <tr>
     <td>statefulsets</td>
     <td>sts</td>
  <td>控制pod资源</td>
 </tr>
 <tr>
  <td rowspan="2">服务发现资源</td>
     <td>services</td>
     <td>svc</td>
  <td>统一pod对外接口</td>
 </tr>
    <tr>
     <td>ingress</td>
     <td>ing</td>
  <td>统一pod对外接口</td>
 </tr>
 <tr>
  <td rowspan="3">存储资源</td>
     <td>volumeattachments</td>
     <td></td>
  <td>存储</td>
 </tr>
 <tr>
     <td>persistentvolumes</td>
     <td>pv</td>
  <td>存储</td>
 </tr>
 <tr>
     <td>persistentvolumeclaims</td>
     <td>pvc</td>
  <td>存储</td>
 </tr>
 <tr>
  <td rowspan="2">配置资源</td>
     <td>configmaps</td>
     <td>cm</td>
  <td>配置</td>
 </tr>
 <tr>
     <td>secrets</td>
     <td></td>
  <td>配置</td>
 </tr>
</table>

<p><strong>操作</strong></p>
<p><code>kubernetes</code>允许对资源进行多种操作，可以通过<code>--help</code>查看详细的操作命令</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">kubectl <span class="literal">--help</span></span><br></pre></td></tr></table></figure>

<p>经常使用的操作有下面这些：</p>
<table>
 <tr>
     <th>命令分类</th>
     <th>命令</th>
  <th>翻译</th>
  <th>命令作用</th>
 </tr>
 <tr>
     <td rowspan="6">基本命令</td>
     <td>create</td>
     <td>创建</td>
  <td>创建一个资源</td>
 </tr>
 <tr>
  <td>edit</td>
     <td>编辑</td>
  <td>编辑一个资源</td>
 </tr>
 <tr>
  <td>get</td>
     <td>获取</td>
     <td>获取一个资源</td>
 </tr>
   <tr>
  <td>patch</td>
     <td>更新</td>
     <td>更新一个资源</td>
 </tr>
 <tr>
     <td>delete</td>
     <td>删除</td>
  <td>删除一个资源</td>
 </tr>
 <tr>
     <td>explain</td>
     <td>解释</td>
  <td>展示资源文档</td>
 </tr>
 <tr>
     <td rowspan="10">运行和调试</td>
     <td>run</td>
     <td>运行</td>
  <td>在集群中运行一个指定的镜像</td>
 </tr>
 <tr>
     <td>expose</td>
     <td>暴露</td>
  <td>暴露资源为Service</td>
 </tr>
 <tr>
     <td>describe</td>
     <td>描述</td>
  <td>显示资源内部信息</td>
 </tr>
 <tr>
     <td>logs</td>
     <td>日志</td>
  <td>输出容器在 pod 中的日志</td>
 </tr>
 <tr>
     <td>attach</td>
     <td>缠绕</td>
  <td>进入运行中的容器</td>
 </tr>
 <tr>
     <td>exec</td>
     <td>执行</td>
  <td>执行容器中的一个命令</td>
 </tr>
 <tr>
     <td>cp</td>
     <td>复制</td>
  <td>在Pod内外复制文件</td>
 </tr>
  <tr>
  <td>rollout</td>
     <td>首次展示</td>
  <td>管理资源的发布</td>
 </tr>
 <tr>
  <td>scale</td>
     <td>规模</td>
  <td>扩(缩)容Pod的数量</td>
 </tr>
 <tr>
  <td>autoscale</td>
     <td>自动调整</td>
  <td>自动调整Pod的数量</td>
 </tr>
 <tr>
  <td rowspan="2">高级命令</td>
     <td>apply</td>
     <td>rc</td>
  <td>通过文件对资源进行配置</td>
 </tr>
 <tr>
     <td>label</td>
     <td>标签</td>
  <td>更新资源上的标签</td>
 </tr>
 <tr>
  <td rowspan="2">其他命令</td>
     <td>cluster-info</td>
     <td>集群信息</td>
  <td>显示集群信息</td>
 </tr>
 <tr>
     <td>version</td>
     <td>版本</td>
  <td>显示当前Server和Client的版本</td>
 </tr>
</table>

<p>下面以一个namespace &#x2F; pod的创建和删除简单演示下命令的使用：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建一个namespace</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create namespace dev</span></span><br><span class="line">namespace/dev created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取namespace</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get ns</span></span><br><span class="line">NAME              STATUS   AGE</span><br><span class="line">default           Active   <span class="number">21</span><span class="built_in">h</span></span><br><span class="line">dev               Active   <span class="number">21</span>s</span><br><span class="line">kube<span class="literal">-node-lease</span>   Active   <span class="number">21</span><span class="built_in">h</span></span><br><span class="line">kube<span class="literal">-public</span>       Active   <span class="number">21</span><span class="built_in">h</span></span><br><span class="line">kube<span class="literal">-system</span>       Active   <span class="number">21</span><span class="built_in">h</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在此namespace下创建并运行一个nginx的Pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl run pod --image=nginx -n dev</span></span><br><span class="line">kubectl run <span class="literal">--generator</span>=deployment/apps.v1 is DEPRECATED and will be removed <span class="keyword">in</span> a future version. Use kubectl run <span class="literal">--generator</span>=run<span class="literal">-pod</span>/v1 or kubectl create instead.</span><br><span class="line">deployment.apps/pod created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看新创建的pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pod -n dev</span></span><br><span class="line">NAME                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod<span class="literal">-864f9875b9-pcw7x</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">21</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除指定的pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete pod pod-864f9875b9-pcw7x</span></span><br><span class="line">pod <span class="string">&quot;pod-864f9875b9-pcw7x&quot;</span> deleted</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除指定的namespace</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete ns dev</span></span><br><span class="line">namespace <span class="string">&quot;dev&quot;</span> deleted</span><br></pre></td></tr></table></figure>

<h3 id="命令式对象配置"><a href="#命令式对象配置" class="headerlink" title="命令式对象配置"></a>命令式对象配置</h3><p>命令式对象配置就是使用命令配合配置文件一起来操作kubernetes资源。</p>
<p>1） 创建一个nginxpod.yaml，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">dev</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginxpod</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-containers</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br></pre></td></tr></table></figure>

<p>2）执行create命令，创建资源：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f nginxpod.yaml</span></span><br><span class="line">namespace/dev created</span><br><span class="line">pod/nginxpod created</span><br></pre></td></tr></table></figure>

<p>此时发现创建了两个资源对象，分别是namespace和pod</p>
<p>3）执行get命令，查看资源：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment">#  kubectl get -f nginxpod.yaml</span></span><br><span class="line">NAME            STATUS   AGE</span><br><span class="line">namespace/dev   Active   <span class="number">18</span>s</span><br><span class="line"></span><br><span class="line">NAME            READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/nginxpod    <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">17</span>s</span><br></pre></td></tr></table></figure>

<p>这样就显示了两个资源对象的信息</p>
<p>4）执行delete命令，删除资源：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete -f nginxpod.yaml</span></span><br><span class="line">namespace <span class="string">&quot;dev&quot;</span> deleted</span><br><span class="line">pod <span class="string">&quot;nginxpod&quot;</span> deleted</span><br></pre></td></tr></table></figure>

<p>此时发现两个资源对象被删除了</p>
<p>总结:<br>命令式对象配置的方式操作资源，可以简单的认为：命令  +  <code>yaml</code>配置文件（里面是命令需要的各种参数）</p>
<h3 id="声明式对象配置"><a href="#声明式对象配置" class="headerlink" title="声明式对象配置"></a>声明式对象配置</h3><p>声明式对象配置跟命令式对象配置很相似，但是它只有一个命令apply。</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 首先执行一次kubectl apply -f yaml文件，发现创建了资源</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment">#  kubectl apply -f nginxpod.yaml</span></span><br><span class="line">namespace/dev created</span><br><span class="line">pod/nginxpod created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 再次执行一次kubectl apply -f yaml文件，发现说资源没有变动</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment">#  kubectl apply -f nginxpod.yaml</span></span><br><span class="line">namespace/dev unchanged</span><br><span class="line">pod/nginxpod unchanged</span><br></pre></td></tr></table></figure>

<p>总结:<br>其实声明式对象配置就是使用apply描述一个资源最终的状态（在yaml中定义状态）<br>使用apply操作资源：<br>如果资源不存在，就创建，相当于 <code>kubectl create</code><br>如果资源已存在，就更新，相当于 <code>kubectl patch</code></p>
<blockquote>
<p>扩展：kubectl可以在node节点上运行吗 ?</p>
</blockquote>
<p><code>kubectl</code>的运行是需要进行配置的，它的配置文件是<code>\$HOME/.kube</code>，如果想要在<code>node</code>节点运行此命令，需要将<code>master</code>上的<code>.kube</code>文件复制到<code>node</code>节点上，即在<code>master</code>节点上执行下面操作：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">scp  <span class="literal">-r</span>  HOME/.kube   node1: HOME/</span><br></pre></td></tr></table></figure>

<blockquote>
<p>使用推荐:  三种方式应该怎么用 ?</p>
<p>创建&#x2F;更新资源      使用声明式对象配置 kubectl apply -f  XXX.yaml</p>
<p>删除资源              使用命令式对象配置 kubectl delete -f  XXX.yaml</p>
<p>查询资源              使用命令式对象管理 kubectl get(describe) 资源名称</p>
</blockquote>
<h1 id="第四章-实战入门"><a href="#第四章-实战入门" class="headerlink" title="第四章 实战入门"></a>第四章 实战入门</h1><p>本章节将介绍如何在<code>kubernetes</code>集群中部署一个<code>nginx</code>服务，并且能够对其进行访问。</p>
<h2 id="Namespace"><a href="#Namespace" class="headerlink" title="Namespace"></a>Namespace</h2><p>Namespace是kubernetes系统中的一种非常重要资源，它的主要作用是用来实现<strong>多套环境的资源隔离</strong>或者<strong>多租户的资源隔离</strong>。</p>
<p>默认情况下，kubernetes集群中的所有的Pod都是可以相互访问的。但是在实际中，可能不想让两个Pod之间进行互相的访问，那此时就可以将两个Pod划分到不同的namespace下。kubernetes通过将集群内部的资源分配到不同的Namespace中，可以形成逻辑上的”组”，以方便不同的组的资源进行隔离使用和管理。</p>
<p>可以通过kubernetes的授权机制，将不同的namespace交给不同租户进行管理，这样就实现了多租户的资源隔离。此时还能结合kubernetes的资源配额机制，限定不同租户能占用的资源，例如CPU使用量、内存使用量等等，来实现租户可用资源的管理。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200407100850484.png" alt="image-20200407100850484"></p>
<p>kubernetes在集群启动之后，会默认创建几个namespace</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl  get namespace</span></span><br><span class="line">NAME              STATUS   AGE</span><br><span class="line">default           Active   <span class="number">45</span><span class="built_in">h</span>     <span class="comment">#  所有未指定Namespace的对象都会被分配在default命名空间</span></span><br><span class="line">kube<span class="literal">-node-lease</span>   Active   <span class="number">45</span><span class="built_in">h</span>     <span class="comment">#  集群节点之间的心跳维护，v1.13开始引入</span></span><br><span class="line">kube<span class="literal">-public</span>       Active   <span class="number">45</span><span class="built_in">h</span>     <span class="comment">#  此命名空间下的资源可以被所有人访问（包括未认证用户）</span></span><br><span class="line">kube<span class="literal">-system</span>       Active   <span class="number">45</span><span class="built_in">h</span>     <span class="comment">#  所有由Kubernetes系统创建的资源都处于这个命名空间</span></span><br></pre></td></tr></table></figure>

<p>下面来看namespace资源的具体操作：</p>
<p><strong>查看</strong></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1 查看所有的ns  命令：kubectl get ns</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get ns</span></span><br><span class="line">NAME              STATUS   AGE</span><br><span class="line">default           Active   <span class="number">45</span><span class="built_in">h</span></span><br><span class="line">kube<span class="literal">-node-lease</span>   Active   <span class="number">45</span><span class="built_in">h</span></span><br><span class="line">kube<span class="literal">-public</span>       Active   <span class="number">45</span><span class="built_in">h</span>     </span><br><span class="line">kube<span class="literal">-system</span>       Active   <span class="number">45</span><span class="built_in">h</span>     </span><br><span class="line"></span><br><span class="line"><span class="comment"># 2 查看指定的ns   命令：kubectl get ns ns名称</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get ns default</span></span><br><span class="line">NAME      STATUS   AGE</span><br><span class="line">default   Active   <span class="number">45</span><span class="built_in">h</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3 指定输出格式  命令：kubectl get ns ns名称  -o 格式参数</span></span><br><span class="line"><span class="comment"># kubernetes支持的格式有很多，比较常见的是wide、json、yaml</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get ns default -o yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: <span class="string">&quot;2020-04-05T04:44:16Z&quot;</span></span><br><span class="line">  name: default</span><br><span class="line">  resourceVersion: <span class="string">&quot;151&quot;</span></span><br><span class="line">  selfLink: /api/v1/namespaces/default</span><br><span class="line">  uid: <span class="number">7405</span>f73a<span class="literal">-e486-43d4-9db6-145f1409f090</span></span><br><span class="line">spec:</span><br><span class="line">  finalizers:</span><br><span class="line">  - kubernetes</span><br><span class="line">status:</span><br><span class="line">  phase: Active</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 4 查看ns详情  命令：kubectl describe ns ns名称</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl describe ns default</span></span><br><span class="line">Name:         default</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  &lt;none&gt;</span><br><span class="line">Status:       Active  <span class="comment"># Active 命名空间正在使用中  Terminating 正在删除命名空间</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ResourceQuota 针对namespace做的资源限制</span></span><br><span class="line"><span class="comment"># LimitRange针对namespace中的每个组件做的资源限制</span></span><br><span class="line">No resource quota.</span><br><span class="line">No LimitRange resource.</span><br></pre></td></tr></table></figure>

<p><strong>创建</strong></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建namespace</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create ns dev</span></span><br><span class="line">namespace/dev created</span><br></pre></td></tr></table></figure>

<p><strong>删除</strong></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 删除namespace</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete ns dev</span></span><br><span class="line">namespace <span class="string">&quot;dev&quot;</span> deleted</span><br></pre></td></tr></table></figure>

<p><strong>配置方式</strong></p>
<p>首先准备一个yaml文件：ns-dev.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">dev</span></span><br></pre></td></tr></table></figure>

<p>然后就可以执行对应的创建和删除命令了：</p>
<p>创建：<code>kubectl  create  -f  ns-dev.yaml</code></p>
<p>删除：<code>kubectl  delete  -f  ns-dev.yaml</code></p>
<h2 id="Pod"><a href="#Pod" class="headerlink" title="Pod"></a>Pod</h2><p>Pod是kubernetes集群进行管理的最小单元，程序要运行必须部署在容器中，而容器必须存在于Pod中。</p>
<p>Pod可以认为是容器的封装，一个Pod中可以存在一个或者多个容器。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200407121501907.png" alt="image-20200407121501907"></p>
<p>kubernetes在集群启动之后，集群中的各个组件也都是以Pod方式运行的。可以通过下面命令查看：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pod -n kube-system</span></span><br><span class="line">NAMESPACE     NAME                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube<span class="literal">-system</span>   coredns<span class="literal">-6955765f44-68g6v</span>         <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>d1<span class="built_in">h</span></span><br><span class="line">kube<span class="literal">-system</span>   coredns<span class="literal">-6955765f44-cs5r8</span>         <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>d1<span class="built_in">h</span></span><br><span class="line">kube<span class="literal">-system</span>   etcd<span class="literal">-master</span>                      <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>d1<span class="built_in">h</span></span><br><span class="line">kube<span class="literal">-system</span>   kube<span class="literal">-apiserver-master</span>            <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>d1<span class="built_in">h</span></span><br><span class="line">kube<span class="literal">-system</span>   kube<span class="literal">-controller-manager-master</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>d1<span class="built_in">h</span></span><br><span class="line">kube<span class="literal">-system</span>   kube<span class="literal">-flannel-ds-amd64-47r25</span>      <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>d1<span class="built_in">h</span></span><br><span class="line">kube<span class="literal">-system</span>   kube<span class="literal">-flannel-ds-amd64-ls5lh</span>      <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>d1<span class="built_in">h</span></span><br><span class="line">kube<span class="literal">-system</span>   kube<span class="literal">-proxy-685tk</span>                 <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>d1<span class="built_in">h</span></span><br><span class="line">kube<span class="literal">-system</span>   kube<span class="literal">-proxy-87spt</span>                 <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>d1<span class="built_in">h</span></span><br><span class="line">kube<span class="literal">-system</span>   kube<span class="literal">-scheduler-master</span>            <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>d1<span class="built_in">h</span></span><br></pre></td></tr></table></figure>

<p><strong>创建并运行</strong></p>
<p>kubernetes没有提供单独运行Pod的命令，都是通过Pod控制器来实现的</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 命令格式： kubectl run (pod控制器名称) [参数] </span></span><br><span class="line"><span class="comment"># --image  指定Pod的镜像</span></span><br><span class="line"><span class="comment"># --port   指定端口</span></span><br><span class="line"><span class="comment"># --namespace  指定namespace</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl run nginx --image=nginx:1.17.1 --port=80 --namespace dev </span></span><br><span class="line">deployment.apps/nginx created</span><br></pre></td></tr></table></figure>

<p><strong>查看pod信息</strong></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看Pod基本信息</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev</span></span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">nginx<span class="literal">-5ff7956ff6-fg2db</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">43</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Pod的详细信息</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl describe pod nginx-5ff7956ff6-fg2db -n dev</span></span><br><span class="line">Name:         nginx<span class="literal">-5ff7956ff6-fg2db</span></span><br><span class="line">Namespace:    dev</span><br><span class="line">Priority:     <span class="number">0</span></span><br><span class="line">Node:         node1/<span class="number">192.168</span>.<span class="number">109.101</span></span><br><span class="line"><span class="built_in">Start</span> Time:   Wed, <span class="number">08</span> Apr <span class="number">2020</span> <span class="number">09</span>:<span class="number">29</span>:<span class="number">24</span> +<span class="number">0800</span></span><br><span class="line">Labels:       pod<span class="literal">-template-hash</span>=<span class="number">5</span>ff7956ff6</span><br><span class="line">              run=nginx</span><br><span class="line">Annotations:  &lt;none&gt;</span><br><span class="line">Status:       Running</span><br><span class="line">IP:           <span class="number">10.244</span>.<span class="number">1.23</span></span><br><span class="line">IPs:</span><br><span class="line">  IP:           <span class="number">10.244</span>.<span class="number">1.23</span></span><br><span class="line">Controlled By:  ReplicaSet/nginx<span class="literal">-5ff7956ff6</span></span><br><span class="line">Containers:</span><br><span class="line">  nginx:</span><br><span class="line">    Container ID:   docker://<span class="number">4</span>c62b8c0648d2512380f4ffa5da2c99d16e05634979973449c98e9b829f6253c</span><br><span class="line">    Image:          nginx:<span class="number">1.17</span>.<span class="number">1</span></span><br><span class="line">    Image ID:       docker<span class="literal">-pullable</span>://nginx@sha256:<span class="number">485</span>b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7</span><br><span class="line">    Port:           <span class="number">80</span>/TCP</span><br><span class="line">    Host Port:      <span class="number">0</span>/TCP</span><br><span class="line">    State:          Running</span><br><span class="line">      Started:      Wed, <span class="number">08</span> Apr <span class="number">2020</span> <span class="number">09</span>:<span class="number">30</span>:<span class="number">01</span> +<span class="number">0800</span></span><br><span class="line">    Ready:          True</span><br><span class="line">    Restart Count:  <span class="number">0</span></span><br><span class="line">    Environment:    &lt;none&gt;</span><br><span class="line">    Mounts:</span><br><span class="line">      /var/run/secrets/kubernetes.io/serviceaccount from default<span class="literal">-token-hwvvw</span> (ro)</span><br><span class="line">Conditions:</span><br><span class="line">  <span class="built_in">Type</span>              Status</span><br><span class="line">  Initialized       True</span><br><span class="line">  Ready             True</span><br><span class="line">  ContainersReady   True</span><br><span class="line">  PodScheduled      True</span><br><span class="line">Volumes:</span><br><span class="line">  default<span class="literal">-token-hwvvw</span>:</span><br><span class="line">    <span class="built_in">Type</span>:        Secret (a volume populated by a Secret)</span><br><span class="line">    SecretName:  default<span class="literal">-token-hwvvw</span></span><br><span class="line">    Optional:    false</span><br><span class="line">QoS <span class="class"><span class="keyword">Class</span>:       <span class="title">BestEffort</span></span></span><br><span class="line"><span class="class"><span class="title">Node</span>-<span class="title">Selectors</span>:  &lt;<span class="title">none</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">Tolerations</span>:     <span class="title">node</span>.<span class="title">kubernetes</span>.<span class="title">io</span>/<span class="title">not</span>-<span class="title">ready</span>:<span class="title">NoExecute</span> <span class="title">for</span> 300<span class="title">s</span></span></span><br><span class="line"><span class="class">                 <span class="title">node</span>.<span class="title">kubernetes</span>.<span class="title">io</span>/<span class="title">unreachable</span>:<span class="title">NoExecute</span> <span class="title">for</span> 300<span class="title">s</span></span></span><br><span class="line"><span class="class"><span class="title">Events</span>:</span></span><br><span class="line"><span class="class">  <span class="title">Type</span>    <span class="title">Reason</span>     <span class="title">Age</span>        <span class="title">From</span>               <span class="title">Message</span></span></span><br><span class="line"><span class="class">  ----    ------     ----       ----               -------</span></span><br><span class="line"><span class="class">  <span class="title">Normal</span>  <span class="title">Scheduled</span>  &lt;<span class="title">unknown</span>&gt;  <span class="title">default</span>-<span class="title">scheduler</span>  <span class="title">Successfully</span> <span class="title">assigned</span> <span class="title">dev</span>/<span class="title">nginx</span>-5<span class="title">ff7956ff6</span>-<span class="title">fg2db</span> <span class="title">to</span> <span class="title">node1</span></span></span><br><span class="line"><span class="class">  <span class="title">Normal</span>  <span class="title">Pulling</span>    4<span class="title">m11s</span>      <span class="title">kubelet</span>, <span class="title">node1</span>     <span class="title">Pulling</span> <span class="title">image</span> &quot;<span class="title">nginx</span>:1.17.1&quot;</span></span><br><span class="line"><span class="class">  <span class="title">Normal</span>  <span class="title">Pulled</span>     3<span class="title">m36s</span>      <span class="title">kubelet</span>, <span class="title">node1</span>     <span class="title">Successfully</span> <span class="title">pulled</span> <span class="title">image</span> &quot;<span class="title">nginx</span>:1.17.1&quot;</span></span><br><span class="line"><span class="class">  <span class="title">Normal</span>  <span class="title">Created</span>    3<span class="title">m36s</span>      <span class="title">kubelet</span>, <span class="title">node1</span>     <span class="title">Created</span> <span class="title">container</span> <span class="title">nginx</span></span></span><br><span class="line"><span class="class">  <span class="title">Normal</span>  <span class="title">Started</span>    3<span class="title">m36s</span>      <span class="title">kubelet</span>, <span class="title">node1</span>     <span class="title">Started</span> <span class="title">container</span> <span class="title">nginx</span></span></span><br></pre></td></tr></table></figure>

<p><strong>访问Pod</strong></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 获取podIP</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev -o wide</span></span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE    IP             NODE    ... </span><br><span class="line">nginx<span class="literal">-5ff7956ff6-fg2db</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">190</span>s   <span class="number">10.244</span>.<span class="number">1.23</span>   node1   ...</span><br><span class="line"></span><br><span class="line"><span class="comment">#访问POD</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># curl http://10.244.1.23:80</span></span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line"> &lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line"> &lt;p&gt;&lt;em&gt;Thank you <span class="keyword">for</span> <span class="keyword">using</span> nginx.&lt;/em&gt;&lt;/p&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure>

<p><strong>删除指定Pod</strong></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 删除指定Pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete pod nginx-5ff7956ff6-fg2db -n dev</span></span><br><span class="line">pod <span class="string">&quot;nginx-5ff7956ff6-fg2db&quot;</span> deleted</span><br><span class="line"></span><br><span class="line"><span class="comment"># 此时，显示删除Pod成功，但是再查询，发现又新产生了一个 </span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev</span></span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">nginx<span class="literal">-5ff7956ff6-jj4ng</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">21</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这是因为当前Pod是由Pod控制器创建的，控制器会监控Pod状况，一旦发现Pod死亡，会立即重建</span></span><br><span class="line"><span class="comment"># 此时要想删除Pod，必须删除Pod控制器</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 先来查询一下当前namespace下的Pod控制器</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get deploy -n  dev</span></span><br><span class="line">NAME    READY   UP<span class="literal">-TO-DATE</span>   AVAILABLE   AGE</span><br><span class="line">nginx   <span class="number">1</span>/<span class="number">1</span>     <span class="number">1</span>            <span class="number">1</span>           <span class="number">9</span>m7s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来，删除此PodPod控制器</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete deploy nginx -n dev</span></span><br><span class="line">deployment.apps <span class="string">&quot;nginx&quot;</span> deleted</span><br><span class="line"></span><br><span class="line"><span class="comment"># 稍等片刻，再查询Pod，发现Pod被删除了</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev</span></span><br><span class="line">No resources found <span class="keyword">in</span> dev namespace.</span><br></pre></td></tr></table></figure>

<p><strong>配置操作</strong></p>
<p>创建一个pod-nginx.yaml，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">pod</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-port</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br></pre></td></tr></table></figure>

<p>然后就可以执行对应的创建和删除命令了：</p>
<p>创建：<code>kubectl  create  -f  pod-nginx.yaml</code></p>
<p>删除：<code>kubectl  delete  -f  pod-nginx.yaml</code></p>
<h2 id="Label"><a href="#Label" class="headerlink" title="Label"></a>Label</h2><p>Label是kubernetes系统中的一个重要概念。它的作用就是在资源上添加标识，用来对它们进行区分和选择。</p>
<p>Label的特点：</p>
<ul>
<li>一个Label会以key&#x2F;value键值对的形式附加到各种对象上，如Node、Pod、Service等等</li>
<li>一个资源对象可以定义任意数量的Label ，同一个Label也可以被添加到任意数量的资源对象上去</li>
<li>Label通常在资源对象定义时确定，当然也可以在对象创建后动态添加或者删除</li>
</ul>
<p>可以通过Label实现资源的多维度分组，以便灵活、方便地进行资源分配、调度、配置、部署等管理工作。</p>
<blockquote>
<p>一些常用的Label 示例如下：</p>
<ul>
<li>版本标签：”version”:”release”, “version”:”stable”……</li>
<li>环境标签：”environment”:”dev”，”environment”:”test”，”environment”:”pro”</li>
<li>架构标签：”tier”:”frontend”，”tier”:”backend”</li>
</ul>
</blockquote>
<p>标签定义完毕之后，还要考虑到标签的选择，这就要使用到Label Selector，即：</p>
<p>Label用于给某个资源对象定义标识</p>
<p>Label Selector用于查询和筛选拥有某些标签的资源对象</p>
<p>当前有两种Label Selector：</p>
<ul>
<li><p>基于等式的Label Selector</p>
<p>  name &#x3D; slave: 选择所有包含Label中key&#x3D;”name”且value&#x3D;”slave”的对象</p>
<p>  env !&#x3D; production: 选择所有包括Label中的key&#x3D;”env”且value不等于”production”的对象</p>
</li>
<li><p>基于集合的Label Selector</p>
<p>  name in (master, slave): 选择所有包含Label中的key&#x3D;”name”且value&#x3D;”master”或”slave”的对象</p>
<p>  name not in (frontend): 选择所有包含Label中的key&#x3D;”name”且value不等于”frontend”的对象</p>
</li>
</ul>
<p>标签的选择条件可以使用多个，此时将多个Label Selector进行组合，使用逗号”,”进行分隔即可。例如：</p>
<p><code>name=slave</code>，<code>env!=production</code></p>
<p><code>name not in (frontend)</code>，<code>env!=production</code></p>
<p><strong>命令方式</strong></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 为pod资源打标签</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl label pod nginx-pod version=1.0 -n dev</span></span><br><span class="line">pod/nginx<span class="literal">-pod</span> labeled</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为pod资源更新标签</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl label pod nginx-pod version=2.0 -n dev --overwrite</span></span><br><span class="line">pod/nginx<span class="literal">-pod</span> labeled</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看标签</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pod nginx-pod  -n dev --show-labels</span></span><br><span class="line">NAME        READY   STATUS    RESTARTS   AGE   LABELS</span><br><span class="line">nginx<span class="literal">-pod</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">10</span>m   version=<span class="number">2.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 筛选标签</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pod -n dev -l version=2.0  --show-labels</span></span><br><span class="line">NAME        READY   STATUS    RESTARTS   AGE   LABELS</span><br><span class="line">nginx<span class="literal">-pod</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">17</span>m   version=<span class="number">2.0</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pod -n dev -l version!=2.0 --show-labels</span></span><br><span class="line">No resources found <span class="keyword">in</span> dev namespace.</span><br><span class="line"></span><br><span class="line"><span class="comment">#删除标签</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl label pod nginx-pod version- -n dev</span></span><br><span class="line">pod/nginx<span class="literal">-pod</span> labeled</span><br></pre></td></tr></table></figure>

<p><strong>配置方式</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">version:</span> <span class="string">&quot;3.0&quot;</span> </span><br><span class="line">    <span class="attr">env:</span> <span class="string">&quot;test&quot;</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">pod</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-port</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br></pre></td></tr></table></figure>

<p>然后就可以执行对应的更新命令了：kubectl  apply  -f  pod-nginx.yaml</p>
<h2 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a>Deployment</h2><p>在kubernetes中，Pod是最小的控制单元，但是kubernetes很少直接控制Pod，一般都是通过Pod控制器来完成的。Pod控制器用于pod的管理，确保pod资源符合预期的状态，当pod的资源出现故障时，会尝试进行重启或重建pod。</p>
<p>在kubernetes中Pod控制器的种类有很多，本章节只介绍一种：<code>Deployment</code>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200408193950807.png" alt="image-20200408193950807"></p>
<p><strong>命令操作</strong></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 命令格式: kubectl run deployment名称  [参数] </span></span><br><span class="line"><span class="comment"># --image  指定pod的镜像</span></span><br><span class="line"><span class="comment"># --port   指定端口</span></span><br><span class="line"><span class="comment"># --replicas  指定创建pod数量</span></span><br><span class="line"><span class="comment"># --namespace  指定namespace</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl run nginx --image=nginx:1.17.1 --port=80 --replicas=3 -n dev</span></span><br><span class="line">deployment.apps/nginx created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看创建的Pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev</span></span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">nginx<span class="literal">-5ff7956ff6-6k8cb</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">19</span>s</span><br><span class="line">nginx<span class="literal">-5ff7956ff6-jxfjt</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">19</span>s</span><br><span class="line">nginx<span class="literal">-5ff7956ff6-v6jqw</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">19</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看deployment的信息</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get deploy -n dev</span></span><br><span class="line">NAME    READY   UP<span class="literal">-TO-DATE</span>   AVAILABLE   AGE</span><br><span class="line">nginx   <span class="number">3</span>/<span class="number">3</span>     <span class="number">3</span>            <span class="number">3</span>           <span class="number">2</span>m42s</span><br><span class="line"></span><br><span class="line"><span class="comment"># UP-TO-DATE：成功升级的副本数量</span></span><br><span class="line"><span class="comment"># AVAILABLE：可用副本的数量</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get deploy -n dev -o wide</span></span><br><span class="line">NAME    READY UP<span class="literal">-TO-DATE</span>  AVAILABLE   AGE     CONTAINERS   IMAGES              SELECTOR</span><br><span class="line">nginx   <span class="number">3</span>/<span class="number">3</span>     <span class="number">3</span>         <span class="number">3</span>           <span class="number">2</span>m51s   nginx        nginx:<span class="number">1.17</span>.<span class="number">1</span>        run=nginx</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看deployment的详细信息</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl describe deploy nginx -n dev</span></span><br><span class="line">Name:                   nginx</span><br><span class="line">Namespace:              dev</span><br><span class="line">CreationTimestamp:      Wed, <span class="number">08</span> Apr <span class="number">2020</span> <span class="number">11</span>:<span class="number">14</span>:<span class="number">14</span> +<span class="number">0800</span></span><br><span class="line">Labels:                 run=nginx</span><br><span class="line">Annotations:            deployment.kubernetes.io/revision: <span class="number">1</span></span><br><span class="line">Selector:               run=nginx</span><br><span class="line">Replicas:               <span class="number">3</span> desired | <span class="number">3</span> updated | <span class="number">3</span> total | <span class="number">3</span> available | <span class="number">0</span> unavailable</span><br><span class="line">StrategyType:           RollingUpdate</span><br><span class="line">MinReadySeconds:        <span class="number">0</span></span><br><span class="line">RollingUpdateStrategy:  <span class="number">25</span>% max unavailable, <span class="number">25</span>% max surge</span><br><span class="line">Pod Template:</span><br><span class="line">  Labels:  run=nginx</span><br><span class="line">  Containers:</span><br><span class="line">   nginx:</span><br><span class="line">    Image:        nginx:<span class="number">1.17</span>.<span class="number">1</span></span><br><span class="line">    Port:         <span class="number">80</span>/TCP</span><br><span class="line">    Host Port:    <span class="number">0</span>/TCP</span><br><span class="line">    Environment:  &lt;none&gt;</span><br><span class="line">    Mounts:       &lt;none&gt;</span><br><span class="line">  Volumes:        &lt;none&gt;</span><br><span class="line">Conditions:</span><br><span class="line">  <span class="built_in">Type</span>           Status  Reason</span><br><span class="line">  <span class="literal">----</span>           <span class="literal">------</span>  <span class="literal">------</span></span><br><span class="line">  Available      True    MinimumReplicasAvailable</span><br><span class="line">  Progressing    True    NewReplicaSetAvailable</span><br><span class="line">OldReplicaSets:  &lt;none&gt;</span><br><span class="line">NewReplicaSet:   nginx<span class="literal">-5ff7956ff6</span> (<span class="number">3</span>/<span class="number">3</span> replicas created)</span><br><span class="line">Events:</span><br><span class="line">  <span class="built_in">Type</span>    Reason             Age    From                   Message</span><br><span class="line">  <span class="literal">----</span>    <span class="literal">------</span>             <span class="literal">----</span>   <span class="literal">----</span>                   <span class="literal">-------</span></span><br><span class="line">  Normal  ScalingReplicaSet  <span class="number">5</span>m43s  deployment<span class="literal">-controller</span>  Scaled up replicaset nginx<span class="literal">-5ff7956ff6</span> to <span class="number">3</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 删除 </span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete deploy nginx -n dev</span></span><br><span class="line">deployment.apps <span class="string">&quot;nginx&quot;</span> deleted</span><br></pre></td></tr></table></figure>

<p><strong>配置操作</strong></p>
<p>创建一个deploy-nginx.yaml，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">run:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">          <span class="attr">protocol:</span> <span class="string">TCP</span></span><br></pre></td></tr></table></figure>

<p>然后就可以执行对应的创建和删除命令了：</p>
<p>创建：<code>kubectl  create  -f  deploy-nginx.yaml</code></p>
<p>删除：<code>kubectl  delete  -f  deploy-nginx.yaml</code></p>
<h2 id="Service"><a href="#Service" class="headerlink" title="Service"></a>Service</h2><p>通过上节课的学习，已经能够利用Deployment来创建一组Pod来提供具有高可用性的服务。</p>
<p>虽然每个Pod都会分配一个单独的Pod IP，然而却存在如下两问题：</p>
<ul>
<li>Pod IP 会随着Pod的重建产生变化</li>
<li>Pod IP 仅仅是集群内可见的虚拟IP，外部无法访问</li>
</ul>
<p>这样对于访问这个服务带来了难度。因此，kubernetes设计了Service来解决这个问题。</p>
<p>Service可以看作是一组同类Pod<strong>对外的访问接口</strong>。借助Service，应用可以方便地实现服务发现和负载均衡。<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200408194716912.png" alt="image-20200408194716912"></p>
<p><strong>操作一：创建集群内部可访问的Service</strong></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 暴露Service</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl expose deploy nginx --name=svc-nginx1 --type=ClusterIP --port=80 --target-port=80 -n dev</span></span><br><span class="line">service/svc<span class="literal">-nginx1</span> exposed</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看service</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get svc svc-nginx -n dev -o wide</span></span><br><span class="line">NAME         <span class="built_in">TYPE</span>        CLUSTER<span class="literal">-IP</span>       EXTERNAL<span class="literal">-IP</span>   PORT(S)   AGE     SELECTOR</span><br><span class="line">svc<span class="literal">-nginx1</span>   ClusterIP   <span class="number">10.109</span>.<span class="number">179.231</span>   &lt;none&gt;        <span class="number">80</span>/TCP    <span class="number">3</span>m51s   run=nginx</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里产生了一个CLUSTER-IP，这就是service的IP，在Service的生命周期中，这个地址是不会变动的</span></span><br><span class="line"><span class="comment"># 可以通过这个IP访问当前service对应的POD</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># curl 10.109.179.231:80</span></span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;</span><br><span class="line">.......</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure>

<p><strong>操作二：创建集群外部也可访问的Service</strong></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 上面创建的Service的type类型为ClusterIP，这个ip地址只用集群内部可访问</span></span><br><span class="line"><span class="comment"># 如果需要创建外部也可以访问的Service，需要修改type为NodePort</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl expose deploy nginx --name=svc-nginx2 --type=NodePort --port=80 --target-port=80 -n dev</span></span><br><span class="line">service/svc<span class="literal">-nginx2</span> exposed</span><br><span class="line"></span><br><span class="line"><span class="comment"># 此时查看，会发现出现了NodePort类型的Service，而且有一对Port（80:31928/TC）</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get svc  svc-nginx-1  -n dev -o wide</span></span><br><span class="line">NAME          <span class="built_in">TYPE</span>        CLUSTER<span class="literal">-IP</span>       EXTERNAL<span class="literal">-IP</span>   PORT(S)        AGE    SELECTOR</span><br><span class="line">svc<span class="literal">-nginx2</span>    NodePort    <span class="number">10.100</span>.<span class="number">94.0</span>      &lt;none&gt;        <span class="number">80</span>:<span class="number">31928</span>/TCP   <span class="number">9</span>s     run=nginx</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来就可以通过集群外的主机访问 节点IP:31928访问服务了</span></span><br><span class="line"><span class="comment"># 例如在的电脑主机上通过浏览器访问下面的地址</span></span><br><span class="line">http://<span class="number">192.168</span>.<span class="number">109.100</span>:<span class="number">31928</span>/</span><br></pre></td></tr></table></figure>

<p><strong>删除Service</strong></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete svc svc-nginx-1 -n dev                                   service &quot;svc-nginx-1&quot; deleted</span></span><br></pre></td></tr></table></figure>

<p><strong>配置方式</strong></p>
<p>创建一个svc-nginx.yaml，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">svc-nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="number">10.109</span><span class="number">.179</span><span class="number">.231</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">run:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br></pre></td></tr></table></figure>

<p>然后就可以执行对应的创建和删除命令了：</p>
<p>创建：<code>kubectl  create  -f  svc-nginx.yaml</code></p>
<p>删除：<code>kubectl  delete  -f  svc-nginx.yaml</code></p>
<blockquote>
<p><strong>小结</strong></p>
<p>至此，已经掌握了Namespace、Pod、Deployment、Service资源的基本操作，有了这些操作，就可以在kubernetes集群中实现一个服务的简单部署和访问了，但是如果想要更好的使用kubernetes，就需要深入学习这几种资源的细节和原理。</p>
</blockquote>
<h1 id="第五章-Pod详解"><a href="#第五章-Pod详解" class="headerlink" title="第五章 Pod详解"></a>第五章 Pod详解</h1><p>本章节将详细介绍Pod资源的各种配置（yaml）和原理。</p>
<h2 id="Pod介绍"><a href="#Pod介绍" class="headerlink" title="Pod介绍"></a>Pod介绍</h2><h3 id="Pod结构"><a href="#Pod结构" class="headerlink" title="Pod结构"></a>Pod结构</h3><p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200407121501907.png"></p>
<p>每个Pod中都可以包含一个或者多个容器，这些容器可以分为两类：</p>
<ul>
<li><p>用户程序所在的容器，数量可多可少</p>
</li>
<li><p>Pause容器，这是每个Pod都会有的一个<strong>根容器</strong>，它的作用有两个：</p>
<ul>
<li><p>可以以它为依据，评估整个Pod的健康状态</p>
</li>
<li><p>可以在根容器上设置Ip地址，其它容器都此Ip（Pod IP），以实现Pod内部的网路通信</p>
<pre><code>这里是Pod内部的通讯，Pod的之间的通讯采用虚拟二层网络技术来实现，我们当前环境用的是Flannel
</code></pre>
</li>
</ul>
</li>
</ul>
<h3 id="Pod定义"><a href="#Pod定义" class="headerlink" title="Pod定义"></a>Pod定义</h3><p>下面是Pod的资源清单：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span>     <span class="comment">#必选，版本号，例如v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span>       　 <span class="comment">#必选，资源类型，例如 Pod</span></span><br><span class="line"><span class="attr">metadata:</span>       　 <span class="comment">#必选，元数据</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">string</span>     <span class="comment">#必选，Pod名称</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">string</span>  <span class="comment">#Pod所属的命名空间,默认为&quot;default&quot;</span></span><br><span class="line">  <span class="attr">labels:</span>       　　  <span class="comment">#自定义标签列表</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span>      　          </span><br><span class="line"><span class="attr">spec:</span>  <span class="comment">#必选，Pod中容器的详细定义</span></span><br><span class="line">  <span class="attr">containers:</span>  <span class="comment">#必选，Pod中容器列表</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span>   <span class="comment">#必选，容器名称</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">string</span>  <span class="comment">#必选，容器的镜像名称</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> [ <span class="string">Always|Never|IfNotPresent</span> ]  <span class="comment">#获取镜像的策略 </span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">string</span>]   <span class="comment">#容器的启动命令列表，如不指定，使用打包时使用的启动命令</span></span><br><span class="line">    <span class="attr">args:</span> [<span class="string">string</span>]      <span class="comment">#容器的启动命令参数列表</span></span><br><span class="line">    <span class="attr">workingDir:</span> <span class="string">string</span>  <span class="comment">#容器的工作目录</span></span><br><span class="line">    <span class="attr">volumeMounts:</span>       <span class="comment">#挂载到容器内部的存储卷配置</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span>      <span class="comment">#引用pod定义的共享存储卷的名称，需用volumes[]部分定义的的卷名</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">string</span> <span class="comment">#存储卷在容器内mount的绝对路径，应少于512字符</span></span><br><span class="line">      <span class="attr">readOnly:</span> <span class="string">boolean</span> <span class="comment">#是否为只读模式</span></span><br><span class="line">    <span class="attr">ports:</span> <span class="comment">#需要暴露的端口库号列表</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span>        <span class="comment">#端口的名称</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="string">int</span>  <span class="comment">#容器需要监听的端口号</span></span><br><span class="line">      <span class="attr">hostPort:</span> <span class="string">int</span>       <span class="comment">#容器所在主机需要监听的端口号，默认与Container相同</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">string</span>    <span class="comment">#端口协议，支持TCP和UDP，默认TCP</span></span><br><span class="line">    <span class="attr">env:</span>   <span class="comment">#容器运行前需设置的环境变量列表</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span>  <span class="comment">#环境变量名称</span></span><br><span class="line">      <span class="attr">value:</span> <span class="string">string</span> <span class="comment">#环境变量的值</span></span><br><span class="line">    <span class="attr">resources:</span> <span class="comment">#资源限制和请求的设置</span></span><br><span class="line">      <span class="attr">limits:</span>  <span class="comment">#资源限制的设置</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">string</span>     <span class="comment">#Cpu的限制，单位为core数，将用于docker run --cpu-shares参数</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">string</span>  <span class="comment">#内存限制，单位可以为Mib/Gib，将用于docker run --memory参数</span></span><br><span class="line">      <span class="attr">requests:</span> <span class="comment">#资源请求的设置</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">string</span>    <span class="comment">#Cpu请求，容器启动的初始可用数量</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">string</span> <span class="comment">#内存请求,容器启动的初始可用数量</span></span><br><span class="line">    <span class="attr">lifecycle:</span> <span class="comment">#生命周期钩子</span></span><br><span class="line">  <span class="attr">postStart:</span> <span class="comment">#容器启动后立即执行此钩子,如果执行失败,会根据重启策略进行重启</span></span><br><span class="line">  <span class="attr">preStop:</span> <span class="comment">#容器终止前执行此钩子,无论结果如何,容器都会终止</span></span><br><span class="line">    <span class="attr">livenessProbe:</span>  <span class="comment">#对Pod内各容器健康检查的设置，当探测无响应几次后将自动重启该容器</span></span><br><span class="line">      <span class="attr">exec:</span>       　 <span class="comment">#对Pod容器内检查方式设置为exec方式</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">string</span>]  <span class="comment">#exec方式需要制定的命令或脚本</span></span><br><span class="line">      <span class="attr">httpGet:</span>       <span class="comment">#对Pod内个容器健康检查方法设置为HttpGet，需要制定Path、port</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">string</span></span><br><span class="line">        <span class="attr">port:</span> <span class="string">number</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">string</span></span><br><span class="line">        <span class="attr">scheme:</span> <span class="string">string</span></span><br><span class="line">        <span class="attr">HttpHeaders:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">string</span></span><br><span class="line">      <span class="attr">tcpSocket:</span>     <span class="comment">#对Pod内个容器健康检查方式设置为tcpSocket方式</span></span><br><span class="line">         <span class="attr">port:</span> <span class="string">number</span></span><br><span class="line">       <span class="attr">initialDelaySeconds:</span> <span class="number">0</span>       <span class="comment">#容器启动完成后首次探测的时间，单位为秒</span></span><br><span class="line">       <span class="attr">timeoutSeconds:</span> <span class="number">0</span>    　　    <span class="comment">#对容器健康检查探测等待响应的超时时间，单位秒，默认1秒</span></span><br><span class="line">       <span class="attr">periodSeconds:</span> <span class="number">0</span>     　　    <span class="comment">#对容器监控检查的定期探测时间设置，单位秒，默认10秒一次</span></span><br><span class="line">       <span class="attr">successThreshold:</span> <span class="number">0</span></span><br><span class="line">       <span class="attr">failureThreshold:</span> <span class="number">0</span></span><br><span class="line">       <span class="attr">securityContext:</span></span><br><span class="line">         <span class="attr">privileged:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> [<span class="string">Always</span> <span class="string">|</span> <span class="string">Never</span> <span class="string">|</span> <span class="string">OnFailure</span>]  <span class="comment">#Pod的重启策略</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="string">&lt;string&gt;</span> <span class="comment">#设置NodeName表示将该Pod调度到指定到名称的node节点上</span></span><br><span class="line">  <span class="attr">nodeSelector:</span> <span class="string">obeject</span> <span class="comment">#设置NodeSelector表示将该Pod调度到包含这个label的node上</span></span><br><span class="line">  <span class="attr">imagePullSecrets:</span> <span class="comment">#Pull镜像时使用的secret名称，以key：secretkey格式指定</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span></span><br><span class="line">  <span class="attr">hostNetwork:</span> <span class="literal">false</span>   <span class="comment">#是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络</span></span><br><span class="line">  <span class="attr">volumes:</span>   <span class="comment">#在该pod上定义共享存储卷列表</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span>    <span class="comment">#共享存储卷名称 （volumes类型有很多种）</span></span><br><span class="line">    <span class="attr">emptyDir:</span> &#123;&#125;       <span class="comment">#类型为emtyDir的存储卷，与Pod同生命周期的一个临时目录。为空值</span></span><br><span class="line">    <span class="attr">hostPath:</span> <span class="string">string</span>   <span class="comment">#类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">string</span>      　　        <span class="comment">#Pod所在宿主机的目录，将被用于同期中mount的目录</span></span><br><span class="line">    <span class="attr">secret:</span>       　　　<span class="comment">#类型为secret的存储卷，挂载集群与定义的secret对象到容器内部</span></span><br><span class="line">      <span class="attr">scretname:</span> <span class="string">string</span>  </span><br><span class="line">      <span class="attr">items:</span>     </span><br><span class="line">      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">string</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">string</span></span><br><span class="line">    <span class="attr">configMap:</span>         <span class="comment">#类型为configMap的存储卷，挂载预定义的configMap对象到容器内部</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">string</span></span><br><span class="line">      <span class="attr">items:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">string</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">string</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment">#小提示：</span></span><br><span class="line"><span class="comment"># 在这里，可通过一个命令来查看每种资源的可配置项</span></span><br><span class="line"><span class="comment">#   kubectl explain 资源类型         查看某种资源可以配置的一级属性</span></span><br><span class="line"><span class="comment"># kubectl explain 资源类型.属性     查看属性的子属性</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl explain pod</span></span><br><span class="line">KIND:     Pod</span><br><span class="line">VERSION:  v1</span><br><span class="line">FIELDS:</span><br><span class="line">   apiVersion   &lt;string&gt;</span><br><span class="line">   kind &lt;string&gt;</span><br><span class="line">   metadata     &lt;Object&gt;</span><br><span class="line">   spec &lt;Object&gt;</span><br><span class="line">   status       &lt;Object&gt;</span><br><span class="line"></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl explain pod.metadata</span></span><br><span class="line">KIND:     Pod</span><br><span class="line">VERSION:  v1</span><br><span class="line">RESOURCE: metadata &lt;Object&gt;</span><br><span class="line">FIELDS:</span><br><span class="line">   annotations  &lt;map[<span class="built_in">string</span>]string&gt;</span><br><span class="line">   clusterName  &lt;string&gt;</span><br><span class="line">   creationTimestamp    &lt;string&gt;</span><br><span class="line">   deletionGracePeriodSeconds   &lt;integer&gt;</span><br><span class="line">   deletionTimestamp    &lt;string&gt;</span><br><span class="line">   finalizers   &lt;[]string&gt;</span><br><span class="line">   generateName &lt;string&gt;</span><br><span class="line">   generation   &lt;integer&gt;</span><br><span class="line">   labels       &lt;map[<span class="built_in">string</span>]string&gt;</span><br><span class="line">   managedFields        &lt;[]Object&gt;</span><br><span class="line">   name &lt;string&gt;</span><br><span class="line">   namespace    &lt;string&gt;</span><br><span class="line">   ownerReferences      &lt;[]Object&gt;</span><br><span class="line">   resourceVersion      &lt;string&gt;</span><br><span class="line">   selfLink     &lt;string&gt;</span><br><span class="line">   uid  &lt;string&gt;</span><br></pre></td></tr></table></figure>

<p>在kubernetes中基本所有资源的一级属性都是一样的，主要包含5部分：</p>
<ul>
<li><p>apiVersion   &lt;string&gt;     版本，由kubernetes内部定义，版本号必须可以用 kubectl api-versions 查询到</p>
</li>
<li><p>kind &lt;string&gt;                类型，由kubernetes内部定义，版本号必须可以用 kubectl api-resources 查询到</p>
</li>
<li><p>metadata   &lt;Object&gt;     元数据，主要是资源标识和说明，常用的有name、namespace、labels等</p>
</li>
<li><p>spec &lt;Object&gt;               描述，这是配置中最重要的一部分，里面是对各种资源配置的详细描述</p>
</li>
<li><p>status  &lt;Object&gt;            状态信息，里面的内容不需要定义，由kubernetes自动生成</p>
</li>
</ul>
<p>在上面的属性中，spec是接下来研究的重点，继续看下它的常见子属性:</p>
<ul>
<li>containers   &lt;[]Object&gt;       容器列表，用于定义容器的详细信息</li>
<li>nodeName &lt;String&gt;           根据nodeName的值将pod调度到指定的Node节点上</li>
<li>nodeSelector   &lt;map[]&gt;      根据NodeSelector中定义的信息选择将该Pod调度到包含这些label的Node 上</li>
<li>hostNetwork  &lt;boolean&gt;    是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络</li>
<li>volumes      &lt;[]Object&gt;       存储卷，用于定义Pod上面挂在的存储信息</li>
<li>restartPolicy &lt;string&gt;       重启策略，表示Pod在遇到故障的时候的处理策略</li>
</ul>
<h2 id="Pod配置"><a href="#Pod配置" class="headerlink" title="Pod配置"></a>Pod配置</h2><p>本小节主要来研究<code>pod.spec.containers</code>属性，这也是pod配置中最为关键的一项配置。</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl explain pod.spec.containers</span></span><br><span class="line">KIND:     Pod</span><br><span class="line">VERSION:  v1</span><br><span class="line">RESOURCE: containers &lt;[]Object&gt;   <span class="comment"># 数组，代表可以有多个容器</span></span><br><span class="line">FIELDS:</span><br><span class="line">   name  &lt;string&gt;     <span class="comment"># 容器名称</span></span><br><span class="line">   image &lt;string&gt;     <span class="comment"># 容器需要的镜像地址</span></span><br><span class="line">   imagePullPolicy  &lt;string&gt; <span class="comment"># 镜像拉取策略 </span></span><br><span class="line">   command  &lt;[]string&gt; <span class="comment"># 容器的启动命令列表，如不指定，使用打包时使用的启动命令</span></span><br><span class="line">   args     &lt;[]string&gt; <span class="comment"># 容器的启动命令需要的参数列表</span></span><br><span class="line">   env      &lt;[]Object&gt; <span class="comment"># 容器环境变量的配置</span></span><br><span class="line">   ports    &lt;[]Object&gt;     <span class="comment"># 容器需要暴露的端口号列表</span></span><br><span class="line">   resources &lt;Object&gt;      <span class="comment"># 资源限制和资源请求的设置</span></span><br></pre></td></tr></table></figure>

<h3 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a>基本配置</h3><p>创建pod-base.yaml文件，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-base</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">user:</span> <span class="string">heima</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br></pre></td></tr></table></figure>

<p>上面定义了一个比较简单Pod的配置，里面有两个容器：</p>
<ul>
<li>nginx：用1.17.1版本的nginx镜像创建，（nginx是一个轻量级web容器）</li>
<li>busybox：用1.30版本的busybox镜像创建，（busybox是一个小巧的linux命令集合）</li>
</ul>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建Pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">pod</span>]<span class="comment"># kubectl apply -f pod-base.yaml</span></span><br><span class="line">pod/pod<span class="literal">-base</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Pod状况</span></span><br><span class="line"><span class="comment"># READY 1/2 : 表示当前Pod中有2个容器，其中1个准备就绪，1个未就绪</span></span><br><span class="line"><span class="comment"># RESTARTS  : 重启次数，因为有1个容器故障了，Pod一直在重启试图恢复它</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">pod</span>]<span class="comment"># kubectl get pod -n dev</span></span><br><span class="line">NAME       READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod<span class="literal">-base</span>   <span class="number">1</span>/<span class="number">2</span>     Running   <span class="number">4</span>          <span class="number">95</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以通过describe查看内部的详情</span></span><br><span class="line"><span class="comment"># 此时已经运行起来了一个基本的Pod，虽然它暂时有问题</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">pod</span>]<span class="comment"># kubectl describe pod pod-base -n dev</span></span><br></pre></td></tr></table></figure>

<h3 id="镜像拉取"><a href="#镜像拉取" class="headerlink" title="镜像拉取"></a>镜像拉取</h3><p>创建pod-imagepullpolicy.yaml文件，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-imagepullpolicy</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">Always</span> <span class="comment"># 用于设置镜像拉取策略</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br></pre></td></tr></table></figure>

<p>imagePullPolicy，用于设置镜像拉取策略，kubernetes支持配置三种拉取策略：</p>
<ul>
<li>Always：总是从远程仓库拉取镜像（一直远程下载）</li>
<li>IfNotPresent：本地有则使用本地镜像，本地没有则从远程仓库拉取镜像（本地有就本地  本地没远程下载）</li>
<li>Never：只使用本地镜像，从不去远程仓库拉取，本地没有就报错 （一直使用本地）</li>
</ul>
<blockquote>
<p>默认值说明：</p>
<p>如果镜像tag为具体版本号， 默认策略是：IfNotPresent</p>
<p>如果镜像tag为：latest（最终版本） ，默认策略是always</p>
</blockquote>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建Pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">pod</span>]<span class="comment"># kubectl create -f pod-imagepullpolicy.yaml</span></span><br><span class="line">pod/pod<span class="literal">-imagepullpolicy</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Pod详情</span></span><br><span class="line"><span class="comment"># 此时明显可以看到nginx镜像有一步Pulling image &quot;nginx:1.17.1&quot;的过程</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">pod</span>]<span class="comment"># kubectl describe pod pod-imagepullpolicy -n dev</span></span><br><span class="line">......</span><br><span class="line">Events:</span><br><span class="line">  <span class="built_in">Type</span>     Reason     Age               From               Message</span><br><span class="line">  <span class="literal">----</span>     <span class="literal">------</span>     <span class="literal">----</span>              <span class="literal">----</span>               <span class="literal">-------</span></span><br><span class="line">  Normal   Scheduled  &lt;unknown&gt;         default<span class="literal">-scheduler</span>  Successfully assigned dev/pod<span class="literal">-imagePullPolicy</span> to node1</span><br><span class="line">  Normal   Pulling    <span class="number">32</span>s               kubelet, node1     Pulling image <span class="string">&quot;nginx:1.17.1&quot;</span></span><br><span class="line">  Normal   Pulled     <span class="number">26</span>s               kubelet, node1     Successfully pulled image <span class="string">&quot;nginx:1.17.1&quot;</span></span><br><span class="line">  Normal   Created    <span class="number">26</span>s               kubelet, node1     Created container nginx</span><br><span class="line">  Normal   Started    <span class="number">25</span>s               kubelet, node1     Started container nginx</span><br><span class="line">  Normal   Pulled     <span class="number">7</span>s (x3 over <span class="number">25</span>s)  kubelet, node1     Container image <span class="string">&quot;busybox:1.30&quot;</span> already present on machine</span><br><span class="line">  Normal   Created    <span class="number">7</span>s (x3 over <span class="number">25</span>s)  kubelet, node1     Created container busybox</span><br><span class="line">  Normal   Started    <span class="number">7</span>s (x3 over <span class="number">25</span>s)  kubelet, node1     Started container busybox</span><br></pre></td></tr></table></figure>

<h3 id="启动命令"><a href="#启动命令" class="headerlink" title="启动命令"></a>启动命令</h3><p>在前面的案例中，一直有一个问题没有解决，就是的busybox容器一直没有成功运行，那么到底是什么原因导致这个容器的故障呢？</p>
<p>原来busybox并不是一个程序，而是类似于一个工具类的集合，kubernetes集群启动管理后，它会自动关闭。解决方法就是让其一直在运行，这就用到了command配置。</p>
<p>创建pod-command.yaml文件，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-command</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;touch /tmp/hello.txt;while true;do /bin/echo $(date +%T) &gt;&gt; /tmp/hello.txt; sleep 3; done;&quot;</span>]</span><br></pre></td></tr></table></figure>

<p>command，用于在pod中的容器初始化完毕之后运行一个命令。</p>
<blockquote>
<p>稍微解释下上面命令的意思：</p>
<p>“&#x2F;bin&#x2F;sh”,”-c”,  使用sh执行命令</p>
<p>touch &#x2F;tmp&#x2F;hello.txt;   创建一个&#x2F;tmp&#x2F;hello.txt 文件</p>
<p>while true;do &#x2F;bin&#x2F;echo $(date +%T) &gt;&gt; &#x2F;tmp&#x2F;hello.txt; sleep 3; done;  每隔3秒向文件中写入当前时间</p>
</blockquote>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建Pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">pod</span>]<span class="comment"># kubectl create  -f pod-command.yaml</span></span><br><span class="line">pod/pod<span class="literal">-command</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Pod状态</span></span><br><span class="line"><span class="comment"># 此时发现两个pod都正常运行了</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">pod</span>]<span class="comment"># kubectl get pods pod-command -n dev</span></span><br><span class="line">NAME          READY   STATUS   RESTARTS   AGE</span><br><span class="line">pod<span class="literal">-command</span>   <span class="number">2</span>/<span class="number">2</span>     Runing   <span class="number">0</span>          <span class="number">2</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入pod中的busybox容器，查看文件内容</span></span><br><span class="line"><span class="comment"># 补充一个命令: kubectl exec  pod名称 -n 命名空间 -it -c 容器名称 /bin/sh  在容器内部执行命令</span></span><br><span class="line"><span class="comment"># 使用这个命令就可以进入某个容器的内部，然后进行相关操作了</span></span><br><span class="line"><span class="comment"># 比如，可以查看txt文件的内容</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">pod</span>]<span class="comment"># kubectl exec pod-command -n dev -it -c busybox /bin/sh</span></span><br><span class="line">/ <span class="comment"># tail -f /tmp/hello.txt</span></span><br><span class="line"><span class="number">13</span>:<span class="number">35</span>:<span class="number">35</span></span><br><span class="line"><span class="number">13</span>:<span class="number">35</span>:<span class="number">38</span></span><br><span class="line"><span class="number">13</span>:<span class="number">35</span>:<span class="number">41</span></span><br></pre></td></tr></table></figure>

<figure class="highlight md"><table><tr><td class="code"><pre><span class="line">特别说明：</span><br><span class="line"><span class="code">    通过上面发现command已经可以完成启动命令和传递参数的功能，为什么这里还要提供一个args选项，用于传递参数呢?这其实跟docker有点关系，kubernetes中的command、args两项其实是实现覆盖Dockerfile中ENTRYPOINT的功能。</span></span><br><span class="line"><span class="code"> 1 如果command和args均没有写，那么用Dockerfile的配置。</span></span><br><span class="line"><span class="code"> 2 如果command写了，但args没有写，那么Dockerfile默认的配置会被忽略，执行输入的command</span></span><br><span class="line"><span class="code"> 3 如果command没写，但args写了，那么Dockerfile中配置的ENTRYPOINT的命令会被执行，使用当前args的参数</span></span><br><span class="line"><span class="code"> 4 如果command和args都写了，那么Dockerfile的配置被忽略，执行command并追加上args参数</span></span><br></pre></td></tr></table></figure>

<h3 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h3><p>创建pod-env.yaml文件，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-env</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;while true;do /bin/echo $(date +%T);sleep 60; done;&quot;</span>]</span><br><span class="line">    <span class="attr">env:</span> <span class="comment"># 设置环境变量列表</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&quot;username&quot;</span></span><br><span class="line">      <span class="attr">value:</span> <span class="string">&quot;admin&quot;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&quot;password&quot;</span></span><br><span class="line">      <span class="attr">value:</span> <span class="string">&quot;123456&quot;</span></span><br></pre></td></tr></table></figure>

<p>env，环境变量，用于在pod中的容器设置环境变量。</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建Pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod-env.yaml</span></span><br><span class="line">pod/pod<span class="literal">-env</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入容器，输出环境变量</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl exec pod-env -n dev -c busybox -it /bin/sh</span></span><br><span class="line">/ <span class="comment"># echo $username</span></span><br><span class="line">admin</span><br><span class="line">/ <span class="comment"># echo $password</span></span><br><span class="line"><span class="number">123456</span></span><br></pre></td></tr></table></figure>

<p>这种方式不是很推荐，推荐将这些配置单独存储在配置文件中，这种方式将在后面介绍。</p>
<h3 id="端口设置"><a href="#端口设置" class="headerlink" title="端口设置"></a>端口设置</h3><p>本小节来介绍容器的端口设置，也就是containers的ports选项。</p>
<p>首先看下ports支持的子选项：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl explain pod.spec.containers.ports</span></span><br><span class="line">KIND:     Pod</span><br><span class="line">VERSION:  v1</span><br><span class="line">RESOURCE: ports &lt;[]Object&gt;</span><br><span class="line">FIELDS:</span><br><span class="line">   name         &lt;string&gt;  <span class="comment"># 端口名称，如果指定，必须保证name在pod中是唯一的  </span></span><br><span class="line">   containerPort&lt;integer&gt; <span class="comment"># 容器要监听的端口(0&lt;x&lt;65536)</span></span><br><span class="line">   hostPort     &lt;integer&gt; <span class="comment"># 容器要在主机上公开的端口，如果设置，主机上只能运行容器的一个副本(一般省略) </span></span><br><span class="line">   hostIP       &lt;string&gt;  <span class="comment"># 要将外部端口绑定到的主机IP(一般省略)</span></span><br><span class="line">   protocol     &lt;string&gt;  <span class="comment"># 端口协议。必须是UDP、TCP或SCTP。默认为“TCP”。</span></span><br></pre></td></tr></table></figure>

<p>接下来，编写一个测试案例，创建pod-ports.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-ports</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">ports:</span> <span class="comment"># 设置容器暴露的端口列表</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-port</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建Pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod-ports.yaml</span></span><br><span class="line">pod/pod<span class="literal">-ports</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod</span></span><br><span class="line"><span class="comment"># 在下面可以明显看到配置信息</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pod pod-ports -n dev -o yaml</span></span><br><span class="line">......</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: nginx:<span class="number">1.17</span>.<span class="number">1</span></span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    name: nginx</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: <span class="number">80</span></span><br><span class="line">      name: nginx<span class="literal">-port</span></span><br><span class="line">      protocol: TCP</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<p>访问容器中的程序需要使用的是<code>podIp:containerPort</code></p>
<h3 id="资源配额"><a href="#资源配额" class="headerlink" title="资源配额"></a>资源配额</h3><p>容器中的程序要运行，肯定是要占用一定资源的，比如cpu和内存等，如果不对某个容器的资源做限制，那么它就可能吃掉大量资源，导致其它容器无法运行。针对这种情况，kubernetes提供了对内存和cpu的资源进行配额的机制，这种机制主要通过resources选项实现，他有两个子选项：</p>
<ul>
<li><p>limits：用于限制运行时容器的最大占用资源，当容器占用资源超过limits时会被终止，并进行重启</p>
</li>
<li><p>requests ：用于设置容器需要的最小资源，如果环境资源不够，容器将无法启动</p>
</li>
</ul>
<p>可以通过上面两个选项设置资源的上下限。</p>
<p>接下来，编写一个测试案例，创建pod-resources.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-resources</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">resources:</span> <span class="comment"># 资源配额</span></span><br><span class="line">      <span class="attr">limits:</span>  <span class="comment"># 限制资源（上限）</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">&quot;2&quot;</span> <span class="comment"># CPU限制，单位是core数</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">&quot;10Gi&quot;</span> <span class="comment"># 内存限制</span></span><br><span class="line">      <span class="attr">requests:</span> <span class="comment"># 请求资源（下限）</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">&quot;1&quot;</span>  <span class="comment"># CPU限制，单位是core数</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">&quot;10Mi&quot;</span>  <span class="comment"># 内存限制</span></span><br></pre></td></tr></table></figure>

<p>在这对cpu和memory的单位做一个说明：</p>
<ul>
<li><p>cpu：core数，可以为整数或小数</p>
</li>
<li><p>memory： 内存大小，可以使用Gi、Mi、G、M等形式</p>
</li>
</ul>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 运行Pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create  -f pod-resources.yaml</span></span><br><span class="line">pod/pod<span class="literal">-resources</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看发现pod运行正常</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pod pod-resources -n dev</span></span><br><span class="line">NAME            READY   STATUS    RESTARTS   AGE  </span><br><span class="line">pod<span class="literal">-resources</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">39</span>s   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来，停止Pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete  -f pod-resources.yaml</span></span><br><span class="line">pod <span class="string">&quot;pod-resources&quot;</span> deleted</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑pod，修改resources.requests.memory的值为10Gi</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># vim pod-resources.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 再次启动pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create  -f pod-resources.yaml</span></span><br><span class="line">pod/pod<span class="literal">-resources</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Pod状态，发现Pod启动失败</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pod pod-resources -n dev -o wide</span></span><br><span class="line">NAME            READY   STATUS    RESTARTS   AGE          </span><br><span class="line">pod<span class="literal">-resources</span>   <span class="number">0</span>/<span class="number">2</span>     Pending   <span class="number">0</span>          <span class="number">20</span>s    </span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod详情会发现，如下提示</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl describe pod pod-resources -n dev</span></span><br><span class="line">......</span><br><span class="line">Warning  FailedScheduling  &lt;unknown&gt;  default<span class="literal">-scheduler</span>  <span class="number">0</span>/<span class="number">2</span> nodes are available: <span class="number">2</span> Insufficient memory.(内存不足)</span><br></pre></td></tr></table></figure>

<h2 id="Pod生命周期"><a href="#Pod生命周期" class="headerlink" title="Pod生命周期"></a>Pod生命周期</h2><p>我们一般将pod对象从创建至终的这段时间范围称为pod的生命周期，它主要包含下面的过程：</p>
<ul>
<li><p>pod创建过程</p>
</li>
<li><p>运行初始化容器（init container）过程</p>
</li>
<li><p>运行主容器（main container）</p>
<ul>
<li><p>容器启动后钩子（post start）、容器终止前钩子（pre stop）</p>
</li>
<li><p>容器的存活性探测（liveness probe）、就绪性探测（readiness probe）</p>
</li>
</ul>
</li>
<li><p>pod终止过程</p>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200412111402706.png" alt="image-20200412111402706"></p>
<p>在整个生命周期中，Pod会出现5种<strong>状态</strong>（<strong>相位</strong>），分别如下：</p>
<ul>
<li>挂起（Pending）：apiserver已经创建了pod资源对象，但它尚未被调度完成或者仍处于下载镜像的过程中</li>
<li>运行中（Running）：pod已经被调度至某节点，并且所有容器都已经被kubelet创建完成</li>
<li>成功（Succeeded）：pod中的所有容器都已经成功终止并且不会被重启</li>
<li>失败（Failed）：所有容器都已经终止，但至少有一个容器终止失败，即容器返回了非0值的退出状态</li>
<li>未知（Unknown）：apiserver无法正常获取到pod对象的状态信息，通常由网络通信失败所导致</li>
</ul>
<h3 id="创建和终止"><a href="#创建和终止" class="headerlink" title="创建和终止"></a>创建和终止</h3><p><strong>pod的创建过程</strong></p>
<ol>
<li><p>用户通过kubectl或其他api客户端提交需要创建的pod信息给apiServer</p>
</li>
<li><p>apiServer开始生成pod对象的信息，并将信息存入etcd，然后返回确认信息至客户端</p>
</li>
<li><p>apiServer开始反映etcd中的pod对象的变化，其它组件使用watch机制来跟踪检查apiServer上的变动</p>
</li>
<li><p>scheduler发现有新的pod对象要创建，开始为Pod分配主机并将结果信息更新至apiServer</p>
</li>
<li><p>node节点上的kubelet发现有pod调度过来，尝试调用docker启动容器，并将结果回送至apiServer</p>
</li>
<li><p>apiServer将接收到的pod状态信息存入etcd中</p>
<p> <img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200406184656917.png"></p>
</li>
</ol>
<p><strong>pod的终止过程</strong></p>
<ol>
<li>用户向apiServer发送删除pod对象的命令</li>
<li>apiServcer中的pod对象信息会随着时间的推移而更新，在宽限期内（默认30s），pod被视为dead</li>
<li>将pod标记为terminating状态</li>
<li>kubelet在监控到pod对象转为terminating状态的同时启动pod关闭过程</li>
<li>端点控制器监控到pod对象的关闭行为时将其从所有匹配到此端点的service资源的端点列表中移除</li>
<li>如果当前pod对象定义了preStop钩子处理器，则在其标记为terminating后即会以同步的方式启动执行</li>
<li>pod对象中的容器进程收到停止信号</li>
<li>宽限期结束后，若pod中还存在仍在运行的进程，那么pod对象会收到立即终止的信号</li>
<li>kubelet请求apiServer将此pod资源的宽限期设置为0从而完成删除操作，此时pod对于用户已不可见</li>
</ol>
<h3 id="初始化容器"><a href="#初始化容器" class="headerlink" title="初始化容器"></a>初始化容器</h3><p>初始化容器是在pod的主容器启动之前要运行的容器，主要是做一些主容器的前置工作，它具有两大特征：</p>
<ol>
<li>初始化容器必须运行完成直至结束，若某初始化容器运行失败，那么kubernetes需要重启它直到成功完成</li>
<li>初始化容器必须按照定义的顺序执行，当且仅当前一个成功之后，后面的一个才能运行</li>
</ol>
<p>初始化容器有很多的应用场景，下面列出的是最常见的几个：</p>
<ul>
<li>提供主容器镜像中不具备的工具程序或自定义代码</li>
<li>初始化容器要先于应用容器串行启动并运行完成，因此可用于延后应用容器的启动直至其依赖的条件得到满足</li>
</ul>
<p>接下来做一个案例，模拟下面这个需求：</p>
<p>假设要以主容器来运行nginx，但是要求在运行nginx之前先要能够连接上mysql和redis所在服务器</p>
<p>为了简化测试，事先规定好mysql<code>(192.168.109.201)</code>和redis<code>(192.168.109.202)</code>服务器的地址</p>
<p>创建pod-initcontainer.yaml，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-initcontainer</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">main-container</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">ports:</span> </span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-port</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">initContainers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-mysql</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;until ping 192.168.109.201 -c 1 ; do echo waiting for mysql...; sleep 2; done;&#x27;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-redis</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;until ping 192.168.109.202 -c 1 ; do echo waiting for reids...; sleep 2; done;&#x27;</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod-initcontainer.yaml</span></span><br><span class="line">pod/pod<span class="literal">-initcontainer</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod状态</span></span><br><span class="line"><span class="comment"># 发现pod卡在启动第一个初始化容器过程中，后面的容器不会运行</span></span><br><span class="line">root@master ~]<span class="comment"># kubectl describe pod  pod-initcontainer -n dev</span></span><br><span class="line">........</span><br><span class="line">Events:</span><br><span class="line">  <span class="built_in">Type</span>    Reason     Age   From               Message</span><br><span class="line">  <span class="literal">----</span>    <span class="literal">------</span>     <span class="literal">----</span>  <span class="literal">----</span>               <span class="literal">-------</span></span><br><span class="line">  Normal  Scheduled  <span class="number">49</span>s   default<span class="literal">-scheduler</span>  Successfully assigned dev/pod<span class="literal">-initcontainer</span> to node1</span><br><span class="line">  Normal  Pulled     <span class="number">48</span>s   kubelet, node1     Container image <span class="string">&quot;busybox:1.30&quot;</span> already present on machine</span><br><span class="line">  Normal  Created    <span class="number">48</span>s   kubelet, node1     Created container <span class="built_in">test-mysql</span></span><br><span class="line">  Normal  Started    <span class="number">48</span>s   kubelet, node1     Started container <span class="built_in">test-mysql</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 动态查看pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods pod-initcontainer -n dev -w</span></span><br><span class="line">NAME                             READY   STATUS     RESTARTS   AGE</span><br><span class="line">pod<span class="literal">-initcontainer</span>                <span class="number">0</span>/<span class="number">1</span>     Init:<span class="number">0</span>/<span class="number">2</span>   <span class="number">0</span>          <span class="number">15</span>s</span><br><span class="line">pod<span class="literal">-initcontainer</span>                <span class="number">0</span>/<span class="number">1</span>     Init:<span class="number">1</span>/<span class="number">2</span>   <span class="number">0</span>          <span class="number">52</span>s</span><br><span class="line">pod<span class="literal">-initcontainer</span>                <span class="number">0</span>/<span class="number">1</span>     Init:<span class="number">1</span>/<span class="number">2</span>   <span class="number">0</span>          <span class="number">53</span>s</span><br><span class="line">pod<span class="literal">-initcontainer</span>                <span class="number">0</span>/<span class="number">1</span>     PodInitializing   <span class="number">0</span>          <span class="number">89</span>s</span><br><span class="line">pod<span class="literal">-initcontainer</span>                <span class="number">1</span>/<span class="number">1</span>     Running           <span class="number">0</span>          <span class="number">90</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来新开一个shell，为当前服务器新增两个ip，观察pod的变化</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># ifconfig ens33:1 192.168.109.201 netmask 255.255.255.0 up</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># ifconfig ens33:2 192.168.109.202 netmask 255.255.255.0 up</span></span><br></pre></td></tr></table></figure>

<h3 id="钩子函数"><a href="#钩子函数" class="headerlink" title="钩子函数"></a>钩子函数</h3><p>钩子函数能够感知自身生命周期中的事件，并在相应的时刻到来时运行用户指定的程序代码。</p>
<p>kubernetes在主容器的启动之后和停止之前提供了两个钩子函数：</p>
<ul>
<li>post start：容器创建之后执行，如果失败了会重启容器</li>
<li>pre stop  ：容器终止之前执行，执行完成之后容器将成功终止，在其完成之前会阻塞删除容器的操作</li>
</ul>
<p>钩子处理器支持使用下面三种方式定义动作：</p>
<ul>
<li><p>Exec命令：在容器内执行一次命令</p>
  <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">……</span></span><br><span class="line">  <span class="attr">lifecycle:</span></span><br><span class="line">    <span class="attr">postStart:</span> </span><br><span class="line">      <span class="attr">exec:</span></span><br><span class="line">        <span class="attr">command:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">cat</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/tmp/healthy</span></span><br><span class="line"><span class="string">……</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>TCPSocket：在当前容器尝试访问指定的socket</p>
  <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">……</span>      </span><br><span class="line">  <span class="attr">lifecycle:</span></span><br><span class="line">    <span class="attr">postStart:</span></span><br><span class="line">      <span class="attr">tcpSocket:</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line"><span class="string">……</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>HTTPGet：在当前容器中向某url发起http请求</p>
  <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">……</span></span><br><span class="line">  <span class="attr">lifecycle:</span></span><br><span class="line">    <span class="attr">postStart:</span></span><br><span class="line">      <span class="attr">httpGet:</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/</span> <span class="comment">#URI地址</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">80</span> <span class="comment">#端口号</span></span><br><span class="line">        <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.109</span><span class="number">.100</span> <span class="comment">#主机地址</span></span><br><span class="line">        <span class="attr">scheme:</span> <span class="string">HTTP</span> <span class="comment">#支持的协议，http或者https</span></span><br><span class="line"><span class="string">……</span></span><br></pre></td></tr></table></figure></li>
</ul>
<p>接下来，以exec方式为例，演示下钩子函数的使用，创建pod-hook-exec.yaml文件，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-hook-exec</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">main-container</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-port</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">lifecycle:</span></span><br><span class="line">      <span class="attr">postStart:</span> </span><br><span class="line">        <span class="attr">exec:</span> <span class="comment"># 在容器启动的时候执行一个命令，修改掉nginx的默认首页内容</span></span><br><span class="line">          <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>, <span class="string">&quot;-c&quot;</span>, <span class="string">&quot;echo postStart... &gt; /usr/share/nginx/html/index.html&quot;</span>]</span><br><span class="line">      <span class="attr">preStop:</span></span><br><span class="line">        <span class="attr">exec:</span> <span class="comment"># 在容器停止之前停止nginx服务</span></span><br><span class="line">          <span class="attr">command:</span> [<span class="string">&quot;/usr/sbin/nginx&quot;</span>,<span class="string">&quot;-s&quot;</span>,<span class="string">&quot;quit&quot;</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod-hook-exec.yaml</span></span><br><span class="line">pod/pod<span class="literal">-hook-exec</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods  pod-hook-exec -n dev -o wide</span></span><br><span class="line">NAME           READY   STATUS     RESTARTS   AGE    IP            NODE    </span><br><span class="line">pod<span class="literal">-hook-exec</span>  <span class="number">1</span>/<span class="number">1</span>     Running    <span class="number">0</span>          <span class="number">29</span>s    <span class="number">10.244</span>.<span class="number">2.48</span>   node2   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 访问pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># curl 10.244.2.48</span></span><br><span class="line">postStart...</span><br></pre></td></tr></table></figure>

<h3 id="容器探测"><a href="#容器探测" class="headerlink" title="容器探测"></a>容器探测</h3><p>容器探测用于检测容器中的应用实例是否正常工作，是保障业务可用性的一种传统机制。如果经过探测，实例的状态不符合预期，那么kubernetes就会把该问题实例” 摘除 “，不承担业务流量。kubernetes提供了两种探针来实现容器探测，分别是：</p>
<ul>
<li><p>liveness probes：存活性探针，用于检测应用实例当前是否处于正常运行状态，如果不是，k8s会重启容器</p>
</li>
<li><p>readiness probes：就绪性探针，用于检测应用实例当前是否可以接收请求，如果不能，k8s不会转发流量</p>
</li>
</ul>
<blockquote>
<p>livenessProbe 决定是否重启容器，readinessProbe 决定是否将请求转发给容器。</p>
</blockquote>
<p>上面两种探针目前均支持三种探测方式：</p>
<ul>
<li><p>Exec命令：在容器内执行一次命令，如果命令执行的退出码为0，则认为程序正常，否则不正常</p>
  <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">……</span></span><br><span class="line">  <span class="attr">livenessProbe:</span></span><br><span class="line">    <span class="attr">exec:</span></span><br><span class="line">      <span class="attr">command:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">cat</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/tmp/healthy</span></span><br><span class="line"><span class="string">……</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>TCPSocket：将会尝试访问一个用户容器的端口，如果能够建立这条连接，则认为程序正常，否则不正常</p>
  <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">……</span>      </span><br><span class="line">  <span class="attr">livenessProbe:</span></span><br><span class="line">    <span class="attr">tcpSocket:</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line"><span class="string">……</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>HTTPGet：调用容器内Web应用的URL，如果返回的状态码在200和399之间，则认为程序正常，否则不正常</p>
  <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">……</span></span><br><span class="line">  <span class="attr">livenessProbe:</span></span><br><span class="line">    <span class="attr">httpGet:</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/</span> <span class="comment">#URI地址</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span> <span class="comment">#端口号</span></span><br><span class="line">      <span class="attr">host:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> <span class="comment">#主机地址</span></span><br><span class="line">      <span class="attr">scheme:</span> <span class="string">HTTP</span> <span class="comment">#支持的协议，http或者https</span></span><br><span class="line"><span class="string">……</span></span><br></pre></td></tr></table></figure></li>
</ul>
<p>下面以liveness probes为例，做几个演示：</p>
<p><strong>方式一：Exec</strong></p>
<p>创建pod-liveness-exec.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-liveness-exec</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">ports:</span> </span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-port</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">livenessProbe:</span></span><br><span class="line">      <span class="attr">exec:</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;/bin/cat&quot;</span>,<span class="string">&quot;/tmp/hello.txt&quot;</span>] <span class="comment"># 执行一个查看文件的命令</span></span><br></pre></td></tr></table></figure>

<p>创建pod，观察效果</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建Pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod-liveness-exec.yaml</span></span><br><span class="line">pod/pod<span class="literal">-liveness-exec</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Pod详情</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl describe pods pod-liveness-exec -n dev</span></span><br><span class="line">......</span><br><span class="line">  Normal   Created    <span class="number">20</span>s (x2 over <span class="number">50</span>s)  kubelet, node1     Created container nginx</span><br><span class="line">  Normal   Started    <span class="number">20</span>s (x2 over <span class="number">50</span>s)  kubelet, node1     Started container nginx</span><br><span class="line">  Normal   Killing    <span class="number">20</span>s                kubelet, node1     Container nginx failed liveness probe, will be restarted</span><br><span class="line">  Warning  Unhealthy  <span class="number">0</span>s (x5 over <span class="number">40</span>s)   kubelet, node1     Liveness probe failed: <span class="built_in">cat</span>: can<span class="string">&#x27;t open &#x27;</span>/tmp/hello11.txt<span class="string">&#x27;: No such file or directory</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string"># 观察上面的信息就会发现nginx容器启动之后就进行了健康检查</span></span><br><span class="line"><span class="string"># 检查失败之后，容器被kill掉，然后尝试进行重启（这是重启策略的作用，后面讲解）</span></span><br><span class="line"><span class="string"># 稍等一会之后，再观察pod信息，就可以看到RESTARTS不再是0，而是一直增长</span></span><br><span class="line"><span class="string">[root@master ~]# kubectl get pods pod-liveness-exec -n dev</span></span><br><span class="line"><span class="string">NAME                READY   STATUS             RESTARTS   AGE</span></span><br><span class="line"><span class="string">pod-liveness-exec   0/1     CrashLoopBackOff   2          3m19s</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 当然接下来，可以修改成一个存在的文件，比如/tmp/hello.txt，再试，结果就正常了......</span></span><br></pre></td></tr></table></figure>

<p><strong>方式二：TCPSocket</strong></p>
<p>创建pod-liveness-tcpsocket.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-liveness-tcpsocket</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">ports:</span> </span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-port</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">livenessProbe:</span></span><br><span class="line">      <span class="attr">tcpSocket:</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">8080</span> <span class="comment"># 尝试访问8080端口</span></span><br></pre></td></tr></table></figure>

<p>创建pod，观察效果</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建Pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod-liveness-tcpsocket.yaml</span></span><br><span class="line">pod/pod<span class="literal">-liveness-tcpsocket</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Pod详情</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl describe pods pod-liveness-tcpsocket -n dev</span></span><br><span class="line">......</span><br><span class="line">  Normal   Scheduled  <span class="number">31</span>s                            default<span class="literal">-scheduler</span>  Successfully assigned dev/pod<span class="literal">-liveness-tcpsocket</span> to node2</span><br><span class="line">  Normal   Pulled     &lt;invalid&gt;                      kubelet, node2     Container image <span class="string">&quot;nginx:1.17.1&quot;</span> already present on machine</span><br><span class="line">  Normal   Created    &lt;invalid&gt;                      kubelet, node2     Created container nginx</span><br><span class="line">  Normal   Started    &lt;invalid&gt;                      kubelet, node2     Started container nginx</span><br><span class="line">  Warning  Unhealthy  &lt;invalid&gt; (x2 over &lt;invalid&gt;)  kubelet, node2     Liveness probe failed: dial tcp <span class="number">10.244</span>.<span class="number">2.44</span>:<span class="number">8080</span>: connect: connection refused</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 观察上面的信息，发现尝试访问8080端口,但是失败了</span></span><br><span class="line"><span class="comment"># 稍等一会之后，再观察pod信息，就可以看到RESTARTS不再是0，而是一直增长</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods pod-liveness-tcpsocket  -n dev</span></span><br><span class="line">NAME                     READY   STATUS             RESTARTS   AGE</span><br><span class="line">pod<span class="literal">-liveness-tcpsocket</span>   <span class="number">0</span>/<span class="number">1</span>     CrashLoopBackOff   <span class="number">2</span>          <span class="number">3</span>m19s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 当然接下来，可以修改成一个可以访问的端口，比如80，再试，结果就正常了......</span></span><br></pre></td></tr></table></figure>

<p><strong>方式三：HTTPGet</strong></p>
<p>创建pod-liveness-httpget.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-liveness-httpget</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-port</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">livenessProbe:</span></span><br><span class="line">      <span class="attr">httpGet:</span>  <span class="comment"># 其实就是访问http://127.0.0.1:80/hello  </span></span><br><span class="line">        <span class="attr">scheme:</span> <span class="string">HTTP</span> <span class="comment">#支持的协议，http或者https</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">80</span> <span class="comment">#端口号</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/hello</span> <span class="comment">#URI地址</span></span><br></pre></td></tr></table></figure>

<p>创建pod，观察效果</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建Pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod-liveness-httpget.yaml</span></span><br><span class="line">pod/pod<span class="literal">-liveness-httpget</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Pod详情</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl describe pod pod-liveness-httpget -n dev</span></span><br><span class="line">.......</span><br><span class="line">  Normal   Pulled     <span class="number">6</span>s (x3 over <span class="number">64</span>s)  kubelet, node1     Container image <span class="string">&quot;nginx:1.17.1&quot;</span> already present on machine</span><br><span class="line">  Normal   Created    <span class="number">6</span>s (x3 over <span class="number">64</span>s)  kubelet, node1     Created container nginx</span><br><span class="line">  Normal   Started    <span class="number">6</span>s (x3 over <span class="number">63</span>s)  kubelet, node1     Started container nginx</span><br><span class="line">  Warning  Unhealthy  <span class="number">6</span>s (x6 over <span class="number">56</span>s)  kubelet, node1     Liveness probe failed: HTTP probe failed with statuscode: <span class="number">404</span></span><br><span class="line">  Normal   Killing    <span class="number">6</span>s (x2 over <span class="number">36</span>s)  kubelet, node1     Container nginx failed liveness probe, will be restarted</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 观察上面信息，尝试访问路径，但是未找到,出现404错误</span></span><br><span class="line"><span class="comment"># 稍等一会之后，再观察pod信息，就可以看到RESTARTS不再是0，而是一直增长</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pod pod-liveness-httpget -n dev</span></span><br><span class="line">NAME                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod<span class="literal">-liveness-httpget</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">5</span>          <span class="number">3</span>m17s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 当然接下来，可以修改成一个可以访问的路径path，比如/，再试，结果就正常了......</span></span><br></pre></td></tr></table></figure>

<p>至此，已经使用liveness Probe演示了三种探测方式，但是查看livenessProbe的子属性，会发现除了这三种方式，还有一些其他的配置，在这里一并解释下：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl explain pod.spec.containers.livenessProbe</span></span><br><span class="line">FIELDS:</span><br><span class="line">   exec &lt;Object&gt;  </span><br><span class="line">   tcpSocket    &lt;Object&gt;</span><br><span class="line">   httpGet      &lt;Object&gt;</span><br><span class="line">   initialDelaySeconds  &lt;integer&gt;  <span class="comment"># 容器启动后等待多少秒执行第一次探测</span></span><br><span class="line">   timeoutSeconds       &lt;integer&gt;  <span class="comment"># 探测超时时间。默认1秒，最小1秒</span></span><br><span class="line">   periodSeconds        &lt;integer&gt;  <span class="comment"># 执行探测的频率。默认是10秒，最小1秒</span></span><br><span class="line">   failureThreshold     &lt;integer&gt;  <span class="comment"># 连续探测失败多少次才被认定为失败。默认是3。最小值是1</span></span><br><span class="line">   successThreshold     &lt;integer&gt;  <span class="comment"># 连续探测成功多少次才被认定为成功。默认是1</span></span><br></pre></td></tr></table></figure>

<p>下面稍微配置两个，演示下效果即可：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">[<span class="string">root@master</span> <span class="string">~</span>]<span class="comment"># more pod-liveness-httpget.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-liveness-httpget</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-port</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">livenessProbe:</span></span><br><span class="line">      <span class="attr">httpGet:</span></span><br><span class="line">        <span class="attr">scheme:</span> <span class="string">HTTP</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">80</span> </span><br><span class="line">        <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">      <span class="attr">initialDelaySeconds:</span> <span class="number">30</span> <span class="comment"># 容器启动后30s开始探测</span></span><br><span class="line">      <span class="attr">timeoutSeconds:</span> <span class="number">5</span> <span class="comment"># 探测超时时间为5s</span></span><br></pre></td></tr></table></figure>

<h3 id="重启策略"><a href="#重启策略" class="headerlink" title="重启策略"></a>重启策略</h3><p>在上一节中，一旦容器探测出现了问题，kubernetes就会对容器所在的Pod进行重启，其实这是由pod的重启策略决定的，pod的重启策略有 3 种，分别如下：</p>
<ul>
<li><p>Always ：容器失效时，自动重启该容器，这也是默认值。</p>
</li>
<li><p>OnFailure ： 容器终止运行且退出码不为0时重启</p>
</li>
<li><p>Never ： 不论状态为何，都不重启该容器</p>
<p>  重启策略适用于pod对象中的所有容器，首次需要重启的容器，将在其需要时立即进行重启，随后再次需要重启的操作将由kubelet延迟一段时间后进行，且反复的重启操作的延迟时长以此为10s、20s、40s、80s、160s和300s，300s是最大延迟时长。</p>
</li>
</ul>
<p>创建pod-restartpolicy.yaml：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-restartpolicy</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-port</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">livenessProbe:</span></span><br><span class="line">      <span class="attr">httpGet:</span></span><br><span class="line">        <span class="attr">scheme:</span> <span class="string">HTTP</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/hello</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Never</span> <span class="comment"># 设置重启策略为Never</span></span><br></pre></td></tr></table></figure>

<p>运行Pod测试</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建Pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod-restartpolicy.yaml</span></span><br><span class="line">pod/pod<span class="literal">-restartpolicy</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Pod详情，发现nginx容器失败</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl  describe pods pod-restartpolicy  -n dev</span></span><br><span class="line">......</span><br><span class="line">  Warning  Unhealthy  <span class="number">15</span>s (x3 over <span class="number">35</span>s)  kubelet, node1     Liveness probe failed: HTTP probe failed with statuscode: <span class="number">404</span></span><br><span class="line">  Normal   Killing    <span class="number">15</span>s                kubelet, node1     Container nginx failed liveness probe</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 多等一会，再观察pod的重启次数，发现一直是0，并未重启   </span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl  get pods pod-restartpolicy -n dev</span></span><br><span class="line">NAME                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod<span class="literal">-restartpolicy</span>      <span class="number">0</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">5</span>min42s</span><br></pre></td></tr></table></figure>

<h2 id="Pod调度"><a href="#Pod调度" class="headerlink" title="Pod调度"></a>Pod调度</h2><p>在默认情况下，一个Pod在哪个Node节点上运行，是由Scheduler组件采用相应的算法计算出来的，这个过程是不受人工控制的。但是在实际使用中，这并不满足的需求，因为很多情况下，我们想控制某些Pod到达某些节点上，那么应该怎么做呢？这就要求了解kubernetes对Pod的调度规则，kubernetes提供了四大类调度方式：</p>
<ul>
<li>自动调度：运行在哪个节点上完全由Scheduler经过一系列的算法计算得出</li>
<li>定向调度：NodeName、NodeSelector</li>
<li>亲和性调度：NodeAffinity、PodAffinity、PodAntiAffinity</li>
<li>污点（容忍）调度：Taints、Toleration</li>
</ul>
<h3 id="定向调度"><a href="#定向调度" class="headerlink" title="定向调度"></a>定向调度</h3><p>定向调度，指的是利用在pod上声明nodeName或者nodeSelector，以此将Pod调度到期望的node节点上。注意，这里的调度是强制的，这就意味着即使要调度的目标Node不存在，也会向上面进行调度，只不过pod运行失败而已。</p>
<p><strong>NodeName</strong></p>
<p>NodeName用于强制约束将Pod调度到指定的Name的Node节点上。这种方式，其实是直接跳过Scheduler的调度逻辑，直接将Pod调度到指定名称的节点。</p>
<p>接下来，实验一下：创建一个pod-nodename.yaml文件</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-nodename</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="string">node1</span> <span class="comment"># 指定调度到node1节点上</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment">#创建Pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod-nodename.yaml</span></span><br><span class="line">pod/pod<span class="literal">-nodename</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看Pod调度到NODE属性，确实是调度到了node1节点上</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods pod-nodename -n dev -o wide</span></span><br><span class="line">NAME           READY   STATUS    RESTARTS   AGE   IP            NODE      ......</span><br><span class="line">pod<span class="literal">-nodename</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">56</span>s   <span class="number">10.244</span>.<span class="number">1.87</span>   node1     ......   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来，删除pod，修改nodeName的值为node3（并没有node3节点）</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete -f pod-nodename.yaml</span></span><br><span class="line">pod <span class="string">&quot;pod-nodename&quot;</span> deleted</span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># vim pod-nodename.yaml</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod-nodename.yaml</span></span><br><span class="line">pod/pod<span class="literal">-nodename</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment">#再次查看，发现已经向Node3节点调度，但是由于不存在node3节点，所以pod无法正常运行</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods pod-nodename -n dev -o wide</span></span><br><span class="line">NAME           READY   STATUS    RESTARTS   AGE   IP       NODE    ......</span><br><span class="line">pod<span class="literal">-nodename</span>   <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">6</span>s    &lt;none&gt;   node3   ......           </span><br></pre></td></tr></table></figure>

<p><strong>NodeSelector</strong></p>
<p>NodeSelector用于将pod调度到添加了指定标签的node节点上。它是通过kubernetes的label-selector机制实现的，也就是说，在pod创建之前，会由scheduler使用MatchNodeSelector调度策略进行label匹配，找出目标node，然后将pod调度到目标节点，该匹配规则是强制约束。</p>
<p>接下来，实验一下：</p>
<p>1 首先分别为node节点添加标签</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl label nodes node1 nodeenv=pro</span></span><br><span class="line">node/node2 labeled</span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl label nodes node2 nodeenv=test</span></span><br><span class="line">node/node2 labeled</span><br></pre></td></tr></table></figure>

<p>2 创建一个pod-nodeselector.yaml文件，并使用它创建Pod</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-nodeselector</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">  <span class="attr">nodeSelector:</span> </span><br><span class="line">    <span class="attr">nodeenv:</span> <span class="string">pro</span> <span class="comment"># 指定调度到具有nodeenv=pro标签的节点上</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment">#创建Pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod-nodeselector.yaml</span></span><br><span class="line">pod/pod<span class="literal">-nodeselector</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看Pod调度到NODE属性，确实是调度到了node1节点上</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods pod-nodeselector -n dev -o wide</span></span><br><span class="line">NAME               READY   STATUS    RESTARTS   AGE     IP          NODE    ......</span><br><span class="line">pod<span class="literal">-nodeselector</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">47</span>s   <span class="number">10.244</span>.<span class="number">1.87</span>   node1   ......</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来，删除pod，修改nodeSelector的值为nodeenv: xxxx（不存在打有此标签的节点）</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete -f pod-nodeselector.yaml</span></span><br><span class="line">pod <span class="string">&quot;pod-nodeselector&quot;</span> deleted</span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># vim pod-nodeselector.yaml</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod-nodeselector.yaml</span></span><br><span class="line">pod/pod<span class="literal">-nodeselector</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment">#再次查看，发现pod无法正常运行,Node的值为none</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev -o wide</span></span><br><span class="line">NAME               READY   STATUS    RESTARTS   AGE     IP       NODE    </span><br><span class="line">pod<span class="literal">-nodeselector</span>   <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">2</span>m20s   &lt;none&gt;   &lt;none&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看详情,发现node selector匹配失败的提示</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl describe pods pod-nodeselector -n dev</span></span><br><span class="line">.......</span><br><span class="line">Events:</span><br><span class="line">  <span class="built_in">Type</span>     Reason            Age        From               Message</span><br><span class="line">  <span class="literal">----</span>     <span class="literal">------</span>            <span class="literal">----</span>       <span class="literal">----</span>               <span class="literal">-------</span></span><br><span class="line">  Warning  FailedScheduling  &lt;unknown&gt;  default<span class="literal">-scheduler</span>  <span class="number">0</span>/<span class="number">3</span> nodes are available: <span class="number">3</span> node(s) didn<span class="string">&#x27;t match node selector.</span></span><br><span class="line"><span class="string">  Warning  FailedScheduling  &lt;unknown&gt;  default-scheduler  0/3 nodes are available: 3 node(s) didn&#x27;</span>t match node selector.</span><br></pre></td></tr></table></figure>

<h3 id="亲和性调度"><a href="#亲和性调度" class="headerlink" title="亲和性调度"></a>亲和性调度</h3><p>上一节，介绍了两种定向调度的方式，使用起来非常方便，但是也有一定的问题，那就是如果没有满足条件的Node，那么Pod将不会被运行，即使在集群中还有可用Node列表也不行，这就限制了它的使用场景。</p>
<p>基于上面的问题，kubernetes还提供了一种亲和性调度（Affinity）。它在NodeSelector的基础之上的进行了扩展，可以通过配置的形式，实现优先选择满足条件的Node进行调度，如果没有，也可以调度到不满足条件的节点上，使调度更加灵活。</p>
<p>Affinity主要分为三类：</p>
<ul>
<li><p>nodeAffinity(node亲和性）: 以node为目标，解决pod可以调度到哪些node的问题</p>
</li>
<li><p>podAffinity(pod亲和性) :  以pod为目标，解决pod可以和哪些已存在的pod部署在同一个拓扑域中的问题</p>
</li>
<li><p>podAntiAffinity(pod反亲和性) :  以pod为目标，解决pod不能和哪些已存在pod部署在同一个拓扑域中的问题</p>
</li>
</ul>
<blockquote>
<p>关于亲和性(反亲和性)使用场景的说明：</p>
<p><strong>亲和性</strong>：如果两个应用频繁交互，那就有必要利用亲和性让两个应用的尽可能的靠近，这样可以减少因网络通信而带来的性能损耗。</p>
<p><strong>反亲和性</strong>：当应用的采用多副本部署时，有必要采用反亲和性让各个应用实例打散分布在各个node上，这样可以提高服务的高可用性。</p>
</blockquote>
<p><strong>NodeAffinity</strong></p>
<p>首先来看一下<code>NodeAffinity</code>的可配置项：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">pod.spec.affinity.nodeAffinity</span><br><span class="line">  requiredDuringSchedulingIgnoredDuringExecution  Node节点必须满足指定的所有规则才可以，相当于硬限制</span><br><span class="line"><span class="code">    nodeSelectorTerms  节点选择列表</span></span><br><span class="line"><span class="code">      matchFields   按节点字段列出的节点选择器要求列表</span></span><br><span class="line"><span class="code">      matchExpressions   按节点标签列出的节点选择器要求列表(推荐)</span></span><br><span class="line"><span class="code">        key    键</span></span><br><span class="line"><span class="code">        values 值</span></span><br><span class="line"><span class="code">        operator 关系符 支持Exists, DoesNotExist, In, NotIn, Gt, Lt</span></span><br><span class="line"><span class="code">  preferredDuringSchedulingIgnoredDuringExecution 优先调度到满足指定的规则的Node，相当于软限制 (倾向)</span></span><br><span class="line"><span class="code">    preference   一个节点选择器项，与相应的权重相关联</span></span><br><span class="line"><span class="code">      matchFields   按节点字段列出的节点选择器要求列表</span></span><br><span class="line"><span class="code">      matchExpressions   按节点标签列出的节点选择器要求列表(推荐)</span></span><br><span class="line"><span class="code">        key    键</span></span><br><span class="line"><span class="code">        values 值</span></span><br><span class="line"><span class="code">        operator 关系符 支持In, NotIn, Exists, DoesNotExist, Gt, Lt</span></span><br><span class="line"><span class="code"> weight 倾向权重，在范围1-100。</span></span><br></pre></td></tr></table></figure>

<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">关系符的使用说明:</span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> matchExpressions:</span><br><span class="line"><span class="bullet">  -</span> key: nodeenv              # 匹配存在标签的key为nodeenv的节点</span><br><span class="line"><span class="code">    operator: Exists</span></span><br><span class="line"><span class="code">  - key: nodeenv              # 匹配标签的key为nodeenv,且value是&quot;xxx&quot;或&quot;yyy&quot;的节点</span></span><br><span class="line"><span class="code">    operator: In</span></span><br><span class="line"><span class="code">    values: [&quot;xxx&quot;,&quot;yyy&quot;]</span></span><br><span class="line"><span class="code">  - key: nodeenv              # 匹配标签的key为nodeenv,且value大于&quot;xxx&quot;的节点</span></span><br><span class="line"><span class="code">    operator: Gt</span></span><br><span class="line"><span class="code">    values: &quot;xxx&quot;</span></span><br></pre></td></tr></table></figure>

<p>接下来首先演示一下<code>requiredDuringSchedulingIgnoredDuringExecution</code> ,</p>
<p>创建pod-nodeaffinity-required.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-nodeaffinity-required</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">  <span class="attr">affinity:</span>  <span class="comment">#亲和性设置</span></span><br><span class="line">    <span class="attr">nodeAffinity:</span> <span class="comment">#设置node亲和性</span></span><br><span class="line">      <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span> <span class="comment"># 硬限制</span></span><br><span class="line">        <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">matchExpressions:</span> <span class="comment"># 匹配env的值在[&quot;xxx&quot;,&quot;yyy&quot;]中的标签</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">nodeenv</span></span><br><span class="line">            <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">            <span class="attr">values:</span> [<span class="string">&quot;xxx&quot;</span>,<span class="string">&quot;yyy&quot;</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod-nodeaffinity-required.yaml</span></span><br><span class="line">pod/pod<span class="literal">-nodeaffinity-required</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod状态 （运行失败）</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods pod-nodeaffinity-required -n dev -o wide</span></span><br><span class="line">NAME                        READY   STATUS    RESTARTS   AGE   IP       NODE    ...... </span><br><span class="line">pod<span class="literal">-nodeaffinity-required</span>   <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">16</span>s   &lt;none&gt;   &lt;none&gt;  ......</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Pod的详情</span></span><br><span class="line"><span class="comment"># 发现调度失败，提示node选择失败</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl describe pod pod-nodeaffinity-required -n dev</span></span><br><span class="line">......</span><br><span class="line">  Warning  FailedScheduling  &lt;unknown&gt;  default<span class="literal">-scheduler</span>  <span class="number">0</span>/<span class="number">3</span> nodes are available: <span class="number">3</span> node(s) didn<span class="string">&#x27;t match node selector.</span></span><br><span class="line"><span class="string">  Warning  FailedScheduling  &lt;unknown&gt;  default-scheduler  0/3 nodes are available: 3 node(s) didn&#x27;</span>t match node selector.</span><br><span class="line"></span><br><span class="line"><span class="comment">#接下来，停止pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete -f pod-nodeaffinity-required.yaml</span></span><br><span class="line">pod <span class="string">&quot;pod-nodeaffinity-required&quot;</span> deleted</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改文件，将values: [&quot;xxx&quot;,&quot;yyy&quot;]------&gt; [&quot;pro&quot;,&quot;yyy&quot;]</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># vim pod-nodeaffinity-required.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 再次启动</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod-nodeaffinity-required.yaml</span></span><br><span class="line">pod/pod<span class="literal">-nodeaffinity-required</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 此时查看，发现调度成功，已经将pod调度到了node1上</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods pod-nodeaffinity-required -n dev -o wide</span></span><br><span class="line">NAME                        READY   STATUS    RESTARTS   AGE   IP            NODE  ...... </span><br><span class="line">pod<span class="literal">-nodeaffinity-required</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">11</span>s   <span class="number">10.244</span>.<span class="number">1.89</span>   node1 ......</span><br></pre></td></tr></table></figure>

<p>接下来再演示一下<code>requiredDuringSchedulingIgnoredDuringExecution</code> ,</p>
<p>创建pod-nodeaffinity-preferred.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-nodeaffinity-preferred</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">  <span class="attr">affinity:</span>  <span class="comment">#亲和性设置</span></span><br><span class="line">    <span class="attr">nodeAffinity:</span> <span class="comment">#设置node亲和性</span></span><br><span class="line">      <span class="attr">preferredDuringSchedulingIgnoredDuringExecution:</span> <span class="comment"># 软限制</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">        <span class="attr">preference:</span></span><br><span class="line">          <span class="attr">matchExpressions:</span> <span class="comment"># 匹配env的值在[&quot;xxx&quot;,&quot;yyy&quot;]中的标签(当前环境没有)</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">nodeenv</span></span><br><span class="line">            <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">            <span class="attr">values:</span> [<span class="string">&quot;xxx&quot;</span>,<span class="string">&quot;yyy&quot;</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod-nodeaffinity-preferred.yaml</span></span><br><span class="line">pod/pod<span class="literal">-nodeaffinity-preferred</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod状态 （运行成功）</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pod pod-nodeaffinity-preferred -n dev</span></span><br><span class="line">NAME                         READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod<span class="literal">-nodeaffinity-preferred</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">40</span>s</span><br></pre></td></tr></table></figure>

<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">NodeAffinity规则设置的注意事项：</span><br><span class="line"><span class="code">    1 如果同时定义了nodeSelector和nodeAffinity，那么必须两个条件都得到满足，Pod才能运行在指定的Node上</span></span><br><span class="line"><span class="code">    2 如果nodeAffinity指定了多个nodeSelectorTerms，那么只需要其中一个能够匹配成功即可</span></span><br><span class="line"><span class="code">    3 如果一个nodeSelectorTerms中有多个matchExpressions ，则一个节点必须满足所有的才能匹配成功</span></span><br><span class="line"><span class="code">    4 如果一个pod所在的Node在Pod运行期间其标签发生了改变，不再符合该Pod的节点亲和性需求，则系统将忽略此变化</span></span><br></pre></td></tr></table></figure>

<p><strong>PodAffinity</strong></p>
<p>PodAffinity主要实现以运行的Pod为参照，实现让新创建的Pod跟参照pod在一个区域的功能。</p>
<p>首先来看一下<code>PodAffinity</code>的可配置项：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">pod.spec.affinity.podAffinity</span><br><span class="line">  requiredDuringSchedulingIgnoredDuringExecution  硬限制</span><br><span class="line"><span class="code">    namespaces       指定参照pod的namespace</span></span><br><span class="line"><span class="code">    topologyKey      指定调度作用域</span></span><br><span class="line"><span class="code">    labelSelector    标签选择器</span></span><br><span class="line"><span class="code">      matchExpressions  按节点标签列出的节点选择器要求列表(推荐)</span></span><br><span class="line"><span class="code">        key    键</span></span><br><span class="line"><span class="code">        values 值</span></span><br><span class="line"><span class="code">        operator 关系符 支持In, NotIn, Exists, DoesNotExist.</span></span><br><span class="line"><span class="code">      matchLabels    指多个matchExpressions映射的内容</span></span><br><span class="line"><span class="code">  preferredDuringSchedulingIgnoredDuringExecution 软限制</span></span><br><span class="line"><span class="code">    podAffinityTerm  选项</span></span><br><span class="line"><span class="code">      namespaces      </span></span><br><span class="line"><span class="code">      topologyKey</span></span><br><span class="line"><span class="code">      labelSelector</span></span><br><span class="line"><span class="code">        matchExpressions  </span></span><br><span class="line"><span class="code">          key    键</span></span><br><span class="line"><span class="code">          values 值</span></span><br><span class="line"><span class="code">          operator</span></span><br><span class="line"><span class="code">        matchLabels </span></span><br><span class="line"><span class="code">    weight 倾向权重，在范围1-100</span></span><br></pre></td></tr></table></figure>

<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">topologyKey用于指定调度时作用域,例如:</span><br><span class="line"><span class="code">    如果指定为kubernetes.io/hostname，那就是以Node节点为区分范围</span></span><br><span class="line"><span class="code"> 如果指定为beta.kubernetes.io/os,则以Node节点的操作系统类型来区分</span></span><br></pre></td></tr></table></figure>

<p>接下来，演示下<code>requiredDuringSchedulingIgnoredDuringExecution</code>,</p>
<p>1）首先创建一个参照Pod，pod-podaffinity-target.yaml：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-podaffinity-target</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">podenv:</span> <span class="string">pro</span> <span class="comment">#设置标签</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="string">node1</span> <span class="comment"># 将目标pod名确指定到node1上</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 启动目标pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod-podaffinity-target.yaml</span></span><br><span class="line">pod/pod<span class="literal">-podaffinity-target</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod状况</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods  pod-podaffinity-target -n dev</span></span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod<span class="literal">-podaffinity-target</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">4</span>s</span><br></pre></td></tr></table></figure>

<p>2）创建pod-podaffinity-required.yaml，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-podaffinity-required</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">  <span class="attr">affinity:</span>  <span class="comment">#亲和性设置</span></span><br><span class="line">    <span class="attr">podAffinity:</span> <span class="comment">#设置pod亲和性</span></span><br><span class="line">      <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span> <span class="comment"># 硬限制</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">labelSelector:</span></span><br><span class="line">          <span class="attr">matchExpressions:</span> <span class="comment"># 匹配env的值在[&quot;xxx&quot;,&quot;yyy&quot;]中的标签</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">podenv</span></span><br><span class="line">            <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">            <span class="attr">values:</span> [<span class="string">&quot;xxx&quot;</span>,<span class="string">&quot;yyy&quot;</span>]</span><br><span class="line">        <span class="attr">topologyKey:</span> <span class="string">kubernetes.io/hostname</span></span><br></pre></td></tr></table></figure>

<p>上面配置表达的意思是：新Pod必须要与拥有标签nodeenv&#x3D;xxx或者nodeenv&#x3D;yyy的pod在同一Node上，显然现在没有这样pod，接下来，运行测试一下。</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 启动pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod-podaffinity-required.yaml</span></span><br><span class="line">pod/pod<span class="literal">-podaffinity-required</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod状态，发现未运行</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods pod-podaffinity-required -n dev</span></span><br><span class="line">NAME                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod<span class="literal">-podaffinity-required</span>   <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">9</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看详细信息</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl describe pods pod-podaffinity-required  -n dev</span></span><br><span class="line">......</span><br><span class="line">Events:</span><br><span class="line">  <span class="built_in">Type</span>     Reason            Age        From               Message</span><br><span class="line">  <span class="literal">----</span>     <span class="literal">------</span>            <span class="literal">----</span>       <span class="literal">----</span>               <span class="literal">-------</span></span><br><span class="line">  Warning  FailedScheduling  &lt;unknown&gt;  default<span class="literal">-scheduler</span>  <span class="number">0</span>/<span class="number">3</span> nodes are available: <span class="number">2</span> node(s) didn<span class="string">&#x27;t match pod affinity rules, 1 node(s) had taints that the pod didn&#x27;</span>t tolerate.</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来修改  values: [&quot;xxx&quot;,&quot;yyy&quot;]-----&gt;values:[&quot;pro&quot;,&quot;yyy&quot;]</span></span><br><span class="line"><span class="comment"># 意思是：新Pod必须要与拥有标签nodeenv=xxx或者nodeenv=yyy的pod在同一Node上</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># vim pod-podaffinity-required.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后重新创建pod，查看效果</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete -f  pod-podaffinity-required.yaml</span></span><br><span class="line">pod <span class="string">&quot;pod-podaffinity-required&quot;</span> deleted</span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod-podaffinity-required.yaml</span></span><br><span class="line">pod/pod<span class="literal">-podaffinity-required</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发现此时Pod运行正常</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods pod-podaffinity-required -n dev</span></span><br><span class="line">NAME                       READY   STATUS    RESTARTS   AGE   LABELS</span><br><span class="line">pod<span class="literal">-podaffinity-required</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">6</span>s    &lt;none&gt;</span><br></pre></td></tr></table></figure>

<p>关于<code>PodAffinity</code>的 <code>preferredDuringSchedulingIgnoredDuringExecution</code>，这里不再演示。</p>
<p><strong>PodAntiAffinity</strong></p>
<p>PodAntiAffinity主要实现以运行的Pod为参照，让新创建的Pod跟参照pod不在一个区域中的功能。</p>
<p>它的配置方式和选项跟PodAffinty是一样的，这里不再做详细解释，直接做一个测试案例。</p>
<p>1）继续使用上个案例中目标pod</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev -o wide --show-labels</span></span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE     IP            NODE    LABELS</span><br><span class="line">pod<span class="literal">-podaffinity-required</span> <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">3</span>m29s   <span class="number">10.244</span>.<span class="number">1.38</span>   node1   &lt;none&gt;     </span><br><span class="line">pod<span class="literal">-podaffinity-target</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">9</span>m25s   <span class="number">10.244</span>.<span class="number">1.37</span>   node1   podenv=pro</span><br></pre></td></tr></table></figure>

<p>2）创建pod-podantiaffinity-required.yaml，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-podantiaffinity-required</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">  <span class="attr">affinity:</span>  <span class="comment">#亲和性设置</span></span><br><span class="line">    <span class="attr">podAntiAffinity:</span> <span class="comment">#设置pod亲和性</span></span><br><span class="line">      <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span> <span class="comment"># 硬限制</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">labelSelector:</span></span><br><span class="line">          <span class="attr">matchExpressions:</span> <span class="comment"># 匹配podenv的值在[&quot;pro&quot;]中的标签</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">podenv</span></span><br><span class="line">            <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">            <span class="attr">values:</span> [<span class="string">&quot;pro&quot;</span>]</span><br><span class="line">        <span class="attr">topologyKey:</span> <span class="string">kubernetes.io/hostname</span></span><br></pre></td></tr></table></figure>

<p>上面配置表达的意思是：新Pod必须要与拥有标签nodeenv&#x3D;pro的pod不在同一Node上，运行测试一下。</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod-podantiaffinity-required.yaml</span></span><br><span class="line">pod/pod<span class="literal">-podantiaffinity-required</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod</span></span><br><span class="line"><span class="comment"># 发现调度到了node2上</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods pod-podantiaffinity-required -n dev -o wide</span></span><br><span class="line">NAME                           READY   STATUS    RESTARTS   AGE   IP            NODE   .. </span><br><span class="line">pod<span class="literal">-podantiaffinity-required</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">30</span>s   <span class="number">10.244</span>.<span class="number">1.96</span>   node2  ..</span><br></pre></td></tr></table></figure>

<h3 id="污点和容忍"><a href="#污点和容忍" class="headerlink" title="污点和容忍"></a>污点和容忍</h3><p><strong>污点（Taints）</strong></p>
<p>前面的调度方式都是站在Pod的角度上，通过在Pod上添加属性，来确定Pod是否要调度到指定的Node上，其实我们也可以站在Node的角度上，通过在Node上添加<strong>污点</strong>属性，来决定是否允许Pod调度过来。</p>
<p>Node被设置上污点之后就和Pod之间存在了一种相斥的关系，进而拒绝Pod调度进来，甚至可以将已经存在的Pod驱逐出去。</p>
<p>污点的格式为：<code>key=value:effect</code>, key和value是污点的标签，effect描述污点的作用，支持如下三个选项：</p>
<ul>
<li>PreferNoSchedule：kubernetes将尽量避免把Pod调度到具有该污点的Node上，除非没有其他节点可调度</li>
<li>NoSchedule：kubernetes将不会把Pod调度到具有该污点的Node上，但不会影响当前Node上已存在的Pod</li>
<li>NoExecute：kubernetes将不会把Pod调度到具有该污点的Node上，同时也会将Node上已存在的Pod驱离</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200605021606508.png" alt="image-20200605021606508"></p>
<p>使用kubectl设置和去除污点的命令示例如下：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设置污点</span></span><br><span class="line">kubectl taint nodes node1 key=value:effect</span><br><span class="line"></span><br><span class="line"><span class="comment"># 去除污点</span></span><br><span class="line">kubectl taint nodes node1 key:effect-</span><br><span class="line"></span><br><span class="line"><span class="comment"># 去除所有污点</span></span><br><span class="line">kubectl taint nodes node1 key-</span><br></pre></td></tr></table></figure>

<p>接下来，演示下污点的效果：</p>
<ol>
<li>准备节点node1（为了演示效果更加明显，暂时停止node2节点）</li>
<li>为node1节点设置一个污点: <code>tag=heima:PreferNoSchedule</code>；然后创建pod1( pod1 可以 )</li>
<li>修改为node1节点设置一个污点: <code>tag=heima:NoSchedule</code>；然后创建pod2( pod1 正常  pod2 失败 )</li>
<li>修改为node1节点设置一个污点: <code>tag=heima:NoExecute</code>；然后创建pod3 ( 3个pod都失败 )</li>
</ol>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 为node1设置污点(PreferNoSchedule)</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl taint nodes node1 tag=heima:PreferNoSchedule</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建pod1</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl run taint1 --image=nginx:1.17.1 -n dev</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev -o wide</span></span><br><span class="line">NAME                      READY   STATUS    RESTARTS   AGE     IP           NODE   </span><br><span class="line">taint1<span class="literal">-7665f7fd85-574h4</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>m24s   <span class="number">10.244</span>.<span class="number">1.59</span>   node1    </span><br><span class="line"></span><br><span class="line"><span class="comment"># 为node1设置污点(取消PreferNoSchedule，设置NoSchedule)</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl taint nodes node1 tag:PreferNoSchedule-</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl taint nodes node1 tag=heima:NoSchedule</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建pod2</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl run taint2 --image=nginx:1.17.1 -n dev</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods taint2 -n dev -o wide</span></span><br><span class="line">NAME                      READY   STATUS    RESTARTS   AGE     IP            NODE</span><br><span class="line">taint1<span class="literal">-7665f7fd85-574h4</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>m24s   <span class="number">10.244</span>.<span class="number">1.59</span>   node1 </span><br><span class="line">taint2<span class="literal">-544694789-6zmlf</span>    <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">21</span>s     &lt;none&gt;        &lt;none&gt;   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 为node1设置污点(取消NoSchedule，设置NoExecute)</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl taint nodes node1 tag:NoSchedule-</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl taint nodes node1 tag=heima:NoExecute</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建pod3</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl run taint3 --image=nginx:1.17.1 -n dev</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev -o wide</span></span><br><span class="line">NAME                      READY   STATUS    RESTARTS   AGE   IP       NODE     NOMINATED </span><br><span class="line">taint1<span class="literal">-7665f7fd85-htkmp</span>   <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">35</span>s   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;    </span><br><span class="line">taint2<span class="literal">-544694789-bn7wb</span>    <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">35</span>s   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;     </span><br><span class="line">taint3<span class="literal">-6d78dbd749-tktkq</span>   <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">6</span>s    &lt;none&gt;   &lt;none&gt;   &lt;none&gt;     </span><br></pre></td></tr></table></figure>

<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">小提示：</span><br><span class="line"><span class="code">    使用kubeadm搭建的集群，默认就会给master节点添加一个污点标记,所以pod就不会调度到master节点上.</span></span><br></pre></td></tr></table></figure>

<p><strong>容忍（Toleration）</strong></p>
<p>上面介绍了污点的作用，我们可以在node上添加污点用于拒绝pod调度上来，但是如果就是想将一个pod调度到一个有污点的node上去，这时候应该怎么做呢？这就要使用到<strong>容忍</strong>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200514095913741.png" alt="image-20200514095913741"></p>
<blockquote>
<p>污点就是拒绝，容忍就是忽略，Node通过污点拒绝pod调度上去，Pod通过容忍忽略拒绝</p>
</blockquote>
<p>下面先通过一个案例看下效果：</p>
<ol>
<li>上一小节，已经在node1节点上打上了<code>NoExecute</code>的污点，此时pod是调度不上去的</li>
<li>本小节，可以通过给pod添加容忍，然后将其调度上去</li>
</ol>
<p>创建pod-toleration.yaml,内容如下</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-toleration</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">  <span class="attr">tolerations:</span>      <span class="comment"># 添加容忍</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&quot;tag&quot;</span>        <span class="comment"># 要容忍的污点的key</span></span><br><span class="line">    <span class="attr">operator:</span> <span class="string">&quot;Equal&quot;</span> <span class="comment"># 操作符</span></span><br><span class="line">    <span class="attr">value:</span> <span class="string">&quot;heima&quot;</span>    <span class="comment"># 容忍的污点的value</span></span><br><span class="line">    <span class="attr">effect:</span> <span class="string">&quot;NoExecute&quot;</span>   <span class="comment"># 添加容忍的规则，这里必须和标记的污点规则相同</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 添加容忍之前的pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev -o wide</span></span><br><span class="line">NAME             READY   STATUS    RESTARTS   AGE   IP       NODE     NOMINATED </span><br><span class="line">pod<span class="literal">-toleration</span>   <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">3</span>s    &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           </span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加容忍之后的pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev -o wide</span></span><br><span class="line">NAME             READY   STATUS    RESTARTS   AGE   IP            NODE    NOMINATED</span><br><span class="line">pod<span class="literal">-toleration</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">3</span>s    <span class="number">10.244</span>.<span class="number">1.62</span>   node1   &lt;none&gt;        </span><br></pre></td></tr></table></figure>

<p>下面看一下容忍的详细配置:</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl explain pod.spec.tolerations</span></span><br><span class="line">......</span><br><span class="line">FIELDS:</span><br><span class="line">   key       <span class="comment"># 对应着要容忍的污点的键，空意味着匹配所有的键</span></span><br><span class="line">   value     <span class="comment"># 对应着要容忍的污点的值</span></span><br><span class="line">   operator  <span class="comment"># key-value的运算符，支持Equal和Exists（默认）</span></span><br><span class="line">   effect    <span class="comment"># 对应污点的effect，空意味着匹配所有影响</span></span><br><span class="line">   tolerationSeconds   <span class="comment"># 容忍时间, 当effect为NoExecute时生效，表示pod在Node上的停留时间</span></span><br></pre></td></tr></table></figure>

<h1 id="第六章-Pod控制器详解"><a href="#第六章-Pod控制器详解" class="headerlink" title="第六章 Pod控制器详解"></a>第六章 Pod控制器详解</h1><p>本章节主要介绍各种Pod控制器的详细使用。</p>
<h2 id="Pod控制器介绍"><a href="#Pod控制器介绍" class="headerlink" title="Pod控制器介绍"></a>Pod控制器介绍</h2><p>Pod是kubernetes的最小管理单元，在kubernetes中，按照pod的创建方式可以将其分为两类：</p>
<ul>
<li><p>自主式pod：kubernetes直接创建出来的Pod，这种pod删除后就没有了，也不会重建</p>
</li>
<li><p>控制器创建的pod：kubernetes通过控制器创建的pod，这种pod删除了之后还会自动重建</p>
</li>
</ul>
<blockquote>
<p><strong><code>什么是Pod控制器</code></strong></p>
<p>Pod控制器是管理pod的中间层，使用Pod控制器之后，只需要告诉Pod控制器，想要多少个什么样的Pod就可以了，它会创建出满足条件的Pod并确保每一个Pod资源处于用户期望的目标状态。如果Pod资源在运行中出现故障，它会基于指定策略重新编排Pod。</p>
</blockquote>
<p>在kubernetes中，有很多类型的pod控制器，每种都有自己的适合的场景，常见的有下面这些：</p>
<ul>
<li><p>ReplicationController：比较原始的pod控制器，已经被废弃，由ReplicaSet替代</p>
</li>
<li><p>ReplicaSet：保证副本数量一直维持在期望值，并支持pod数量扩缩容，镜像版本升级</p>
</li>
<li><p>Deployment：通过控制ReplicaSet来控制Pod，并支持滚动升级、回退版本</p>
</li>
<li><p>Horizontal Pod Autoscaler：可以根据集群负载自动水平调整Pod的数量，实现削峰填谷</p>
</li>
<li><p>DaemonSet：在集群中的指定Node上运行且仅运行一个副本，一般用于守护进程类的任务</p>
</li>
<li><p>Job：它创建出来的pod只要完成任务就立即退出，不需要重启或重建，用于执行一次性任务</p>
</li>
<li><p>Cronjob：它创建的Pod负责周期性任务控制，不需要持续后台运行</p>
</li>
<li><p>StatefulSet：管理有状态应用</p>
</li>
</ul>
<h2 id="ReplicaSet-RS"><a href="#ReplicaSet-RS" class="headerlink" title="ReplicaSet(RS)"></a>ReplicaSet(RS)</h2><p>ReplicaSet的主要作用是<strong>保证一定数量的pod正常运行</strong>，它会持续监听这些Pod的运行状态，一旦Pod发生故障，就会重启或重建。同时它还支持对pod数量的扩缩容和镜像版本的升降级。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200612005334159.png"></p>
<p>ReplicaSet的资源清单文件：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span> <span class="comment"># 版本号</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicaSet</span> <span class="comment"># 类型       </span></span><br><span class="line"><span class="attr">metadata:</span> <span class="comment"># 元数据</span></span><br><span class="line">  <span class="attr">name:</span> <span class="comment"># rs名称 </span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="comment"># 所属命名空间 </span></span><br><span class="line">  <span class="attr">labels:</span> <span class="comment">#标签</span></span><br><span class="line">    <span class="attr">controller:</span> <span class="string">rs</span></span><br><span class="line"><span class="attr">spec:</span> <span class="comment"># 详情描述</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span> <span class="comment"># 副本数量</span></span><br><span class="line">  <span class="attr">selector:</span> <span class="comment"># 选择器，通过它指定该控制器管理哪些pod</span></span><br><span class="line">    <span class="attr">matchLabels:</span>      <span class="comment"># Labels匹配规则</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">matchExpressions:</span> <span class="comment"># Expressions匹配规则</span></span><br><span class="line">      <span class="bullet">-</span> &#123;<span class="attr">key:</span> <span class="string">app</span>, <span class="attr">operator:</span> <span class="string">In</span>, <span class="attr">values:</span> [<span class="string">nginx-pod</span>]&#125;</span><br><span class="line">  <span class="attr">template:</span> <span class="comment"># 模板，当副本数量不足时，会根据下面的模板创建pod副本</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p>在这里面，需要新了解的配置项就是<code>spec</code>下面几个选项：</p>
<ul>
<li><p>replicas：指定副本数量，其实就是当前rs创建出来的pod的数量，默认为1</p>
</li>
<li><p>selector：选择器，它的作用是建立pod控制器和pod之间的关联关系，采用的Label Selector机制在pod模板上定义label，在控制器上定义选择器，就可以表明当前控制器能管理哪些pod了</p>
</li>
<li><p>template：模板，就是当前控制器创建pod所使用的模板板，里面其实就是前一章学过的pod的定义</p>
</li>
</ul>
<p><strong>创建ReplicaSet</strong></p>
<p>创建pc-replicaset.yaml文件，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicaSet</span>   </span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pc-replicaset</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span> </span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建rs</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pc-replicaset.yaml</span></span><br><span class="line">replicaset.apps/pc<span class="literal">-replicaset</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看rs</span></span><br><span class="line"><span class="comment"># DESIRED:期望副本数量  </span></span><br><span class="line"><span class="comment"># CURRENT:当前副本数量  </span></span><br><span class="line"><span class="comment"># READY:已经准备好提供服务的副本数量</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get rs pc-replicaset -n dev -o wide</span></span><br><span class="line">NAME          DESIRED   CURRENT READY AGE   CONTAINERS   IMAGES             SELECTOR</span><br><span class="line">pc<span class="literal">-replicaset</span> <span class="number">3</span>         <span class="number">3</span>       <span class="number">3</span>     <span class="number">22</span>s   nginx        nginx:<span class="number">1.17</span>.<span class="number">1</span>       app=nginx<span class="literal">-pod</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看当前控制器创建出来的pod</span></span><br><span class="line"><span class="comment"># 这里发现控制器创建出来的pod的名称是在控制器名称后面拼接了-xxxxx随机码</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pod -n dev</span></span><br><span class="line">NAME                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc<span class="literal">-replicaset-6vmvt</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">54</span>s</span><br><span class="line">pc<span class="literal">-replicaset-fmb8f</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">54</span>s</span><br><span class="line">pc<span class="literal">-replicaset-snrk2</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">54</span>s</span><br></pre></td></tr></table></figure>

<p><strong>扩缩容</strong></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 编辑rs的副本数量，修改spec:replicas: 6即可</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl edit rs pc-replicaset -n dev</span></span><br><span class="line">replicaset.apps/pc<span class="literal">-replicaset</span> edited</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev</span></span><br><span class="line">NAME                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc<span class="literal">-replicaset-6vmvt</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">114</span>m</span><br><span class="line">pc<span class="literal">-replicaset-cftnp</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">10</span>s</span><br><span class="line">pc<span class="literal">-replicaset-fjlm6</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">10</span>s</span><br><span class="line">pc<span class="literal">-replicaset-fmb8f</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">114</span>m</span><br><span class="line">pc<span class="literal">-replicaset-s2whj</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">10</span>s</span><br><span class="line">pc<span class="literal">-replicaset-snrk2</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">114</span>m</span><br><span class="line"></span><br><span class="line"><span class="comment"># 当然也可以直接使用命令实现</span></span><br><span class="line"><span class="comment"># 使用scale命令实现扩缩容， 后面--replicas=n直接指定目标数量即可</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl scale rs pc-replicaset --replicas=2 -n dev</span></span><br><span class="line">replicaset.apps/pc<span class="literal">-replicaset</span> scaled</span><br><span class="line"></span><br><span class="line"><span class="comment"># 命令运行完毕，立即查看，发现已经有4个开始准备退出了</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev</span></span><br><span class="line">NAME                       READY   STATUS        RESTARTS   AGE</span><br><span class="line">pc<span class="literal">-replicaset-6vmvt</span>   <span class="number">0</span>/<span class="number">1</span>     Terminating   <span class="number">0</span>          <span class="number">118</span>m</span><br><span class="line">pc<span class="literal">-replicaset-cftnp</span>   <span class="number">0</span>/<span class="number">1</span>     Terminating   <span class="number">0</span>          <span class="number">4</span>m17s</span><br><span class="line">pc<span class="literal">-replicaset-fjlm6</span>   <span class="number">0</span>/<span class="number">1</span>     Terminating   <span class="number">0</span>          <span class="number">4</span>m17s</span><br><span class="line">pc<span class="literal">-replicaset-fmb8f</span>   <span class="number">1</span>/<span class="number">1</span>     Running       <span class="number">0</span>          <span class="number">118</span>m</span><br><span class="line">pc<span class="literal">-replicaset-s2whj</span>   <span class="number">0</span>/<span class="number">1</span>     Terminating   <span class="number">0</span>          <span class="number">4</span>m17s</span><br><span class="line">pc<span class="literal">-replicaset-snrk2</span>   <span class="number">1</span>/<span class="number">1</span>     Running       <span class="number">0</span>          <span class="number">118</span>m</span><br><span class="line"></span><br><span class="line"><span class="comment">#稍等片刻，就只剩下2个了</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev</span></span><br><span class="line">NAME                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc<span class="literal">-replicaset-fmb8f</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">119</span>m</span><br><span class="line">pc<span class="literal">-replicaset-snrk2</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">119</span>m</span><br></pre></td></tr></table></figure>

<p><strong>镜像升级</strong></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 编辑rs的容器镜像 - image: nginx:1.17.2</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl edit rs pc-replicaset -n dev</span></span><br><span class="line">replicaset.apps/pc<span class="literal">-replicaset</span> edited</span><br><span class="line"></span><br><span class="line"><span class="comment"># 再次查看，发现镜像版本已经变更了</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get rs -n dev -o wide</span></span><br><span class="line">NAME                DESIRED  CURRENT   READY   AGE    CONTAINERS   IMAGES        ...</span><br><span class="line">pc<span class="literal">-replicaset</span>       <span class="number">2</span>        <span class="number">2</span>         <span class="number">2</span>       <span class="number">140</span>m   nginx         nginx:<span class="number">1.17</span>.<span class="number">2</span>  ...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 同样的道理，也可以使用命令完成这个工作</span></span><br><span class="line"><span class="comment"># kubectl set image rs rs名称 容器=镜像版本 -n namespace</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl set image rs pc-replicaset nginx=nginx:1.17.1  -n dev</span></span><br><span class="line">replicaset.apps/pc<span class="literal">-replicaset</span> image updated</span><br><span class="line"></span><br><span class="line"><span class="comment"># 再次查看，发现镜像版本已经变更了</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get rs -n dev -o wide</span></span><br><span class="line">NAME                 DESIRED  CURRENT   READY   AGE    CONTAINERS   IMAGES            ...</span><br><span class="line">pc<span class="literal">-replicaset</span>        <span class="number">2</span>        <span class="number">2</span>         <span class="number">2</span>       <span class="number">145</span>m   nginx        nginx:<span class="number">1.17</span>.<span class="number">1</span> ... </span><br></pre></td></tr></table></figure>

<p><strong>删除ReplicaSet</strong></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用kubectl delete命令会删除此RS以及它管理的Pod</span></span><br><span class="line"><span class="comment"># 在kubernetes删除RS前，会将RS的replicasclear调整为0，等待所有的Pod被删除后，在执行RS对象的删除</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete rs pc-replicaset -n dev</span></span><br><span class="line">replicaset.apps <span class="string">&quot;pc-replicaset&quot;</span> deleted</span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pod -n dev -o wide</span></span><br><span class="line">No resources found <span class="keyword">in</span> dev namespace.</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果希望仅仅删除RS对象（保留Pod），可以使用kubectl delete命令时添加--cascade=false选项（不推荐）。</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete rs pc-replicaset -n dev --cascade=false</span></span><br><span class="line">replicaset.apps <span class="string">&quot;pc-replicaset&quot;</span> deleted</span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev</span></span><br><span class="line">NAME                  READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc<span class="literal">-replicaset-cl82j</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">75</span>s</span><br><span class="line">pc<span class="literal">-replicaset-dslhb</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">75</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以使用yaml直接删除(推荐)</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete -f pc-replicaset.yaml</span></span><br><span class="line">replicaset.apps <span class="string">&quot;pc-replicaset&quot;</span> deleted</span><br></pre></td></tr></table></figure>

<h2 id="Deployment-Deploy"><a href="#Deployment-Deploy" class="headerlink" title="Deployment(Deploy)"></a>Deployment(Deploy)</h2><p>为了更好的解决服务编排的问题，kubernetes在V1.2版本开始，引入了Deployment控制器。值得一提的是，这种控制器并不直接管理pod，而是通过管理ReplicaSet来简介管理Pod，即：Deployment管理ReplicaSet，ReplicaSet管理Pod。所以Deployment比ReplicaSet功能更加强大。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200612005524778.png"></p>
<p>Deployment主要功能有下面几个：</p>
<ul>
<li>支持ReplicaSet的所有功能</li>
<li>支持发布的停止、继续</li>
<li>支持滚动升级和回滚版本</li>
</ul>
<p>Deployment的资源清单文件：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span> <span class="comment"># 版本号</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span> <span class="comment"># 类型       </span></span><br><span class="line"><span class="attr">metadata:</span> <span class="comment"># 元数据</span></span><br><span class="line">  <span class="attr">name:</span> <span class="comment"># rs名称 </span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="comment"># 所属命名空间 </span></span><br><span class="line">  <span class="attr">labels:</span> <span class="comment">#标签</span></span><br><span class="line">    <span class="attr">controller:</span> <span class="string">deploy</span></span><br><span class="line"><span class="attr">spec:</span> <span class="comment"># 详情描述</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span> <span class="comment"># 副本数量</span></span><br><span class="line">  <span class="attr">revisionHistoryLimit:</span> <span class="number">3</span> <span class="comment"># 保留历史版本</span></span><br><span class="line">  <span class="attr">paused:</span> <span class="literal">false</span> <span class="comment"># 暂停部署，默认是false</span></span><br><span class="line">  <span class="attr">progressDeadlineSeconds:</span> <span class="number">600</span> <span class="comment"># 部署超时时间（s），默认是600</span></span><br><span class="line">  <span class="attr">strategy:</span> <span class="comment"># 策略</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span> <span class="comment"># 滚动更新策略</span></span><br><span class="line">    <span class="attr">rollingUpdate:</span> <span class="comment"># 滚动更新</span></span><br><span class="line">      <span class="attr">maxSurge:</span> <span class="number">30</span><span class="string">%</span> <span class="comment"># 最大额外可以存在的副本数，可以为百分比，也可以为整数</span></span><br><span class="line">      <span class="attr">maxUnavailable:</span> <span class="number">30</span><span class="string">%</span> <span class="comment"># 最大不可用状态的 Pod 的最大值，可以为百分比，也可以为整数</span></span><br><span class="line">  <span class="attr">selector:</span> <span class="comment"># 选择器，通过它指定该控制器管理哪些pod</span></span><br><span class="line">    <span class="attr">matchLabels:</span>      <span class="comment"># Labels匹配规则</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">matchExpressions:</span> <span class="comment"># Expressions匹配规则</span></span><br><span class="line">      <span class="bullet">-</span> &#123;<span class="attr">key:</span> <span class="string">app</span>, <span class="attr">operator:</span> <span class="string">In</span>, <span class="attr">values:</span> [<span class="string">nginx-pod</span>]&#125;</span><br><span class="line">  <span class="attr">template:</span> <span class="comment"># 模板，当副本数量不足时，会根据下面的模板创建pod副本</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p><strong>创建deployment</strong></p>
<p>创建pc-deployment.yaml，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span>      </span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pc-deployment</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span> </span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建deployment</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pc-deployment.yaml --record=true</span></span><br><span class="line">deployment.apps/pc<span class="literal">-deployment</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看deployment</span></span><br><span class="line"><span class="comment"># UP-TO-DATE 最新版本的pod的数量</span></span><br><span class="line"><span class="comment"># AVAILABLE  当前可用的pod的数量</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get deploy pc-deployment -n dev</span></span><br><span class="line">NAME            READY   UP<span class="literal">-TO-DATE</span>   AVAILABLE   AGE</span><br><span class="line">pc<span class="literal">-deployment</span>   <span class="number">3</span>/<span class="number">3</span>     <span class="number">3</span>            <span class="number">3</span>           <span class="number">15</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看rs</span></span><br><span class="line"><span class="comment"># 发现rs的名称是在原来deployment的名字后面添加了一个10位数的随机串</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get rs -n dev</span></span><br><span class="line">NAME                       DESIRED   CURRENT   READY   AGE</span><br><span class="line">pc<span class="literal">-deployment-6696798b78</span>   <span class="number">3</span>         <span class="number">3</span>         <span class="number">3</span>       <span class="number">23</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev</span></span><br><span class="line">NAME                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc<span class="literal">-deployment-6696798b78-d2c8n</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">107</span>s</span><br><span class="line">pc<span class="literal">-deployment-6696798b78-smpvp</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">107</span>s</span><br><span class="line">pc<span class="literal">-deployment-6696798b78-wvjd8</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">107</span>s</span><br></pre></td></tr></table></figure>

<p><strong>扩缩容</strong></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 变更副本数量为5个</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl scale deploy pc-deployment --replicas=5  -n dev</span></span><br><span class="line">deployment.apps/pc<span class="literal">-deployment</span> scaled</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看deployment</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get deploy pc-deployment -n dev</span></span><br><span class="line">NAME            READY   UP<span class="literal">-TO-DATE</span>   AVAILABLE   AGE</span><br><span class="line">pc<span class="literal">-deployment</span>   <span class="number">5</span>/<span class="number">5</span>     <span class="number">5</span>            <span class="number">5</span>           <span class="number">2</span>m</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment">#  kubectl get pods -n dev</span></span><br><span class="line">NAME                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc<span class="literal">-deployment-6696798b78-d2c8n</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">4</span>m19s</span><br><span class="line">pc<span class="literal">-deployment-6696798b78-jxmdq</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">94</span>s</span><br><span class="line">pc<span class="literal">-deployment-6696798b78-mktqv</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">93</span>s</span><br><span class="line">pc<span class="literal">-deployment-6696798b78-smpvp</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">4</span>m19s</span><br><span class="line">pc<span class="literal">-deployment-6696798b78-wvjd8</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">4</span>m19s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑deployment的副本数量，修改spec:replicas: 4即可</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl edit deploy pc-deployment -n dev</span></span><br><span class="line">deployment.apps/pc<span class="literal">-deployment</span> edited</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev</span></span><br><span class="line">NAME                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc<span class="literal">-deployment-6696798b78-d2c8n</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">5</span>m23s</span><br><span class="line">pc<span class="literal">-deployment-6696798b78-jxmdq</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>m38s</span><br><span class="line">pc<span class="literal">-deployment-6696798b78-smpvp</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">5</span>m23s</span><br><span class="line">pc<span class="literal">-deployment-6696798b78-wvjd8</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">5</span>m23s</span><br></pre></td></tr></table></figure>

<p><strong>镜像更新</strong></p>
<p>deployment支持两种更新策略:<code>重建更新</code>和<code>滚动更新</code>,可以通过<code>strategy</code>指定策略类型,支持两个属性:</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">strategy：指定新的Pod替换旧的Pod的策略， 支持两个属性：</span><br><span class="line">  type：指定策略类型，支持两种策略</span><br><span class="line"><span class="code">    Recreate：在创建出新的Pod之前会先杀掉所有已存在的Pod</span></span><br><span class="line"><span class="code">    RollingUpdate：滚动更新，就是杀死一部分，就启动一部分，在更新过程中，存在两个版本Pod</span></span><br><span class="line"><span class="code">  rollingUpdate：当type为RollingUpdate时生效，用于为RollingUpdate设置参数，支持两个属性：</span></span><br><span class="line"><span class="code">    maxUnavailable：用来指定在升级过程中不可用Pod的最大数量，默认为25%。</span></span><br><span class="line"><span class="code">    maxSurge： 用来指定在升级过程中可以超过期望的Pod的最大数量，默认为25%。</span></span><br></pre></td></tr></table></figure>

<p>重建更新</p>
<ol>
<li>编辑pc-deployment.yaml,在spec节点下添加更新策略</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">strategy:</span> <span class="comment"># 策略</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">Recreate</span> <span class="comment"># 重建更新</span></span><br></pre></td></tr></table></figure>

<ol>
<li>创建deploy进行验证</li>
</ol>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 变更镜像</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl set image deployment pc-deployment nginx=nginx:1.17.2 -n dev</span></span><br><span class="line">deployment.apps/pc<span class="literal">-deployment</span> image updated</span><br><span class="line"></span><br><span class="line"><span class="comment"># 观察升级过程</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment">#  kubectl get pods -n dev -w</span></span><br><span class="line">NAME                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc<span class="literal">-deployment-5d89bdfbf9-65qcw</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">31</span>s</span><br><span class="line">pc<span class="literal">-deployment-5d89bdfbf9-w5nzv</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">31</span>s</span><br><span class="line">pc<span class="literal">-deployment-5d89bdfbf9-xpt7w</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">31</span>s</span><br><span class="line"></span><br><span class="line">pc<span class="literal">-deployment-5d89bdfbf9-xpt7w</span>   <span class="number">1</span>/<span class="number">1</span>     Terminating   <span class="number">0</span>          <span class="number">41</span>s</span><br><span class="line">pc<span class="literal">-deployment-5d89bdfbf9-65qcw</span>   <span class="number">1</span>/<span class="number">1</span>     Terminating   <span class="number">0</span>          <span class="number">41</span>s</span><br><span class="line">pc<span class="literal">-deployment-5d89bdfbf9-w5nzv</span>   <span class="number">1</span>/<span class="number">1</span>     Terminating   <span class="number">0</span>          <span class="number">41</span>s</span><br><span class="line"></span><br><span class="line">pc<span class="literal">-deployment-675d469f8b-grn8z</span>   <span class="number">0</span>/<span class="number">1</span>     Pending       <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">pc<span class="literal">-deployment-675d469f8b-hbl4v</span>   <span class="number">0</span>/<span class="number">1</span>     Pending       <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">pc<span class="literal">-deployment-675d469f8b-67nz2</span>   <span class="number">0</span>/<span class="number">1</span>     Pending       <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line"></span><br><span class="line">pc<span class="literal">-deployment-675d469f8b-grn8z</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">pc<span class="literal">-deployment-675d469f8b-hbl4v</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">pc<span class="literal">-deployment-675d469f8b-67nz2</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line"></span><br><span class="line">pc<span class="literal">-deployment-675d469f8b-grn8z</span>   <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">1</span>s</span><br><span class="line">pc<span class="literal">-deployment-675d469f8b-67nz2</span>   <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">1</span>s</span><br><span class="line">pc<span class="literal">-deployment-675d469f8b-hbl4v</span>   <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">2</span>s</span><br></pre></td></tr></table></figure>

<p>滚动更新</p>
<ol>
<li>编辑pc-deployment.yaml,在spec节点下添加更新策略</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">strategy:</span> <span class="comment"># 策略</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span> <span class="comment"># 滚动更新策略</span></span><br><span class="line">    <span class="attr">rollingUpdate:</span></span><br><span class="line">      <span class="attr">maxSurge:</span> <span class="number">25</span><span class="string">%</span> </span><br><span class="line">      <span class="attr">maxUnavailable:</span> <span class="number">25</span><span class="string">%</span></span><br></pre></td></tr></table></figure>

<ol>
<li>创建deploy进行验证</li>
</ol>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 变更镜像</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl set image deployment pc-deployment nginx=nginx:1.17.3 -n dev</span></span><br><span class="line">deployment.apps/pc<span class="literal">-deployment</span> image updated</span><br><span class="line"></span><br><span class="line"><span class="comment"># 观察升级过程</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev -w</span></span><br><span class="line">NAME                           READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc<span class="literal">-deployment-c848d767-8rbzt</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">31</span>m</span><br><span class="line">pc<span class="literal">-deployment-c848d767-h4p68</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">31</span>m</span><br><span class="line">pc<span class="literal">-deployment-c848d767-hlmz4</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">31</span>m</span><br><span class="line">pc<span class="literal">-deployment-c848d767-rrqcn</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">31</span>m</span><br><span class="line"></span><br><span class="line">pc<span class="literal">-deployment-966bf7f44-226rx</span>   <span class="number">0</span>/<span class="number">1</span>     Pending             <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">pc<span class="literal">-deployment-966bf7f44-226rx</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">pc<span class="literal">-deployment-966bf7f44-226rx</span>   <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">1</span>s</span><br><span class="line">pc<span class="literal">-deployment-c848d767-h4p68</span>    <span class="number">0</span>/<span class="number">1</span>     Terminating         <span class="number">0</span>          <span class="number">34</span>m</span><br><span class="line"></span><br><span class="line">pc<span class="literal">-deployment-966bf7f44-cnd44</span>   <span class="number">0</span>/<span class="number">1</span>     Pending             <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">pc<span class="literal">-deployment-966bf7f44-cnd44</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">pc<span class="literal">-deployment-966bf7f44-cnd44</span>   <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">2</span>s</span><br><span class="line">pc<span class="literal">-deployment-c848d767-hlmz4</span>    <span class="number">0</span>/<span class="number">1</span>     Terminating         <span class="number">0</span>          <span class="number">34</span>m</span><br><span class="line"></span><br><span class="line">pc<span class="literal">-deployment-966bf7f44-px48p</span>   <span class="number">0</span>/<span class="number">1</span>     Pending             <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">pc<span class="literal">-deployment-966bf7f44-px48p</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">pc<span class="literal">-deployment-966bf7f44-px48p</span>   <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">pc<span class="literal">-deployment-c848d767-8rbzt</span>    <span class="number">0</span>/<span class="number">1</span>     Terminating         <span class="number">0</span>          <span class="number">34</span>m</span><br><span class="line"></span><br><span class="line">pc<span class="literal">-deployment-966bf7f44-dkmqp</span>   <span class="number">0</span>/<span class="number">1</span>     Pending             <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">pc<span class="literal">-deployment-966bf7f44-dkmqp</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">pc<span class="literal">-deployment-966bf7f44-dkmqp</span>   <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">2</span>s</span><br><span class="line">pc<span class="literal">-deployment-c848d767-rrqcn</span>    <span class="number">0</span>/<span class="number">1</span>     Terminating         <span class="number">0</span>          <span class="number">34</span>m</span><br><span class="line"></span><br><span class="line"><span class="comment"># 至此，新版本的pod创建完毕，就版本的pod销毁完毕</span></span><br><span class="line"><span class="comment"># 中间过程是滚动进行的，也就是边销毁边创建</span></span><br></pre></td></tr></table></figure>

<p>滚动更新的过程：</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200416140251491.png" style="border:1px solid;" />

<p>镜像更新中rs的变化:</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看rs,发现原来的rs的依旧存在，只是pod数量变为了0，而后又新产生了一个rs，pod数量为4</span></span><br><span class="line"><span class="comment"># 其实这就是deployment能够进行版本回退的奥妙所在，后面会详细解释</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get rs -n dev</span></span><br><span class="line">NAME                       DESIRED   CURRENT   READY   AGE</span><br><span class="line">pc<span class="literal">-deployment-6696798b78</span>   <span class="number">0</span>         <span class="number">0</span>         <span class="number">0</span>       <span class="number">7</span>m37s</span><br><span class="line">pc<span class="literal">-deployment-6696798b11</span>   <span class="number">0</span>         <span class="number">0</span>         <span class="number">0</span>       <span class="number">5</span>m37s</span><br><span class="line">pc<span class="literal">-deployment-c848d76789</span>   <span class="number">4</span>         <span class="number">4</span>         <span class="number">4</span>       <span class="number">72</span>s</span><br></pre></td></tr></table></figure>

<p><strong>版本回退</strong></p>
<p>deployment支持版本升级过程中的暂停、继续功能以及版本回退等诸多功能，下面具体来看.</p>
<p>kubectl rollout： 版本升级相关功能，支持下面的选项：</p>
<ul>
<li><p>status       显示当前升级状态</p>
</li>
<li><p>history     显示 升级历史记录</p>
</li>
<li><p>pause       暂停版本升级过程</p>
</li>
<li><p>resume    继续已经暂停的版本升级过程</p>
</li>
<li><p>restart      重启版本升级过程</p>
</li>
<li><p>undo        回滚到上一级版本（可以使用–to-revision回滚到指定版本）</p>
</li>
</ul>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看当前升级版本的状态</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl rollout status deploy pc-deployment -n dev</span></span><br><span class="line">deployment <span class="string">&quot;pc-deployment&quot;</span> successfully rolled out</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看升级历史记录</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl rollout history deploy pc-deployment -n dev</span></span><br><span class="line">deployment.apps/pc<span class="literal">-deployment</span></span><br><span class="line">REVISION  CHANGE<span class="literal">-CAUSE</span></span><br><span class="line"><span class="number">1</span>         kubectl create <span class="literal">--filename</span>=pc<span class="literal">-deployment</span>.yaml <span class="literal">--record</span>=true</span><br><span class="line"><span class="number">2</span>         kubectl create <span class="literal">--filename</span>=pc<span class="literal">-deployment</span>.yaml <span class="literal">--record</span>=true</span><br><span class="line"><span class="number">3</span>         kubectl create <span class="literal">--filename</span>=pc<span class="literal">-deployment</span>.yaml <span class="literal">--record</span>=true</span><br><span class="line"><span class="comment"># 可以发现有三次版本记录，说明完成过两次升级</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 版本回滚</span></span><br><span class="line"><span class="comment"># 这里直接使用--to-revision=1回滚到了1版本， 如果省略这个选项，就是回退到上个版本，就是2版本</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl rollout undo deployment pc-deployment --to-revision=1 -n dev</span></span><br><span class="line">deployment.apps/pc<span class="literal">-deployment</span> rolled back</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看发现，通过nginx镜像版本可以发现到了第一版</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get deploy -n dev -o wide</span></span><br><span class="line">NAME            READY   UP<span class="literal">-TO-DATE</span>   AVAILABLE   AGE   CONTAINERS   IMAGES         </span><br><span class="line">pc<span class="literal">-deployment</span>   <span class="number">4</span>/<span class="number">4</span>     <span class="number">4</span>            <span class="number">4</span>           <span class="number">74</span>m   nginx        nginx:<span class="number">1.17</span>.<span class="number">1</span>   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看rs，发现第一个rs中有4个pod运行，后面两个版本的rs中pod为运行</span></span><br><span class="line"><span class="comment"># 其实deployment之所以可是实现版本的回滚，就是通过记录下历史rs来实现的，</span></span><br><span class="line"><span class="comment"># 一旦想回滚到哪个版本，只需要将当前版本pod数量降为0，然后将回滚版本的pod提升为目标数量就可以了</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get rs -n dev</span></span><br><span class="line">NAME                       DESIRED   CURRENT   READY   AGE</span><br><span class="line">pc<span class="literal">-deployment-6696798b78</span>   <span class="number">4</span>         <span class="number">4</span>         <span class="number">4</span>       <span class="number">78</span>m</span><br><span class="line">pc<span class="literal">-deployment-966bf7f44</span>    <span class="number">0</span>         <span class="number">0</span>         <span class="number">0</span>       <span class="number">37</span>m</span><br><span class="line">pc<span class="literal">-deployment-c848d767</span>     <span class="number">0</span>         <span class="number">0</span>         <span class="number">0</span>       <span class="number">71</span>m</span><br></pre></td></tr></table></figure>

<p><strong>金丝雀发布</strong></p>
<p>Deployment控制器支持控制更新过程中的控制，如“暂停(pause)”或“继续(resume)”更新操作。</p>
<p>比如有一批新的Pod资源创建完成后立即暂停更新过程，此时，仅存在一部分新版本的应用，主体部分还是旧的版本。然后，再筛选一小部分的用户请求路由到新版本的Pod应用，继续观察能否稳定地按期望的方式运行。确定没问题之后再继续完成余下的Pod资源滚动更新，否则立即回滚更新操作。这就是所谓的金丝雀发布。</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 更新deployment的版本，并配置暂停deployment</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment">#  kubectl set image deploy pc-deployment nginx=nginx:1.17.4 -n dev &amp;&amp; kubectl rollout pause deployment pc-deployment  -n dev</span></span><br><span class="line">deployment.apps/pc<span class="literal">-deployment</span> image updated</span><br><span class="line">deployment.apps/pc<span class="literal">-deployment</span> paused</span><br><span class="line"></span><br><span class="line"><span class="comment">#观察更新状态</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl rollout status deploy pc-deployment -n dev　</span></span><br><span class="line">Waiting <span class="keyword">for</span> deployment <span class="string">&quot;pc-deployment&quot;</span> rollout to finish: <span class="number">2</span> out of <span class="number">4</span> new replicas have been updated...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 监控更新的过程，可以看到已经新增了一个资源，但是并未按照预期的状态去删除一个旧的资源，就是因为使用了pause暂停命令</span></span><br><span class="line"></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get rs -n dev -o wide</span></span><br><span class="line">NAME                       DESIRED   CURRENT   READY   AGE     CONTAINERS   IMAGES         </span><br><span class="line">pc<span class="literal">-deployment-5d89bdfbf9</span>   <span class="number">3</span>         <span class="number">3</span>         <span class="number">3</span>       <span class="number">19</span>m     nginx        nginx:<span class="number">1.17</span>.<span class="number">1</span>   </span><br><span class="line">pc<span class="literal">-deployment-675d469f8b</span>   <span class="number">0</span>         <span class="number">0</span>         <span class="number">0</span>       <span class="number">14</span>m     nginx        nginx:<span class="number">1.17</span>.<span class="number">2</span>   </span><br><span class="line">pc<span class="literal">-deployment-6c9f56fcfb</span>   <span class="number">2</span>         <span class="number">2</span>         <span class="number">2</span>       <span class="number">3</span>m16s   nginx        nginx:<span class="number">1.17</span>.<span class="number">4</span>   </span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev</span></span><br><span class="line">NAME                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc<span class="literal">-deployment-5d89bdfbf9-rj8sq</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">7</span>m33s</span><br><span class="line">pc<span class="literal">-deployment-5d89bdfbf9-ttwgg</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">7</span>m35s</span><br><span class="line">pc<span class="literal">-deployment-5d89bdfbf9-v4wvc</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">7</span>m34s</span><br><span class="line">pc<span class="literal">-deployment-6c9f56fcfb-996rt</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">3</span>m31s</span><br><span class="line">pc<span class="literal">-deployment-6c9f56fcfb-j2gtj</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">3</span>m31s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 确保更新的pod没问题了，继续更新</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl rollout resume deploy pc-deployment -n dev</span></span><br><span class="line">deployment.apps/pc<span class="literal">-deployment</span> resumed</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看最后的更新情况</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get rs -n dev -o wide</span></span><br><span class="line">NAME                       DESIRED   CURRENT   READY   AGE     CONTAINERS   IMAGES         </span><br><span class="line">pc<span class="literal">-deployment-5d89bdfbf9</span>   <span class="number">0</span>         <span class="number">0</span>         <span class="number">0</span>       <span class="number">21</span>m     nginx        nginx:<span class="number">1.17</span>.<span class="number">1</span>   </span><br><span class="line">pc<span class="literal">-deployment-675d469f8b</span>   <span class="number">0</span>         <span class="number">0</span>         <span class="number">0</span>       <span class="number">16</span>m     nginx        nginx:<span class="number">1.17</span>.<span class="number">2</span>   </span><br><span class="line">pc<span class="literal">-deployment-6c9f56fcfb</span>   <span class="number">4</span>         <span class="number">4</span>         <span class="number">4</span>       <span class="number">5</span>m11s   nginx        nginx:<span class="number">1.17</span>.<span class="number">4</span>   </span><br><span class="line"></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev</span></span><br><span class="line">NAME                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc<span class="literal">-deployment-6c9f56fcfb-7bfwh</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">37</span>s</span><br><span class="line">pc<span class="literal">-deployment-6c9f56fcfb-996rt</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">5</span>m27s</span><br><span class="line">pc<span class="literal">-deployment-6c9f56fcfb-j2gtj</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">5</span>m27s</span><br><span class="line">pc<span class="literal">-deployment-6c9f56fcfb-rf84v</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">37</span>s</span><br></pre></td></tr></table></figure>

<p><strong>删除Deployment</strong></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 删除deployment，其下的rs和pod也将被删除</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete -f pc-deployment.yaml</span></span><br><span class="line">deployment.apps <span class="string">&quot;pc-deployment&quot;</span> deleted</span><br></pre></td></tr></table></figure>

<h2 id="Horizontal-Pod-Autoscaler-HPA"><a href="#Horizontal-Pod-Autoscaler-HPA" class="headerlink" title="Horizontal Pod Autoscaler(HPA)"></a>Horizontal Pod Autoscaler(HPA)</h2><p>在前面的课程中，我们已经可以实现通过手工执行<code>kubectl scale</code>命令实现Pod扩容或缩容，但是这显然不符合Kubernetes的定位目标–自动化、智能化。 Kubernetes期望可以实现通过监测Pod的使用情况，实现pod数量的自动调整，于是就产生了Horizontal Pod Autoscaler（HPA）这种控制器。</p>
<p>HPA可以获取每个Pod利用率，然后和HPA中定义的指标进行对比，同时计算出需要伸缩的具体值，最后实现Pod的数量的调整。其实HPA与之前的Deployment一样，也属于一种Kubernetes资源对象，它通过追踪分析RC控制的所有目标Pod的负载变化情况，来确定是否需要针对性地调整目标Pod的副本数，这是HPA的实现原理。</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200608155858271.png" style="border:1px solid;" />

<p>接下来，我们来做一个实验</p>
<p><strong>1 安装metrics-server</strong></p>
<p>metrics-server可以用来收集集群中的资源使用情况</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装git</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># yum install git -y</span></span><br><span class="line"><span class="comment"># 获取metrics-server, 注意使用的版本</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># git clone -b v0.3.6 https://github.com/kubernetes-incubator/metrics-server</span></span><br><span class="line"><span class="comment"># 修改deployment, 注意修改的是镜像和初始化参数</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># cd /root/metrics-server/deploy/1.8+/</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="number">1.8</span>+]<span class="comment"># vim metrics-server-deployment.yaml</span></span><br><span class="line">按图中添加下面选项</span><br><span class="line">hostNetwork: true</span><br><span class="line">image: registry.cn<span class="literal">-hangzhou</span>.aliyuncs.com/google_containers/metrics<span class="literal">-server-amd64</span>:v0.<span class="number">3.6</span></span><br><span class="line">args:</span><br><span class="line">- <span class="literal">--kubelet-insecure-tls</span></span><br><span class="line">- <span class="literal">--kubelet-preferred-address-types</span>=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200608163326496.png" alt="image-20200608163326496"></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装metrics-server</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="number">1.8</span>+]<span class="comment"># kubectl apply -f ./</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod运行情况</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="number">1.8</span>+]<span class="comment"># kubectl get pod -n kube-system</span></span><br><span class="line">metrics<span class="literal">-server-6b976979db-2xwbj</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">90</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用kubectl top node 查看资源使用情况</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="number">1.8</span>+]<span class="comment"># kubectl top node</span></span><br><span class="line">NAME     CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%</span><br><span class="line">master   <span class="number">98</span>m          <span class="number">4</span>%     <span class="number">1067</span><span class="built_in">Mi</span>          <span class="number">62</span>%</span><br><span class="line">node1    <span class="number">27</span>m          <span class="number">1</span>%     <span class="number">727</span><span class="built_in">Mi</span>           <span class="number">42</span>%</span><br><span class="line">node2    <span class="number">34</span>m          <span class="number">1</span>%     <span class="number">800</span><span class="built_in">Mi</span>           <span class="number">46</span>%</span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="number">1.8</span>+]<span class="comment"># kubectl top pod -n kube-system</span></span><br><span class="line">NAME                              CPU(cores)   MEMORY(bytes)</span><br><span class="line">coredns<span class="literal">-6955765f44-7ptsb</span>          <span class="number">3</span>m           <span class="number">9</span><span class="built_in">Mi</span></span><br><span class="line">coredns<span class="literal">-6955765f44-vcwr5</span>          <span class="number">3</span>m           <span class="number">8</span><span class="built_in">Mi</span></span><br><span class="line">etcd<span class="literal">-master</span>                       <span class="number">14</span>m          <span class="number">145</span><span class="built_in">Mi</span></span><br><span class="line">...</span><br><span class="line"><span class="comment"># 至此,metrics-server安装完成</span></span><br></pre></td></tr></table></figure>

<p><strong>2 准备deployment和servie</strong></p>
<p>为了操作简单,直接使用命令</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建deployment </span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="number">1.8</span>+]<span class="comment"># kubectl run nginx --image=nginx:latest --requests=cpu=100m -n dev</span></span><br><span class="line"><span class="comment"># 创建service</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="number">1.8</span>+]<span class="comment"># kubectl expose deployment nginx --type=NodePort --port=80 -n dev</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="number">1.8</span>+]<span class="comment"># kubectl get deployment,pod,svc -n dev</span></span><br><span class="line">NAME                    READY   UP<span class="literal">-TO-DATE</span>   AVAILABLE   AGE</span><br><span class="line">deployment.apps/nginx   <span class="number">1</span>/<span class="number">1</span>     <span class="number">1</span>            <span class="number">1</span>           <span class="number">47</span>s</span><br><span class="line"></span><br><span class="line">NAME                         READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/nginx<span class="literal">-7df9756ccc-bh8dr</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">47</span>s</span><br><span class="line"></span><br><span class="line">NAME            <span class="built_in">TYPE</span>       CLUSTER<span class="literal">-IP</span>      EXTERNAL<span class="literal">-IP</span>   PORT(S)        AGE</span><br><span class="line">service/nginx   NodePort   <span class="number">10.109</span>.<span class="number">57.248</span>   &lt;none&gt;        <span class="number">80</span>:<span class="number">31136</span>/TCP   <span class="number">35</span>s</span><br></pre></td></tr></table></figure>

<p><strong>3 部署HPA</strong></p>
<p>创建pc-hpa.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">autoscaling/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">HorizontalPodAutoscaler</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pc-hpa</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">minReplicas:</span> <span class="number">1</span>  <span class="comment">#最小pod数量</span></span><br><span class="line">  <span class="attr">maxReplicas:</span> <span class="number">10</span> <span class="comment">#最大pod数量</span></span><br><span class="line">  <span class="attr">targetCPUUtilizationPercentage:</span> <span class="number">3</span> <span class="comment"># CPU使用率指标</span></span><br><span class="line">  <span class="attr">scaleTargetRef:</span>   <span class="comment"># 指定要控制的nginx信息</span></span><br><span class="line">    <span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">Deployment</span>  </span><br><span class="line">    <span class="attr">name:</span> <span class="string">nginx</span>  </span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建hpa</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="number">1.8</span>+]<span class="comment"># kubectl create -f pc-hpa.yaml</span></span><br><span class="line">horizontalpodautoscaler.autoscaling/pc<span class="literal">-hpa</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看hpa</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="number">1.8</span>+]<span class="comment"># kubectl get hpa -n dev</span></span><br><span class="line">NAME     REFERENCE          TARGETS   MINPODS   MAXPODS   REPLICAS   AGE</span><br><span class="line">pc<span class="literal">-hpa</span>   Deployment/nginx   <span class="number">0</span>%/<span class="number">3</span>%     <span class="number">1</span>         <span class="number">10</span>        <span class="number">1</span>          <span class="number">62</span>s</span><br></pre></td></tr></table></figure>

<p><strong>4 测试</strong></p>
<p>使用压测工具对service地址<code>192.168.109.100:31136</code>进行压测，然后通过控制台查看hpa和pod的变化</p>
<p><code>hpa变化</code></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get hpa -n dev -w</span></span><br><span class="line">NAME     REFERENCE          TARGETS   MINPODS   MAXPODS   REPLICAS   AGE</span><br><span class="line">pc<span class="literal">-hpa</span>   Deployment/nginx   <span class="number">0</span>%/<span class="number">3</span>%     <span class="number">1</span>         <span class="number">10</span>        <span class="number">1</span>          <span class="number">4</span>m11s</span><br><span class="line">pc<span class="literal">-hpa</span>   Deployment/nginx   <span class="number">0</span>%/<span class="number">3</span>%     <span class="number">1</span>         <span class="number">10</span>        <span class="number">1</span>          <span class="number">5</span>m19s</span><br><span class="line">pc<span class="literal">-hpa</span>   Deployment/nginx   <span class="number">22</span>%/<span class="number">3</span>%    <span class="number">1</span>         <span class="number">10</span>        <span class="number">1</span>          <span class="number">6</span>m50s</span><br><span class="line">pc<span class="literal">-hpa</span>   Deployment/nginx   <span class="number">22</span>%/<span class="number">3</span>%    <span class="number">1</span>         <span class="number">10</span>        <span class="number">4</span>          <span class="number">7</span>m5s</span><br><span class="line">pc<span class="literal">-hpa</span>   Deployment/nginx   <span class="number">22</span>%/<span class="number">3</span>%    <span class="number">1</span>         <span class="number">10</span>        <span class="number">8</span>          <span class="number">7</span>m21s</span><br><span class="line">pc<span class="literal">-hpa</span>   Deployment/nginx   <span class="number">6</span>%/<span class="number">3</span>%     <span class="number">1</span>         <span class="number">10</span>        <span class="number">8</span>          <span class="number">7</span>m51s</span><br><span class="line">pc<span class="literal">-hpa</span>   Deployment/nginx   <span class="number">0</span>%/<span class="number">3</span>%     <span class="number">1</span>         <span class="number">10</span>        <span class="number">8</span>          <span class="number">9</span>m6s</span><br><span class="line">pc<span class="literal">-hpa</span>   Deployment/nginx   <span class="number">0</span>%/<span class="number">3</span>%     <span class="number">1</span>         <span class="number">10</span>        <span class="number">8</span>          <span class="number">13</span>m</span><br><span class="line">pc<span class="literal">-hpa</span>   Deployment/nginx   <span class="number">0</span>%/<span class="number">3</span>%     <span class="number">1</span>         <span class="number">10</span>        <span class="number">1</span>          <span class="number">14</span>m</span><br></pre></td></tr></table></figure>

<p><code>deployment变化</code></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get deployment -n dev -w</span></span><br><span class="line">NAME    READY   UP<span class="literal">-TO-DATE</span>   AVAILABLE   AGE</span><br><span class="line">nginx   <span class="number">1</span>/<span class="number">1</span>     <span class="number">1</span>            <span class="number">1</span>           <span class="number">11</span>m</span><br><span class="line">nginx   <span class="number">1</span>/<span class="number">4</span>     <span class="number">1</span>            <span class="number">1</span>           <span class="number">13</span>m</span><br><span class="line">nginx   <span class="number">1</span>/<span class="number">4</span>     <span class="number">1</span>            <span class="number">1</span>           <span class="number">13</span>m</span><br><span class="line">nginx   <span class="number">1</span>/<span class="number">4</span>     <span class="number">1</span>            <span class="number">1</span>           <span class="number">13</span>m</span><br><span class="line">nginx   <span class="number">1</span>/<span class="number">4</span>     <span class="number">4</span>            <span class="number">1</span>           <span class="number">13</span>m</span><br><span class="line">nginx   <span class="number">1</span>/<span class="number">8</span>     <span class="number">4</span>            <span class="number">1</span>           <span class="number">14</span>m</span><br><span class="line">nginx   <span class="number">1</span>/<span class="number">8</span>     <span class="number">4</span>            <span class="number">1</span>           <span class="number">14</span>m</span><br><span class="line">nginx   <span class="number">1</span>/<span class="number">8</span>     <span class="number">4</span>            <span class="number">1</span>           <span class="number">14</span>m</span><br><span class="line">nginx   <span class="number">1</span>/<span class="number">8</span>     <span class="number">8</span>            <span class="number">1</span>           <span class="number">14</span>m</span><br><span class="line">nginx   <span class="number">2</span>/<span class="number">8</span>     <span class="number">8</span>            <span class="number">2</span>           <span class="number">14</span>m</span><br><span class="line">nginx   <span class="number">3</span>/<span class="number">8</span>     <span class="number">8</span>            <span class="number">3</span>           <span class="number">14</span>m</span><br><span class="line">nginx   <span class="number">4</span>/<span class="number">8</span>     <span class="number">8</span>            <span class="number">4</span>           <span class="number">14</span>m</span><br><span class="line">nginx   <span class="number">5</span>/<span class="number">8</span>     <span class="number">8</span>            <span class="number">5</span>           <span class="number">14</span>m</span><br><span class="line">nginx   <span class="number">6</span>/<span class="number">8</span>     <span class="number">8</span>            <span class="number">6</span>           <span class="number">14</span>m</span><br><span class="line">nginx   <span class="number">7</span>/<span class="number">8</span>     <span class="number">8</span>            <span class="number">7</span>           <span class="number">14</span>m</span><br><span class="line">nginx   <span class="number">8</span>/<span class="number">8</span>     <span class="number">8</span>            <span class="number">8</span>           <span class="number">15</span>m</span><br><span class="line">nginx   <span class="number">8</span>/<span class="number">1</span>     <span class="number">8</span>            <span class="number">8</span>           <span class="number">20</span>m</span><br><span class="line">nginx   <span class="number">8</span>/<span class="number">1</span>     <span class="number">8</span>            <span class="number">8</span>           <span class="number">20</span>m</span><br><span class="line">nginx   <span class="number">1</span>/<span class="number">1</span>     <span class="number">1</span>            <span class="number">1</span>           <span class="number">20</span>m</span><br></pre></td></tr></table></figure>

<p><code>pod变化</code></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev -w</span></span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">nginx<span class="literal">-7df9756ccc-bh8dr</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">11</span>m</span><br><span class="line">nginx<span class="literal">-7df9756ccc-cpgrv</span>   <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-8zhwk</span>   <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-rr9bn</span>   <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-cpgrv</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-8zhwk</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-rr9bn</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-m9gsj</span>   <span class="number">0</span>/<span class="number">1</span>     Pending             <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-g56qb</span>   <span class="number">0</span>/<span class="number">1</span>     Pending             <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-sl9c6</span>   <span class="number">0</span>/<span class="number">1</span>     Pending             <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-fgst7</span>   <span class="number">0</span>/<span class="number">1</span>     Pending             <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-g56qb</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-m9gsj</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-sl9c6</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-fgst7</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-8zhwk</span>   <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">19</span>s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-rr9bn</span>   <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">30</span>s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-m9gsj</span>   <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">21</span>s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-cpgrv</span>   <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">47</span>s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-sl9c6</span>   <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">33</span>s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-g56qb</span>   <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">48</span>s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-fgst7</span>   <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">66</span>s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-fgst7</span>   <span class="number">1</span>/<span class="number">1</span>     Terminating         <span class="number">0</span>          <span class="number">6</span>m50s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-8zhwk</span>   <span class="number">1</span>/<span class="number">1</span>     Terminating         <span class="number">0</span>          <span class="number">7</span>m5s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-cpgrv</span>   <span class="number">1</span>/<span class="number">1</span>     Terminating         <span class="number">0</span>          <span class="number">7</span>m5s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-g56qb</span>   <span class="number">1</span>/<span class="number">1</span>     Terminating         <span class="number">0</span>          <span class="number">6</span>m50s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-rr9bn</span>   <span class="number">1</span>/<span class="number">1</span>     Terminating         <span class="number">0</span>          <span class="number">7</span>m5s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-m9gsj</span>   <span class="number">1</span>/<span class="number">1</span>     Terminating         <span class="number">0</span>          <span class="number">6</span>m50s</span><br><span class="line">nginx<span class="literal">-7df9756ccc-sl9c6</span>   <span class="number">1</span>/<span class="number">1</span>     Terminating         <span class="number">0</span>          <span class="number">6</span>m50s</span><br></pre></td></tr></table></figure>

<h2 id="DaemonSet-DS"><a href="#DaemonSet-DS" class="headerlink" title="DaemonSet(DS)"></a>DaemonSet(DS)</h2><p>DaemonSet类型的控制器可以保证在集群中的每一台（或指定）节点上都运行一个副本。一般适用于日志收集、节点监控等场景。也就是说，如果一个Pod提供的功能是节点级别的（每个节点都需要且只需要一个），那么这类Pod就适合使用DaemonSet类型的控制器创建。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200612010223537.png"></p>
<p>DaemonSet控制器的特点：</p>
<ul>
<li>每当向集群中添加一个节点时，指定的 Pod 副本也将添加到该节点上</li>
<li>当节点从集群中移除时，Pod 也就被垃圾回收了</li>
</ul>
<p>下面先来看下DaemonSet的资源清单文件</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span> <span class="comment"># 版本号</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span> <span class="comment"># 类型       </span></span><br><span class="line"><span class="attr">metadata:</span> <span class="comment"># 元数据</span></span><br><span class="line">  <span class="attr">name:</span> <span class="comment"># rs名称 </span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="comment"># 所属命名空间 </span></span><br><span class="line">  <span class="attr">labels:</span> <span class="comment">#标签</span></span><br><span class="line">    <span class="attr">controller:</span> <span class="string">daemonset</span></span><br><span class="line"><span class="attr">spec:</span> <span class="comment"># 详情描述</span></span><br><span class="line">  <span class="attr">revisionHistoryLimit:</span> <span class="number">3</span> <span class="comment"># 保留历史版本</span></span><br><span class="line">  <span class="attr">updateStrategy:</span> <span class="comment"># 更新策略</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span> <span class="comment"># 滚动更新策略</span></span><br><span class="line">    <span class="attr">rollingUpdate:</span> <span class="comment"># 滚动更新</span></span><br><span class="line">      <span class="attr">maxUnavailable:</span> <span class="number">1</span> <span class="comment"># 最大不可用状态的 Pod 的最大值，可以为百分比，也可以为整数</span></span><br><span class="line">  <span class="attr">selector:</span> <span class="comment"># 选择器，通过它指定该控制器管理哪些pod</span></span><br><span class="line">    <span class="attr">matchLabels:</span>      <span class="comment"># Labels匹配规则</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">matchExpressions:</span> <span class="comment"># Expressions匹配规则</span></span><br><span class="line">      <span class="bullet">-</span> &#123;<span class="attr">key:</span> <span class="string">app</span>, <span class="attr">operator:</span> <span class="string">In</span>, <span class="attr">values:</span> [<span class="string">nginx-pod</span>]&#125;</span><br><span class="line">  <span class="attr">template:</span> <span class="comment"># 模板，当副本数量不足时，会根据下面的模板创建pod副本</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p>创建pc-daemonset.yaml，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span>      </span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pc-daemonset</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span> </span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建daemonset</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f  pc-daemonset.yaml</span></span><br><span class="line">daemonset.apps/pc<span class="literal">-daemonset</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看daemonset</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment">#  kubectl get ds -n dev -o wide</span></span><br><span class="line">NAME        DESIRED  CURRENT  READY  UP<span class="literal">-TO-DATE</span>  AVAILABLE   AGE   CONTAINERS   IMAGES         </span><br><span class="line">pc<span class="literal">-daemonset</span>   <span class="number">2</span>        <span class="number">2</span>        <span class="number">2</span>      <span class="number">2</span>           <span class="number">2</span>        <span class="number">24</span>s   nginx        nginx:<span class="number">1.17</span>.<span class="number">1</span>   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod,发现在每个Node上都运行一个pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment">#  kubectl get pods -n dev -o wide</span></span><br><span class="line">NAME                 READY   STATUS    RESTARTS   AGE   IP            NODE    </span><br><span class="line">pc<span class="literal">-daemonset-9bck8</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">37</span>s   <span class="number">10.244</span>.<span class="number">1.43</span>   node1     </span><br><span class="line">pc<span class="literal">-daemonset-k224w</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">37</span>s   <span class="number">10.244</span>.<span class="number">2.74</span>   node2      </span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除daemonset</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete -f pc-daemonset.yaml</span></span><br><span class="line">daemonset.apps <span class="string">&quot;pc-daemonset&quot;</span> deleted</span><br></pre></td></tr></table></figure>

<h2 id="Job"><a href="#Job" class="headerlink" title="Job"></a>Job</h2><p>Job，主要用于负责**批量处理(一次要处理指定数量任务)<strong>短暂的</strong>一次性(每个任务仅运行一次就结束)**任务。Job特点如下：</p>
<ul>
<li>当Job创建的pod执行成功结束时，Job将记录成功结束的pod数量</li>
<li>当成功结束的pod达到指定的数量时，Job将完成执行</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200618213054113.png" style />

<p>Job的资源清单文件：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span> <span class="comment"># 版本号</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span> <span class="comment"># 类型       </span></span><br><span class="line"><span class="attr">metadata:</span> <span class="comment"># 元数据</span></span><br><span class="line">  <span class="attr">name:</span> <span class="comment"># rs名称 </span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="comment"># 所属命名空间 </span></span><br><span class="line">  <span class="attr">labels:</span> <span class="comment">#标签</span></span><br><span class="line">    <span class="attr">controller:</span> <span class="string">job</span></span><br><span class="line"><span class="attr">spec:</span> <span class="comment"># 详情描述</span></span><br><span class="line">  <span class="attr">completions:</span> <span class="number">1</span> <span class="comment"># 指定job需要成功运行Pods的次数。默认值: 1</span></span><br><span class="line">  <span class="attr">parallelism:</span> <span class="number">1</span> <span class="comment"># 指定job在任一时刻应该并发运行Pods的数量。默认值: 1</span></span><br><span class="line">  <span class="attr">activeDeadlineSeconds:</span> <span class="number">30</span> <span class="comment"># 指定job可运行的时间期限，超过时间还未结束，系统将会尝试进行终止。</span></span><br><span class="line">  <span class="attr">backoffLimit:</span> <span class="number">6</span> <span class="comment"># 指定job失败后进行重试的次数。默认是6</span></span><br><span class="line">  <span class="attr">manualSelector:</span> <span class="literal">true</span> <span class="comment"># 是否可以使用selector选择器选择pod，默认是false</span></span><br><span class="line">  <span class="attr">selector:</span> <span class="comment"># 选择器，通过它指定该控制器管理哪些pod</span></span><br><span class="line">    <span class="attr">matchLabels:</span>      <span class="comment"># Labels匹配规则</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">counter-pod</span></span><br><span class="line">    <span class="attr">matchExpressions:</span> <span class="comment"># Expressions匹配规则</span></span><br><span class="line">      <span class="bullet">-</span> &#123;<span class="attr">key:</span> <span class="string">app</span>, <span class="attr">operator:</span> <span class="string">In</span>, <span class="attr">values:</span> [<span class="string">counter-pod</span>]&#125;</span><br><span class="line">  <span class="attr">template:</span> <span class="comment"># 模板，当副本数量不足时，会根据下面的模板创建pod副本</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">counter-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">Never</span> <span class="comment"># 重启策略只能设置为Never或者OnFailure</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">counter</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 2;done&quot;</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">关于重启策略设置的说明：</span><br><span class="line"><span class="code">    如果指定为OnFailure，则job会在pod出现故障时重启容器，而不是创建pod，failed次数不变</span></span><br><span class="line"><span class="code">    如果指定为Never，则job会在pod出现故障时创建新的pod，并且故障pod不会消失，也不会重启，failed次数加1</span></span><br><span class="line"><span class="code">    如果指定为Always的话，就意味着一直重启，意味着job任务会重复去执行了，当然不对，所以不能设置为Always</span></span><br></pre></td></tr></table></figure>

<p>创建pc-job.yaml，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span>      </span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pc-job</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">manualSelector:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">counter-pod</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">counter-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">counter</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 3;done&quot;</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建job</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pc-job.yaml</span></span><br><span class="line">job.batch/pc<span class="literal">-job</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看job</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get job -n dev -o wide  -w</span></span><br><span class="line">NAME     COMPLETIONS   DURATION   AGE   CONTAINERS   IMAGES         SELECTOR</span><br><span class="line">pc<span class="literal">-job</span>   <span class="number">0</span>/<span class="number">1</span>           <span class="number">21</span>s        <span class="number">21</span>s   counter      busybox:<span class="number">1.30</span>   app=counter<span class="literal">-pod</span></span><br><span class="line">pc<span class="literal">-job</span>   <span class="number">1</span>/<span class="number">1</span>           <span class="number">31</span>s        <span class="number">79</span>s   counter      busybox:<span class="number">1.30</span>   app=counter<span class="literal">-pod</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过观察pod状态可以看到，pod在运行完毕任务后，就会变成Completed状态</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev -w</span></span><br><span class="line">NAME           READY   STATUS     RESTARTS      AGE</span><br><span class="line">pc<span class="literal">-job-rxg96</span>   <span class="number">1</span>/<span class="number">1</span>     Running     <span class="number">0</span>            <span class="number">29</span>s</span><br><span class="line">pc<span class="literal">-job-rxg96</span>   <span class="number">0</span>/<span class="number">1</span>     Completed   <span class="number">0</span>            <span class="number">33</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来，调整下pod运行的总数量和并行数量 即：在spec下设置下面两个选项</span></span><br><span class="line"><span class="comment">#  completions: 6 # 指定job需要成功运行Pods的次数为6</span></span><br><span class="line"><span class="comment">#  parallelism: 3 # 指定job并发运行Pods的数量为3</span></span><br><span class="line"><span class="comment">#  然后重新运行job，观察效果，此时会发现，job会每次运行3个pod，总共执行了6个pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev -w</span></span><br><span class="line">NAME           READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc<span class="literal">-job-684ft</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">5</span>s</span><br><span class="line">pc<span class="literal">-job-jhj49</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">5</span>s</span><br><span class="line">pc<span class="literal">-job-pfcvh</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">5</span>s</span><br><span class="line">pc<span class="literal">-job-684ft</span>   <span class="number">0</span>/<span class="number">1</span>     Completed   <span class="number">0</span>          <span class="number">11</span>s</span><br><span class="line">pc<span class="literal">-job-v7rhr</span>   <span class="number">0</span>/<span class="number">1</span>     Pending     <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">pc<span class="literal">-job-v7rhr</span>   <span class="number">0</span>/<span class="number">1</span>     Pending     <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">pc<span class="literal">-job-v7rhr</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">pc<span class="literal">-job-jhj49</span>   <span class="number">0</span>/<span class="number">1</span>     Completed           <span class="number">0</span>          <span class="number">11</span>s</span><br><span class="line">pc<span class="literal">-job-fhwf7</span>   <span class="number">0</span>/<span class="number">1</span>     Pending             <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">pc<span class="literal">-job-fhwf7</span>   <span class="number">0</span>/<span class="number">1</span>     Pending             <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">pc<span class="literal">-job-pfcvh</span>   <span class="number">0</span>/<span class="number">1</span>     Completed           <span class="number">0</span>          <span class="number">11</span>s</span><br><span class="line">pc<span class="literal">-job-5vg2j</span>   <span class="number">0</span>/<span class="number">1</span>     Pending             <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">pc<span class="literal">-job-fhwf7</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">pc<span class="literal">-job-5vg2j</span>   <span class="number">0</span>/<span class="number">1</span>     Pending             <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">pc<span class="literal">-job-5vg2j</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line">pc<span class="literal">-job-fhwf7</span>   <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">2</span>s</span><br><span class="line">pc<span class="literal">-job-v7rhr</span>   <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">2</span>s</span><br><span class="line">pc<span class="literal">-job-5vg2j</span>   <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">3</span>s</span><br><span class="line">pc<span class="literal">-job-fhwf7</span>   <span class="number">0</span>/<span class="number">1</span>     Completed           <span class="number">0</span>          <span class="number">12</span>s</span><br><span class="line">pc<span class="literal">-job-v7rhr</span>   <span class="number">0</span>/<span class="number">1</span>     Completed           <span class="number">0</span>          <span class="number">12</span>s</span><br><span class="line">pc<span class="literal">-job-5vg2j</span>   <span class="number">0</span>/<span class="number">1</span>     Completed           <span class="number">0</span>          <span class="number">12</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除job</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete -f pc-job.yaml</span></span><br><span class="line">job.batch <span class="string">&quot;pc-job&quot;</span> deleted</span><br></pre></td></tr></table></figure>

<h2 id="CronJob-CJ"><a href="#CronJob-CJ" class="headerlink" title="CronJob(CJ)"></a>CronJob(CJ)</h2><p>CronJob控制器以Job控制器资源为其管控对象，并借助它管理pod资源对象，Job控制器定义的作业任务在其控制器资源创建之后便会立即执行，但CronJob可以以类似于Linux操作系统的周期性任务作业计划的方式控制其运行<strong>时间点</strong>及<strong>重复运行</strong>的方式。也就是说，<strong>CronJob可以在特定的时间点(反复的)去运行job任务</strong>。</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200618213149531.png" style />

<p>CronJob的资源清单文件：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1beta1</span> <span class="comment"># 版本号</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CronJob</span> <span class="comment"># 类型       </span></span><br><span class="line"><span class="attr">metadata:</span> <span class="comment"># 元数据</span></span><br><span class="line">  <span class="attr">name:</span> <span class="comment"># rs名称 </span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="comment"># 所属命名空间 </span></span><br><span class="line">  <span class="attr">labels:</span> <span class="comment">#标签</span></span><br><span class="line">    <span class="attr">controller:</span> <span class="string">cronjob</span></span><br><span class="line"><span class="attr">spec:</span> <span class="comment"># 详情描述</span></span><br><span class="line">  <span class="attr">schedule:</span> <span class="comment"># cron格式的作业调度运行时间点,用于控制任务在什么时间执行</span></span><br><span class="line">  <span class="attr">concurrencyPolicy:</span> <span class="comment"># 并发执行策略，用于定义前一次作业运行尚未完成时是否以及如何运行后一次的作业</span></span><br><span class="line">  <span class="attr">failedJobHistoryLimit:</span> <span class="comment"># 为失败的任务执行保留的历史记录数，默认为1</span></span><br><span class="line">  <span class="attr">successfulJobHistoryLimit:</span> <span class="comment"># 为成功的任务执行保留的历史记录数，默认为3</span></span><br><span class="line">  <span class="attr">startingDeadlineSeconds:</span> <span class="comment"># 启动作业错误的超时时长</span></span><br><span class="line">  <span class="attr">jobTemplate:</span> <span class="comment"># job控制器模板，用于为cronjob控制器生成job对象;下面其实就是job的定义</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">completions:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">parallelism:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">activeDeadlineSeconds:</span> <span class="number">30</span></span><br><span class="line">      <span class="attr">backoffLimit:</span> <span class="number">6</span></span><br><span class="line">      <span class="attr">manualSelector:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">selector:</span></span><br><span class="line">        <span class="attr">matchLabels:</span></span><br><span class="line">          <span class="attr">app:</span> <span class="string">counter-pod</span></span><br><span class="line">        <span class="attr">matchExpressions:</span> <span class="string">规则</span></span><br><span class="line">          <span class="bullet">-</span> &#123;<span class="attr">key:</span> <span class="string">app</span>, <span class="attr">operator:</span> <span class="string">In</span>, <span class="attr">values:</span> [<span class="string">counter-pod</span>]&#125;</span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">        <span class="attr">metadata:</span></span><br><span class="line">          <span class="attr">labels:</span></span><br><span class="line">            <span class="attr">app:</span> <span class="string">counter-pod</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">restartPolicy:</span> <span class="string">Never</span> </span><br><span class="line">          <span class="attr">containers:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">counter</span></span><br><span class="line">            <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">            <span class="attr">command:</span> [<span class="string">&quot;bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 20;done&quot;</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">需要重点解释的几个选项：</span><br><span class="line">schedule: cron表达式，用于指定任务的执行时间</span><br><span class="line"> <span class="emphasis">*/1    *</span>      *    *     *</span><br><span class="line"> &lt;分钟&gt; &lt;小时&gt; &lt;日&gt; &lt;月份&gt; &lt;星期&gt;</span><br><span class="line"></span><br><span class="line"><span class="code">    分钟 值从 0 到 59.</span></span><br><span class="line"><span class="code">    小时 值从 0 到 23.</span></span><br><span class="line"><span class="code">    日 值从 1 到 31.</span></span><br><span class="line"><span class="code">    月 值从 1 到 12.</span></span><br><span class="line"><span class="code">    星期 值从 0 到 6, 0 代表星期日</span></span><br><span class="line"><span class="code">    多个时间可以用逗号隔开； 范围可以用连字符给出；*可以作为通配符； /表示每...</span></span><br><span class="line"><span class="code">concurrencyPolicy:</span></span><br><span class="line"><span class="code"> Allow:   允许Jobs并发运行(默认)</span></span><br><span class="line"><span class="code"> Forbid:  禁止并发运行，如果上一次运行尚未完成，则跳过下一次运行</span></span><br><span class="line"><span class="code"> Replace: 替换，取消当前正在运行的作业并用新作业替换它</span></span><br></pre></td></tr></table></figure>

<p>创建pc-cronjob.yaml，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CronJob</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pc-cronjob</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">controller:</span> <span class="string">cronjob</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">schedule:</span> <span class="string">&quot;*/1 * * * *&quot;</span></span><br><span class="line">  <span class="attr">jobTemplate:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">          <span class="attr">containers:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">counter</span></span><br><span class="line">            <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">            <span class="attr">command:</span> [<span class="string">&quot;bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 3;done&quot;</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建cronjob</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pc-cronjob.yaml</span></span><br><span class="line">cronjob.batch/pc<span class="literal">-cronjob</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看cronjob</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get cronjobs -n dev</span></span><br><span class="line">NAME         SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE</span><br><span class="line">pc<span class="literal">-cronjob</span>   */<span class="number">1</span> * * * *   False     <span class="number">0</span>        &lt;none&gt;          <span class="number">6</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看job</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get jobs -n dev</span></span><br><span class="line">NAME                    COMPLETIONS   DURATION   AGE</span><br><span class="line">pc<span class="literal">-cronjob-1592587800</span>   <span class="number">1</span>/<span class="number">1</span>           <span class="number">28</span>s        <span class="number">3</span>m26s</span><br><span class="line">pc<span class="literal">-cronjob-1592587860</span>   <span class="number">1</span>/<span class="number">1</span>           <span class="number">28</span>s        <span class="number">2</span>m26s</span><br><span class="line">pc<span class="literal">-cronjob-1592587920</span>   <span class="number">1</span>/<span class="number">1</span>           <span class="number">28</span>s        <span class="number">86</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev</span></span><br><span class="line">pc<span class="literal">-cronjob-1592587800-x4tsm</span>   <span class="number">0</span>/<span class="number">1</span>     Completed   <span class="number">0</span>          <span class="number">2</span>m24s</span><br><span class="line">pc<span class="literal">-cronjob-1592587860-r5gv4</span>   <span class="number">0</span>/<span class="number">1</span>     Completed   <span class="number">0</span>          <span class="number">84</span>s</span><br><span class="line">pc<span class="literal">-cronjob-1592587920-9dxxq</span>   <span class="number">1</span>/<span class="number">1</span>     Running     <span class="number">0</span>          <span class="number">24</span>s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除cronjob</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl  delete -f pc-cronjob.yaml</span></span><br><span class="line">cronjob.batch <span class="string">&quot;pc-cronjob&quot;</span> deleted</span><br></pre></td></tr></table></figure>

<h1 id="第七章-Service详解"><a href="#第七章-Service详解" class="headerlink" title="第七章 Service详解"></a>第七章 Service详解</h1><p>本章节主要介绍kubernetes的流量负载组件：Service和Ingress。</p>
<h2 id="Service介绍"><a href="#Service介绍" class="headerlink" title="Service介绍"></a>Service介绍</h2><p>在kubernetes中，pod是应用程序的载体，我们可以通过pod的ip来访问应用程序，但是pod的ip地址不是固定的，这也就意味着不方便直接采用pod的ip对服务进行访问。</p>
<p>为了解决这个问题，kubernetes提供了Service资源，Service会对提供同一个服务的多个pod进行聚合，并且提供一个统一的入口地址。通过访问Service的入口地址就能访问到后面的pod服务。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200408194716912.png"></p>
<p>Service在很多情况下只是一个概念，真正起作用的其实是kube-proxy服务进程，每个Node节点上都运行着一个kube-proxy服务进程。当创建Service的时候会通过api-server向etcd写入创建的service的信息，而kube-proxy会基于监听的机制发现这种Service的变动，然后<strong>它会将最新的Service信息转换成对应的访问规则</strong>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200509121254425.png"></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 10.97.97.97:80 是service提供的访问入口</span></span><br><span class="line"><span class="comment"># 当访问这个入口的时候，可以发现后面有三个pod的服务在等待调用，</span></span><br><span class="line"><span class="comment"># kube-proxy会基于rr（轮询）的策略，将请求分发到其中一个pod上去</span></span><br><span class="line"><span class="comment"># 这个规则会同时在集群内的所有节点上都生成，所以在任何一个节点上访问都可以。</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">node1</span> ~]<span class="comment"># ipvsadm -Ln</span></span><br><span class="line">IP Virtual Server version <span class="number">1.2</span>.<span class="number">1</span> (size=<span class="number">4096</span>)</span><br><span class="line">Prot LocalAddress:Port Scheduler Flags</span><br><span class="line">  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span><br><span class="line">TCP  <span class="number">10.97</span>.<span class="number">97.97</span>:<span class="number">80</span> rr</span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">1.39</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">1.40</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">2.33</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>kube-proxy目前支持三种工作模式:</p>
<p><strong>userspace 模式</strong></p>
<p>userspace模式下，kube-proxy会为每一个Service创建一个监听端口，发向Cluster IP的请求被Iptables规则重定向到kube-proxy监听的端口上，kube-proxy根据LB算法选择一个提供服务的Pod并和其建立链接，以将请求转发到Pod上。<br>该模式下，kube-proxy充当了一个四层负责均衡器的角色。由于kube-proxy运行在userspace中，在进行转发处理时会增加内核和用户空间之间的数据拷贝，虽然比较稳定，但是效率比较低。</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200509151424280.png" style="border:1px solid;" />

<p><strong>iptables 模式</strong></p>
<p>iptables模式下，kube-proxy为service后端的每个Pod创建对应的iptables规则，直接将发向Cluster IP的请求重定向到一个Pod IP。<br>该模式下kube-proxy不承担四层负责均衡器的角色，只负责创建iptables规则。该模式的优点是较userspace模式效率更高，但不能提供灵活的LB策略，当后端Pod不可用时也无法进行重试。</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200509152947714.png" style />

<p><strong>ipvs 模式</strong></p>
<p>ipvs模式和iptables类似，kube-proxy监控Pod的变化并创建相应的ipvs规则。ipvs相对iptables转发效率更高。除此以外，ipvs支持更多的LB算法。</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200509153731363.png" style />

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 此模式必须安装ipvs内核模块，否则会降级为iptables</span></span><br><span class="line"><span class="comment"># 开启ipvs</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl edit cm kube-proxy -n kube-system</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete pod -l k8s-app=kube-proxy -n kube-system</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">node1</span> ~]<span class="comment"># ipvsadm -Ln</span></span><br><span class="line">IP Virtual Server version <span class="number">1.2</span>.<span class="number">1</span> (size=<span class="number">4096</span>)</span><br><span class="line">Prot LocalAddress:Port Scheduler Flags</span><br><span class="line">  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span><br><span class="line">TCP  <span class="number">10.97</span>.<span class="number">97.97</span>:<span class="number">80</span> rr</span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">1.39</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">1.40</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">2.33</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br></pre></td></tr></table></figure>

<h2 id="Service类型"><a href="#Service类型" class="headerlink" title="Service类型"></a>Service类型</h2><p>Service的资源清单文件：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Service</span>  <span class="comment"># 资源类型</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span>  <span class="comment"># 资源版本</span></span><br><span class="line"><span class="attr">metadata:</span> <span class="comment"># 元数据</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">service</span> <span class="comment"># 资源名称</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span> <span class="comment"># 命名空间</span></span><br><span class="line"><span class="attr">spec:</span> <span class="comment"># 描述</span></span><br><span class="line">  <span class="attr">selector:</span> <span class="comment"># 标签选择器，用于确定当前service代理哪些pod</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">type:</span> <span class="comment"># Service类型，指定service的访问方式</span></span><br><span class="line">  <span class="attr">clusterIP:</span>  <span class="comment"># 虚拟服务的ip地址</span></span><br><span class="line">  <span class="attr">sessionAffinity:</span> <span class="comment"># session亲和性，支持ClientIP、None两个选项</span></span><br><span class="line">  <span class="attr">ports:</span> <span class="comment"># 端口信息</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span> </span><br><span class="line">      <span class="attr">port:</span> <span class="number">3017</span>  <span class="comment"># service端口</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">5003</span> <span class="comment"># pod端口</span></span><br><span class="line">      <span class="attr">nodePort:</span> <span class="number">31122</span> <span class="comment"># 主机端口</span></span><br></pre></td></tr></table></figure>

<ul>
<li>ClusterIP：默认值，它是Kubernetes系统自动分配的虚拟IP，只能在集群内部访问</li>
<li>NodePort：将Service通过指定的Node上的端口暴露给外部，通过此方法，就可以在集群外部访问服务</li>
<li>LoadBalancer：使用外接负载均衡器完成到服务的负载分发，注意此模式需要外部云环境支持</li>
<li>ExternalName： 把集群外部的服务引入集群内部，直接使用</li>
</ul>
<h2 id="Service使用"><a href="#Service使用" class="headerlink" title="Service使用"></a>Service使用</h2><h3 id="实验环境准备"><a href="#实验环境准备" class="headerlink" title="实验环境准备"></a>实验环境准备</h3><p>在使用service之前，首先利用Deployment创建出3个pod，注意要为pod设置<code>app=nginx-pod</code>的标签</p>
<p>创建deployment.yaml，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span>      </span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pc-deployment</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span> </span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f deployment.yaml</span></span><br><span class="line">deployment.apps/pc<span class="literal">-deployment</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod详情</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev -o wide --show-labels</span></span><br><span class="line">NAME                             READY   STATUS     IP            NODE     LABELS</span><br><span class="line">pc<span class="literal">-deployment-66cb59b984-8p84h</span>   <span class="number">1</span>/<span class="number">1</span>     Running    <span class="number">10.244</span>.<span class="number">1.40</span>   node1    app=nginx<span class="literal">-pod</span></span><br><span class="line">pc<span class="literal">-deployment-66cb59b984-vx8vx</span>   <span class="number">1</span>/<span class="number">1</span>     Running    <span class="number">10.244</span>.<span class="number">2.33</span>   node2    app=nginx<span class="literal">-pod</span></span><br><span class="line">pc<span class="literal">-deployment-66cb59b984-wnncx</span>   <span class="number">1</span>/<span class="number">1</span>     Running    <span class="number">10.244</span>.<span class="number">1.39</span>   node1    app=nginx<span class="literal">-pod</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为了方便后面的测试，修改下三台nginx的index.html页面（三台修改的IP地址不一致）</span></span><br><span class="line"><span class="comment"># kubectl exec -it pc-deployment-66cb59b984-8p84h -n dev /bin/sh</span></span><br><span class="line"><span class="comment"># echo &quot;10.244.1.40&quot; &gt; /usr/share/nginx/html/index.html</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#修改完毕之后，访问测试</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># curl 10.244.1.40</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">1.40</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># curl 10.244.2.33</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">2.33</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># curl 10.244.1.39</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">1.39</span></span><br></pre></td></tr></table></figure>

<h3 id="ClusterIP类型的Service"><a href="#ClusterIP类型的Service" class="headerlink" title="ClusterIP类型的Service"></a>ClusterIP类型的Service</h3><p>创建service-clusterip.yaml文件</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">service-clusterip</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="number">10.97</span><span class="number">.97</span><span class="number">.97</span> <span class="comment"># service的ip地址，如果不写，默认会生成一个</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span>  <span class="comment"># Service端口       </span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span> <span class="comment"># pod端口</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建service</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f service-clusterip.yaml</span></span><br><span class="line">service/service<span class="literal">-clusterip</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看service</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get svc -n dev -o wide</span></span><br><span class="line">NAME                <span class="built_in">TYPE</span>        CLUSTER<span class="literal">-IP</span>    EXTERNAL<span class="literal">-IP</span>   PORT(S)   AGE   SELECTOR</span><br><span class="line">service<span class="literal">-clusterip</span>   ClusterIP   <span class="number">10.97</span>.<span class="number">97.97</span>   &lt;none&gt;        <span class="number">80</span>/TCP    <span class="number">13</span>s   app=nginx<span class="literal">-pod</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看service的详细信息</span></span><br><span class="line"><span class="comment"># 在这里有一个Endpoints列表，里面就是当前service可以负载到的服务入口</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl describe svc service-clusterip -n dev</span></span><br><span class="line">Name:              service<span class="literal">-clusterip</span></span><br><span class="line">Namespace:         dev</span><br><span class="line">Labels:            &lt;none&gt;</span><br><span class="line">Annotations:       &lt;none&gt;</span><br><span class="line">Selector:          app=nginx<span class="literal">-pod</span></span><br><span class="line"><span class="built_in">Type</span>:              ClusterIP</span><br><span class="line">IP:                <span class="number">10.97</span>.<span class="number">97.97</span></span><br><span class="line">Port:              &lt;unset&gt;  <span class="number">80</span>/TCP</span><br><span class="line">TargetPort:        <span class="number">80</span>/TCP</span><br><span class="line">Endpoints:         <span class="number">10.244</span>.<span class="number">1.39</span>:<span class="number">80</span>,<span class="number">10.244</span>.<span class="number">1.40</span>:<span class="number">80</span>,<span class="number">10.244</span>.<span class="number">2.33</span>:<span class="number">80</span></span><br><span class="line">Session Affinity:  None</span><br><span class="line">Events:            &lt;none&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看ipvs的映射规则</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># ipvsadm -Ln</span></span><br><span class="line">TCP  <span class="number">10.97</span>.<span class="number">97.97</span>:<span class="number">80</span> rr</span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">1.39</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">1.40</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">2.33</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 访问10.97.97.97:80观察效果</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># curl 10.97.97.97:80</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">2.33</span></span><br></pre></td></tr></table></figure>

<p><strong>Endpoint</strong></p>
<p>Endpoint是kubernetes中的一个资源对象，存储在etcd中，用来记录一个service对应的所有pod的访问地址，它是根据service配置文件中selector描述产生的。</p>
<p>一个Service由一组Pod组成，这些Pod通过Endpoints暴露出来，<strong>Endpoints是实现实际服务的端点集合</strong>。换句话说，service和pod之间的联系是通过endpoints实现的。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200509191917069.png" alt="image-20200509191917069"></p>
<p><strong>负载分发策略</strong></p>
<p>对Service的访问被分发到了后端的Pod上去，目前kubernetes提供了两种负载分发策略：</p>
<ul>
<li><p>如果不定义，默认使用kube-proxy的策略，比如随机、轮询</p>
</li>
<li><p>基于客户端地址的会话保持模式，即来自同一个客户端发起的所有请求都会转发到固定的一个Pod上</p>
<p>  此模式可以使在spec中添加<code>sessionAffinity:ClientIP</code>选项</p>
</li>
</ul>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看ipvs的映射规则【rr 轮询】</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># ipvsadm -Ln</span></span><br><span class="line">TCP  <span class="number">10.97</span>.<span class="number">97.97</span>:<span class="number">80</span> rr</span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">1.39</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">1.40</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">2.33</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 循环访问测试</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># while true;do curl 10.97.97.97:80; sleep 5; done;</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">1.40</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">1.39</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">2.33</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">1.40</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">1.39</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">2.33</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改分发策略----sessionAffinity:ClientIP</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看ipvs规则【persistent 代表持久】</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># ipvsadm -Ln</span></span><br><span class="line">TCP  <span class="number">10.97</span>.<span class="number">97.97</span>:<span class="number">80</span> rr persistent <span class="number">10800</span></span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">1.39</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">1.40</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">2.33</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 循环访问测试</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># while true;do curl 10.97.97.97; sleep 5; done;</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">2.33</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">2.33</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">2.33</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 删除service</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete -f service-clusterip.yaml</span></span><br><span class="line">service <span class="string">&quot;service-clusterip&quot;</span> deleted</span><br></pre></td></tr></table></figure>

<h3 id="HeadLiness类型的Service"><a href="#HeadLiness类型的Service" class="headerlink" title="HeadLiness类型的Service"></a>HeadLiness类型的Service</h3><p>在某些场景中，开发人员可能不想使用Service提供的负载均衡功能，而希望自己来控制负载均衡策略，针对这种情况，kubernetes提供了HeadLiness  Service，这类Service不会分配Cluster IP，如果想要访问service，只能通过service的域名进行查询。</p>
<p>创建service-headliness.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">service-headliness</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span> <span class="comment"># 将clusterIP设置为None，即可创建headliness Service</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span>    </span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建service</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f service-headliness.yaml</span></span><br><span class="line">service/service<span class="literal">-headliness</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取service， 发现CLUSTER-IP未分配</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get svc service-headliness -n dev -o wide</span></span><br><span class="line">NAME                 <span class="built_in">TYPE</span>        CLUSTER<span class="literal">-IP</span>   EXTERNAL<span class="literal">-IP</span>   PORT(S)   AGE   SELECTOR</span><br><span class="line">service<span class="literal">-headliness</span>   ClusterIP   None         &lt;none&gt;        <span class="number">80</span>/TCP    <span class="number">11</span>s   app=nginx<span class="literal">-pod</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看service详情</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl describe svc service-headliness  -n dev</span></span><br><span class="line">Name:              service<span class="literal">-headliness</span></span><br><span class="line">Namespace:         dev</span><br><span class="line">Labels:            &lt;none&gt;</span><br><span class="line">Annotations:       &lt;none&gt;</span><br><span class="line">Selector:          app=nginx<span class="literal">-pod</span></span><br><span class="line"><span class="built_in">Type</span>:              ClusterIP</span><br><span class="line">IP:                None</span><br><span class="line">Port:              &lt;unset&gt;  <span class="number">80</span>/TCP</span><br><span class="line">TargetPort:        <span class="number">80</span>/TCP</span><br><span class="line">Endpoints:         <span class="number">10.244</span>.<span class="number">1.39</span>:<span class="number">80</span>,<span class="number">10.244</span>.<span class="number">1.40</span>:<span class="number">80</span>,<span class="number">10.244</span>.<span class="number">2.33</span>:<span class="number">80</span></span><br><span class="line">Session Affinity:  None</span><br><span class="line">Events:            &lt;none&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看域名的解析情况</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl exec -it pc-deployment-66cb59b984-8p84h -n dev /bin/sh</span></span><br><span class="line">/ <span class="comment"># cat /etc/resolv.conf</span></span><br><span class="line">nameserver <span class="number">10.96</span>.<span class="number">0.10</span></span><br><span class="line">search dev.svc.cluster.local svc.cluster.local cluster.local</span><br><span class="line"></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># dig @10.96.0.10 service-headliness.dev.svc.cluster.local</span></span><br><span class="line">service<span class="literal">-headliness</span>.dev.svc.cluster.local. <span class="number">30</span> <span class="keyword">IN</span> A <span class="number">10.244</span>.<span class="number">1.40</span></span><br><span class="line">service<span class="literal">-headliness</span>.dev.svc.cluster.local. <span class="number">30</span> <span class="keyword">IN</span> A <span class="number">10.244</span>.<span class="number">1.39</span></span><br><span class="line">service<span class="literal">-headliness</span>.dev.svc.cluster.local. <span class="number">30</span> <span class="keyword">IN</span> A <span class="number">10.244</span>.<span class="number">2.33</span></span><br></pre></td></tr></table></figure>

<h3 id="NodePort类型的Service"><a href="#NodePort类型的Service" class="headerlink" title="NodePort类型的Service"></a>NodePort类型的Service</h3><p>在之前的样例中，创建的Service的ip地址只有集群内部才可以访问，如果希望将Service暴露给集群外部使用，那么就要使用到另外一种类型的Service，称为NodePort类型。NodePort的工作原理其实就是<strong>将service的端口映射到Node的一个端口上</strong>，然后就可以通过<code>NodeIp:NodePort</code>来访问service了。</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200620175731338.png" style="border:1px solid;" />

<p>创建service-nodeport.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">service-nodeport</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span> <span class="comment"># service类型</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">nodePort:</span> <span class="number">30002</span> <span class="comment"># 指定绑定的node的端口(默认的取值范围是：30000-32767), 如果不指定，会默认分配</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建service</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f service-nodeport.yaml</span></span><br><span class="line">service/service<span class="literal">-nodeport</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看service</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get svc -n dev -o wide</span></span><br><span class="line">NAME               <span class="built_in">TYPE</span>       CLUSTER<span class="literal">-IP</span>      EXTERNAL<span class="literal">-IP</span>   PORT(S)       SELECTOR</span><br><span class="line">service<span class="literal">-nodeport</span>   NodePort   <span class="number">10.105</span>.<span class="number">64.191</span>   &lt;none&gt;        <span class="number">80</span>:<span class="number">30002</span>/TCP  app=nginx<span class="literal">-pod</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来可以通过电脑主机的浏览器去访问集群中任意一个nodeip的30002端口，即可访问到pod</span></span><br></pre></td></tr></table></figure>

<h3 id="LoadBalancer类型的Service"><a href="#LoadBalancer类型的Service" class="headerlink" title="LoadBalancer类型的Service"></a>LoadBalancer类型的Service</h3><p>LoadBalancer和NodePort很相似，目的都是向外部暴露一个端口，区别在于LoadBalancer会在集群的外部再来做一个负载均衡设备，而这个设备需要外部环境支持的，外部服务发送到这个设备上的请求，会被设备负载之后转发到集群中。</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200510103945494.png" style="border:1px solid;" />

<h3 id="ExternalName类型的Service"><a href="#ExternalName类型的Service" class="headerlink" title="ExternalName类型的Service"></a>ExternalName类型的Service</h3><p>ExternalName类型的Service用于引入集群外部的服务，它通过<code>externalName</code>属性指定外部一个服务的地址，然后在集群内部访问此service就可以访问到外部的服务了。</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200510113311209.png" style="border:1px solid;" />

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">service-externalname</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ExternalName</span> <span class="comment"># service类型</span></span><br><span class="line">  <span class="attr">externalName:</span> <span class="string">www.baidu.com</span>  <span class="comment">#改成ip地址也可以</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建service</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl  create -f service-externalname.yaml</span></span><br><span class="line">service/service<span class="literal">-externalname</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 域名解析</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># dig @10.96.0.10 service-externalname.dev.svc.cluster.local</span></span><br><span class="line">service<span class="literal">-externalname</span>.dev.svc.cluster.local. <span class="number">30</span> <span class="keyword">IN</span> CNAME www.baidu.com.</span><br><span class="line">www.baidu.com.          <span class="number">30</span>      <span class="keyword">IN</span>      CNAME   www.a.shifen.com.</span><br><span class="line">www.a.shifen.com.       <span class="number">30</span>      <span class="keyword">IN</span>      A       <span class="number">39.156</span>.<span class="number">66.18</span></span><br><span class="line">www.a.shifen.com.       <span class="number">30</span>      <span class="keyword">IN</span>      A       <span class="number">39.156</span>.<span class="number">66.14</span></span><br></pre></td></tr></table></figure>

<h2 id="Ingress介绍"><a href="#Ingress介绍" class="headerlink" title="Ingress介绍"></a>Ingress介绍</h2><p>在前面课程中已经提到，Service对集群之外暴露服务的主要方式有两种：NotePort和LoadBalancer，但是这两种方式，都有一定的缺点：</p>
<ul>
<li><p>NodePort方式的缺点是会占用很多集群机器的端口，那么当集群服务变多的时候，这个缺点就愈发明显</p>
</li>
<li><p>LB方式的缺点是每个service需要一个LB，浪费、麻烦，并且需要kubernetes之外设备的支持</p>
<p>  基于这种现状，kubernetes提供了Ingress资源对象，Ingress只需要一个NodePort或者一个LB就可以满足暴露多个Service的需求。工作机制大致如下图表示：</p>
</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200623092808049.png" style="border:1px solid;" />

<p>实际上，Ingress相当于一个7层的负载均衡器，是kubernetes对反向代理的一个抽象，它的工作原理类似于Nginx，可以理解成在<strong>Ingress里建立诸多映射规则，Ingress Controller通过监听这些配置规则并转化成Nginx的反向代理配置 , 然后对外部提供服务</strong>。在这里有两个核心概念：</p>
<ul>
<li>ingress：kubernetes中的一个对象，作用是定义请求如何转发到service的规则</li>
<li>ingress controller：具体实现反向代理及负载均衡的程序，对ingress定义的规则进行解析，根据配置的规则来实现请求转发，实现方式有很多，比如Nginx, Contour, Haproxy等等</li>
</ul>
<p>Ingress（以Nginx为例）的工作原理如下：</p>
<ol>
<li>用户编写Ingress规则，说明哪个域名对应kubernetes集群中的哪个Service</li>
<li>Ingress控制器动态感知Ingress服务规则的变化，然后生成一段对应的Nginx反向代理配置</li>
<li>Ingress控制器会将生成的Nginx配置写入到一个运行着的Nginx服务中，并动态更新</li>
<li>到此为止，其实真正在工作的就是一个Nginx了，内部配置了用户定义的请求转发规则</li>
</ol>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200516112704764.png" style="border:1px solid;" />

<h2 id="Ingress使用"><a href="#Ingress使用" class="headerlink" title="Ingress使用"></a>Ingress使用</h2><h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><p><strong>搭建ingress环境</strong></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建文件夹</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># mkdir ingress-controller</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># cd ingress-controller/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取ingress-nginx，本次案例使用的是0.30版本</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">ingress</span>-<span class="type">controller</span>]<span class="comment"># wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/mandatory.yaml</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">ingress</span>-<span class="type">controller</span>]<span class="comment"># wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/provider/baremetal/service-nodeport.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改mandatory.yaml文件中的仓库</span></span><br><span class="line"><span class="comment"># 修改quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0</span></span><br><span class="line"><span class="comment"># 为quay-mirror.qiniu.com/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0</span></span><br><span class="line"><span class="comment"># 创建ingress-nginx</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">ingress</span>-<span class="type">controller</span>]<span class="comment"># kubectl apply -f ./</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看ingress-nginx</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">ingress</span>-<span class="type">controller</span>]<span class="comment"># kubectl get pod -n ingress-nginx</span></span><br><span class="line">NAME                                           READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/nginx<span class="literal">-ingress-controller-fbf967dd5-4qpbp</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">12</span><span class="built_in">h</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看service</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">ingress</span>-<span class="type">controller</span>]<span class="comment"># kubectl get svc -n ingress-nginx</span></span><br><span class="line">NAME            <span class="built_in">TYPE</span>       CLUSTER<span class="literal">-IP</span>     EXTERNAL<span class="literal">-IP</span>   PORT(S)                      AGE</span><br><span class="line">ingress<span class="literal">-nginx</span>   NodePort   <span class="number">10.98</span>.<span class="number">75.163</span>   &lt;none&gt;        <span class="number">80</span>:<span class="number">32240</span>/TCP,<span class="number">443</span>:<span class="number">31335</span>/TCP   <span class="number">11</span><span class="built_in">h</span></span><br></pre></td></tr></table></figure>

<p><strong>准备service和pod</strong></p>
<p>为了后面的实验比较方便，创建如下图所示的模型</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200516102419998.png" style="border:1px solid;" />

<p>创建tomcat-nginx.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-deployment</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tomcat-deployment</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">tomcat-pod</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">tomcat-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tomcat</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">tomcat:8.5-jre10-slim</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-service</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tomcat-service</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">tomcat-pod</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">8080</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f tomcat-nginx.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get svc -n dev</span></span><br><span class="line">NAME             <span class="built_in">TYPE</span>        CLUSTER<span class="literal">-IP</span>   EXTERNAL<span class="literal">-IP</span>   PORT(S)    AGE</span><br><span class="line">nginx<span class="literal">-service</span>    ClusterIP   None         &lt;none&gt;        <span class="number">80</span>/TCP     <span class="number">48</span>s</span><br><span class="line">tomcat<span class="literal">-service</span>   ClusterIP   None         &lt;none&gt;        <span class="number">8080</span>/TCP   <span class="number">48</span>s</span><br></pre></td></tr></table></figure>

<h3 id="Http代理"><a href="#Http代理" class="headerlink" title="Http代理"></a>Http代理</h3><p>创建ingress-http.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-http</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">nginx.itheima.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">nginx-service</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">80</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">tomcat.itheima.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">tomcat-service</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">8080</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f ingress-http.yaml</span></span><br><span class="line">ingress.extensions/ingress<span class="literal">-http</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get ing ingress-http -n dev</span></span><br><span class="line">NAME           HOSTS                                  ADDRESS   PORTS   AGE</span><br><span class="line">ingress<span class="literal">-http</span>   nginx.itheima.com,tomcat.itheima.com             <span class="number">80</span>      <span class="number">22</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看详情</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl describe ing ingress-http  -n dev</span></span><br><span class="line">...</span><br><span class="line">Rules:</span><br><span class="line">Host                Path  Backends</span><br><span class="line"><span class="literal">----</span>                <span class="literal">----</span>  <span class="literal">--------</span></span><br><span class="line">nginx.itheima.com   / nginx<span class="literal">-service</span>:<span class="number">80</span> (<span class="number">10.244</span>.<span class="number">1.96</span>:<span class="number">80</span>,<span class="number">10.244</span>.<span class="number">1.97</span>:<span class="number">80</span>,<span class="number">10.244</span>.<span class="number">2.112</span>:<span class="number">80</span>)</span><br><span class="line">tomcat.itheima.com  / tomcat<span class="literal">-service</span>:<span class="number">8080</span>(<span class="number">10.244</span>.<span class="number">1.94</span>:<span class="number">8080</span>,<span class="number">10.244</span>.<span class="number">1.95</span>:<span class="number">8080</span>,<span class="number">10.244</span>.<span class="number">2.111</span>:<span class="number">8080</span>)</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来,在本地电脑上配置host文件,解析上面的两个域名到192.168.109.100(master)上</span></span><br><span class="line"><span class="comment"># 然后,就可以分别访问tomcat.itheima.com:32240  和  nginx.itheima.com:32240 查看效果了</span></span><br></pre></td></tr></table></figure>

<h3 id="Https代理"><a href="#Https代理" class="headerlink" title="Https代理"></a>Https代理</h3><p>创建证书</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成证书</span></span><br><span class="line">openssl req <span class="literal">-x509</span> <span class="literal">-sha256</span> <span class="literal">-nodes</span> <span class="literal">-days</span> <span class="number">365</span> <span class="literal">-newkey</span> rsa:<span class="number">2048</span> <span class="literal">-keyout</span> tls.key <span class="literal">-out</span> tls.crt <span class="literal">-subj</span> <span class="string">&quot;/C=CN/ST=BJ/L=BJ/O=nginx/CN=itheima.com&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建密钥</span></span><br><span class="line">kubectl create secret tls tls<span class="literal">-secret</span> <span class="literal">--key</span> tls.key <span class="literal">--cert</span> tls.crt</span><br></pre></td></tr></table></figure>

<p>创建ingress-https.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-https</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">tls:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">hosts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">nginx.itheima.com</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">tomcat.itheima.com</span></span><br><span class="line">      <span class="attr">secretName:</span> <span class="string">tls-secret</span> <span class="comment"># 指定秘钥</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">nginx.itheima.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">nginx-service</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">80</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">tomcat.itheima.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">tomcat-service</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">8080</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f ingress-https.yaml</span></span><br><span class="line">ingress.extensions/ingress<span class="literal">-https</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get ing ingress-https -n dev</span></span><br><span class="line">NAME            HOSTS                                  ADDRESS         PORTS     AGE</span><br><span class="line">ingress<span class="literal">-https</span>   nginx.itheima.com,tomcat.itheima.com   <span class="number">10.104</span>.<span class="number">184.38</span>   <span class="number">80</span>, <span class="number">443</span>   <span class="number">2</span>m42s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看详情</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl describe ing ingress-https -n dev</span></span><br><span class="line">...</span><br><span class="line">TLS:</span><br><span class="line">  tls<span class="literal">-secret</span> terminates nginx.itheima.com,tomcat.itheima.com</span><br><span class="line">Rules:</span><br><span class="line">Host              Path Backends</span><br><span class="line"><span class="literal">----</span>              <span class="literal">----</span> <span class="literal">--------</span></span><br><span class="line">nginx.itheima.com  /  nginx<span class="literal">-service</span>:<span class="number">80</span> (<span class="number">10.244</span>.<span class="number">1.97</span>:<span class="number">80</span>,<span class="number">10.244</span>.<span class="number">1.98</span>:<span class="number">80</span>,<span class="number">10.244</span>.<span class="number">2.119</span>:<span class="number">80</span>)</span><br><span class="line">tomcat.itheima.com /  tomcat<span class="literal">-service</span>:<span class="number">8080</span>(<span class="number">10.244</span>.<span class="number">1.99</span>:<span class="number">8080</span>,<span class="number">10.244</span>.<span class="number">2.117</span>:<span class="number">8080</span>,<span class="number">10.244</span>.<span class="number">2.120</span>:<span class="number">8080</span>)</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面可以通过浏览器访问https://nginx.itheima.com:31335 和 https://tomcat.itheima.com:31335来查看了</span></span><br></pre></td></tr></table></figure>

<h1 id="第七章-Service详解-1"><a href="#第七章-Service详解-1" class="headerlink" title="第七章 Service详解"></a>第七章 Service详解</h1><p>本章节主要介绍kubernetes的流量负载组件：Service和Ingress。</p>
<h2 id="Service介绍-1"><a href="#Service介绍-1" class="headerlink" title="Service介绍"></a>Service介绍</h2><p>在kubernetes中，pod是应用程序的载体，我们可以通过pod的ip来访问应用程序，但是pod的ip地址不是固定的，这也就意味着不方便直接采用pod的ip对服务进行访问。</p>
<p>为了解决这个问题，kubernetes提供了Service资源，Service会对提供同一个服务的多个pod进行聚合，并且提供一个统一的入口地址。通过访问Service的入口地址就能访问到后面的pod服务。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200408194716912-20220901093550626.png"></p>
<p>Service在很多情况下只是一个概念，真正起作用的其实是kube-proxy服务进程，每个Node节点上都运行着一个kube-proxy服务进程。当创建Service的时候会通过api-server向etcd写入创建的service的信息，而kube-proxy会基于监听的机制发现这种Service的变动，然后<strong>它会将最新的Service信息转换成对应的访问规则</strong>。</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200509121254425.png" style="border:1px solid;" />

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 10.97.97.97:80 是service提供的访问入口</span></span><br><span class="line"><span class="comment"># 当访问这个入口的时候，可以发现后面有三个pod的服务在等待调用，</span></span><br><span class="line"><span class="comment"># kube-proxy会基于rr（轮询）的策略，将请求分发到其中一个pod上去</span></span><br><span class="line"><span class="comment"># 这个规则会同时在集群内的所有节点上都生成，所以在任何一个节点上访问都可以。</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">node1</span> ~]<span class="comment"># ipvsadm -Ln</span></span><br><span class="line">IP Virtual Server version <span class="number">1.2</span>.<span class="number">1</span> (size=<span class="number">4096</span>)</span><br><span class="line">Prot LocalAddress:Port Scheduler Flags</span><br><span class="line">  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span><br><span class="line">TCP  <span class="number">10.97</span>.<span class="number">97.97</span>:<span class="number">80</span> rr</span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">1.39</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">1.40</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">2.33</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>kube-proxy目前支持三种工作模式:</p>
<p><strong>userspace 模式</strong></p>
<p>userspace模式下，kube-proxy会为每一个Service创建一个监听端口，发向Cluster IP的请求被Iptables规则重定向到kube-proxy监听的端口上，kube-proxy根据LB算法选择一个提供服务的Pod并和其建立链接，以将请求转发到Pod上。<br>该模式下，kube-proxy充当了一个四层负责均衡器的角色。由于kube-proxy运行在userspace中，在进行转发处理时会增加内核和用户空间之间的数据拷贝，虽然比较稳定，但是效率比较低。</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200509151424280.png" style />

<p><strong>iptables 模式</strong></p>
<p>iptables模式下，kube-proxy为service后端的每个Pod创建对应的iptables规则，直接将发向Cluster IP的请求重定向到一个Pod IP。<br>该模式下kube-proxy不承担四层负责均衡器的角色，只负责创建iptables规则。该模式的优点是较userspace模式效率更高，但不能提供灵活的LB策略，当后端Pod不可用时也无法进行重试。</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200509152947714.png" style />

<p><strong>ipvs 模式</strong></p>
<p>ipvs模式和iptables类似，kube-proxy监控Pod的变化并创建相应的ipvs规则。ipvs相对iptables转发效率更高。除此以外，ipvs支持更多的LB算法。</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200509153731363.png" style />

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 此模式必须安装ipvs内核模块，否则会降级为iptables</span></span><br><span class="line"><span class="comment"># 开启ipvs</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl edit cm kube-proxy -n kube-system</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete pod -l k8s-app=kube-proxy -n kube-system</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">node1</span> ~]<span class="comment"># ipvsadm -Ln</span></span><br><span class="line">IP Virtual Server version <span class="number">1.2</span>.<span class="number">1</span> (size=<span class="number">4096</span>)</span><br><span class="line">Prot LocalAddress:Port Scheduler Flags</span><br><span class="line">  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span><br><span class="line">TCP  <span class="number">10.97</span>.<span class="number">97.97</span>:<span class="number">80</span> rr</span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">1.39</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">1.40</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">2.33</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br></pre></td></tr></table></figure>

<h2 id="Service类型-1"><a href="#Service类型-1" class="headerlink" title="Service类型"></a>Service类型</h2><p>Service的资源清单文件：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Service</span>  <span class="comment"># 资源类型</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span>  <span class="comment"># 资源版本</span></span><br><span class="line"><span class="attr">metadata:</span> <span class="comment"># 元数据</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">service</span> <span class="comment"># 资源名称</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span> <span class="comment"># 命名空间</span></span><br><span class="line"><span class="attr">spec:</span> <span class="comment"># 描述</span></span><br><span class="line">  <span class="attr">selector:</span> <span class="comment"># 标签选择器，用于确定当前service代理哪些pod</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">type:</span> <span class="comment"># Service类型，指定service的访问方式</span></span><br><span class="line">  <span class="attr">clusterIP:</span>  <span class="comment"># 虚拟服务的ip地址</span></span><br><span class="line">  <span class="attr">sessionAffinity:</span> <span class="comment"># session亲和性，支持ClientIP、None两个选项</span></span><br><span class="line">  <span class="attr">ports:</span> <span class="comment"># 端口信息</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span> </span><br><span class="line">      <span class="attr">port:</span> <span class="number">3017</span>  <span class="comment"># service端口</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">5003</span> <span class="comment"># pod端口</span></span><br><span class="line">      <span class="attr">nodePort:</span> <span class="number">31122</span> <span class="comment"># 主机端口</span></span><br></pre></td></tr></table></figure>

<ul>
<li>ClusterIP：默认值，它是Kubernetes系统自动分配的虚拟IP，只能在集群内部访问</li>
<li>NodePort：将Service通过指定的Node上的端口暴露给外部，通过此方法，就可以在集群外部访问服务</li>
<li>LoadBalancer：使用外接负载均衡器完成到服务的负载分发，注意此模式需要外部云环境支持</li>
<li>ExternalName： 把集群外部的服务引入集群内部，直接使用</li>
</ul>
<h2 id="Service使用-1"><a href="#Service使用-1" class="headerlink" title="Service使用"></a>Service使用</h2><h3 id="实验环境准备-1"><a href="#实验环境准备-1" class="headerlink" title="实验环境准备"></a>实验环境准备</h3><p>在使用service之前，首先利用Deployment创建出3个pod，注意要为pod设置<code>app=nginx-pod</code>的标签</p>
<p>创建deployment.yaml，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span>      </span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pc-deployment</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span> </span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f deployment.yaml</span></span><br><span class="line">deployment.apps/pc<span class="literal">-deployment</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod详情</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev -o wide --show-labels</span></span><br><span class="line">NAME                             READY   STATUS     IP            NODE     LABELS</span><br><span class="line">pc<span class="literal">-deployment-66cb59b984-8p84h</span>   <span class="number">1</span>/<span class="number">1</span>     Running    <span class="number">10.244</span>.<span class="number">1.40</span>   node1    app=nginx<span class="literal">-pod</span></span><br><span class="line">pc<span class="literal">-deployment-66cb59b984-vx8vx</span>   <span class="number">1</span>/<span class="number">1</span>     Running    <span class="number">10.244</span>.<span class="number">2.33</span>   node2    app=nginx<span class="literal">-pod</span></span><br><span class="line">pc<span class="literal">-deployment-66cb59b984-wnncx</span>   <span class="number">1</span>/<span class="number">1</span>     Running    <span class="number">10.244</span>.<span class="number">1.39</span>   node1    app=nginx<span class="literal">-pod</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为了方便后面的测试，修改下三台nginx的index.html页面（三台修改的IP地址不一致）</span></span><br><span class="line"><span class="comment"># kubectl exec -it pc-deployment-66cb59b984-8p84h -n dev /bin/sh</span></span><br><span class="line"><span class="comment"># echo &quot;10.244.1.40&quot; &gt; /usr/share/nginx/html/index.html</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#修改完毕之后，访问测试</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># curl 10.244.1.40</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">1.40</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># curl 10.244.2.33</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">2.33</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># curl 10.244.1.39</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">1.39</span></span><br></pre></td></tr></table></figure>

<h3 id="ClusterIP类型的Service-1"><a href="#ClusterIP类型的Service-1" class="headerlink" title="ClusterIP类型的Service"></a>ClusterIP类型的Service</h3><p>创建service-clusterip.yaml文件</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">service-clusterip</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="number">10.97</span><span class="number">.97</span><span class="number">.97</span> <span class="comment"># service的ip地址，如果不写，默认会生成一个</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span>  <span class="comment"># Service端口       </span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span> <span class="comment"># pod端口</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建service</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f service-clusterip.yaml</span></span><br><span class="line">service/service<span class="literal">-clusterip</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看service</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get svc -n dev -o wide</span></span><br><span class="line">NAME                <span class="built_in">TYPE</span>        CLUSTER<span class="literal">-IP</span>    EXTERNAL<span class="literal">-IP</span>   PORT(S)   AGE   SELECTOR</span><br><span class="line">service<span class="literal">-clusterip</span>   ClusterIP   <span class="number">10.97</span>.<span class="number">97.97</span>   &lt;none&gt;        <span class="number">80</span>/TCP    <span class="number">13</span>s   app=nginx<span class="literal">-pod</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看service的详细信息</span></span><br><span class="line"><span class="comment"># 在这里有一个Endpoints列表，里面就是当前service可以负载到的服务入口</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl describe svc service-clusterip -n dev</span></span><br><span class="line">Name:              service<span class="literal">-clusterip</span></span><br><span class="line">Namespace:         dev</span><br><span class="line">Labels:            &lt;none&gt;</span><br><span class="line">Annotations:       &lt;none&gt;</span><br><span class="line">Selector:          app=nginx<span class="literal">-pod</span></span><br><span class="line"><span class="built_in">Type</span>:              ClusterIP</span><br><span class="line">IP:                <span class="number">10.97</span>.<span class="number">97.97</span></span><br><span class="line">Port:              &lt;unset&gt;  <span class="number">80</span>/TCP</span><br><span class="line">TargetPort:        <span class="number">80</span>/TCP</span><br><span class="line">Endpoints:         <span class="number">10.244</span>.<span class="number">1.39</span>:<span class="number">80</span>,<span class="number">10.244</span>.<span class="number">1.40</span>:<span class="number">80</span>,<span class="number">10.244</span>.<span class="number">2.33</span>:<span class="number">80</span></span><br><span class="line">Session Affinity:  None</span><br><span class="line">Events:            &lt;none&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看ipvs的映射规则</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># ipvsadm -Ln</span></span><br><span class="line">TCP  <span class="number">10.97</span>.<span class="number">97.97</span>:<span class="number">80</span> rr</span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">1.39</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">1.40</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">2.33</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 访问10.97.97.97:80观察效果</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># curl 10.97.97.97:80</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">2.33</span></span><br></pre></td></tr></table></figure>

<p><strong>Endpoint</strong></p>
<pre><code>Endpoint是kubernetes中的一个资源对象，存储在etcd中，用来记录一个service对应的所有pod的访问地址，它是根据service配置文件中selector描述产生的。

一个Service由一组Pod组成，这些Pod通过Endpoints暴露出来，**Endpoints是实现实际服务的端点集合**。换句话说，service和pod之间的联系是通过endpoints实现的。
</code></pre>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200509191917069.png" style />

<p><strong>负载分发策略</strong></p>
<p>对Service的访问被分发到了后端的Pod上去，目前kubernetes提供了两种负载分发策略：</p>
<ul>
<li><p>如果不定义，默认使用kube-proxy的策略，比如随机、轮询</p>
</li>
<li><p>基于客户端地址的会话保持模式，即来自同一个客户端发起的所有请求都会转发到固定的一个Pod上</p>
<p>  此模式可以使在spec中添加<code>sessionAffinity:ClientIP</code>选项</p>
</li>
</ul>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看ipvs的映射规则【rr 轮询】</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># ipvsadm -Ln</span></span><br><span class="line">TCP  <span class="number">10.97</span>.<span class="number">97.97</span>:<span class="number">80</span> rr</span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">1.39</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">1.40</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">2.33</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 循环访问测试</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># while true;do curl 10.97.97.97:80; sleep 5; done;</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">1.40</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">1.39</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">2.33</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">1.40</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">1.39</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">2.33</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改分发策略----sessionAffinity:ClientIP</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看ipvs规则【persistent 代表持久】</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># ipvsadm -Ln</span></span><br><span class="line">TCP  <span class="number">10.97</span>.<span class="number">97.97</span>:<span class="number">80</span> rr persistent <span class="number">10800</span></span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">1.39</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">1.40</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line">  -&gt; <span class="number">10.244</span>.<span class="number">2.33</span>:<span class="number">80</span>               Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 循环访问测试</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># while true;do curl 10.97.97.97; sleep 5; done;</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">2.33</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">2.33</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">2.33</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 删除service</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl delete -f service-clusterip.yaml</span></span><br><span class="line">service <span class="string">&quot;service-clusterip&quot;</span> deleted</span><br></pre></td></tr></table></figure>

<h3 id="HeadLiness类型的Service-1"><a href="#HeadLiness类型的Service-1" class="headerlink" title="HeadLiness类型的Service"></a>HeadLiness类型的Service</h3><p>在某些场景中，开发人员可能不想使用Service提供的负载均衡功能，而希望自己来控制负载均衡策略，针对这种情况，kubernetes提供了HeadLiness  Service，这类Service不会分配Cluster IP，如果想要访问service，只能通过service的域名进行查询。</p>
<p>创建service-headliness.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">service-headliness</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span> <span class="comment"># 将clusterIP设置为None，即可创建headliness Service</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span>    </span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建service</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f service-headliness.yaml</span></span><br><span class="line">service/service<span class="literal">-headliness</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取service， 发现CLUSTER-IP未分配</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get svc service-headliness -n dev -o wide</span></span><br><span class="line">NAME                 <span class="built_in">TYPE</span>        CLUSTER<span class="literal">-IP</span>   EXTERNAL<span class="literal">-IP</span>   PORT(S)   AGE   SELECTOR</span><br><span class="line">service<span class="literal">-headliness</span>   ClusterIP   None         &lt;none&gt;        <span class="number">80</span>/TCP    <span class="number">11</span>s   app=nginx<span class="literal">-pod</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看service详情</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl describe svc service-headliness  -n dev</span></span><br><span class="line">Name:              service<span class="literal">-headliness</span></span><br><span class="line">Namespace:         dev</span><br><span class="line">Labels:            &lt;none&gt;</span><br><span class="line">Annotations:       &lt;none&gt;</span><br><span class="line">Selector:          app=nginx<span class="literal">-pod</span></span><br><span class="line"><span class="built_in">Type</span>:              ClusterIP</span><br><span class="line">IP:                None</span><br><span class="line">Port:              &lt;unset&gt;  <span class="number">80</span>/TCP</span><br><span class="line">TargetPort:        <span class="number">80</span>/TCP</span><br><span class="line">Endpoints:         <span class="number">10.244</span>.<span class="number">1.39</span>:<span class="number">80</span>,<span class="number">10.244</span>.<span class="number">1.40</span>:<span class="number">80</span>,<span class="number">10.244</span>.<span class="number">2.33</span>:<span class="number">80</span></span><br><span class="line">Session Affinity:  None</span><br><span class="line">Events:            &lt;none&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看域名的解析情况</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl exec -it pc-deployment-66cb59b984-8p84h -n dev /bin/sh</span></span><br><span class="line">/ <span class="comment"># cat /etc/resolv.conf</span></span><br><span class="line">nameserver <span class="number">10.96</span>.<span class="number">0.10</span></span><br><span class="line">search dev.svc.cluster.local svc.cluster.local cluster.local</span><br><span class="line"></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># dig @10.96.0.10 service-headliness.dev.svc.cluster.local</span></span><br><span class="line">service<span class="literal">-headliness</span>.dev.svc.cluster.local. <span class="number">30</span> <span class="keyword">IN</span> A <span class="number">10.244</span>.<span class="number">1.40</span></span><br><span class="line">service<span class="literal">-headliness</span>.dev.svc.cluster.local. <span class="number">30</span> <span class="keyword">IN</span> A <span class="number">10.244</span>.<span class="number">1.39</span></span><br><span class="line">service<span class="literal">-headliness</span>.dev.svc.cluster.local. <span class="number">30</span> <span class="keyword">IN</span> A <span class="number">10.244</span>.<span class="number">2.33</span></span><br></pre></td></tr></table></figure>

<h3 id="NodePort类型的Service-1"><a href="#NodePort类型的Service-1" class="headerlink" title="NodePort类型的Service"></a>NodePort类型的Service</h3><p>在之前的样例中，创建的Service的ip地址只有集群内部才可以访问，如果希望将Service暴露给集群外部使用，那么就要使用到另外一种类型的Service，称为NodePort类型。NodePort的工作原理其实就是<strong>将service的端口映射到Node的一个端口上</strong>，然后就可以通过<code>NodeIp:NodePort</code>来访问service了。</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200620175731338.png" style />

<p>创建service-nodeport.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">service-nodeport</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span> <span class="comment"># service类型</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">nodePort:</span> <span class="number">30002</span> <span class="comment"># 指定绑定的node的端口(默认的取值范围是：30000-32767), 如果不指定，会默认分配</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建service</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f service-nodeport.yaml</span></span><br><span class="line">service/service<span class="literal">-nodeport</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看service</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get svc -n dev -o wide</span></span><br><span class="line">NAME               <span class="built_in">TYPE</span>       CLUSTER<span class="literal">-IP</span>      EXTERNAL<span class="literal">-IP</span>   PORT(S)       SELECTOR</span><br><span class="line">service<span class="literal">-nodeport</span>   NodePort   <span class="number">10.105</span>.<span class="number">64.191</span>   &lt;none&gt;        <span class="number">80</span>:<span class="number">30002</span>/TCP  app=nginx<span class="literal">-pod</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来可以通过电脑主机的浏览器去访问集群中任意一个nodeip的30002端口，即可访问到pod</span></span><br></pre></td></tr></table></figure>

<h3 id="LoadBalancer类型的Service-1"><a href="#LoadBalancer类型的Service-1" class="headerlink" title="LoadBalancer类型的Service"></a>LoadBalancer类型的Service</h3><p>LoadBalancer和NodePort很相似，目的都是向外部暴露一个端口，区别在于LoadBalancer会在集群的外部再来做一个负载均衡设备，而这个设备需要外部环境支持的，外部服务发送到这个设备上的请求，会被设备负载之后转发到集群中。</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200510103945494.png" style="border:1px solid;" />

<h3 id="ExternalName类型的Service-1"><a href="#ExternalName类型的Service-1" class="headerlink" title="ExternalName类型的Service"></a>ExternalName类型的Service</h3><p>ExternalName类型的Service用于引入集群外部的服务，它通过<code>externalName</code>属性指定外部一个服务的地址，然后在集群内部访问此service就可以访问到外部的服务了。</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200510113311209.png" style="border:solid 1px;" />

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">service-externalname</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ExternalName</span> <span class="comment"># service类型</span></span><br><span class="line">  <span class="attr">externalName:</span> <span class="string">www.baidu.com</span>  <span class="comment">#改成ip地址也可以</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建service</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl  create -f service-externalname.yaml</span></span><br><span class="line">service/service<span class="literal">-externalname</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 域名解析</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># dig @10.96.0.10 service-externalname.dev.svc.cluster.local</span></span><br><span class="line">service<span class="literal">-externalname</span>.dev.svc.cluster.local. <span class="number">30</span> <span class="keyword">IN</span> CNAME www.baidu.com.</span><br><span class="line">www.baidu.com.          <span class="number">30</span>      <span class="keyword">IN</span>      CNAME   www.a.shifen.com.</span><br><span class="line">www.a.shifen.com.       <span class="number">30</span>      <span class="keyword">IN</span>      A       <span class="number">39.156</span>.<span class="number">66.18</span></span><br><span class="line">www.a.shifen.com.       <span class="number">30</span>      <span class="keyword">IN</span>      A       <span class="number">39.156</span>.<span class="number">66.14</span></span><br></pre></td></tr></table></figure>

<h2 id="Ingress介绍-1"><a href="#Ingress介绍-1" class="headerlink" title="Ingress介绍"></a>Ingress介绍</h2><p>在前面课程中已经提到，Service对集群之外暴露服务的主要方式有两种：NotePort和LoadBalancer，但是这两种方式，都有一定的缺点：</p>
<ul>
<li><p>NodePort方式的缺点是会占用很多集群机器的端口，那么当集群服务变多的时候，这个缺点就愈发明显</p>
</li>
<li><p>LB方式的缺点是每个service需要一个LB，浪费、麻烦，并且需要kubernetes之外设备的支持</p>
<p>  基于这种现状，kubernetes提供了Ingress资源对象，Ingress只需要一个NodePort或者一个LB就可以满足暴露多个Service的需求。工作机制大致如下图表示：</p>
</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200623092808049.png" style="border:solid 1px;" />

<p>实际上，Ingress相当于一个7层的负载均衡器，是kubernetes对反向代理的一个抽象，它的工作原理类似于Nginx，可以理解成在<strong>Ingress里建立诸多映射规则，Ingress Controller通过监听这些配置规则并转化成Nginx的反向代理配置 , 然后对外部提供服务</strong>。在这里有两个核心概念：</p>
<ul>
<li>ingress：kubernetes中的一个对象，作用是定义请求如何转发到service的规则</li>
<li>ingress controller：具体实现反向代理及负载均衡的程序，对ingress定义的规则进行解析，根据配置的规则来实现请求转发，实现方式有很多，比如Nginx, Contour, Haproxy等等</li>
</ul>
<p>Ingress（以Nginx为例）的工作原理如下：</p>
<ol>
<li>用户编写Ingress规则，说明哪个域名对应kubernetes集群中的哪个Service</li>
<li>Ingress控制器动态感知Ingress服务规则的变化，然后生成一段对应的Nginx反向代理配置</li>
<li>Ingress控制器会将生成的Nginx配置写入到一个运行着的Nginx服务中，并动态更新</li>
<li>到此为止，其实真正在工作的就是一个Nginx了，内部配置了用户定义的请求转发规则</li>
</ol>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200516112704764.png" style="border:solid 1px;" />

<h2 id="Ingress使用-1"><a href="#Ingress使用-1" class="headerlink" title="Ingress使用"></a>Ingress使用</h2><h3 id="环境准备-1"><a href="#环境准备-1" class="headerlink" title="环境准备"></a>环境准备</h3><p><strong>搭建ingress环境</strong></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建文件夹</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># mkdir ingress-controller</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># cd ingress-controller/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取ingress-nginx，本次案例使用的是0.30版本</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">ingress</span>-<span class="type">controller</span>]<span class="comment"># wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/mandatory.yaml</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">ingress</span>-<span class="type">controller</span>]<span class="comment"># wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/provider/baremetal/service-nodeport.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改mandatory.yaml文件中的仓库</span></span><br><span class="line"><span class="comment"># 修改quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0</span></span><br><span class="line"><span class="comment"># 为quay-mirror.qiniu.com/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0</span></span><br><span class="line"><span class="comment"># 创建ingress-nginx</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">ingress</span>-<span class="type">controller</span>]<span class="comment"># kubectl apply -f ./</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看ingress-nginx</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">ingress</span>-<span class="type">controller</span>]<span class="comment"># kubectl get pod -n ingress-nginx</span></span><br><span class="line">NAME                                           READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/nginx<span class="literal">-ingress-controller-fbf967dd5-4qpbp</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">12</span><span class="built_in">h</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看service</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">ingress</span>-<span class="type">controller</span>]<span class="comment"># kubectl get svc -n ingress-nginx</span></span><br><span class="line">NAME            <span class="built_in">TYPE</span>       CLUSTER<span class="literal">-IP</span>     EXTERNAL<span class="literal">-IP</span>   PORT(S)                      AGE</span><br><span class="line">ingress<span class="literal">-nginx</span>   NodePort   <span class="number">10.98</span>.<span class="number">75.163</span>   &lt;none&gt;        <span class="number">80</span>:<span class="number">32240</span>/TCP,<span class="number">443</span>:<span class="number">31335</span>/TCP   <span class="number">11</span><span class="built_in">h</span></span><br></pre></td></tr></table></figure>

<p><strong>准备service和pod</strong></p>
<p>为了后面的实验比较方便，创建如下图所示的模型</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200516102419998.png" style="border:solid 1px;" />

<p>创建tomcat-nginx.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-deployment</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tomcat-deployment</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">tomcat-pod</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">tomcat-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tomcat</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">tomcat:8.5-jre10-slim</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-service</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tomcat-service</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">tomcat-pod</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">8080</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f tomcat-nginx.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get svc -n dev</span></span><br><span class="line">NAME             <span class="built_in">TYPE</span>        CLUSTER<span class="literal">-IP</span>   EXTERNAL<span class="literal">-IP</span>   PORT(S)    AGE</span><br><span class="line">nginx<span class="literal">-service</span>    ClusterIP   None         &lt;none&gt;        <span class="number">80</span>/TCP     <span class="number">48</span>s</span><br><span class="line">tomcat<span class="literal">-service</span>   ClusterIP   None         &lt;none&gt;        <span class="number">8080</span>/TCP   <span class="number">48</span>s</span><br></pre></td></tr></table></figure>

<h3 id="Http代理-1"><a href="#Http代理-1" class="headerlink" title="Http代理"></a>Http代理</h3><p>创建ingress-http.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-http</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">nginx.itheima.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">nginx-service</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">80</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">tomcat.itheima.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">tomcat-service</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">8080</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f ingress-http.yaml</span></span><br><span class="line">ingress.extensions/ingress<span class="literal">-http</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get ing ingress-http -n dev</span></span><br><span class="line">NAME           HOSTS                                  ADDRESS   PORTS   AGE</span><br><span class="line">ingress<span class="literal">-http</span>   nginx.itheima.com,tomcat.itheima.com             <span class="number">80</span>      <span class="number">22</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看详情</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl describe ing ingress-http  -n dev</span></span><br><span class="line">...</span><br><span class="line">Rules:</span><br><span class="line">Host                Path  Backends</span><br><span class="line"><span class="literal">----</span>                <span class="literal">----</span>  <span class="literal">--------</span></span><br><span class="line">nginx.itheima.com   / nginx<span class="literal">-service</span>:<span class="number">80</span> (<span class="number">10.244</span>.<span class="number">1.96</span>:<span class="number">80</span>,<span class="number">10.244</span>.<span class="number">1.97</span>:<span class="number">80</span>,<span class="number">10.244</span>.<span class="number">2.112</span>:<span class="number">80</span>)</span><br><span class="line">tomcat.itheima.com  / tomcat<span class="literal">-service</span>:<span class="number">8080</span>(<span class="number">10.244</span>.<span class="number">1.94</span>:<span class="number">8080</span>,<span class="number">10.244</span>.<span class="number">1.95</span>:<span class="number">8080</span>,<span class="number">10.244</span>.<span class="number">2.111</span>:<span class="number">8080</span>)</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来,在本地电脑上配置host文件,解析上面的两个域名到192.168.109.100(master)上</span></span><br><span class="line"><span class="comment"># 然后,就可以分别访问tomcat.itheima.com:32240  和  nginx.itheima.com:32240 查看效果了</span></span><br></pre></td></tr></table></figure>

<h3 id="Https代理-1"><a href="#Https代理-1" class="headerlink" title="Https代理"></a>Https代理</h3><p>创建证书</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成证书</span></span><br><span class="line">openssl req <span class="literal">-x509</span> <span class="literal">-sha256</span> <span class="literal">-nodes</span> <span class="literal">-days</span> <span class="number">365</span> <span class="literal">-newkey</span> rsa:<span class="number">2048</span> <span class="literal">-keyout</span> tls.key <span class="literal">-out</span> tls.crt <span class="literal">-subj</span> <span class="string">&quot;/C=CN/ST=BJ/L=BJ/O=nginx/CN=itheima.com&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建密钥</span></span><br><span class="line">kubectl create secret tls tls<span class="literal">-secret</span> <span class="literal">--key</span> tls.key <span class="literal">--cert</span> tls.crt</span><br></pre></td></tr></table></figure>

<p>创建ingress-https.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-https</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">tls:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">hosts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">nginx.itheima.com</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">tomcat.itheima.com</span></span><br><span class="line">      <span class="attr">secretName:</span> <span class="string">tls-secret</span> <span class="comment"># 指定秘钥</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">nginx.itheima.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">nginx-service</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">80</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">tomcat.itheima.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">tomcat-service</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">8080</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f ingress-https.yaml</span></span><br><span class="line">ingress.extensions/ingress<span class="literal">-https</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get ing ingress-https -n dev</span></span><br><span class="line">NAME            HOSTS                                  ADDRESS         PORTS     AGE</span><br><span class="line">ingress<span class="literal">-https</span>   nginx.itheima.com,tomcat.itheima.com   <span class="number">10.104</span>.<span class="number">184.38</span>   <span class="number">80</span>, <span class="number">443</span>   <span class="number">2</span>m42s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看详情</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl describe ing ingress-https -n dev</span></span><br><span class="line">...</span><br><span class="line">TLS:</span><br><span class="line">  tls<span class="literal">-secret</span> terminates nginx.itheima.com,tomcat.itheima.com</span><br><span class="line">Rules:</span><br><span class="line">Host              Path Backends</span><br><span class="line"><span class="literal">----</span>              <span class="literal">----</span> <span class="literal">--------</span></span><br><span class="line">nginx.itheima.com  /  nginx<span class="literal">-service</span>:<span class="number">80</span> (<span class="number">10.244</span>.<span class="number">1.97</span>:<span class="number">80</span>,<span class="number">10.244</span>.<span class="number">1.98</span>:<span class="number">80</span>,<span class="number">10.244</span>.<span class="number">2.119</span>:<span class="number">80</span>)</span><br><span class="line">tomcat.itheima.com /  tomcat<span class="literal">-service</span>:<span class="number">8080</span>(<span class="number">10.244</span>.<span class="number">1.99</span>:<span class="number">8080</span>,<span class="number">10.244</span>.<span class="number">2.117</span>:<span class="number">8080</span>,<span class="number">10.244</span>.<span class="number">2.120</span>:<span class="number">8080</span>)</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面可以通过浏览器访问https://nginx.itheima.com:31335 和 https://tomcat.itheima.com:31335来查看了</span></span><br></pre></td></tr></table></figure>

<h1 id="第八章-数据存储"><a href="#第八章-数据存储" class="headerlink" title="第八章 数据存储"></a>第八章 数据存储</h1><p>在前面已经提到，容器的生命周期可能很短，会被频繁地创建和销毁。那么容器在销毁时，保存在容器中的数据也会被清除。这种结果对用户来说，在某些情况下是不乐意看到的。为了持久化保存容器的数据，kubernetes引入了Volume的概念。</p>
<p>Volume是Pod中能够被多个容器访问的共享目录，它被定义在Pod上，然后被一个Pod里的多个容器挂载到具体的文件目录下，kubernetes通过Volume实现同一个Pod中不同容器之间的数据共享以及数据的持久化存储。Volume的生命容器不与Pod中单个容器的生命周期相关，当容器终止或者重启时，Volume中的数据也不会丢失。</p>
<p>kubernetes的Volume支持多种类型，比较常见的有下面几个：</p>
<ul>
<li>简单存储：EmptyDir、HostPath、NFS</li>
<li>高级存储：PV、PVC</li>
<li>配置存储：ConfigMap、Secret</li>
</ul>
<h2 id="基本存储"><a href="#基本存储" class="headerlink" title="基本存储"></a>基本存储</h2><h3 id="EmptyDir"><a href="#EmptyDir" class="headerlink" title="EmptyDir"></a>EmptyDir</h3><p>EmptyDir是最基础的Volume类型，一个EmptyDir就是Host上的一个空目录。</p>
<p>EmptyDir是在Pod被分配到Node时创建的，它的初始内容为空，并且无须指定宿主机上对应的目录文件，因为kubernetes会自动分配一个目录，当Pod销毁时， EmptyDir中的数据也会被永久删除。 EmptyDir用途如下：</p>
<ul>
<li><p>临时空间，例如用于某些应用程序运行时所需的临时目录，且无须永久保留</p>
</li>
<li><p>一个容器需要从另一个容器中获取数据的目录（多容器共享目录）</p>
</li>
</ul>
<p>接下来，通过一个容器之间文件共享的案例来使用一下EmptyDir。</p>
<p>在一个Pod中准备两个容器nginx和busybox，然后声明一个Volume分别挂在到两个容器的目录中，然后nginx容器负责向Volume中写日志，busybox中通过命令将日志内容读到控制台。</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200413174713773.png" style="border:solid 1px;" />

<p>创建一个volume-emptydir.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">volume-emptydir</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.14-alpine</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">volumeMounts:</span>  <span class="comment"># 将logs-volume挂在到nginx容器中，对应的目录为 /var/log/nginx</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">logs-volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/var/log/nginx</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;tail -f /logs/access.log&quot;</span>] <span class="comment"># 初始命令，动态读取指定文件中内容</span></span><br><span class="line">    <span class="attr">volumeMounts:</span>  <span class="comment"># 将logs-volume 挂在到busybox容器中，对应的目录为 /logs</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">logs-volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/logs</span></span><br><span class="line">  <span class="attr">volumes:</span> <span class="comment"># 声明volume， name为logs-volume，类型为emptyDir</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">logs-volume</span></span><br><span class="line">    <span class="attr">emptyDir:</span> &#123;&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建Pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f volume-emptydir.yaml</span></span><br><span class="line">pod/volume<span class="literal">-emptydir</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods volume-emptydir -n dev -o wide</span></span><br><span class="line">NAME                  READY   STATUS    RESTARTS   AGE   IP             NODE   ...... </span><br><span class="line">volume<span class="literal">-emptydir</span>   <span class="number">2</span>/<span class="number">2</span>     Running   <span class="number">0</span>          <span class="number">97</span>s   <span class="number">10.244</span>.<span class="number">1.100</span>   node1  ......</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过podIp访问nginx</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># curl 10.244.1.100</span></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过kubectl logs命令查看指定容器的标准输出</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl logs -f volume-emptydir -n dev -c busybox</span></span><br><span class="line"><span class="number">10.244</span>.<span class="number">0.0</span> - - [<span class="number">13</span>/<span class="type">Apr</span>/<span class="number">2020</span>:<span class="number">10</span>:<span class="number">58</span>:<span class="number">47</span> +<span class="number">0000</span>] <span class="string">&quot;GET / HTTP/1.1&quot;</span> <span class="number">200</span> <span class="number">612</span> <span class="string">&quot;-&quot;</span> <span class="string">&quot;curl/7.29.0&quot;</span> <span class="string">&quot;-&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="HostPath"><a href="#HostPath" class="headerlink" title="HostPath"></a>HostPath</h3><p>上节课提到，EmptyDir中数据不会被持久化，它会随着Pod的结束而销毁，如果想简单的将数据持久化到主机中，可以选择HostPath。</p>
<p>HostPath就是将Node主机中一个实际目录挂在到Pod中，以供容器使用，这样的设计就可以保证Pod销毁了，但是数据依据可以存在于Node主机上。</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200413214031331.png" style="border:1px solid;" />

<p>创建一个volume-hostpath.yaml：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">volume-hostpath</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">logs-volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/var/log/nginx</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;tail -f /logs/access.log&quot;</span>]</span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">logs-volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/logs</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">logs-volume</span></span><br><span class="line">    <span class="attr">hostPath:</span> </span><br><span class="line">      <span class="attr">path:</span> <span class="string">/root/logs</span></span><br><span class="line">      <span class="attr">type:</span> <span class="string">DirectoryOrCreate</span>  <span class="comment"># 目录存在就使用，不存在就先创建后使用</span></span><br></pre></td></tr></table></figure>

<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">关于type的值的一点说明：</span><br><span class="line"> DirectoryOrCreate 目录存在就使用，不存在就先创建后使用</span><br><span class="line"> Directory 目录必须存在</span><br><span class="line"> FileOrCreate  文件存在就使用，不存在就先创建后使用</span><br><span class="line"> File 文件必须存在 </span><br><span class="line"><span class="code">    Socket unix套接字必须存在</span></span><br><span class="line"><span class="code"> CharDevice 字符设备必须存在</span></span><br><span class="line"><span class="code"> BlockDevice 块设备必须存在</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建Pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f volume-hostpath.yaml</span></span><br><span class="line">pod/volume<span class="literal">-hostpath</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods volume-hostpath -n dev -o wide</span></span><br><span class="line">NAME                  READY   STATUS    RESTARTS   AGE   IP             NODE   ......</span><br><span class="line">pod<span class="literal">-volume-hostpath</span>   <span class="number">2</span>/<span class="number">2</span>     Running   <span class="number">0</span>          <span class="number">16</span>s   <span class="number">10.244</span>.<span class="number">1.104</span>   node1  ......</span><br><span class="line"></span><br><span class="line"><span class="comment">#访问nginx</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># curl 10.244.1.104</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来就可以去host的/root/logs目录下查看存储的文件了</span></span><br><span class="line"><span class="comment">###  注意: 下面的操作需要到Pod所在的节点运行（案例中是node1）</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">node1</span> ~]<span class="comment"># ls /root/logs/</span></span><br><span class="line">access.log  error.log</span><br><span class="line"></span><br><span class="line"><span class="comment"># 同样的道理，如果在此目录下创建一个文件，到容器中也是可以看到的</span></span><br></pre></td></tr></table></figure>

<h3 id="NFS"><a href="#NFS" class="headerlink" title="NFS"></a>NFS</h3><pre><code>HostPath可以解决数据持久化的问题，但是一旦Node节点故障了，Pod如果转移到了别的节点，又会出现问题了，此时需要准备单独的网络存储系统，比较常用的用NFS、CIFS。

NFS是一个网络文件存储系统，可以搭建一台NFS服务器，然后将Pod中的存储直接连接到NFS系统上，这样的话，无论Pod在节点上怎么转移，只要Node跟NFS的对接没问题，数据就可以成功访问。
</code></pre>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200413215133559.png" alt="image-20200413215133559"></p>
<p>1）首先要准备nfs的服务器，这里为了简单，直接是master节点做nfs服务器</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在master上安装nfs服务</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># yum install nfs-utils -y</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备一个共享目录</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># mkdir /root/data/nfs -pv</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将共享目录以读写权限暴露给192.168.109.0/24网段中的所有主机</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># vim /etc/exports</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># more /etc/exports</span></span><br><span class="line">/root/<span class="keyword">data</span>/nfs     <span class="number">192.168</span>.<span class="number">109.0</span>/<span class="number">24</span>(rw,no_root_squash)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动nfs服务</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># systemctl start nfs</span></span><br></pre></td></tr></table></figure>

<p>2）接下来，要在的每个node节点上都安装下nfs，这样的目的是为了node节点可以驱动nfs设备</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在node上安装nfs服务，注意不需要启动</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># yum install nfs-utils -y</span></span><br></pre></td></tr></table></figure>

<p>3）接下来，就可以编写pod的配置文件了，创建volume-nfs.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">volume-nfs</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">logs-volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/var/log/nginx</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;tail -f /logs/access.log&quot;</span>] </span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">logs-volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/logs</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">logs-volume</span></span><br><span class="line">    <span class="attr">nfs:</span></span><br><span class="line">      <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.109</span><span class="number">.100</span>  <span class="comment">#nfs服务器地址</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/root/data/nfs</span> <span class="comment">#共享文件路径</span></span><br></pre></td></tr></table></figure>

<p>4）最后，运行下pod，观察结果</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f volume-nfs.yaml</span></span><br><span class="line">pod/volume<span class="literal">-nfs</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods volume-nfs -n dev</span></span><br><span class="line">NAME                  READY   STATUS    RESTARTS   AGE</span><br><span class="line">volume<span class="literal">-nfs</span>        <span class="number">2</span>/<span class="number">2</span>     Running   <span class="number">0</span>          <span class="number">2</span>m9s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看nfs服务器上的共享目录，发现已经有文件了</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># ls /root/data/</span></span><br><span class="line">access.log  error.log</span><br></pre></td></tr></table></figure>

<h2 id="高级存储"><a href="#高级存储" class="headerlink" title="高级存储"></a>高级存储</h2><h3 id="PV和PVC"><a href="#PV和PVC" class="headerlink" title="PV和PVC"></a>PV和PVC</h3><p>前面已经学习了使用NFS提供存储，此时就要求用户会搭建NFS系统，并且会在yaml配置nfs。由于kubernetes支持的存储系统有很多，要求客户全都掌握，显然不现实。为了能够屏蔽底层存储实现的细节，方便用户使用， kubernetes引入PV和PVC两种资源对象。</p>
<p>PV（Persistent Volume）是持久化卷的意思，是对底层的共享存储的一种抽象。一般情况下PV由kubernetes管理员进行创建和配置，它与底层具体的共享存储技术有关，并通过插件完成与共享存储的对接。</p>
<p>PVC（Persistent Volume Claim）是持久卷声明的意思，是用户对于存储需求的一种声明。换句话说，PVC其实就是用户向kubernetes系统发出的一种资源需求申请。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200514194111567.png" alt="image-20200514194111567"></p>
<p>使用了PV和PVC之后，工作可以得到进一步的细分：</p>
<ul>
<li>存储：存储工程师维护</li>
<li>PV：  kubernetes管理员维护</li>
<li>PVC：kubernetes用户维护</li>
</ul>
<h3 id="PV"><a href="#PV" class="headerlink" title="PV"></a>PV</h3><p>PV是存储资源的抽象，下面是资源清单文件:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span>  </span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pv2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">nfs:</span> <span class="comment"># 存储类型，与底层真正存储对应</span></span><br><span class="line">  <span class="attr">capacity:</span>  <span class="comment"># 存储能力，目前只支持存储空间的设置</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">2Gi</span></span><br><span class="line">  <span class="attr">accessModes:</span>  <span class="comment"># 访问模式</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="comment"># 存储类别</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="comment"># 回收策略</span></span><br></pre></td></tr></table></figure>

<p>PV 的关键配置参数说明：</p>
<ul>
<li><p><strong>存储类型</strong></p>
<p>  底层实际存储的类型，kubernetes支持多种存储类型，每种存储类型的配置都有所差异</p>
</li>
<li><p><strong>存储能力（capacity）</strong></p>
<p>  目前只支持存储空间的设置( storage&#x3D;1Gi )，不过未来可能会加入IOPS、吞吐量等指标的配置</p>
</li>
<li><p><strong>访问模式（accessModes）</strong></p>
<p>  用于描述用户应用对存储资源的访问权限，访问权限包括下面几种方式：</p>
<ul>
<li><p>ReadWriteOnce（RWO）：读写权限，但是只能被单个节点挂载</p>
</li>
<li><p>ReadOnlyMany（ROX）：  只读权限，可以被多个节点挂载</p>
</li>
<li><p>ReadWriteMany（RWX）：读写权限，可以被多个节点挂载</p>
<p><code>需要注意的是，底层不同的存储类型可能支持的访问模式不同</code></p>
</li>
</ul>
</li>
<li><p><strong>回收策略（persistentVolumeReclaimPolicy）</strong></p>
<p>  当PV不再被使用了之后，对其的处理方式。目前支持三种策略：</p>
<ul>
<li><p>Retain  （保留）  保留数据，需要管理员手工清理数据</p>
</li>
<li><p>Recycle（回收）  清除 PV 中的数据，效果相当于执行 rm -rf &#x2F;thevolume&#x2F;*</p>
</li>
<li><p>Delete  （删除） 与 PV 相连的后端存储完成 volume 的删除操作，当然这常见于云服务商的存储服务</p>
<p>需要注意的是，底层不同的存储类型可能支持的回收策略不同</p>
</li>
</ul>
</li>
<li><p><strong>存储类别</strong></p>
<p>  PV可以通过storageClassName参数指定一个存储类别</p>
<ul>
<li><p>具有特定类别的PV只能与请求了该类别的PVC进行绑定</p>
</li>
<li><p>未设定类别的PV则只能与不请求任何类别的PVC进行绑定</p>
</li>
</ul>
</li>
<li><p><strong>状态（status）</strong></p>
<p>  一个 PV 的生命周期中，可能会处于4中不同的阶段：</p>
<ul>
<li>Available（可用）：     表示可用状态，还未被任何 PVC 绑定</li>
<li>Bound（已绑定）：     表示 PV 已经被 PVC 绑定</li>
<li>Released（已释放）： 表示 PVC 被删除，但是资源还未被集群重新声明</li>
<li>Failed（失败）：         表示该 PV 的自动回收失败</li>
</ul>
</li>
</ul>
<p><strong>实验</strong></p>
<p>使用NFS作为存储，来演示PV的使用，创建3个PV，对应NFS中的3个暴露的路径。</p>
<ol>
<li>准备NFS环境</li>
</ol>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建目录</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># mkdir /root/data/&#123;pv1,pv2,pv3&#125; -pv</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 暴露服务</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># more /etc/exports</span></span><br><span class="line">/root/<span class="keyword">data</span>/pv1     <span class="number">192.168</span>.<span class="number">109.0</span>/<span class="number">24</span>(rw,no_root_squash)</span><br><span class="line">/root/<span class="keyword">data</span>/pv2     <span class="number">192.168</span>.<span class="number">109.0</span>/<span class="number">24</span>(rw,no_root_squash)</span><br><span class="line">/root/<span class="keyword">data</span>/pv3     <span class="number">192.168</span>.<span class="number">109.0</span>/<span class="number">24</span>(rw,no_root_squash)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启服务</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment">#  systemctl restart nfs</span></span><br></pre></td></tr></table></figure>

<ol>
<li>创建pv.yaml</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span>  <span class="string">pv1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span> </span><br><span class="line">    <span class="attr">storage:</span> <span class="string">1Gi</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Retain</span></span><br><span class="line">  <span class="attr">nfs:</span></span><br><span class="line">   <span class="attr">path:</span> <span class="string">/root/data/pv1</span></span><br><span class="line">    <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.109</span><span class="number">.100</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span>  <span class="string">pv2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span> </span><br><span class="line">    <span class="attr">storage:</span> <span class="string">2Gi</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Retain</span></span><br><span class="line">  <span class="attr">nfs:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/root/data/pv2</span></span><br><span class="line">    <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.109</span><span class="number">.100</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span>  <span class="string">pv3</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span> </span><br><span class="line">    <span class="attr">storage:</span> <span class="string">3Gi</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Retain</span></span><br><span class="line">  <span class="attr">nfs:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/root/data/pv3</span></span><br><span class="line">    <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.109</span><span class="number">.100</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建 pv</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pv.yaml</span></span><br><span class="line">persistentvolume/pv1 created</span><br><span class="line">persistentvolume/pv2 created</span><br><span class="line">persistentvolume/pv3 created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pv</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pv -o wide</span></span><br><span class="line">NAME   CAPACITY   ACCESS MODES  RECLAIM POLICY  STATUS      AGE   VOLUMEMODE</span><br><span class="line">pv1    <span class="number">1</span><span class="built_in">Gi</span>        RWX            Retain        Available    <span class="number">10</span>s   Filesystem</span><br><span class="line">pv2    <span class="number">2</span><span class="built_in">Gi</span>        RWX            Retain        Available    <span class="number">10</span>s   Filesystem</span><br><span class="line">pv3    <span class="number">3</span><span class="built_in">Gi</span>        RWX            Retain        Available    <span class="number">9</span>s    Filesystem</span><br></pre></td></tr></table></figure>

<h3 id="PVC"><a href="#PVC" class="headerlink" title="PVC"></a>PVC</h3><p>PVC是资源的申请，用来声明对存储空间、访问模式、存储类别需求信息。下面是资源清单文件:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pvc</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span> <span class="comment"># 访问模式</span></span><br><span class="line">  <span class="attr">selector:</span> <span class="comment"># 采用标签对PV选择</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="comment"># 存储类别</span></span><br><span class="line">  <span class="attr">resources:</span> <span class="comment"># 请求空间</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">5Gi</span></span><br></pre></td></tr></table></figure>

<p>PVC 的关键配置参数说明：</p>
<ul>
<li><p><strong>访问模式（accessModes）</strong></p>
<p>  用于描述用户应用对存储资源的访问权限</p>
</li>
<li><p><strong>选择条件（selector）</strong></p>
<p>  通过Label Selector的设置，可使PVC对于系统中己存在的PV进行筛选</p>
</li>
<li><p><strong>存储类别（storageClassName）</strong></p>
<p>  PVC在定义时可以设定需要的后端存储的类别，只有设置了该class的pv才能被系统选出</p>
</li>
<li><p><strong>资源请求（Resources ）</strong></p>
<p>  描述对存储资源的请求</p>
</li>
</ul>
<p><strong>实验</strong></p>
<ol>
<li>创建pvc.yaml，申请pv</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pvc1</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span> </span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">equests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">1Gi</span></span><br><span class="line">      </span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pvc2</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span> </span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">1Gi</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pvc3</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span> </span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">equests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">1Gi</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建pvc</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pvc.yaml</span></span><br><span class="line">persistentvolumeclaim/pvc1 created</span><br><span class="line">persistentvolumeclaim/pvc2 created</span><br><span class="line">persistentvolumeclaim/pvc3 created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pvc</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pvc  -n dev -o wide</span></span><br><span class="line">NAME   STATUS   VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE   VOLUMEMODE</span><br><span class="line">pvc1   Bound    pv1      <span class="number">1</span><span class="built_in">Gi</span>        RWX                           <span class="number">15</span>s   Filesystem</span><br><span class="line">pvc2   Bound    pv2      <span class="number">2</span><span class="built_in">Gi</span>        RWX                           <span class="number">15</span>s   Filesystem</span><br><span class="line">pvc3   Bound    pv3      <span class="number">3</span><span class="built_in">Gi</span>        RWX                           <span class="number">15</span>s   Filesystem</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pv</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pv -o wide</span></span><br><span class="line">NAME  CAPACITY ACCESS MODES  RECLAIM POLICY  STATUS    CLAIM       AGE     VOLUMEMODE</span><br><span class="line">pv1    <span class="number">1</span><span class="built_in">Gi</span>        RWx        Retain          Bound    dev/pvc1    <span class="number">3</span>h37m    Filesystem</span><br><span class="line">pv2    <span class="number">2</span><span class="built_in">Gi</span>        RWX        Retain          Bound    dev/pvc2    <span class="number">3</span>h37m    Filesystem</span><br><span class="line">pv3    <span class="number">3</span><span class="built_in">Gi</span>        RWX        Retain          Bound    dev/pvc3    <span class="number">3</span>h37m    Filesystem   </span><br></pre></td></tr></table></figure>

<ol>
<li>创建pods.yaml, 使用pv</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod1</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">usybox:1.30</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;while true;do echo pod1 &gt;&gt; /root/out.txt; sleep 10; done;&quot;</span>]</span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/root/</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">ame:</span> <span class="string">volume</span></span><br><span class="line">      <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">        <span class="attr">claimName:</span> <span class="string">pvc1</span></span><br><span class="line">        <span class="attr">readOnly:</span> <span class="literal">false</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod2</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">mage:</span> <span class="string">busybox:1.30</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;while true;do echo pod2 &gt;&gt; /root/out.txt; sleep 10; done;&quot;</span>]</span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/root/</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">volume</span></span><br><span class="line">      <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">        <span class="attr">claimName:</span> <span class="string">pvc2</span></span><br><span class="line">        <span class="attr">readOnly:</span> <span class="literal">false</span>        </span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pods.yaml</span></span><br><span class="line">pod/pod1 created</span><br><span class="line">pod/pod2 created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n dev -o wide</span></span><br><span class="line">NAME   READY   STATUS    RESTARTS   AGE   IP            NODE   </span><br><span class="line">pod1   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">14</span>s   <span class="number">10.244</span>.<span class="number">1.69</span>   node1   </span><br><span class="line">pod2   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">14</span>s   <span class="number">10.244</span>.<span class="number">1.70</span>   node1  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pvc</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pvc -n dev -o wide</span></span><br><span class="line">NAME   STATUS   VOLUME   CAPACITY   ACCESS MODES      AGE   VOLUMEMODE</span><br><span class="line">pvc1   Bound    pv1      <span class="number">1</span><span class="built_in">Gi</span>        RWX               <span class="number">94</span>m   Filesystem</span><br><span class="line">pvc2   Bound    pv2      <span class="number">2</span><span class="built_in">Gi</span>        RWX               <span class="number">94</span>m   Filesystem</span><br><span class="line">pvc3   Bound    pv3      <span class="number">3</span><span class="built_in">Gi</span>        RWX               <span class="number">94</span>m   Filesystem</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pv</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pv -n dev -o wide</span></span><br><span class="line">NAME   CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM       AGE     VOLUMEMODE</span><br><span class="line">pv1    <span class="number">1</span><span class="built_in">Gi</span>        RWX            Retain           Bound    dev/pvc1    <span class="number">5</span>h11m   Filesystem</span><br><span class="line">pv2    <span class="number">2</span><span class="built_in">Gi</span>        RWX            Retain           Bound    dev/pvc2    <span class="number">5</span>h11m   Filesystem</span><br><span class="line">pv3    <span class="number">3</span><span class="built_in">Gi</span>        RWX            Retain           Bound    dev/pvc3    <span class="number">5</span>h11m   Filesystem</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看nfs中的文件存储</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># more /root/data/pv1/out.txt</span></span><br><span class="line">node1</span><br><span class="line">node1</span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># more /root/data/pv2/out.txt</span></span><br><span class="line">node2</span><br><span class="line">node2</span><br></pre></td></tr></table></figure>

<h3 id="生命周期"><a href="#生命周期" class="headerlink" title="生命周期"></a>生命周期</h3><p>PVC和PV是一一对应的，PV和PVC之间的相互作用遵循以下生命周期：</p>
<ul>
<li><p><strong>资源供应</strong>：管理员手动创建底层存储和PV</p>
</li>
<li><p><strong>资源绑定</strong>：用户创建PVC，kubernetes负责根据PVC的声明去寻找PV，并绑定</p>
<p>  在用户定义好PVC之后，系统将根据PVC对存储资源的请求在已存在的PV中选择一个满足条件的</p>
<ul>
<li><p>一旦找到，就将该PV与用户定义的PVC进行绑定，用户的应用就可以使用这个PVC了</p>
</li>
<li><p>如果找不到，PVC则会无限期处于Pending状态，直到等到系统管理员创建了一个符合其要求的PV</p>
<p>PV一旦绑定到某个PVC上，就会被这个PVC独占，不能再与其他PVC进行绑定了</p>
</li>
</ul>
</li>
<li><p><strong>资源使用</strong>：用户可在pod中像volume一样使用pvc</p>
<p>  Pod使用Volume的定义，将PVC挂载到容器内的某个路径进行使用。</p>
</li>
<li><p><strong>资源释放</strong>：用户删除pvc来释放pv</p>
</li>
</ul>
<p>当存储资源使用完毕后，用户可以删除PVC，与该PVC绑定的PV将会被标记为“已释放”，但还不能立刻与其他PVC进行绑定。通过之前PVC写入的数据可能还被留在存储设备上，只有在清除之后该PV才能再次使用。</p>
<ul>
<li><p><strong>资源回收</strong>：kubernetes根据pv设置的回收策略进行资源的回收</p>
<p>  对于PV，管理员可以设定回收策略，用于设置与之绑定的PVC释放资源之后如何处理遗留数据的问题。只有PV的存储空间完成回收，才能供新的PVC绑定和使用</p>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200515002806726.png" alt="image-20200515002806726"></p>
<h2 id="配置存储"><a href="#配置存储" class="headerlink" title="配置存储"></a>配置存储</h2><h3 id="ConfigMap"><a href="#ConfigMap" class="headerlink" title="ConfigMap"></a>ConfigMap</h3><p>ConfigMap是一种比较特殊的存储卷，它的主要作用是用来存储配置信息的。<br>创建configmap.yaml，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">configmap</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">info:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    username:admin</span></span><br><span class="line"><span class="string">    password:123456</span></span><br></pre></td></tr></table></figure>

<p>接下来，使用此配置文件创建configmap</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建configmap</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f configmap.yaml</span></span><br><span class="line">configmap/configmap created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看configmap详情</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl describe cm configmap -n dev</span></span><br><span class="line">Name:         configmap</span><br><span class="line">Namespace:    dev</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  &lt;none&gt;</span><br><span class="line"></span><br><span class="line"><span class="keyword">Data</span></span><br><span class="line">====</span><br><span class="line">info:</span><br><span class="line"><span class="literal">----</span></span><br><span class="line">username:admin</span><br><span class="line">password:<span class="number">123456</span></span><br><span class="line"></span><br><span class="line">Events:  &lt;none&gt;</span><br></pre></td></tr></table></figure>

<p>接下来创建一个pod-configmap.yaml，将上面创建的configmap挂载进去</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-configmap</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">volumeMounts:</span> <span class="comment"># 将configmap挂载到目录</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/configmap/config</span></span><br><span class="line">  <span class="attr">volumes:</span> <span class="comment"># 引用configmap</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line">    <span class="attr">configMap:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">configmap</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod-configmap.yaml</span></span><br><span class="line">pod/pod<span class="literal">-configmap</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pod pod-configmap -n dev</span></span><br><span class="line">NAME            READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod<span class="literal">-configmap</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">6</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment">#进入容器</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl exec -it pod-configmap -n dev /bin/sh</span></span><br><span class="line"><span class="comment"># cd /configmap/config/</span></span><br><span class="line"><span class="comment"># ls</span></span><br><span class="line">info</span><br><span class="line"><span class="comment"># more info</span></span><br><span class="line">username:admin</span><br><span class="line">password:<span class="number">123456</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以看到映射已经成功，每个configmap都映射成了一个目录</span></span><br><span class="line"><span class="comment"># key---&gt;文件     value----&gt;文件中的内容</span></span><br><span class="line"><span class="comment"># 此时如果更新configmap的内容, 容器中的值也会动态更新</span></span><br></pre></td></tr></table></figure>

<h3 id="Secret"><a href="#Secret" class="headerlink" title="Secret"></a>Secret</h3><p>在kubernetes中，还存在一种和ConfigMap非常类似的对象，称为Secret对象。它主要用于存储敏感信息，例如密码、秘钥、证书等等。</p>
<ol>
<li>首先使用base64对数据进行编码</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">[<span class="string">root@master</span> <span class="string">~</span>]<span class="comment"># echo -n &#x27;admin&#x27; | base64 #准备username</span></span><br><span class="line"><span class="string">YWRtaW4=</span></span><br><span class="line">[<span class="string">root@master</span> <span class="string">~</span>]<span class="comment"># echo -n &#x27;123456&#x27; | base64 #准备password</span></span><br><span class="line"><span class="string">MTIzNDU2</span></span><br></pre></td></tr></table></figure>

<ol>
<li>接下来编写secret.yaml，并创建Secret</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">secret</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">Opaque</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">username:</span> <span class="string">YWRtaW4=</span></span><br><span class="line">  <span class="attr">password:</span> <span class="string">MTIzNDU2</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建secret</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f secret.yaml</span></span><br><span class="line">secret/secret created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看secret详情</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl describe secret secret -n dev</span></span><br><span class="line">Name:         secret</span><br><span class="line">Namespace:    dev</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  &lt;none&gt;</span><br><span class="line"><span class="built_in">Type</span>:  Opaque</span><br><span class="line"><span class="keyword">Data</span></span><br><span class="line">====</span><br><span class="line">password:  <span class="number">6</span> bytes</span><br><span class="line">username:  <span class="number">5</span> bytes</span><br></pre></td></tr></table></figure>

<ol>
<li>创建pod-secret.yaml，将上面创建的secret挂载进去：</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-secret</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">volumeMounts:</span> <span class="comment"># 将secret挂载到目录</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/secret/config</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line">    <span class="attr">secret:</span></span><br><span class="line">      <span class="attr">secretName:</span> <span class="string">secret</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod-secret.yaml</span></span><br><span class="line">pod/pod<span class="literal">-secret</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pod pod-secret -n dev</span></span><br><span class="line">NAME            READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod<span class="literal">-secret</span>      <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>m28s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入容器，查看secret信息，发现已经自动解码了</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl exec -it pod-secret /bin/sh -n dev</span></span><br><span class="line">/ <span class="comment"># ls /secret/config/</span></span><br><span class="line">password  username</span><br><span class="line">/ <span class="comment"># more /secret/config/username</span></span><br><span class="line">admin</span><br><span class="line">/ <span class="comment"># more /secret/config/password</span></span><br><span class="line"><span class="number">123456</span></span><br></pre></td></tr></table></figure>

<p>至此，已经实现了利用secret实现了信息的编码。</p>
<h1 id="第九章-安全认证"><a href="#第九章-安全认证" class="headerlink" title="第九章 安全认证"></a>第九章 安全认证</h1><p>本章节主要介绍Kubernetes的安全认证机制。</p>
<h2 id="访问控制概述"><a href="#访问控制概述" class="headerlink" title="访问控制概述"></a>访问控制概述</h2><p>Kubernetes作为一个分布式集群的管理工具，保证集群的安全性是其一个重要的任务。所谓的安全性其实就是保证对Kubernetes的各种<strong>客户端</strong>进行<strong>认证和鉴权</strong>操作。</p>
<p><strong>客户端</strong></p>
<p>在Kubernetes集群中，客户端通常有两类：</p>
<ul>
<li><p><strong>User Account</strong>：一般是独立于kubernetes之外的其他服务管理的用户账号。</p>
</li>
<li><p><strong>Service Account</strong>：kubernetes管理的账号，用于为Pod中的服务进程在访问Kubernetes时提供身份标识。</p>
</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200520102949189.png" style="border:1px solid;" />

<p><strong>认证、授权与准入控制</strong></p>
<p>ApiServer是访问及管理资源对象的唯一入口。任何一个请求访问ApiServer，都要经过下面三个流程：</p>
<ul>
<li>Authentication（认证）：身份鉴别，只有正确的账号才能够通过认证</li>
<li>Authorization（授权）：  判断用户是否有权限对访问的资源执行特定的动作</li>
<li>Admission Control（准入控制）：用于补充授权机制以实现更加精细的访问控制功能。</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200520103942580.png" style="border:1px solid;" />

<h2 id="认证管理"><a href="#认证管理" class="headerlink" title="认证管理"></a>认证管理</h2><p>Kubernetes集群安全的最关键点在于如何识别并认证客户端身份，它提供了3种客户端身份认证方式：</p>
<ul>
<li><p>HTTP Base认证：通过用户名+密码的方式认证</p>
  <figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">这种认证方式是把“用户名:密码”用BASE64算法进行编码后的字符串放在HTTP请求中的Header Authorization域里发送给服务端。服务端收到后进行解码，获取用户名及密码，然后进行用户身份认证的过程。</span><br></pre></td></tr></table></figure>
</li>
<li><p>HTTP Token认证：通过一个Token来识别合法用户</p>
  <figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">这种认证方式是用一个很长的难以被模仿的字符串--Token来表明客户身份的一种方式。每个Token对应一个用户名，当客户端发起API调用请求时，需要在HTTP Header里放入Token，API Server接到Token后会跟服务器中保存的token进行比对，然后进行用户身份认证的过程。</span><br></pre></td></tr></table></figure>
</li>
<li><p>HTTPS证书认证：基于CA根证书签名的双向数字证书认证方式</p>
  <figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">这种认证方式是安全性最高的一种方式，但是同时也是操作起来最麻烦的一种方式。</span><br></pre></td></tr></table></figure></li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200518211037434.png" alt="image-20200518211037434"></p>
<p><strong>HTTPS认证大体分为3个过程：</strong></p>
<ol>
<li><p>证书申请和下发</p>
 <figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">HTTPS通信双方的服务器向CA机构申请证书，CA机构下发根证书、服务端证书及私钥给申请者</span><br></pre></td></tr></table></figure>
</li>
<li><p>客户端和服务端的双向认证</p>
 <figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">1&gt; 客户端向服务器端发起请求，服务端下发自己的证书给客户端，</span><br><span class="line">   客户端接收到证书后，通过私钥解密证书，在证书中获得服务端的公钥，</span><br><span class="line">   客户端利用服务器端的公钥认证证书中的信息，如果一致，则认可这个服务器</span><br><span class="line">2&gt; 客户端发送自己的证书给服务器端，服务端接收到证书后，通过私钥解密证书，</span><br><span class="line">   在证书中获得客户端的公钥，并用该公钥认证证书信息，确认客户端是否合法</span><br></pre></td></tr></table></figure>
</li>
<li><p>服务器端和客户端进行通信</p>
 <figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">服务器端和客户端协商好加密方案后，客户端会产生一个随机的秘钥并加密，然后发送到服务器端。</span><br><span class="line">服务器端接收这个秘钥后，双方接下来通信的所有内容都通过该随机秘钥加密</span><br></pre></td></tr></table></figure></li>
</ol>
<blockquote>
<p>注意:  Kubernetes允许同时配置多种认证方式，只要其中任意一个方式认证通过即可</p>
</blockquote>
<h2 id="授权管理"><a href="#授权管理" class="headerlink" title="授权管理"></a>授权管理</h2><p>授权发生在认证成功之后，通过认证就可以知道请求用户是谁， 然后Kubernetes会根据事先定义的授权策略来决定用户是否有权限访问，这个过程就称为授权。</p>
<p>每个发送到ApiServer的请求都带上了用户和资源的信息：比如发送请求的用户、请求的路径、请求的动作等，授权就是根据这些信息和授权策略进行比较，如果符合策略，则认为授权通过，否则会返回错误。</p>
<p>API Server目前支持以下几种授权策略：</p>
<ul>
<li><p>AlwaysDeny：表示拒绝所有请求，一般用于测试</p>
</li>
<li><p>AlwaysAllow：允许接收所有请求，相当于集群不需要授权流程（Kubernetes默认的策略）</p>
</li>
<li><p>ABAC：基于属性的访问控制，表示使用用户配置的授权规则对用户请求进行匹配和控制</p>
</li>
<li><p>Webhook：通过调用外部REST服务对用户进行授权</p>
</li>
<li><p>Node：是一种专用模式，用于对kubelet发出的请求进行访问控制</p>
</li>
<li><p>RBAC：基于角色的访问控制（kubeadm安装方式下的默认选项）</p>
</li>
</ul>
<p>RBAC(Role-Based Access Control) 基于角色的访问控制，主要是在描述一件事情：<strong>给哪些对象授予了哪些权限</strong></p>
<p>其中涉及到了下面几个概念：</p>
<ul>
<li>对象：User、Groups、ServiceAccount</li>
<li>角色：代表着一组定义在资源上的可操作动作(权限)的集合</li>
<li>绑定：将定义好的角色跟用户绑定在一起</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200519181209566.png" style="border:1px solid;" />

<p>RBAC引入了4个顶级资源对象：</p>
<ul>
<li>Role、ClusterRole：角色，用于指定一组权限</li>
<li>RoleBinding、ClusterRoleBinding：角色绑定，用于将角色（权限）赋予给对象</li>
</ul>
<p><strong>Role、ClusterRole</strong></p>
<p>一个角色就是一组权限的集合，这里的权限都是许可形式的（白名单）。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Role只能对命名空间内的资源进行授权，需要指定nameapce</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">authorization-role</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]  <span class="comment"># 支持的API组列表,&quot;&quot; 空字符串，表示核心API群</span></span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>] <span class="comment"># 支持的资源对象列表</span></span><br><span class="line">  <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;list&quot;</span>] <span class="comment"># 允许的对资源对象的操作方法列表</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ClusterRole可以对集群范围内资源、跨namespaces的范围资源、非资源类型进行授权</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"> <span class="attr">name:</span> <span class="string">authorization-clusterrole</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>]</span><br><span class="line">  <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;list&quot;</span>]</span><br></pre></td></tr></table></figure>

<p>需要详细说明的是，rules中的参数：</p>
<ul>
<li><p>apiGroups: 支持的API组列表</p>
  <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;</span>,<span class="string">&quot;apps&quot;</span>, <span class="string">&quot;autoscaling&quot;</span>, <span class="string">&quot;batch&quot;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>resources：支持的资源对象列表</p>
  <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;services&quot;</span>, <span class="string">&quot;endpoints&quot;</span>, <span class="string">&quot;pods&quot;</span>,<span class="string">&quot;secrets&quot;</span>,<span class="string">&quot;configmaps&quot;</span>,<span class="string">&quot;crontabs&quot;</span>,<span class="string">&quot;deployments&quot;</span>,<span class="string">&quot;jobs&quot;</span>,</span><br><span class="line"><span class="string">&quot;nodes&quot;</span>,<span class="string">&quot;rolebindings&quot;</span>,<span class="string">&quot;clusterroles&quot;</span>,<span class="string">&quot;daemonsets&quot;</span>,<span class="string">&quot;replicasets&quot;</span>,<span class="string">&quot;statefulsets&quot;</span>,</span><br><span class="line"><span class="string">&quot;horizontalpodautoscalers&quot;</span>,<span class="string">&quot;replicationcontrollers&quot;</span>,<span class="string">&quot;cronjobs&quot;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>verbs：对资源对象的操作方法列表</p>
  <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>, <span class="string">&quot;delete&quot;</span>, <span class="string">&quot;exec&quot;</span></span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>RoleBinding、ClusterRoleBinding</strong></p>
<p>角色绑定用来把一个角色绑定到一个目标对象上，绑定目标可以是User、Group或者ServiceAccount。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># RoleBinding可以将同一namespace中的subject绑定到某个Role下，则此subject即具有该Role定义的权限</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">authorization-role-binding</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">heima</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">authorization-role</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ClusterRoleBinding在整个集群级别和所有namespaces将特定的subject与ClusterRole绑定，授予权限</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"> <span class="attr">name:</span> <span class="string">authorization-clusterrole-binding</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">heima</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">authorization-clusterrole</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure>

<p><strong>RoleBinding引用ClusterRole进行授权</strong></p>
<p>RoleBinding可以引用ClusterRole，对属于同一命名空间内ClusterRole定义的资源主体进行授权。</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">一种很常用的做法就是，集群管理员为集群范围预定义好一组角色（ClusterRole），然后在多个命名空间中重复使用这些ClusterRole。这样可以大幅提高授权管理工作效率，也使得各个命名空间下的基础性授权规则与使用体验保持一致。</span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 虽然authorization-clusterrole是一个集群角色，但是因为使用了RoleBinding</span></span><br><span class="line"><span class="comment"># 所以heima只能读取dev命名空间中的资源</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">authorization-role-binding-ns</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">heima</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">authorization-clusterrole</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure>

<p><strong>实战：创建一个只能管理dev空间下Pods资源的账号</strong></p>
<ol>
<li>创建账号</li>
</ol>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1) 创建证书</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">pki</span>]<span class="comment"># cd /etc/kubernetes/pki/</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">pki</span>]<span class="comment"># (umask 077;openssl genrsa -out devman.key 2048)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2) 用apiserver的证书去签署</span></span><br><span class="line"><span class="comment"># 2-1) 签名申请，申请的用户是devman,组是devgroup</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">pki</span>]<span class="comment"># openssl req -new -key devman.key -out devman.csr -subj &quot;/CN=devman/O=devgroup&quot;     </span></span><br><span class="line"><span class="comment"># 2-2) 签署证书</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">pki</span>]<span class="comment"># openssl x509 -req -in devman.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out devman.crt -days 3650</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3) 设置集群、用户、上下文信息</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">pki</span>]<span class="comment"># kubectl config set-cluster kubernetes --embed-certs=true --certificate-authority=/etc/kubernetes/pki/ca.crt --server=https://192.168.109.100:6443</span></span><br><span class="line"></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">pki</span>]<span class="comment"># kubectl config set-credentials devman --embed-certs=true --client-certificate=/etc/kubernetes/pki/devman.crt --client-key=/etc/kubernetes/pki/devman.key</span></span><br><span class="line"></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">pki</span>]<span class="comment"># kubectl config set-context devman@kubernetes --cluster=kubernetes --user=devman</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换账户到devman</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">pki</span>]<span class="comment"># kubectl config use-context devman@kubernetes</span></span><br><span class="line">Switched to context <span class="string">&quot;devman@kubernetes&quot;</span>.</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看dev下pod，发现没有权限</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">pki</span>]<span class="comment"># kubectl get pods -n dev</span></span><br><span class="line">Error from server (Forbidden): pods is forbidden: User <span class="string">&quot;devman&quot;</span> cannot list resource <span class="string">&quot;pods&quot;</span> <span class="keyword">in</span> API <span class="built_in">group</span> <span class="string">&quot;&quot;</span> <span class="keyword">in</span> the namespace <span class="string">&quot;dev&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换到admin账户</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">pki</span>]<span class="comment"># kubectl config use-context kubernetes-admin@kubernetes</span></span><br><span class="line">Switched to context <span class="string">&quot;kubernetes-admin@kubernetes&quot;</span>.</span><br></pre></td></tr></table></figure>

<p>2） 创建Role和RoleBinding，为devman用户授权</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">dev-role</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>]</span><br><span class="line">  <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;list&quot;</span>]</span><br><span class="line">  </span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">authorization-role-binding</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">devman</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">dev-role</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">pki</span>]<span class="comment"># kubectl create -f dev-role.yaml</span></span><br><span class="line">role.rbac.authorization.k8s.io/dev<span class="literal">-role</span> created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/authorization<span class="literal">-role-binding</span> created</span><br></pre></td></tr></table></figure>

<ol>
<li>切换账户，再次验证</li>
</ol>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 切换账户到devman</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">pki</span>]<span class="comment"># kubectl config use-context devman@kubernetes</span></span><br><span class="line">Switched to context <span class="string">&quot;devman@kubernetes&quot;</span>.</span><br><span class="line"></span><br><span class="line"><span class="comment"># 再次查看</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">pki</span>]<span class="comment"># kubectl get pods -n dev</span></span><br><span class="line">NAME                                 READY   STATUS             RESTARTS   AGE</span><br><span class="line">nginx<span class="literal">-deployment-66cb59b984-8wp2k</span>    <span class="number">1</span>/<span class="number">1</span>     Running            <span class="number">0</span>          <span class="number">4</span>d1<span class="built_in">h</span></span><br><span class="line">nginx<span class="literal">-deployment-66cb59b984-dc46j</span>    <span class="number">1</span>/<span class="number">1</span>     Running            <span class="number">0</span>          <span class="number">4</span>d1<span class="built_in">h</span></span><br><span class="line">nginx<span class="literal">-deployment-66cb59b984-thfck</span>    <span class="number">1</span>/<span class="number">1</span>     Running            <span class="number">0</span>          <span class="number">4</span>d1<span class="built_in">h</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为了不影响后面的学习,切回admin账户</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">pki</span>]<span class="comment"># kubectl config use-context kubernetes-admin@kubernetes</span></span><br><span class="line">Switched to context <span class="string">&quot;kubernetes-admin@kubernetes&quot;</span>.</span><br></pre></td></tr></table></figure>

<h2 id="准入控制"><a href="#准入控制" class="headerlink" title="准入控制"></a>准入控制</h2><p>通过了前面的认证和授权之后，还需要经过准入控制处理通过之后，apiserver才会处理这个请求。</p>
<p>准入控制是一个可配置的控制器列表，可以通过在Api-Server上通过命令行设置选择执行哪些准入控制器：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="literal">--admission-control</span>=NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel,</span><br><span class="line">                      DefaultStorageClass,ResourceQuota,DefaultTolerationSeconds</span><br></pre></td></tr></table></figure>

<p>只有当所有的准入控制器都检查通过之后，apiserver才执行该请求，否则返回拒绝。</p>
<p>当前可配置的Admission Control准入控制如下：</p>
<ul>
<li>AlwaysAdmit：允许所有请求</li>
<li>AlwaysDeny：禁止所有请求，一般用于测试</li>
<li>AlwaysPullImages：在启动容器之前总去下载镜像</li>
<li>DenyExecOnPrivileged：它会拦截所有想在Privileged Container上执行命令的请求</li>
<li>ImagePolicyWebhook：这个插件将允许后端的一个Webhook程序来完成admission controller的功能。</li>
<li>Service Account：实现ServiceAccount实现了自动化</li>
<li>SecurityContextDeny：这个插件将使用SecurityContext的Pod中的定义全部失效</li>
<li>ResourceQuota：用于资源配额管理目的，观察所有请求，确保在namespace上的配额不会超标</li>
<li>LimitRanger：用于资源限制管理，作用于namespace上，确保对Pod进行资源限制</li>
<li>InitialResources：为未设置资源请求与限制的Pod，根据其镜像的历史资源的使用情况进行设置</li>
<li>NamespaceLifecycle：如果尝试在一个不存在的namespace中创建资源对象，则该创建请求将被拒绝。当删除一个namespace时，系统将会删除该namespace中所有对象。</li>
<li>DefaultStorageClass：为了实现共享存储的动态供应，为未指定StorageClass或PV的PVC尝试匹配默认的StorageClass，尽可能减少用户在申请PVC时所需了解的后端存储细节</li>
<li>DefaultTolerationSeconds：这个插件为那些没有设置forgiveness tolerations并具有notready:NoExecute和unreachable:NoExecute两种taints的Pod设置默认的“容忍”时间，为5min</li>
<li>PodSecurityPolicy：这个插件用于在创建或修改Pod时决定是否根据Pod的security context和可用的PodSecurityPolicy对Pod的安全策略进行控制</li>
</ul>
<h1 id="第十章-DashBoard"><a href="#第十章-DashBoard" class="headerlink" title="第十章 DashBoard"></a>第十章 DashBoard</h1><pre><code>之前在kubernetes中完成的所有操作都是通过命令行工具kubectl完成的。其实，为了提供更丰富的用户体验，kubernetes还开发了一个基于web的用户界面（Dashboard）。用户可以使用Dashboard部署容器化的应用，还可以监控应用的状态，执行故障排查以及管理kubernetes中各种资源。
</code></pre>
<h2 id="部署Dashboard"><a href="#部署Dashboard" class="headerlink" title="部署Dashboard"></a>部署Dashboard</h2><ol>
<li>下载yaml，并运行Dashboard</li>
</ol>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 下载yaml</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># wget  https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0/aio/deploy/recommended.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改kubernetes-dashboard的Service类型</span></span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s<span class="literal">-app</span>: kubernetes<span class="literal">-dashboard</span></span><br><span class="line">  name: kubernetes<span class="literal">-dashboard</span></span><br><span class="line">  namespace: kubernetes<span class="literal">-dashboard</span></span><br><span class="line">spec:</span><br><span class="line">  <span class="built_in">type</span>: NodePort  <span class="comment"># 新增</span></span><br><span class="line">  ports:</span><br><span class="line">    - port: <span class="number">443</span></span><br><span class="line">      targetPort: <span class="number">8443</span></span><br><span class="line">      nodePort: <span class="number">30009</span>  <span class="comment"># 新增</span></span><br><span class="line">  selector:</span><br><span class="line">    k8s<span class="literal">-app</span>: kubernetes<span class="literal">-dashboard</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 部署</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f recommended.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看namespace下的kubernetes-dashboard下的资源</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get pod,svc -n kubernetes-dashboard</span></span><br><span class="line">NAME                                            READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/dashboard<span class="literal">-metrics-scraper-c79c65bb7-zwfvw</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">111</span>s</span><br><span class="line">pod/kubernetes<span class="literal">-dashboard-56484d4c5-z95z5</span>        <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">111</span>s</span><br><span class="line"></span><br><span class="line">NAME                               <span class="built_in">TYPE</span>       CLUSTER<span class="literal">-IP</span>      EXTERNAL<span class="literal">-IP</span>  PORT(S)         AGE</span><br><span class="line">service/dashboard<span class="literal">-metrics-scraper</span>  ClusterIP  <span class="number">10.96</span>.<span class="number">89.218</span>    &lt;none&gt;       <span class="number">8000</span>/TCP        <span class="number">111</span>s</span><br><span class="line">service/kubernetes<span class="literal">-dashboard</span>       NodePort   <span class="number">10.104</span>.<span class="number">178.171</span>  &lt;none&gt;       <span class="number">443</span>:<span class="number">30009</span>/TCP   <span class="number">111</span>s</span><br></pre></td></tr></table></figure>

<p>2）创建访问账户，获取token</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建账号</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span>-<span class="number">1</span> ~]<span class="comment"># kubectl create serviceaccount dashboard-admin -n kubernetes-dashboard</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 授权</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span>-<span class="number">1</span> ~]<span class="comment"># kubectl create clusterrolebinding dashboard-admin-rb --clusterrole=cluster-admin --serviceaccount=kubernetes-dashboard:dashboard-admin</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取账号token</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment">#  kubectl get secrets -n kubernetes-dashboard | grep dashboard-admin</span></span><br><span class="line">dashboard<span class="literal">-admin-token-xbqhh</span>        kubernetes.io/service<span class="literal">-account-token</span>   <span class="number">3</span>      <span class="number">2</span>m35s</span><br><span class="line"></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl describe secrets dashboard-admin-token-xbqhh -n kubernetes-dashboard</span></span><br><span class="line">Name:         dashboard<span class="literal">-admin-token-xbqhh</span></span><br><span class="line">Namespace:    kubernetes<span class="literal">-dashboard</span></span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubernetes.io/service<span class="literal">-account</span>.name: dashboard<span class="literal">-admin</span></span><br><span class="line">              kubernetes.io/service<span class="literal">-account</span>.uid: <span class="number">95</span>d84d80<span class="literal">-be7a-4d10-a2e0-68f90222d039</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">Type</span>:  kubernetes.io/service<span class="literal">-account-token</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">Data</span></span><br><span class="line">====</span><br><span class="line">namespace:  <span class="number">20</span> bytes</span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6ImJrYkF4bW5XcDhWcmNGUGJtek5NODFuSXl1aWptMmU2M3o4LTY5a2FKS2cifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4teGJxaGgiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiOTVkODRkODAtYmU3YS00ZDEwLWEyZTAtNjhmOTAyMjJkMDM5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmVybmV0ZXMtZGFzaGJvYXJkOmRhc2hib2FyZC1hZG1pbiJ9.NAl7e8ZfWWdDoPxkqzJzTB46sK9E8iuJYnUI9vnBaY3Jts7T1g1msjsBnbxzQSYgAG<span class="literal">--cV0WYxjndzJY_UWCwaGPrQrt_GunxmOK9AUnzURqm55GR2RXIZtjsWVP2EBatsDgHRmuUbQvTFOvdJB4x3nXcYLN2opAaMqg3rnU2rr-A8zCrIuX_eca12wIp_QiuP3SF-tzpdLpsyRfegTJZl6YnSGyaVkC9id-cxZRb307qdCfXPfCHR_2rt5FVfxARgg_C0e3eFHaaYQO7CitxsnIoIXpOFNAR8aUrmopJyODQIPqBWUehb7FhlU1DCduHnIIXVC_UICZ-MKYewBDLw</span></span><br><span class="line">ca.crt:     <span class="number">1025</span> bytes</span><br></pre></td></tr></table></figure>

<p>3）通过浏览器访问Dashboard的UI</p>
<p>在登录页面上输入上面的token</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200520144548997.png" alt="image-20200520144548997"></p>
<p>出现下面的页面代表成功</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200520144959353.png" alt="image-20200520144959353" style="border:1px solid;" />

<h2 id="使用DashBoard"><a href="#使用DashBoard" class="headerlink" title="使用DashBoard"></a>使用DashBoard</h2><p>本章节以Deployment为例演示DashBoard的使用</p>
<p><strong>查看</strong></p>
<p>选择指定的命名空间<code>dev</code>，然后点击<code>Deployments</code>，查看dev空间下的所有deployment</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200520154628679.png" style="border:1px solid;" />

<p><strong>扩缩容</strong></p>
<p>在<code>Deployment</code>上点击<code>规模</code>，然后指定<code>目标副本数量</code>，点击确定</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200520162605102.png" style="border:1px solid;" />

<p><strong>编辑</strong></p>
<p>在<code>Deployment</code>上点击<code>编辑</code>，然后修改<code>yaml文件</code>，点击确定</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200520163253644.png" alt="image-20200520163253644" style="border:1px solid;" />

<p><strong>查看Pod</strong></p>
<p>点击<code>Pods</code>, 查看pods列表</p>
<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200520163552110.png" style="border:1px solid;" />

<p><strong>操作Pod</strong></p>
<p>选中某个Pod，可以对其执行日志（logs）、进入执行（exec）、编辑、删除操作</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image-20200520163832827.png" alt="image-20200520163832827"></p>
<blockquote>
<p>Dashboard提供了kubectl的绝大部分功能，这里不再一一演示</p>
</blockquote>
]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s常见的问题处理</title>
    <url>/2022/12/28/k8s%E5%B8%B8%E8%A7%81%E7%9A%84%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<h2 id="Coredns容器或local-dns容器重启"><a href="#Coredns容器或local-dns容器重启" class="headerlink" title="Coredns容器或local-dns容器重启"></a>Coredns容器或local-dns容器重启</h2><p>集群中的coredns组件发生重启(重新创建)，一般是由于coredns组件压力较大导致oom，请检查业务是否异常，是否存在应用容器无法解析域名的异常。</p>
<p>如果是local-dns重启，说明local-dns的性能也不够了，需要优化</p>
<h2 id="Pod-was-OOM-killed"><a href="#Pod-was-OOM-killed" class="headerlink" title="Pod was OOM killed"></a>Pod was OOM killed</h2><p>云应用容器实例发生OOM，请检查云应用是否正常。一般地，如果云应用配置了健康检查，当进程OOM了，健康检查如果失败，集群会自动重启容器。</p>
<p>OOM问题排查步骤：</p>
<p>检查应用进程内存配置，如Java的jvm参数，对比应用监控-基础监控中的内存指标，判断是否是参数设置低导致进程内存不够用，适当进行参数优化</p>
<h2 id="Out-of-memory-Kill-process"><a href="#Out-of-memory-Kill-process" class="headerlink" title="Out of memory: Kill process"></a>Out of memory: Kill process</h2><h3 id="原因描述"><a href="#原因描述" class="headerlink" title="原因描述"></a>原因描述</h3><p>一般是操作系统把容器内进程Kill而导致的系统内核事件。比如一个java应用，当实际占用内存超过堆内存配置大小时，就会出现OOM错误。发生进程被Kill之后，容器依旧是存活状态，容器的健康检查还会继续进行。所以后面通常会伴随出现健康检查失败的错误。</p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>要具体分析进程被Kill的原因，适当的调整进程内存的限制值。可以结合应用监控来参考进程内存的变化趋势。</p>
<h2 id="Memory-cgroup-out-of-memory-Kill-process"><a href="#Memory-cgroup-out-of-memory-Kill-process" class="headerlink" title="Memory cgroup out of memory: Kill process"></a>Memory cgroup out of memory: Kill process</h2><h3 id="原因描述-1"><a href="#原因描述-1" class="headerlink" title="原因描述"></a>原因描述</h3><p>一般是由于容器的内存实际使用量超过了容器内存限制值而导致的事件。比如容器的内存限制值配置了1Gi，而容器的内存随着容器内进程内存使用量的增加超过了1Gi，就会导致容器被操作系统Cgroup Kill。发生容器被Kill之后，容器已经被停止，所以后续会出现应用实例被重启的情况。</p>
<h3 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h3><p>检查容器内进程是否有内存泄漏问题，同时适当调整容器内存的限制值大小。可以结合应用监控来看变化趋势。需要注意的是，容器内存限制值大小不应该过大，否则可能导致极端资源争抢情况下，容器被迫驱逐的问题。</p>
<h2 id="System-OOM-encountered"><a href="#System-OOM-encountered" class="headerlink" title="System OOM encountered"></a>System OOM encountered</h2><h3 id="原因描述-2"><a href="#原因描述-2" class="headerlink" title="原因描述"></a>原因描述</h3><p>上述两种OOM（进程OOM，容器OOM）发生后，都可能会伴随一个系统OOM事件，该事件的原因是由上述OOM事件伴随导致。</p>
<h3 id="解决方案-2"><a href="#解决方案-2" class="headerlink" title="解决方案"></a>解决方案</h3><p>需要解决上面进程OOM或者容器CgroupOOM的问题。</p>
<h2 id="failed-to-garbage-collect-required-amount-of-images"><a href="#failed-to-garbage-collect-required-amount-of-images" class="headerlink" title="failed to garbage collect required amount of images"></a>failed to garbage collect required amount of images</h2><h3 id="原因描述-3"><a href="#原因描述-3" class="headerlink" title="原因描述"></a>原因描述</h3><p>当容器集群中的节点（宿主机）磁盘使用率达到85%之后，会触发自动的容器镜像回收策略，以便于释放足够的宿主机磁盘。该事件发生于当触发镜像回收策略之后，磁盘空间仍然不足以达到健康阈值（默认为80%）。通常该错误是由于宿主机磁盘被占用太多导致。当磁盘空间占用率持续增长（超过90%），会导致该节点上的所有容器被驱逐，也就是当前节点由于磁盘压力不再对外提供服务，直到磁盘空间释放。</p>
<h3 id="解决方案："><a href="#解决方案：" class="headerlink" title="解决方案："></a>解决方案：</h3><p>检查节点的磁盘分配情况，通常有以下一些常见情况导致磁盘占用率过高：</p>
<p>有大量日志在磁盘上没有清理；请清理日志。<br>有进程在宿主机不停的写文件；请控制文件大小，将文件存储至OSS或者NAS。<br>下载的或者是其他的静态资源文件占用空间过大；静态资源请存储至OSS或CDN。</p>
<h2 id="Attempting-to-xxxx"><a href="#Attempting-to-xxxx" class="headerlink" title="Attempting to xxxx"></a>Attempting to xxxx</h2><p>节点资源不足(EvictionThresholdMet)，一般是节点资源将要达到阈值，可能会触发Pod驱逐。如 Attempting to reclaim ephemeral-storage</p>
<h3 id="原因描述-4"><a href="#原因描述-4" class="headerlink" title="原因描述"></a>原因描述</h3><p>ephemeral storage是临时存储空间，当磁盘空间使用率达到阈值，会触发临时存储空间的回收任务。回收任务会尝试回收系统日志，以及没有正在使用的镜像缓存等数据。当磁盘空间占用率持续增长（超过90%），会导致该节点上的所有容器被驱逐，也就是当前节点由于磁盘压力不再对外提供服务，直到磁盘空间释放。</p>
<h3 id="解决方案-3"><a href="#解决方案-3" class="headerlink" title="解决方案"></a>解决方案</h3><p>请注意磁盘空间的使用：</p>
<p>避免使用“空目录”类型的挂载方式；使用NAS或者其他类似方式替代。<br>尽量避免使用“宿主机目录”类型的挂载方式，以便于保证容器是无状态的，可以迁移的。<br>要注意避免在容器内大量写文件，而导致容器运行时可写数据层过大（imagefs）。</p>
<h2 id="NTP-service-is-not-running"><a href="#NTP-service-is-not-running" class="headerlink" title="NTP service is not running"></a>NTP service is not running</h2><h3 id="原因描述-5"><a href="#原因描述-5" class="headerlink" title="原因描述"></a>原因描述</h3><p>NTP service是系统时间校准服务，由操作系统systemd管理的服务。可以通过 systemctl status chronyd 查看对应服务的状态。</p>
<h3 id="解决方案-4"><a href="#解决方案-4" class="headerlink" title="解决方案"></a>解决方案</h3><p>使用命令systemctl start chronyd尝试重新启动。也可以通过命令 journalctl -u chronyd 查看服务的日志。</p>
<h2 id="节点PLEG异常"><a href="#节点PLEG异常" class="headerlink" title="节点PLEG异常"></a>节点PLEG异常</h2><h3 id="原因描述-6"><a href="#原因描述-6" class="headerlink" title="原因描述"></a>原因描述</h3><p>PLEG是pod生命周期事件生成器，会记录Pod生命周期中的各种事件，如容器的启动、终止等。一般是由于节点上的daemon进程异常或者节点systemd版本bug导致。出现该问题会导致集群节点不可用</p>
<h3 id="解决方案-5"><a href="#解决方案-5" class="headerlink" title="解决方案"></a>解决方案</h3><p>可以尝试重启kubelet；再尝试重启Docker进程。重启这两个进程过程中，不会对已运行容器造成影响</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">//重启kubelet</span><br><span class="line">systemctl restart kubelet</span><br><span class="line"></span><br><span class="line">//重启docker</span><br><span class="line">systemctl restart docker</span><br><span class="line"></span><br><span class="line">//查看docker日志</span><br><span class="line">journalctl -xeu docker &gt; docker.log</span><br><span class="line">如果是由于systemd版本问题导致，重启节点可短暂修复，彻底解决的话需要升级节点的systemd</span><br><span class="line"></span><br><span class="line">systemd: (rpm -qa | grep systemd, 版本&lt;219-67.el7需要升级)</span><br><span class="line">升级systemd指令: </span><br><span class="line">yum update -y systemd &amp;&amp; systemctl daemon-reexec &amp;&amp; killall runc</span><br></pre></td></tr></table></figure>

<h2 id="节点PID不足"><a href="#节点PID不足" class="headerlink" title="节点PID不足"></a>节点PID不足</h2><h3 id="问题原因"><a href="#问题原因" class="headerlink" title="问题原因"></a>问题原因</h3><p>通常是节点上的容器占用PID过多导致节点的PID不足</p>
<h3 id="问题现象"><a href="#问题现象" class="headerlink" title="问题现象"></a>问题现象</h3><p>当节点的可用PID低于pid.available配置项时，则节点状态中NodePIDPressure为True，同时该节点上的容器被驱逐。关于节点驱逐，请参见节点压力驱逐。<br>若集群配置了集群节点异常报警，则节点PID不足时可收到相关报警。关于配置报警，请参见容器服务报警管理。</p>
<h3 id="解决方案-6"><a href="#解决方案-6" class="headerlink" title="解决方案"></a>解决方案</h3><p>执行如下命令，查看节点的最大PID数和节点当前的最大PID。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sysctl kernel.pid_max  <span class="comment">#查看最大PID数。</span></span><br><span class="line">  ps -eLf|awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span> | <span class="built_in">sort</span> -rn| <span class="built_in">head</span> -n 1   <span class="comment">#查看当前的最大PID。</span></span><br><span class="line">执行如下命令，查看占用PID最多的前5个进程。</span><br><span class="line">ps -elT | awk <span class="string">&#x27;&#123;print $4&#125;&#x27;</span> | <span class="built_in">sort</span> | <span class="built_in">uniq</span> -c | <span class="built_in">sort</span> -k1 -g | <span class="built_in">tail</span> -5</span><br><span class="line">预期输出：</span><br><span class="line"></span><br><span class="line"><span class="comment">#第一列为进程占用的PID数，第二列为当前进程号。</span></span><br><span class="line">73 9743</span><br><span class="line">75 9316</span><br><span class="line">76 2812</span><br><span class="line">77 5726</span><br><span class="line">93 5691</span><br></pre></td></tr></table></figure>

<p>根据进程号找到对应进程和所属的Pod，分析占用PID过多的原因并优化对应代码。<br>降低节点的负载。具体操作，请参见节点调度资源不足。<br>如需重启节点，可尝试重启异常节点。具体操作，请参见重启实例。</p>
<h2 id="节点FD不足"><a href="#节点FD不足" class="headerlink" title="节点FD不足"></a>节点FD不足</h2><h3 id="原因描述："><a href="#原因描述：" class="headerlink" title="原因描述："></a>原因描述：</h3><p>节点文件句柄使用数量超过80%，具体原因与节点上进程使用情况相关打开文件未释放打开管道未释放建立网络连接未释放（pipe,eventpoll多出现在 NIO 网络编程未释放资源 —— selector.close()）创建进程调用命令未释放（Runtime.exe(…) 得到的 Process, InputStream, OutputStream 未关闭，这也会导致 pipe,eventpoll 未释放）</p>
<h2 id="解决方案：-1"><a href="#解决方案：-1" class="headerlink" title="解决方案："></a>解决方案：</h2><p>删除不需要的文件，调整应用代码，文件流等操作结束后记得关闭。或者尝试先排空再重启主机</p>
<h2 id="节点Docker-Hung"><a href="#节点Docker-Hung" class="headerlink" title="节点Docker Hung"></a>节点Docker Hung</h2><h3 id="原因描述：-1"><a href="#原因描述：-1" class="headerlink" title="原因描述："></a>原因描述：</h3><p>节点docker daemon异常，导致集群无法与之通信，伴随有docker ps、docker exec等命令hung住或异常失败</p>
<h3 id="解决方案：-2"><a href="#解决方案：-2" class="headerlink" title="解决方案："></a>解决方案：</h3><p>尝试重启docker服务，重启过程不会影响已存在容器的运行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">//重启节点上的docker daemon，对运行中容器没有影响</span><br><span class="line">systemctl restart docker</span><br><span class="line"></span><br><span class="line">//查看docker日志</span><br><span class="line">journalctl -xeu docker &gt; docker.log</span><br></pre></td></tr></table></figure>

<p>如果docker服务重启后依然无法解决，可以尝试重启主机。主机重启过程会对容器有影响，谨慎操作。</p>
<h2 id="节点磁盘资源不足"><a href="#节点磁盘资源不足" class="headerlink" title="节点磁盘资源不足"></a>节点磁盘资源不足</h2><p>InvalidDiskCapacity</p>
<h3 id="原因描述-7"><a href="#原因描述-7" class="headerlink" title="原因描述"></a>原因描述</h3><p>节点磁盘不足，无法分配空间给容器镜像</p>
<h3 id="解决方案-7"><a href="#解决方案-7" class="headerlink" title="解决方案"></a>解决方案</h3><p>检查节点的磁盘分配情况，通常有以下一些常见情况导致磁盘占用率过高：</p>
<p>有大量日志在磁盘上没有清理；请清理日志。<br>有进程在宿主机不停的写文件；请控制文件大小，将文件存储至OSS或者NAS。<br>下载的或者是其他的静态资源文件占用空间过大；静态资源请存储至OSS或CDN。</p>
<h2 id="应用相关"><a href="#应用相关" class="headerlink" title="应用相关"></a>应用相关</h2><h3 id="Container-Restart"><a href="#Container-Restart" class="headerlink" title="Container Restart"></a>Container Restart</h3><h4 id="原因描述：-2"><a href="#原因描述：-2" class="headerlink" title="原因描述："></a>原因描述：</h4><p>该事件表示应用实例(重启)重启，一般是由于配置了健康检查且健康检查失败导致，会伴随有Readiness probe failed和Liveness probe failed等事件。健康检查失败的原因有很多，通常情况下，比如进程OOM被Kill、比如高负载情况下应用无法正常响应(例如RDS瓶颈导致应用线程全部hang住)，都可能会导致健康检查失败</p>
<h4 id="解决方案：-3"><a href="#解决方案：-3" class="headerlink" title="解决方案："></a>解决方案：</h4><p>需要结合临近的相关事件定位具体的Pod重启原因。如伴随有集群相关的Out of memory事件，参考此文档上面Out of memory事件的解决方案；其他情况下，结合应用监控或者云产品自身监控来定位问题</p>
<h3 id="The-node-had-condition-XXX"><a href="#The-node-had-condition-XXX" class="headerlink" title="The node had condition: [XXX]"></a>The node had condition: [XXX]</h3><h4 id="原因描述：-3"><a href="#原因描述：-3" class="headerlink" title="原因描述："></a>原因描述：</h4><p>该事件表示Pod由于节点上的异常情况被驱逐，比如<em>The node had condition: [DiskPressure]，</em>表示节点磁盘使用率比较高，通常会伴随有 failed to garbage collect required amount of images 和 Attempting to reclaim ephemeral-storage 等集群维度(节点)的异常事件</p>
<h4 id="解决方案：-4"><a href="#解决方案：-4" class="headerlink" title="解决方案："></a>解决方案：</h4><p>需要结合临近的相关事件定位具体的驱逐原因。对于已经被驱逐的Pod实例，可以通过kubectl get po 进行查看和手动清理</p>
<h3 id="K8S-Pod-Pending"><a href="#K8S-Pod-Pending" class="headerlink" title="K8S Pod Pending"></a>K8S Pod Pending</h3><h4 id="原因描述：-4"><a href="#原因描述：-4" class="headerlink" title="原因描述："></a>原因描述：</h4><p>该事件表示集群调度Pod被挂起，一般是由于节点资源不足以调度容器或者Volume挂载失败（比如持久化存储卷找不到）或者其他原因导致。</p>
<h4 id="解决方案：-5"><a href="#解决方案：-5" class="headerlink" title="解决方案："></a>解决方案：</h4><p>需要结合临近的相关事件定位具体的Pod挂起原因</p>
<h3 id="Readiness-probe-failed"><a href="#Readiness-probe-failed" class="headerlink" title="Readiness probe failed"></a>Readiness probe failed</h3><h4 id="原因描述-8"><a href="#原因描述-8" class="headerlink" title="原因描述"></a>原因描述</h4><p>由于应用就绪探针失败而引发的异常事件。应用就绪探针失败会导致相应容器的流量被摘除，例如被动从SLB摘掉该容器的流量入口。</p>
<h4 id="解决方案-8"><a href="#解决方案-8" class="headerlink" title="解决方案"></a>解决方案</h4><p>需要结合应用就绪探针的配置，定位应用就绪探针失败的原因。</p>
<h3 id="Liveness-probe-failed"><a href="#Liveness-probe-failed" class="headerlink" title="Liveness probe failed"></a>Liveness probe failed</h3><h4 id="原因描述：-5"><a href="#原因描述：-5" class="headerlink" title="原因描述："></a>原因描述：</h4><p>由于应用存活探针失败而引发的异常事件。该事件可能会导致后续达到一定阈值之后，容器被动重启。具体要看应用就绪探针的配置。</p>
<h4 id="解决方案：-6"><a href="#解决方案：-6" class="headerlink" title="解决方案："></a>解决方案：</h4><p>需要结合应用存活探针的配置，定位探针检查失败的原因。</p>
<h3 id="Container-runtime-did-not-kill-the-pod-within-specified-grace-period"><a href="#Container-runtime-did-not-kill-the-pod-within-specified-grace-period" class="headerlink" title="Container runtime did not kill the pod within specified grace period."></a>Container runtime did not kill the pod within specified grace period.</h3><h4 id="原因描述：-6"><a href="#原因描述：-6" class="headerlink" title="原因描述："></a>原因描述：</h4><p>此事件表示容器没有在优雅下线的时间段内正常退出。比如如果配置了优雅下线脚本，脚本执行时长需要60s，而优雅下线时间（默认为30s）配置为30s。就会在容器下线期间触发这个事件。</p>
<h4 id="解决方案：-7"><a href="#解决方案：-7" class="headerlink" title="解决方案："></a>解决方案：</h4><p>调整优雅下线探针的配置，或者优雅下线时间的配置。</p>
<h3 id="Back-off-restarting-failed-container"><a href="#Back-off-restarting-failed-container" class="headerlink" title="Back-off restarting failed container"></a>Back-off restarting failed container</h3><h4 id="原因描述：-7"><a href="#原因描述：-7" class="headerlink" title="原因描述："></a>原因描述：</h4><p>此事件表示容器启动失败，而被再次拉起尝试启动。通常常见与应用发布过程中的容器启动失败。具体的原因常见为镜像拉取失败，或者容器启动失败（容器没有打到running状态）。</p>
<h4 id="解决方案：-8"><a href="#解决方案：-8" class="headerlink" title="解决方案："></a>解决方案：</h4><p>需要在发布页查看容器启动日志或者调度日志，进一步定位容器启动失败的原因。</p>
<h3 id="The-node-was-low-on-resource-xxxx"><a href="#The-node-was-low-on-resource-xxxx" class="headerlink" title="The node was low on resource: xxxx"></a>The node was low on resource: xxxx</h3><h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">2020-07-21 10:24:43.000 [Event] Type: Warning, Reason: Evicted, Message: The node was low on resource: ephemeral-storage. </span><br></pre></td></tr></table></figure>

<h4 id="原因描述：-8"><a href="#原因描述：-8" class="headerlink" title="原因描述："></a>原因描述：</h4><p>该事件表示Pod由于节点上的异常情况(资源不足)被驱逐</p>
<h4 id="解决方案-9"><a href="#解决方案-9" class="headerlink" title="解决方案"></a>解决方案</h4><p>需要看具体哪类资源不足，例如示例中的ephemeral-storage，表示集群节点临时存储空间不足，一般是由于磁盘使用量较大导致。请参考文档上方解决方案</p>
<p>检查节点的磁盘分配情况，通常有以下一些常见情况导致磁盘占用率过高：</p>
<p>有大量日志在磁盘上没有清理；请清理日志。<br>有进程在宿主机不停的写文件；请控制文件大小，将文件存储至OSS或者NAS。<br>下载的或者是其他的静态资源文件占用空间过大；静态资源请存储至OSS或CDN。<br>可以对系统盘进行扩容，扩大磁盘空间。</p>
<h3 id="集群DNS性能瓶颈"><a href="#集群DNS性能瓶颈" class="headerlink" title="集群DNS性能瓶颈"></a>集群DNS性能瓶颈</h3><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>集群中的容器实例，DNS解析均依赖集群内的DNS组件，应用中业务请求的地址都需要经过集群DNS组件。例如，代码中访问RDS、REDIS、TOP api等。如果集群dns性能不足，会出现业务请求失败的问题。</p>
<p>集群DNS组件：</p>
<p>默认已安装的集群组件为coredns，副本数为2<br>可选的高性能组件为localdns</p>
<h4 id="是否有性能瓶颈"><a href="#是否有性能瓶颈" class="headerlink" title="是否有性能瓶颈"></a>是否有性能瓶颈</h4><p>应用有大量DNS请求的场景(比如连接rds，凡是涉及到域名地址解析的)<br>PHP等语言自身没有连接池特性的，或者应用自身没有DNS缓存的<br>偶尔出现域名地址无法解析错误的</p>
<h4 id="解决方案-10"><a href="#解决方案-10" class="headerlink" title="解决方案"></a>解决方案</h4><p>一、集群默认已安装的coredns组件，进行扩容。扩容比例为1&#x2F;5的节点数(如15台ecs，那么coredns数量为3)</p>
<p>二、为集群安装更高性能的localdns组件(该组件为daemonset，会在每个ECS节点起一个本地缓存)</p>
<p>一般来说，如果业务量小，扩容下coredns就足够了；如果业务量大(域名地址解析QPS高，比如访问RDS)，特别是php等不带连接池的开发语言，建议直接上localdns。如果是java等配置了连接池的应用，可以先扩容coredns观察，如果仍然有解析问题，再上localdns。</p>
<h3 id="localdns缓存原理"><a href="#localdns缓存原理" class="headerlink" title="localdns缓存原理"></a>localdns缓存原理</h3><p>NodeLocalDNS 是一个 DaemonSet，会在Kubernetes集群的每个节点上运行一个专门处理 DNS 查询请求的 Pod，该 Pod 会将集群内部域名查询请求发往 CoreDNS；将集群外部请求直接发往外部域名解析服务器。同时能够Cache所有请求。可以被看作是节点级别的高效DNS 缓存，能够大幅提高集群整体 DNS 查询的 QPS。NodeLocalDNS 会在集群的每个节点上创建一个专用的虚拟接口（接口绑定的 IP 需要通过 local_dns_ip 这个值来指定），节点上所有发往该 IP 的 DNS 查询请求都会被拦截到 NodeLocalDNS Pod 内进行处理；通过集群原有的 kube-dns 服务（该服务的 clusterIP 值需要通过kube_dns_ip来指定）来与CoreDNS进行通信。<br><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/image.png" alt="image"></p>
]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>用 Ansible 简化 K8S 部署</title>
    <url>/2023/01/12/k8s%E9%83%A8%E7%BD%B2ceph/</url>
    <content><![CDATA[<h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><blockquote>
<p><em>Ceph 在 k8s 中用做共享存储还是非常方便的，Ceph 是比较老牌的分布式存储系统，非常成熟，功能也强大，支持三种模式（快存储、文件系统存储、对象存储），所以接下来就详细讲解如何在 k8s 使用 ceph，关于 ceph 的介绍可以参考以下几篇文章：</em></p>
</blockquote>
<ul>
<li>[*分布式存储系统 Ceph 环境部署*](<a href="https://blog.kkun.site/2023/01/05/Ceph">https://blog.kkun.site/2023/01/05/Ceph</a> 环境部署)</li>
<li>[*分布式存储系统 Ceph操作*](<a href="https://blog.kkun.site/2023/01/09/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F">https://blog.kkun.site/2023/01/09/分布式存储系统</a> Ceph操作)</li>
</ul>
<p>前提是需要一个 k8s 环境，</p>
<h2 id="二、Ceph-Rook-介绍"><a href="#二、Ceph-Rook-介绍" class="headerlink" title="二、Ceph Rook 介绍"></a>二、Ceph Rook 介绍</h2><blockquote>
<p><em><code>Rook</code>是一个开源的<strong>云原生存储编排工具</strong>，**提供平台、框架和对各种存储解决方案的支持，以和云原生环境进行本地集成。</em></p>
</blockquote>
<ul>
<li>Rook 将存储软件转变成自我管理、自我扩展和自我修复的存储服务，通过自动化部署、启动、配置、供应、扩展、升级、迁移、灾难恢复、监控和资源管理来实现。Rook 底层使用云原生容器管理、调度和编排平台提供的能力来提供这些功能。</li>
<li>Rook 利用扩展功能将其深度地集成到云原生环境中，并为调度、生命周期管理、资源管理、安全性、监控等提供了无缝的体验。有关 Rook 当前支持的存储解决方案的状态相关的更多详细信息，可以参考 Rook 仓库 的项目介绍。Rook 目前支持 Ceph、NFS、Minio Object Store 和 CockroachDB。</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301121532495.png" alt="图片"></p>
<blockquote>
<p><em>官网: <a href="https://rook.io/">https://rook.io/</a></em><br><em>项目地址: <a href="https://github.com/rook">https://github.com/rook</a></em>*</p>
</blockquote>
<h2 id="三、通过-Rook-在-k8s-中部署-Ceph"><a href="#三、通过-Rook-在-k8s-中部署-Ceph" class="headerlink" title="三、通过 Rook 在 k8s 中部署 Ceph"></a>三、通过 Rook 在 k8s 中部署 Ceph</h2><blockquote>
<p><em>官方文档: <a href="https://rook.io/docs/rook/v1.10/Getting-Started/quickstart/">https://rook.io/docs/rook/v1.10/Getting-Started/quickstart/</a></em><br><em>【温馨提示】k8s 节点各挂载一块（或者多块）20GB 的未使用的磁盘。</em></p>
</blockquote>
<h3 id="1）下载部署包"><a href="#1）下载部署包" class="headerlink" title="1）下载部署包"></a>1）下载部署包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> --single-branch --branch v1.10.8 https://github.com/rook/rook.git</span><br></pre></td></tr></table></figure>

<p>部署所用到的镜像如下：<br><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301121530144.png" alt="图片"></p>
<p>由于镜像源在国外，国内无法下载，这里需要修改一些镜像或者提前下载 tag，操作如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> rook/deploy/examples/</span><br><span class="line"></span><br><span class="line"><span class="comment">#(registry.aliyuncs.com/google_containers/&lt;image&gt;:&lt;tag&gt;)，后四个镜像我FQ下</span></span><br><span class="line">docker pull registry.aliyuncs.com/google_containers/csi-node-driver-registrar:v2.5.1</span><br><span class="line"></span><br><span class="line">docker tag registry.aliyuncs.com/google_containers/csi-node-driver-registrar:v2.5.1 registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.5.1</span><br><span class="line"></span><br><span class="line">docker pull registry.aliyuncs.com/google_containers/csi-snapshotter:v6.1.0</span><br><span class="line">docker tag registry.aliyuncs.com/google_containers/csi-snapshotter:v6.1.0 registry.k8s.io/sig-storage/csi-snapshotter:v6.1.0</span><br><span class="line"></span><br><span class="line">docker pull registry.aliyuncs.com/google_containers/csi-attacher:v4.0.0</span><br><span class="line">docker tag registry.aliyuncs.com/google_containers/csi-attacher:v4.0.0 registry.k8s.io/sig-storage/csi-attacher:v4.0.0</span><br><span class="line"></span><br><span class="line">docker pull registry.aliyuncs.com/google_containers/csi-resizer:v1.6.0</span><br><span class="line">docker tag registry.aliyuncs.com/google_containers/csi-resizer:v1.6.0 registry.k8s.io/sig-storage/csi-resizer:v1.6.0</span><br><span class="line"></span><br><span class="line">docker pull registry.aliyuncs.com/google_containers/csi-resizer:v1.6.0</span><br><span class="line">docker tag registry.aliyuncs.com/google_containers/csi-resizer:v1.6.0 registry.k8s.io/sig-storage/csi-resizer:v1.6.0</span><br><span class="line"></span><br><span class="line">docker pull registry.aliyuncs.com/google_containers/csi-provisioner:v3.3.0</span><br><span class="line">docker tag registry.aliyuncs.com/google_containers/csi-provisioner:v3.3.0 registry.k8s.io/sig-storage/csi-provisioner:v3.3.0</span><br></pre></td></tr></table></figure>

<h3 id="2）部署-Rook-Operator"><a href="#2）部署-Rook-Operator" class="headerlink" title="2）部署 Rook Operator"></a>2）部署 Rook Operator</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> rook/deploy/examples</span><br><span class="line">kubectl create -f crds.yaml -f common.yaml -f operator.yaml</span><br><span class="line"><span class="comment"># 检查</span></span><br><span class="line">kubectl -n rook-ceph get pod</span><br></pre></td></tr></table></figure>

<p>也可以通过 helm 部署</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm repo add rook-release https://charts.rook.io/release</span><br><span class="line">helm install --create-namespace --namespace rook-ceph rook-ceph rook-release/rook-ceph -f values.yaml</span><br></pre></td></tr></table></figure>

<h3 id="3）创建-Rook-Ceph-集群"><a href="#3）创建-Rook-Ceph-集群" class="headerlink" title="3）创建 Rook Ceph 集群"></a>3）创建 Rook Ceph 集群</h3><p>现在 Rook Operator 处于 Running 状态，接下来我们就可以创建 Ceph 集群了。为了使集群在重启后不受影响，请确保设置的 dataDirHostPath 属性值为有效得主机路径。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> rook/deploy/examples</span><br><span class="line">kubectl apply -f cluster.yaml</span><br></pre></td></tr></table></figure>

<h3 id="4）部署-Rook-Ceph-工具"><a href="#4）部署-Rook-Ceph-工具" class="headerlink" title="4）部署 Rook Ceph 工具"></a>4）部署 Rook Ceph 工具</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> rook/deploy/examples</span><br><span class="line">kubectl create -f toolbox.yaml</span><br></pre></td></tr></table></figure>

<h3 id="5）部署-Ceph-Dashboard"><a href="#5）部署-Ceph-Dashboard" class="headerlink" title="5）部署 Ceph Dashboard"></a>5）部署 Ceph Dashboard</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> rook/deploy/examples</span><br><span class="line">kubectl apply -f dashboard-external-https.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取 dashboard admin密码</span></span><br><span class="line">kubectl -n rook-ceph get secret rook-ceph-dashboard-password -o jsonpath=<span class="string">&quot;&#123;[&#x27;data&#x27;][&#x27;password&#x27;]&#125;&quot;</span> | <span class="built_in">base64</span> -d</span><br></pre></td></tr></table></figure>

<p>通过 Ceph Dashboard 查看 Ceph 集群状态</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看对外端口</span></span><br><span class="line">kubectl get svc -n rook-ceph</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301121530398.png" alt="图片"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">https://&lt;nodeip&gt;:nodePort/</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301121531344.png" alt="图片"></p>
<h3 id="6）检查"><a href="#6）检查" class="headerlink" title="6）检查"></a>6）检查</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pods,svc -n rook-ceph</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301121531115.png" alt="图片"></p>
<h3 id="7）通过-ceph-tool-工具-pod-查看-ceph-集群状态"><a href="#7）通过-ceph-tool-工具-pod-查看-ceph-集群状态" class="headerlink" title="7）通过 ceph-tool 工具 pod 查看 ceph 集群状态"></a>7）通过 ceph-tool 工具 pod 查看 ceph 集群状态</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl <span class="built_in">exec</span> -it `kubectl get pods -n rook-ceph|grep rook-ceph-tools|awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>` -n rook-ceph -- bash</span><br><span class="line"></span><br><span class="line">ceph -s</span><br></pre></td></tr></table></figure>

<p><img src="https://mmbiz.qpic.cn/mmbiz_png/gIkzzLe4eUWDPp5oPW5DIbib8ibhSZRiauNEZEXV5x4peuFYynqfvaWMNZWSeCZH790CRuaUMqyiaia4xTvS5Gbk85g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p>
<h2 id="四、-测试验证"><a href="#四、-测试验证" class="headerlink" title="四、 测试验证"></a>四、 测试验证</h2><h3 id="1）-块存储（RBD）测试"><a href="#1）-块存储（RBD）测试" class="headerlink" title="1） 块存储（RBD）测试"></a>1） 块存储（RBD）测试</h3><h4 id="1、创建-StorageClass"><a href="#1、创建-StorageClass" class="headerlink" title="1、创建 StorageClass"></a>1、创建 StorageClass</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> rook/deploy/examples</span><br><span class="line"><span class="comment"># 创建一个名为replicapool的rbd pool</span></span><br><span class="line">kubectl apply -f csi/rbd/storageclass.yaml</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301121531747.png" alt="图片"></p>
<h4 id="2、部署-WordPress"><a href="#2、部署-WordPress" class="headerlink" title="2、部署 WordPress"></a>2、部署 WordPress</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f mysql.yaml</span><br><span class="line">kubectl apply -f wordpress.yaml</span><br></pre></td></tr></table></figure>

<h3 id="2）文件系统-（CephFS）-测试"><a href="#2）文件系统-（CephFS）-测试" class="headerlink" title="2）文件系统 （CephFS） 测试"></a>2）文件系统 （CephFS） 测试</h3><h4 id="1、创建-StorageClass-1"><a href="#1、创建-StorageClass-1" class="headerlink" title="1、创建 StorageClass"></a>1、创建 StorageClass</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f csi/cephfs/storageclass.yaml</span><br></pre></td></tr></table></figure>

<h4 id="2、部署应用"><a href="#2、部署应用" class="headerlink" title="2、部署应用"></a>2、部署应用</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f filesystem.yaml</span><br></pre></td></tr></table></figure>

<h3 id="3）对象存储-（RGW）-测试"><a href="#3）对象存储-（RGW）-测试" class="headerlink" title="3）对象存储 （RGW） 测试"></a>3）对象存储 （RGW） 测试</h3><h4 id="1、创建对象存储"><a href="#1、创建对象存储" class="headerlink" title="1、创建对象存储"></a>1、创建对象存储</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create -f object.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证rgw pod正常运行</span></span><br><span class="line">kubectl -n rook-ceph get pod -l app=rook-ceph-rgw</span><br></pre></td></tr></table></figure>

<h4 id="2、创建对象存储-user"><a href="#2、创建对象存储-user" class="headerlink" title="2、创建对象存储 user"></a>2、创建对象存储 user</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create -f object-user.yaml</span><br></pre></td></tr></table></figure>

<h4 id="3、获取-accesskey-secretkey"><a href="#3、获取-accesskey-secretkey" class="headerlink" title="3、获取 accesskey secretkey"></a>3、获取 accesskey secretkey</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 获取AccessKey</span></span><br><span class="line">kubectl -n rook-ceph get secret rook-ceph-object-user-my-store-my-user -o yaml | grep AccessKey | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span> | <span class="built_in">base64</span> --decode</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取 SecretKey</span></span><br><span class="line">kubectl -n rook-ceph get secret rook-ceph-object-user-my-store-my-user -o yaml | grep SecretKey | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span> | <span class="built_in">base64</span> --decode</span><br></pre></td></tr></table></figure>

<h4 id="4、部署-rgw-nodeport"><a href="#4、部署-rgw-nodeport" class="headerlink" title="4、部署 rgw nodeport"></a>4、部署 rgw nodeport</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f rgw-external.yaml</span><br><span class="line"></span><br><span class="line">kubectl -n rook-ceph get service rook-ceph-rgw-my-store rook-ceph-rgw-my-store-external</span><br></pre></td></tr></table></figure>

<h4 id="5、通过-api-接口使用-Ceph-对象存储"><a href="#5、通过-api-接口使用-Ceph-对象存储" class="headerlink" title="5、通过 api 接口使用 Ceph 对象存储"></a>5、通过 api 接口使用 Ceph 对象存储</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#首先，我们需要安装 python-boto 包，用于测试连接 S3。：</span></span><br><span class="line">yum install python-boto -y</span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后，编写 python 测试脚本。</span></span><br><span class="line"><span class="comment"># cat s3.py</span></span><br><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"></span><br><span class="line">import boto</span><br><span class="line">import boto.s3.connection</span><br><span class="line">access_key = <span class="string">&#x27;C7492VVSL8O11NZBK3GT&#x27;</span></span><br><span class="line">secret_key = <span class="string">&#x27;lo8IIwMfmow4fjkSOMbjebmgjzTRBQSO7w83SvBd&#x27;</span></span><br><span class="line">conn = boto.connect_s3(</span><br><span class="line">    aws_access_key_id = access_key,</span><br><span class="line">    aws_secret_access_key = secret_key,</span><br><span class="line">    host = <span class="string">&#x27;192.168.182.110&#x27;</span>, port=30369,</span><br><span class="line">    is_secure=False,</span><br><span class="line">    calling_format = boto.s3.connection.OrdinaryCallingFormat(),</span><br><span class="line">)</span><br><span class="line">bucket = conn.create_bucket(<span class="string">&#x27;my-first-s3-bucket&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> bucket <span class="keyword">in</span> conn.get_all_buckets():</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;&#123;name&#125;\t&#123;created&#125;&quot;</span>.format(</span><br><span class="line">                name = bucket.name,</span><br><span class="line">                created = bucket.creation_date,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>具体测试过程在之前的文章中有很详细的介绍</p>
]]></content>
      <categories>
        <category>kubernetes</category>
        <category>Ceph</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>Ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络异常排查思路</title>
    <url>/2023/02/14/k8s%E7%BD%91%E7%BB%9C%E5%BC%82%E5%B8%B8%E6%8E%92%E6%9F%A5%E6%80%9D%E8%B7%AF/</url>
    <content><![CDATA[<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a><strong>Overview</strong></h2><p>本文将引入一个思路：“在 Kubernetes 集群发生网络异常时如何排查”。文章将引入 Kubernetes 集群中网络排查的思路，包含网络异常模型，常用工具，并且提出一些案例以供学习。</p>
<ul>
<li>Pod 常见网络异常分类</li>
<li>网络排查工具</li>
<li>Pod 网络异常排查思路及流程模型</li>
<li>CNI 网络异常排查步骤</li>
<li>案例学习</li>
</ul>
<h2 id="Pod-网络异常"><a href="#Pod-网络异常" class="headerlink" title="Pod 网络异常"></a><strong>Pod 网络异常</strong></h2><p>网络异常大概分为如下几类：</p>
<ul>
<li><p><strong>网络不可达</strong>，主要现象为 ping 不通，其可能原因为：</p>
<ul>
<li>源端和目的端防火墙（<code>iptables</code>, <code>selinux</code>）限制</li>
<li>网络路由配置不正确</li>
<li>源端和目的端的系统负载过高，网络连接数满，网卡队列满</li>
<li>网络链路故障</li>
</ul>
</li>
<li><p><strong>端口不可达</strong>：主要现象为可以 ping 通，但 telnet 端口不通，其可能原因为：</p>
<ul>
<li>源端和目的端防火墙限制</li>
<li>源端和目的端的系统负载过高，网络连接数满，网卡队列满，端口耗尽</li>
<li>目的端应用未正常监听导致（应用未启动，或监听为 127.0.0.1 等）</li>
</ul>
</li>
<li><p><strong>DNS 解析异常</strong>：主要现象为基础网络可以连通，访问域名报错无法解析，访问 IP 可以正常连通。其可能原因为</p>
<ul>
<li>Pod 的 DNS 配置不正确</li>
<li>DNS 服务异常</li>
<li>pod 与 DNS 服务通讯异常</li>
</ul>
</li>
<li><p><strong>大数据包丢包</strong>：主要现象为基础网络和端口均可以连通，小数据包收发无异常，大数据包丢包。可能原因为：</p>
<ul>
<li>可使用 <code>ping -s</code> 指定数据包大小进行测试</li>
<li>数据包的大小超过了 docker0，CNI 插件，或者宿主机网卡的 <em>MTU</em> 值。</li>
</ul>
</li>
<li><p><strong>CNI 异常</strong>：主要现象为 Node 可以通，但 Pod 无法访问集群地址，可能原因有：</p>
<ul>
<li><em>kube-proxy</em> 服务异常，没有生成 <em>iptables</em> 策略或者 <em>ipvs</em> 规则导致无法访问</li>
<li>CIDR 耗尽，无法为 Node 注入 <code>PodCIDR</code> 导致 <em>CNI</em> 插件异常</li>
<li>其他 <em>CNI</em> 插件问题</li>
</ul>
</li>
</ul>
<p>那么整个 Pod 网络异常分类可以如下图所示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302141335423.png" alt="图片"></p>
<p>Pod network trouble hirarchy</p>
<p>总结一下，Pod 最常见的网络故障有，网络不可达（ping 不通）；端口不可达（telnet 不通）；DNS 解析异常（域名不通）与大数据包丢失（大包不通）。</p>
<h2 id="常用网络排查工具"><a href="#常用网络排查工具" class="headerlink" title="常用网络排查工具"></a><strong>常用网络排查工具</strong></h2><p>在了解到常见的网络异常后，在排查时就需要使用到一些网络工具才可以很有效的定位到网络故障原因，下面会介绍一些网络排查工具。</p>
<h3 id="tcpdump"><a href="#tcpdump" class="headerlink" title="tcpdump"></a><strong>tcpdump</strong></h3><p>tcpdump 网络嗅探器，将强大和简单结合到一个单一的命令行界面中，能够将网络中的报文抓取，输出到屏幕或者记录到文件中。</p>
<blockquote>
<p><strong>各系统下的安装</strong></p>
<ul>
<li>Ubuntu&#x2F;Debian: <code>apt-get install -y tcpdump</code></li>
<li>Centos&#x2F;Fedora: <code>yum install -y tcpdump</code></li>
<li>Apline：<code>apk add tcpdump --no-cache</code></li>
</ul>
</blockquote>
<p>查看指定接口上的所有通讯</p>
<p>语法</p>
<table>
<thead>
<tr>
<th align="center">参数</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">-i [interface]</td>
<td align="center">指定要过滤的网卡接口，如果要查看所有网卡，可以 <code>-i any</code></td>
</tr>
<tr>
<td align="center">-w [file]</td>
<td align="center">写入数据到文件，参数后接一个以 <code>.pcap</code> 后缀命令的文件名，就可以将 tcpdump 抓到的数据保存到文件中</td>
</tr>
<tr>
<td align="center">-n 与-nn</td>
<td align="center">-n 表示：不把 ip 转化成域名，直接显示 ip，避免执行 DNS lookups 的过程；-nn 表示：不把协议和端口号转化成名字</td>
</tr>
<tr>
<td align="center">-X</td>
<td align="center">以 16 进制和 ASCII 码形式打印出每个包的数据(但不包括连接层的头部)</td>
</tr>
<tr>
<td align="center">-A</td>
<td align="center">以 ASCII 码方式显示每一个数据包(不显示链路层头部信息). 在抓取包含网页数据的数据包时, 可方便查看数据</td>
</tr>
<tr>
<td align="center">-XX</td>
<td align="center">以 16 进制和 ASCII 码形式打印出每个包的数据(包括连接层的头部)</td>
</tr>
<tr>
<td align="center">-v</td>
<td align="center">产生详细的输出，比如包的 TTL，id 标识，数据包长度，以及 IP 包的一些选项。同时它还会打开一些附加的包完整性检测，比如对 IP 或 ICMP 包头部的校验和。</td>
</tr>
<tr>
<td align="center">-r</td>
<td align="center">读取文件而不是实时抓包</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">关键字</th>
</tr>
</thead>
<tbody><tr>
<td align="center">type</td>
<td align="center">host（主机名，域名，IP 地址）, net, port, portrange</td>
</tr>
<tr>
<td align="center">direction</td>
<td align="center">src, dst, src or dst , src and ds</td>
</tr>
<tr>
<td align="center">protocol</td>
<td align="center">ether, ip，arp, tcp, udp, wlan</td>
</tr>
</tbody></table>
<h4 id="捕获所有网络接口"><a href="#捕获所有网络接口" class="headerlink" title="捕获所有网络接口"></a>捕获所有网络接口</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump -D</span><br></pre></td></tr></table></figure>

<h4 id="按-IP-查找流量"><a href="#按-IP-查找流量" class="headerlink" title="按 IP 查找流量"></a>按 IP 查找流量</h4><p>最常见的查询之一 <code>host</code>，可以看到来往于 <code>1.1.1.1</code> 的流量。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump host 1.1.1.1</span><br></pre></td></tr></table></figure>

<h4 id="按源-x2F-目的-地址过滤"><a href="#按源-x2F-目的-地址过滤" class="headerlink" title="按源&#x2F;目的 地址过滤"></a>按源&#x2F;目的 地址过滤</h4><p>如果只想查看来自&#x2F;向某方向流量，可以使用 <code>src</code> 和 <code>dst</code>。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump src|dst 1.1.1.1</span><br></pre></td></tr></table></figure>

<h4 id="通过网络查找数据包"><a href="#通过网络查找数据包" class="headerlink" title="通过网络查找数据包"></a>通过网络查找数据包</h4><p>使用 <code>net</code> 选项，来要查找出&#x2F;入某个网络或子网的数据包。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump net 1.2.3.0/24</span><br></pre></td></tr></table></figure>

<h4 id="使用十六进制输出数据包内容"><a href="#使用十六进制输出数据包内容" class="headerlink" title="使用十六进制输出数据包内容"></a>使用十六进制输出数据包内容</h4><p><code>hex</code> 可以以 16 进制输出包的内容</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump -c 1 -X icmp</span><br></pre></td></tr></table></figure>

<h4 id="查看特定端口的流量"><a href="#查看特定端口的流量" class="headerlink" title="查看特定端口的流量"></a>查看特定端口的流量</h4><p>使用 <code>port</code> 选项来查找特定的端口流量。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump port 3389</span><br><span class="line">tcpdump src port 1025</span><br></pre></td></tr></table></figure>

<h4 id="查找端口范围的流量"><a href="#查找端口范围的流量" class="headerlink" title="查找端口范围的流量"></a>查找端口范围的流量</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump portrange 21-23</span><br></pre></td></tr></table></figure>

<h4 id="过滤包的大小"><a href="#过滤包的大小" class="headerlink" title="过滤包的大小"></a>过滤包的大小</h4><p>如果需要查找特定大小的数据包，可以使用以下选项。你可以使用 <code>less</code>，<code>greater</code>。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump less 32</span><br><span class="line">tcpdump greater 64</span><br><span class="line">tcpdump &lt;= 128</span><br></pre></td></tr></table></figure>

<h4 id="捕获流量输出为文件"><a href="#捕获流量输出为文件" class="headerlink" title="捕获流量输出为文件"></a>捕获流量输出为文件</h4><p><code>-w</code> 可以将数据包捕获保存到一个文件中以便将来进行分析。这些文件称为<code>PCAP</code>（PEE-cap）文件，它们可以由不同的工具处理，包括 <code>Wireshark</code> 。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump port 80 -w capture_file</span><br></pre></td></tr></table></figure>

<h4 id="组合条件"><a href="#组合条件" class="headerlink" title="组合条件"></a>组合条件</h4><p>tcpdump 也可以结合逻辑运算符进行组合条件查询</p>
<ul>
<li><strong>AND</strong><br><em><code>and</code></em> or <code>&amp;&amp;</code></li>
<li><strong>OR</strong><br><em><code>or</code></em> or <code>||</code></li>
<li><strong>EXCEPT</strong><br><em><code>not</code></em> or <code>!</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump -i eth0 -nn host 220.181.57.216 and 10.0.0.1  <span class="comment"># 主机之间的通讯</span></span><br><span class="line">tcpdump -i eth0 -nn host 220.181.57.216 or 10.0.0.1</span><br><span class="line"><span class="comment"># 获取10.0.0.1与 10.0.0.9或 10.0.0.1 与10.0.0.3之间的通讯</span></span><br><span class="line">tcpdump -i eth0 -nn host 10.0.0.1 and \(10.0.0.9 or 10.0.0.3\)</span><br></pre></td></tr></table></figure>

<h4 id="原始输出"><a href="#原始输出" class="headerlink" title="原始输出"></a>原始输出</h4><p>并显示人类可读的内容进行输出包（不包含内容）。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump -ttnnvvS -i eth0</span><br><span class="line">tcpdump -ttnnvvS -i eth0</span><br></pre></td></tr></table></figure>

<h4 id="IP-到端口"><a href="#IP-到端口" class="headerlink" title="IP 到端口"></a>IP 到端口</h4><p>让我们查找从某个 IP 到端口任何主机的某个端口所有流量。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump -nnvvS src 10.5.2.3 and dst port 3389</span><br></pre></td></tr></table></figure>

<h4 id="去除特定流量"><a href="#去除特定流量" class="headerlink" title="去除特定流量"></a>去除特定流量</h4><p>可以将指定的流量排除，如这显示所有到 192.168.0.2 的 非 ICMP 的流量。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump dst 192.168.0.2 and src net and not icmp</span><br></pre></td></tr></table></figure>

<p>来自非指定端口的流量，如，显示来自不是 SSH 流量的主机的所有流量。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump -vv src mars and not dst port 22</span><br></pre></td></tr></table></figure>

<h4 id="选项分组"><a href="#选项分组" class="headerlink" title="选项分组"></a>选项分组</h4><p>在构建复杂查询时，必须使用单引号 <code>&#39;</code>。单引号用于忽略特殊符号 <code>()</code> ，以便于使用其他表达式（如 host, port, net 等）进行分组。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump <span class="string">&#x27;src 10.0.2.4 and (dst port 3389 or 22)&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="过滤-TCP-标记位"><a href="#过滤-TCP-标记位" class="headerlink" title="过滤 TCP 标记位"></a>过滤 TCP 标记位</h4><p>TCP RST</p>
<p>下面的过滤器找到这些不同的数据包，因为 <code>TCP [13]</code> 查看 TCP 头中的偏移量 13，数字表示字节内的位置，而<code>!=0</code>意味着有问题的标志被设置为 1，也就是说它是打开的。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump <span class="string">&#x27;tcp[13] &amp; 4!=0&#x27;</span></span><br><span class="line">tcpdump <span class="string">&#x27;tcp[tcpflags] == tcp-rst&#x27;</span></span><br></pre></td></tr></table></figure>

<p>TCP SYN</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump <span class="string">&#x27;tcp[13] &amp; 2!=0&#x27;</span></span><br><span class="line">tcpdump <span class="string">&#x27;tcp[tcpflags] == tcp-syn&#x27;</span></span><br></pre></td></tr></table></figure>

<p>同时忽略 SYN 和 ACK 标志的数据包</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump <span class="string">&#x27;tcp[13]=18&#x27;</span></span><br></pre></td></tr></table></figure>

<p>TCP URG</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump <span class="string">&#x27;tcp[13] &amp; 32!=0&#x27;</span></span><br><span class="line">tcpdump <span class="string">&#x27;tcp[tcpflags] == tcp-urg&#x27;</span></span><br></pre></td></tr></table></figure>

<p>TCP ACK</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump <span class="string">&#x27;tcp[13] &amp; 16!=0&#x27;</span></span><br><span class="line">tcpdump <span class="string">&#x27;tcp[tcpflags] == tcp-ack&#x27;</span></span><br></pre></td></tr></table></figure>

<p>TCP PSH</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump <span class="string">&#x27;tcp[13] &amp; 8!=0&#x27;</span></span><br><span class="line">tcpdump <span class="string">&#x27;tcp[tcpflags] == tcp-push&#x27;</span></span><br></pre></td></tr></table></figure>

<p>TCP FIN</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump <span class="string">&#x27;tcp[13] &amp; 1!=0&#x27;</span></span><br><span class="line">tcpdump <span class="string">&#x27;tcp[tcpflags] == tcp-fin&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="查找-http-包"><a href="#查找-http-包" class="headerlink" title="查找 http 包"></a>查找 http 包</h4><p>查找 <code>user-agent</code> 信息</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump -vvAls0 | grep <span class="string">&#x27;User-Agent:&#x27;</span></span><br></pre></td></tr></table></figure>

<p>查找只是 <code>GET</code> 请求的流量</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump -vvAls0 | grep <span class="string">&#x27;GET&#x27;</span></span><br></pre></td></tr></table></figure>

<p>查找 http 客户端 IP</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump -vvAls0 | grep <span class="string">&#x27;Host:&#x27;</span></span><br></pre></td></tr></table></figure>

<p>查询客户端 cookie</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump -vvAls0 | grep <span class="string">&#x27;Set-Cookie|Host:|Cookie:&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="查找-DNS-流量"><a href="#查找-DNS-流量" class="headerlink" title="查找 DNS 流量"></a>查找 DNS 流量</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump -vvAs0 port 53</span><br></pre></td></tr></table></figure>

<h4 id="查找对应流量的明文密码"><a href="#查找对应流量的明文密码" class="headerlink" title="查找对应流量的明文密码"></a>查找对应流量的明文密码</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump port http or port ftp or port smtp or port imap or port pop3 or port telnet -lA | egrep -i -B5 <span class="string">&#x27;pass=|pwd=|log=|login=|user=|username=|pw=|passw=|passwd= |password=|pass:|user:|username:|password:|login:|pass |user &#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="wireshark-追踪流"><a href="#wireshark-追踪流" class="headerlink" title="wireshark 追踪流"></a>wireshark 追踪流</h4><p>wireshare 追踪流可以很好的了解出在一次交互过程中都发生了那些问题。</p>
<p>wireshare 选中包，右键选择 “追踪流“ 如果该包是允许的协议是可以打开该选项的</p>
<h4 id="关于抓包节点和抓包设备"><a href="#关于抓包节点和抓包设备" class="headerlink" title="关于抓包节点和抓包设备"></a>关于抓包节点和抓包设备</h4><p>如何抓取有用的包，以及如何找到对应的接口，有以下建议</p>
<p><strong>抓包节点</strong>：</p>
<p>通常情况下会在源端和目的端两端同时抓包，观察数据包是否从源端正常发出，目的端是否接收到数据包并给源端回包，以及源端是否正常接收到回包。如果有丢包现象，则沿网络链路上各节点抓包排查。例如，A 节点经过 c 节点到 B 节点，先在 AB 两端同时抓包，如果 B 节点未收到 A 节点的包，则在 c 节点同时抓包。</p>
<p><strong>抓包设备</strong>：</p>
<p>对于 Kubernetes 集群中的 Pod，由于容器内不便于抓包，通常视情况在 Pod 数据包经过的 veth 设备，docker0 网桥， <em>CNI</em> 插件设备（如 cni0，flannel.1 etc..）及 Pod 所在节点的网卡设备上指定 Pod IP 进行抓包。选取的设备根据怀疑导致网络问题的原因而定，比如范围由大缩小，从源端逐渐靠近目的端，比如怀疑是 <em>CNI</em> 插件导致，则在 <em>CNI</em> 插件设备上抓包。从 pod 发出的包逐一经过 veth 设备， <em>cni0</em> 设备，flannel0， 宿主机网卡，到达对端，抓包时可按顺序逐一抓包，定位问题节点。</p>
<blockquote>
<p>需要注意在不同设备上抓包时指定的源目 IP 地址需要转换，如抓取某 Pod 时，ping <em>{host}</em> 的包，在 <em>veth</em> 和 <em>cni0</em> 上可以指定 Pod IP 抓包，而在宿主机网卡上如果仍然指定 Pod IP 会发现抓不到包，因为此时 Pod IP 已被转换为宿主机网卡 IP。</p>
</blockquote>
<p>下图是一个使用 <em>VxLAN</em> 模式的 <em>flannel</em> 的跨界点通讯的网络模型，在抓包时需要注意对应的网络接口</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302141339522.png" alt="图片"></p>
<p>VxLAN in kubernetes</p>
<h3 id="nsenter"><a href="#nsenter" class="headerlink" title="nsenter"></a><strong>nsenter</strong></h3><p>nsenter 是一款可以进入进程的名称空间中。例如，如果一个容器以非 root 用户身份运行，而使用 <code>docker exec</code> 进入其中后，但该容器没有安装 <code>sudo</code> 或未 <code>netstat</code> ，并且您想查看其当前的网络属性，如开放端口，这种场景下将如何做到这一点？<em>nsenter</em> 就是用来解决这个问题的。</p>
<p><strong>nsenter</strong> (<em>namespace enter</em>) 可以在容器的宿主机上使用 <code>nsenter</code> 命令进入容器的命名空间，以容器视角使用宿主机上的相应网络命令进行操作。当然需要拥有 <code>root</code> 权限</p>
<blockquote>
<p><strong>nsenter 在各系统下的安装</strong></p>
<ul>
<li>Ubuntu&#x2F;Debian: <code>apt-get install -y util-linux</code></li>
<li>Centos&#x2F;Fedora: <code>yum install -y util-linux</code></li>
<li>Apline：<code>apk add util-linux --no-cache</code></li>
</ul>
</blockquote>
<p><em>nsenter</em> 的使用语法为，<code>nsenter -t pid -n &lt;commond&gt;</code>，<code>-t</code> 接 进程 ID 号，<code>-n</code> 表示进入名称空间内，<code>&lt;commond&gt;</code> 为执行的命令。</p>
<p>实例：如我们有一个 Pod 进程 ID 为 30858，进入该 Pod 名称空间内执行 <code>ifconfig</code> ，如下列所示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ps -ef|grep <span class="built_in">tail</span></span><br><span class="line">root      17636  62887  0 20:19 pts/2    00:00:00 grep --color=auto <span class="built_in">tail</span></span><br><span class="line">root      30858  30838  0 15:55 ?        00:00:01 <span class="built_in">tail</span> -f</span><br><span class="line"></span><br><span class="line">$ nsenter -t 30858 -n ifconfig</span><br><span class="line">eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1480</span><br><span class="line">        inet 192.168.1.213  netmask 255.255.255.0  broadcast 192.168.1.255</span><br><span class="line">        ether 5e:d5:98:af:dc:6b  txqueuelen 0  (Ethernet)</span><br><span class="line">        RX packets 92  bytes 9100 (8.8 KiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 92  bytes 8422 (8.2 KiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536</span><br><span class="line">        inet 127.0.0.1  netmask 255.0.0.0</span><br><span class="line">        loop  txqueuelen 1000  (Local Loopback)</span><br><span class="line">        RX packets 5  bytes 448 (448.0 B)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 5  bytes 448 (448.0 B)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">net1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 10.1.0.201  netmask 255.255.255.0  broadcast 10.1.0.255</span><br><span class="line">        ether b2:79:f9:<span class="built_in">dd</span>:2a:10  txqueuelen 0  (Ethernet)</span><br><span class="line">        RX packets 228  bytes 21272 (20.7 KiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 216  bytes 20272 (19.7 KiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure>

<h4 id="如何定位-Pod-名称空间"><a href="#如何定位-Pod-名称空间" class="headerlink" title="如何定位 Pod 名称空间"></a>如何定位 Pod 名称空间</h4><p>首先需要确定 Pod 所在的节点名称</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl get pods -owide |awk <span class="string">&#x27;&#123;print $1,$7&#125;&#x27;</span></span><br><span class="line">NAME NODE</span><br><span class="line">netbox-85865d5556-hfg6v master-machine</span><br><span class="line">netbox-85865d5556-vlgr4 node01</span><br></pre></td></tr></table></figure>

<p>如果 Pod 不在当前节点还需要用 IP 登录则还需要查看 IP（可选）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl get pods -owide |awk <span class="string">&#x27;&#123;print $1,$6,$7&#125;&#x27;</span></span><br><span class="line">NAME IP NODE</span><br><span class="line">netbox-85865d5556-hfg6v 192.168.1.213 master-machine</span><br><span class="line">netbox-85865d5556-vlgr4 192.168.0.4 node01</span><br></pre></td></tr></table></figure>

<p>接下来，登录节点，获取容器 lD，如下列所示，每个 pod 默认有一个 <em>pause</em> 容器，其他为用户 yaml 文件中定义的容器，理论上所有容器共享相同的网络命名空间，排查时可任选一个容器。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker ps |grep netbox-85865d5556-hfg6v</span><br><span class="line">6f8c58377aae   f78dd05f11ff                                                    <span class="string">&quot;tail -f&quot;</span>                45 hours ago   Up 45 hours             k8s_netbox_netbox-85865d5556-hfg6v_default_4a8e2da8-05d1-4c81-97a7-3d76343a323a_0</span><br><span class="line">b9c732ee457e   registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1   <span class="string">&quot;/pause&quot;</span>                 45 hours ago   Up 45 hours             k8s_POD_netbox-85865d5556-hfg6v_default_4a8e2da8-05d1-4c81-97a7-3d76343a323a_0</span><br></pre></td></tr></table></figure>

<p>接下来获得获取容器在节点系统中对应的进程号，如下所示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker inspect --format <span class="string">&quot;&#123;&#123; .State.Pid &#125;&#125;&quot;</span> 6f8c58377aae</span><br><span class="line">30858</span><br></pre></td></tr></table></figure>

<p>最后就可以通过 <em>nsenter</em> 进入容器网络空间执行命令了</p>
<h3 id="paping"><a href="#paping" class="headerlink" title="paping"></a><strong>paping</strong></h3><p><strong>paping</strong> 命令可对目标地址指定端口以 TCP 协议进行连续 ping，通过这种特性可以弥补 <em>ping</em> ICMP 协议，以及 <em>nmap</em> , <em>telnet</em> 只能进行一次操作的的不足；通常情况下会用于测试端口连通性和丢包率</p>
<p>paping download：paping</p>
<p><em>paping</em> 还需要安装以下依赖，这取决于你安装的 <em>paping</em> 版本</p>
<ul>
<li>RedHat&#x2F;CentOS：<code>yum install -y libstdc++.i686 glibc.i686</code></li>
<li>Ubuntu&#x2F;Debian：最小化安装无需依赖</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ paping -h</span><br><span class="line">paping v1.5.5 - Copyright (c) 2011 Mike Lovell</span><br><span class="line"></span><br><span class="line">Syntax: paping [options] destination</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line"> -?, --<span class="built_in">help</span>     display usage</span><br><span class="line"> -p, --port N   <span class="built_in">set</span> TCP port N (required)</span><br><span class="line">     --nocolor  Disable color output</span><br><span class="line"> -t, --<span class="built_in">timeout</span>  <span class="built_in">timeout</span> <span class="keyword">in</span> milliseconds (default 1000)</span><br><span class="line"> -c, --count N  <span class="built_in">set</span> number of checks to N</span><br></pre></td></tr></table></figure>

<h3 id="mtr"><a href="#mtr" class="headerlink" title="mtr"></a><strong>mtr</strong></h3><p><strong>mtr</strong> 是一个跨平台的网络诊断工具，将 <strong>traceroute</strong> 和 <strong>ping</strong> 的功能结合到一个工具。与 <em>traceroute</em> 不同的是 <em>mtr</em> 显示的信息比起 <em>traceroute</em> 更加丰富：通过 <em>mtr</em> 可以确定网络的条数，并且可以同时打印响应百分比以及网络中各跳跃点的响应时间。</p>
<blockquote>
<p><strong>各系统下的安装</strong></p>
<ul>
<li>Ubuntu&#x2F;Debian: <code>apt-get install -y mtr</code></li>
<li>Centos&#x2F;Fedora: <code>yum install -y mtr</code></li>
<li>Apline：<code>apk add mtr --no-cache</code></li>
</ul>
</blockquote>
<h4 id="简单的使用示例"><a href="#简单的使用示例" class="headerlink" title="简单的使用示例"></a>简单的使用示例</h4><p>最简单的示例，就是后接域名或 IP，这将跟踪整个路由</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ mtr google.com</span><br><span class="line"></span><br><span class="line">Start: Thu Jun 28 12:10:13 2018</span><br><span class="line">HOST: TecMint                     Loss%   Snt   Last   Avg  Best  Wrst StDev</span><br><span class="line">  1.|-- 192.168.0.1                0.0%     5    0.3   0.3   0.3   0.4   0.0</span><br><span class="line">  2.|-- 5.5.5.211                  0.0%     5    0.7   0.9   0.7   1.3   0.0</span><br><span class="line">  3.|-- 209.snat-111-91-120.hns.n 80.0%     5    7.1   7.1   7.1   7.1   0.0</span><br><span class="line">  4.|-- 72.14.194.226              0.0%     5    1.9   2.9   1.9   4.4   1.1</span><br><span class="line">  5.|-- 108.170.248.161            0.0%     5    2.9   3.5   2.0   4.3   0.7</span><br><span class="line">  6.|-- 216.239.62.237             0.0%     5    3.0   6.2   2.9  18.3   6.7</span><br><span class="line">  7.|-- bom05s12-in-f14.1e100.net  0.0%     5    2.1   2.4   2.0   3.8   0.5</span><br></pre></td></tr></table></figure>

<p><code>-n</code> 强制 <em>mtr</em> 打印 IP 地址而不是主机名</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ mtr -n google.com</span><br><span class="line"></span><br><span class="line">Start: Thu Jun 28 12:12:58 2018</span><br><span class="line">HOST: TecMint                     Loss%   Snt   Last   Avg  Best  Wrst StDev</span><br><span class="line">  1.|-- 192.168.0.1                0.0%     5    0.3   0.3   0.3   0.4   0.0</span><br><span class="line">  2.|-- 5.5.5.211                  0.0%     5    0.9   0.9   0.8   1.1   0.0</span><br><span class="line">  3.|-- ???                       100.0     5    0.0   0.0   0.0   0.0   0.0</span><br><span class="line">  4.|-- 72.14.194.226              0.0%     5    2.0   2.0   1.9   2.0   0.0</span><br><span class="line">  5.|-- 108.170.248.161            0.0%     5    2.3   2.3   2.2   2.4   0.0</span><br><span class="line">  6.|-- 216.239.62.237             0.0%     5    3.0   3.2   3.0   3.3   0.0</span><br><span class="line">  7.|-- 172.217.160.174            0.0%     5    3.7   3.6   2.0   5.3   1.4</span><br></pre></td></tr></table></figure>

<p><code>-b</code> 同时显示 IP 地址与主机名</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ mtr -b google.com</span><br><span class="line"></span><br><span class="line">Start: Thu Jun 28 12:14:36 2018</span><br><span class="line">HOST: TecMint                     Loss%   Snt   Last   Avg  Best  Wrst StDev</span><br><span class="line">  1.|-- 192.168.0.1                0.0%     5    0.3   0.3   0.3   0.4   0.0</span><br><span class="line">  2.|-- 5.5.5.211                  0.0%     5    0.7   0.8   0.6   1.0   0.0</span><br><span class="line">  3.|-- 209.snat-111-91-120.hns.n  0.0%     5    1.4   1.6   1.3   2.1   0.0</span><br><span class="line">  4.|-- 72.14.194.226              0.0%     5    1.8   2.1   1.8   2.6   0.0</span><br><span class="line">  5.|-- 108.170.248.209            0.0%     5    2.0   1.9   1.8   2.0   0.0</span><br><span class="line">  6.|-- 216.239.56.115             0.0%     5    2.4   2.7   2.4   2.9   0.0</span><br><span class="line">  7.|-- bom07s15-in-f14.1e100.net  0.0%     5    3.7   2.2   1.7   3.7   0.9</span><br></pre></td></tr></table></figure>

<p><code>-c</code> 跟一个具体的值，这将限制 <em>mtr</em> ping 的次数，到达次数后会退出</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mtr -c5 google.com</span><br></pre></td></tr></table></figure>

<p>如果需要指定次数，并且在退出后保存这些数据，使用 <code>-r</code> flag</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mtr -r -c 5 google.com &gt;  1</span><br><span class="line"><span class="built_in">cat</span> 1</span><br><span class="line">Start: Sun Aug 21 22:06:49 2022</span><br><span class="line">HOST: xxxxx.xxxxx.xxxx.xxxx Loss%   Snt   Last   Avg  Best  Wrst StDev</span><br><span class="line">  1.|-- gateway                    0.0%     5    0.6 146.8   0.6 420.2 191.4</span><br><span class="line">  2.|-- 212.xx.21.241              0.0%     5    0.4   1.0   0.4   2.3   0.5</span><br><span class="line">  3.|-- 188.xxx.106.124            0.0%     5    0.7   1.1   0.7   2.1   0.5</span><br><span class="line">  4.|-- ???                       100.0     5    0.0   0.0   0.0   0.0   0.0</span><br><span class="line">  5.|-- 72.14.209.89               0.0%     5   43.2  43.3  43.1  43.3   0.0</span><br><span class="line">  6.|-- 108.xxx.250.33             0.0%     5   43.2  43.1  43.1  43.2   0.0</span><br><span class="line">  7.|-- 108.xxx.250.34             0.0%     5   43.7  43.6  43.5  43.7   0.0</span><br><span class="line">  8.|-- 142.xxx.238.82             0.0%     5   60.6  60.9  60.6  61.2   0.0</span><br><span class="line">  9.|-- 142.xxx.238.64             0.0%     5   59.7  67.5  59.3  89.8  13.2</span><br><span class="line"> 10.|-- 142.xxx.37.81              0.0%     5   62.7  62.9  62.6  63.5   0.0</span><br><span class="line"> 11.|-- 142.xxx.229.85             0.0%     5   61.0  60.9  60.7  61.3   0.0</span><br><span class="line"> 12.|-- xx-in-f14.1e100.net  0.0%     5   59.0  58.9  58.9  59.0   0.0</span><br></pre></td></tr></table></figure>

<p>默认使用的是 ICMP 协议 <code>-i</code> ，可以指定 <code>-u</code>, <code>-t</code> 使用其他协议</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mtr --tcp google.com</span><br></pre></td></tr></table></figure>

<p><code>-m</code> 指定最大的跳数</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mtr -m 35 216.58.223.78</span><br></pre></td></tr></table></figure>

<p><code>-s</code> 指定包的大小</p>
<h4 id="mtr-输出的数据"><a href="#mtr-输出的数据" class="headerlink" title="mtr 输出的数据"></a>mtr 输出的数据</h4><table>
<thead>
<tr>
<th align="center">colum</th>
<th align="center">describe</th>
</tr>
</thead>
<tbody><tr>
<td align="center">last</td>
<td align="center">最近一次的探测延迟值</td>
</tr>
<tr>
<td align="center">avg</td>
<td align="center">探测延迟的平均值</td>
</tr>
<tr>
<td align="center">best</td>
<td align="center">探测延迟的最小值</td>
</tr>
<tr>
<td align="center">wrst</td>
<td align="center">探测延迟的最大值</td>
</tr>
<tr>
<td align="center">stdev</td>
<td align="center">标准偏差。越大说明相应节点越不稳定</td>
</tr>
</tbody></table>
<h4 id="丢包判断"><a href="#丢包判断" class="headerlink" title="丢包判断"></a>丢包判断</h4><p>任一节点的 <code>Loss%</code>（丢包率）如果不为零，则说明这一跳网络可能存在问题。导致相应节点丢包的原因通常有两种。</p>
<ul>
<li>运营商基于安全或性能需求，人为限制了节点的 ICMP 发送速率，导致丢包。</li>
<li>节点确实存在异常，导致丢包。可以结合异常节点及其后续节点的丢包情况，来判定丢包原因。</li>
</ul>
<blockquote>
<p>Notes:</p>
<ul>
<li>如果随后节点均没有丢包，则通常说明异常节点丢包是由于运营商策略限制所致。可以忽略相关丢包。</li>
<li>如果随后节点也出现丢包，则通常说明节点确实存在网络异常，导致丢包。对于这种情况，如果异常节点及其后续节点连续出现丢包，而且各节点的丢包率不同，则通常以最后几跳的丢包率为准。如链路测试在第 5、6、7 跳均出现了丢包。最终丢包情况以第 7 跳作为参考。</li>
</ul>
</blockquote>
<h4 id="延迟判断"><a href="#延迟判断" class="headerlink" title="延迟判断"></a>延迟判断</h4><p>由于链路抖动或其它因素的影响，节点的 <em>Best</em> 和 <em>Worst</em> 值可能相差很大。而 Avg（平均值）统计了自链路测试以来所有探测的平均值，所以能更好的反应出相应节点的网络质量。而 StDev（标准偏差值）越高，则说明数据包在相应节点的延时值越不相同（越离散）。所以标准偏差值可用于协助判断 <em>Avg</em> 是否真实反应了相应节点的网络质量。例如，如果标准偏差很大，说明数据包的延迟是不确定的。可能某些数据包延迟很小（例如：25ms），而另一些延迟却很大（例如：350ms），但最终得到的平均延迟反而可能是正常的。所以此时 <em>Avg</em> 并不能很好的反应出实际的网络质量情况。</p>
<p>这就需要结合如下情况进行判断：</p>
<ul>
<li>如果 <em>StDev</em> 很高，则同步观察相应节点的 <em>Best</em> 和 wrst，来判断相应节点是否存在异常。</li>
<li>如果<em>StDev</em> 不高，则通过 Avg 来判断相应节点是否存在异常。</li>
</ul>
<h2 id="Pod-网络排查流程"><a href="#Pod-网络排查流程" class="headerlink" title="Pod 网络排查流程"></a><strong>Pod 网络排查流程</strong></h2><p>Pod 网络异常时排查思路，可以按照下图所示</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302141335442.png" alt="图片">Pod network troubleshooting idea</p>
<h2 id="案例学习"><a href="#案例学习" class="headerlink" title="案例学习"></a><strong>案例学习</strong></h2><h3 id="扩容节点访问-service-地址不通"><a href="#扩容节点访问-service-地址不通" class="headerlink" title="扩容节点访问 service 地址不通"></a><strong>扩容节点访问 service 地址不通</strong></h3><h4 id="测试环境-k8s-节点扩容后无法访问集群-clusterlP-类型的-registry-服务"><a href="#测试环境-k8s-节点扩容后无法访问集群-clusterlP-类型的-registry-服务" class="headerlink" title="测试环境 k8s 节点扩容后无法访问集群 clusterlP 类型的 registry 服务"></a>测试环境 k8s 节点扩容后无法访问集群 clusterlP 类型的 registry 服务</h4><p>环境信息：</p>
<table>
<thead>
<tr>
<th align="center">IP</th>
<th align="center">Hostname</th>
<th align="center">role</th>
</tr>
</thead>
<tbody><tr>
<td align="center">10.153.204.15</td>
<td align="center">yq01-aip-aikefu12</td>
<td align="center">worknode 节点（本次扩容的问题节点）</td>
</tr>
<tr>
<td align="center">10.153.203.14</td>
<td align="center">yq01-aip-aikefu31</td>
<td align="center">master 节点</td>
</tr>
<tr>
<td align="center">10.61.187.42</td>
<td align="center">yq01-aip-aikefu2746f8e9</td>
<td align="center">master 节点</td>
</tr>
<tr>
<td align="center">10.61.187.48</td>
<td align="center">yq01-aip-aikefu30b61e25</td>
<td align="center">master 节点（本次 registry 服务 pod 所在 节点）</td>
</tr>
</tbody></table>
<ul>
<li><p>cni 插件：flannel vxlan</p>
</li>
<li><p>kube-proxy 工作模式为 iptables</p>
</li>
<li><p>registry 服务</p>
<ul>
<li>单实例部署在 10.61.187.48:5000</li>
<li>Pod IP：10.233.65.46，</li>
<li>Cluster IP：10.233.0.100</li>
</ul>
</li>
</ul>
<p>现象：</p>
<ul>
<li>所有节点之间的 pod 通信正常</li>
<li>任意节点和 Pod curl registry 的 Pod 的 <em>IP:5000</em> 均可以连通</li>
<li>新扩容节点 10.153.204.15 curl registry 服务的 Cluster lP 10.233.0.100:5000 不通，其他节点 curl 均可以连通</li>
</ul>
<p>分析思路：</p>
<ul>
<li>根据现象 1 可以初步判断 <em>CNI</em> 插件无异常</li>
<li>根据现象 2 可以判断 <em>registry</em> 的 <em>Pod</em> 无异常</li>
<li>根据现象 3 可以判断 <em>registry</em> 的 <em>service</em> 异常的可能性不大，可能是新扩容节点访问 <em>registry</em> 的 <em>service</em> 存在异常</li>
</ul>
<p>怀疑方向：</p>
<ul>
<li>问题节点的 kube-proxy 存在异常</li>
<li>问题节点的 iptables 规则存在异常</li>
<li>问题节点到 service 的网络层面存在异常</li>
</ul>
<p>排查过程：</p>
<ul>
<li>排查问题节点的 <code>kube-proxy</code></li>
<li>执行 <code>kubectl get pod -owide -nkube-system l grep kube-proxy</code> 查看 <em>kube-proxy</em> Pod 的状态，问题节点上的 <em>kube-proxy</em> Pod 为 <em><strong>running</strong></em> 状态</li>
<li>执行 <code>kubecti logs &lt;nodename&gt; &lt;kube-proxy pod name&gt; -nkube-system</code> 查看问题节点 <em>kube-proxy</em>的 Pod 日志，没有异常报错</li>
<li>在问题节点操作系统上执行 <code>iptables -S -t nat</code> 查看 <code>iptables</code> 规则</li>
</ul>
<p>排查过程：</p>
<p>确认存在到 <em>registry</em> 服务的 Cluster lP <em>10.233.0.100</em> 的 <em>KUBE-SERVICES</em> 链，跳转至 <em>KUBE-SVC-</em>* 链做负载均衡，再跳转至 <em>KUBE-SEP-</em>* 链通过 <em>DNAT</em> 替换为服务后端 Pod 的 IP 10.233.65.46。因此判断 iptables 规则无异常执行 route-n 查看问题节点存在访问 10.233.65.46 所在网段的路由，如图所示</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302141342608.png" alt="图片">10.233.65.46 路由</p>
<p>查看对端的回程路由</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302141336153.png" alt="图片">回程路由</p>
<p>以上排查证明问题原因不是 <em>cni</em> 插件或者 <em>kube-proxy</em> 异常导致，因此需要在访问链路上抓包，判断问题原因、问题节点执行 <code>curl 10.233.0.100:5000</code>，在问题节点和后端 pod 所在节点的 flannel.1 上同时抓包发包节点一直在重传，Cluster lP 已 <em>DNAT</em> 转换为后端 Pod IP，如图所示</p>
<p>![图片](data:image&#x2F;svg+xml,%3C%3Fxml version&#x3D;’1.0’ encoding&#x3D;’UTF-8’%3F%3E%3Csvg width&#x3D;’1px’ height&#x3D;’1px’ viewBox&#x3D;’0 0 1 1’ version&#x3D;’1.1’ xmlns&#x3D;’<a href="http://www.w3.org/2000/svg">http://www.w3.org/2000/svg</a>‘ xmlns:xlink&#x3D;’<a href="http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg">http://www.w3.org/1999/xlink&#39;%3E%3Ctitle%3E%3C/title%3E%3Cg</a> stroke&#x3D;’none’ stroke-width&#x3D;’1’ fill&#x3D;’none’ fill-rule&#x3D;’evenodd’ fill-opacity&#x3D;’0’%3E%3Cg transform&#x3D;’translate(-249.000000, -126.000000)’ fill&#x3D;’%23FFFFFF’%3E%3Crect x&#x3D;’249’ y&#x3D;’126’ width&#x3D;’1’ height&#x3D;’1’%3E%3C&#x2F;rect%3E%3C&#x2F;g%3E%3C&#x2F;g%3E%3C&#x2F;svg%3E)抓包过程，发送端</p>
<p>后端 Pod（ <em>registry</em> 服务）所在节点的 <em>flannel.1</em> 上未抓到任何数据包，如图所示</p>
<p>![图片](data:image&#x2F;svg+xml,%3C%3Fxml version&#x3D;’1.0’ encoding&#x3D;’UTF-8’%3F%3E%3Csvg width&#x3D;’1px’ height&#x3D;’1px’ viewBox&#x3D;’0 0 1 1’ version&#x3D;’1.1’ xmlns&#x3D;’<a href="http://www.w3.org/2000/svg">http://www.w3.org/2000/svg</a>‘ xmlns:xlink&#x3D;’<a href="http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg">http://www.w3.org/1999/xlink&#39;%3E%3Ctitle%3E%3C/title%3E%3Cg</a> stroke&#x3D;’none’ stroke-width&#x3D;’1’ fill&#x3D;’none’ fill-rule&#x3D;’evenodd’ fill-opacity&#x3D;’0’%3E%3Cg transform&#x3D;’translate(-249.000000, -126.000000)’ fill&#x3D;’%23FFFFFF’%3E%3Crect x&#x3D;’249’ y&#x3D;’126’ width&#x3D;’1’ height&#x3D;’1’%3E%3C&#x2F;rect%3E%3C&#x2F;g%3E%3C&#x2F;g%3E%3C&#x2F;svg%3E)抓包过程，服务端</p>
<p>请求 <em>service</em> 的 <em>ClusterlP</em> 时，在两端物理机网卡抓包，发包端如图所示，封装的源端节点 IP 是 10.153.204.15，但一直在重传</p>
<p>![图片](data:image&#x2F;svg+xml,%3C%3Fxml version&#x3D;’1.0’ encoding&#x3D;’UTF-8’%3F%3E%3Csvg width&#x3D;’1px’ height&#x3D;’1px’ viewBox&#x3D;’0 0 1 1’ version&#x3D;’1.1’ xmlns&#x3D;’<a href="http://www.w3.org/2000/svg">http://www.w3.org/2000/svg</a>‘ xmlns:xlink&#x3D;’<a href="http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg">http://www.w3.org/1999/xlink&#39;%3E%3Ctitle%3E%3C/title%3E%3Cg</a> stroke&#x3D;’none’ stroke-width&#x3D;’1’ fill&#x3D;’none’ fill-rule&#x3D;’evenodd’ fill-opacity&#x3D;’0’%3E%3Cg transform&#x3D;’translate(-249.000000, -126.000000)’ fill&#x3D;’%23FFFFFF’%3E%3Crect x&#x3D;’249’ y&#x3D;’126’ width&#x3D;’1’ height&#x3D;’1’%3E%3C&#x2F;rect%3E%3C&#x2F;g%3E%3C&#x2F;g%3E%3C&#x2F;svg%3E)包传送过程，发送端</p>
<p>收包端收到了包，但未回包，如图所示</p>
<p>![图片](data:image&#x2F;svg+xml,%3C%3Fxml version&#x3D;’1.0’ encoding&#x3D;’UTF-8’%3F%3E%3Csvg width&#x3D;’1px’ height&#x3D;’1px’ viewBox&#x3D;’0 0 1 1’ version&#x3D;’1.1’ xmlns&#x3D;’<a href="http://www.w3.org/2000/svg">http://www.w3.org/2000/svg</a>‘ xmlns:xlink&#x3D;’<a href="http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg">http://www.w3.org/1999/xlink&#39;%3E%3Ctitle%3E%3C/title%3E%3Cg</a> stroke&#x3D;’none’ stroke-width&#x3D;’1’ fill&#x3D;’none’ fill-rule&#x3D;’evenodd’ fill-opacity&#x3D;’0’%3E%3Cg transform&#x3D;’translate(-249.000000, -126.000000)’ fill&#x3D;’%23FFFFFF’%3E%3Crect x&#x3D;’249’ y&#x3D;’126’ width&#x3D;’1’ height&#x3D;’1’%3E%3C&#x2F;rect%3E%3C&#x2F;g%3E%3C&#x2F;g%3E%3C&#x2F;svg%3E)包传送过程，服务端</p>
<p>由此可以知道，NAT 的动作已经完成，而只是后端 Pod（ <em>registry</em> 服务）没有回包，接下来在问题节点执行 <code>curl10.233.65.46:5000</code>，在问题节点和后端（ <em>registry</em> 服务）Pod 所在节点的 <em>flannel.1</em> 上同时抓包，两节点收发正常，发包如图所示</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302141336430.png" alt="图片">正常包发送端</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302141336328.png" alt="图片">正常包接收端</p>
<p>接下来在两端物理机网卡接口抓包，因为数据包通过物理机网卡会进行 <em>vxlan</em> 封装，需要抓 <em>vxlan</em> 设备的 8472 端口，发包端如图所示</p>
<p>发现网络链路连通，但封装的 IP 不对，封装的源端节点 IP 是 10.153.204.228，但是存在问题节点的 IP 是 10.153.204.15</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302141336661.png" alt="图片">问题节点物理机网卡接口抓包</p>
<p>后端 Pod 所在节点的物理网卡上抓包，注意需要过滤其他正常节点的请求包，如图所示；发现收到的数据包，源地址是 10.153.204.228，但是问题节点的 IP 是 10.153.204.15。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302141336413.png" alt="图片">对端节点物理机网卡接口抓包</p>
<p>此时问题以及清楚了，是一个 Pod 存在两个 IP，导致发包和回包时无法通过隧道设备找到对端的接口，所以发可以收到，但不能回。</p>
<p>问题节点执行<code>ip addr</code>，发现网卡 <em>enp26s0f0</em>上配置了两个 IP，如图所示</p>
<p>![图片](data:image&#x2F;svg+xml,%3C%3Fxml version&#x3D;’1.0’ encoding&#x3D;’UTF-8’%3F%3E%3Csvg width&#x3D;’1px’ height&#x3D;’1px’ viewBox&#x3D;’0 0 1 1’ version&#x3D;’1.1’ xmlns&#x3D;’<a href="http://www.w3.org/2000/svg">http://www.w3.org/2000/svg</a>‘ xmlns:xlink&#x3D;’<a href="http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg">http://www.w3.org/1999/xlink&#39;%3E%3Ctitle%3E%3C/title%3E%3Cg</a> stroke&#x3D;’none’ stroke-width&#x3D;’1’ fill&#x3D;’none’ fill-rule&#x3D;’evenodd’ fill-opacity&#x3D;’0’%3E%3Cg transform&#x3D;’translate(-249.000000, -126.000000)’ fill&#x3D;’%23FFFFFF’%3E%3Crect x&#x3D;’249’ y&#x3D;’126’ width&#x3D;’1’ height&#x3D;’1’%3E%3C&#x2F;rect%3E%3C&#x2F;g%3E%3C&#x2F;g%3E%3C&#x2F;svg%3E)问题节点 IP</p>
<p>进一步查看网卡配置文件，发现网卡既配置了静态 IP，又配置了 dhcp 动态获取 IP。如图所示</p>
<p>![图片](data:image&#x2F;svg+xml,%3C%3Fxml version&#x3D;’1.0’ encoding&#x3D;’UTF-8’%3F%3E%3Csvg width&#x3D;’1px’ height&#x3D;’1px’ viewBox&#x3D;’0 0 1 1’ version&#x3D;’1.1’ xmlns&#x3D;’<a href="http://www.w3.org/2000/svg">http://www.w3.org/2000/svg</a>‘ xmlns:xlink&#x3D;’<a href="http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg">http://www.w3.org/1999/xlink&#39;%3E%3Ctitle%3E%3C/title%3E%3Cg</a> stroke&#x3D;’none’ stroke-width&#x3D;’1’ fill&#x3D;’none’ fill-rule&#x3D;’evenodd’ fill-opacity&#x3D;’0’%3E%3Cg transform&#x3D;’translate(-249.000000, -126.000000)’ fill&#x3D;’%23FFFFFF’%3E%3Crect x&#x3D;’249’ y&#x3D;’126’ width&#x3D;’1’ height&#x3D;’1’%3E%3C&#x2F;rect%3E%3C&#x2F;g%3E%3C&#x2F;g%3E%3C&#x2F;svg%3E)</p>
<p>问题节点网卡配置</p>
<p>最终定位原因为问题节点既配置了 dhcp 获取 IP，又配置了静态 IP，导致 IP 冲突，引发网络异常</p>
<p>解决方法：</p>
<p>修改网卡配置文件 <code>/etc/sysconfig/network-scripts/ifcfg-enp26s0f0</code> 里 <code>BOOTPROTO=&quot;dhcp&quot;</code> 为 <code>BOOTPROTO=&quot;none&quot;</code>；<br>重启 <em>docker</em> 和 <em>kubelet</em> 问题解决。</p>
<h3 id="集群外云主机调用集群内应用超时"><a href="#集群外云主机调用集群内应用超时" class="headerlink" title="集群外云主机调用集群内应用超时"></a><strong>集群外云主机调用集群内应用超时</strong></h3><p>问题现象：Kubernetes 集群外云主机以 http post 方式访问 Kubernetes 集群应用接口超时</p>
<p>环境信息：Kubernetes 集群：calicoIP-IP 模式，应用接口以 nodeport 方式对外提供服务</p>
<p>客户端：Kubernetes 集群之外的云主机</p>
<p>排查过程：</p>
<ul>
<li>在云主机 telnet 应用接口地址和端口，可以连通，证明网络连通正常，如图所示</li>
<li>云主机上调用接口不通，在云主机和 Pod 所在 Kubernetes 节点同时抓包，使用 wireshark 分析数据包</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302141336949.png" alt="图片"></p>
<p>通过抓包结果分析结果为 TCP 链接建立没有问题，但是在传输大数据的时候会一直重传 <code>1514</code> 大小的第一个数据包直至超时。怀疑是链路两端 MTU 大小不一致导致（现象：某一个固定大小的包一直超时的情况）。如图所示，1514 大小的包一直在重传。</p>
<p>报文 1-3 TCP 三次握手正常</p>
<p>报文 1 info 中 MSS 字段可以看到 MSS 协商为 1460，MTU&#x3D;1460+20bytes（IP 包头）+20bytes（TCP 包头）&#x3D;1500</p>
<p>报文 7 k8s 主机确认了包 4 的数据包，但是后续再没有对数据的 ACK</p>
<p>报文 21-29 可以看到云主机一直在发送后面的数据，但是没有收到 k8s 节点的 ACK，结合 pod 未收到任何报文，表明是 k8s 节点和 POD 通信出现了问题。</p>
<p>![图片](data:image&#x2F;svg+xml,%3C%3Fxml version&#x3D;’1.0’ encoding&#x3D;’UTF-8’%3F%3E%3Csvg width&#x3D;’1px’ height&#x3D;’1px’ viewBox&#x3D;’0 0 1 1’ version&#x3D;’1.1’ xmlns&#x3D;’<a href="http://www.w3.org/2000/svg">http://www.w3.org/2000/svg</a>‘ xmlns:xlink&#x3D;’<a href="http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg">http://www.w3.org/1999/xlink&#39;%3E%3Ctitle%3E%3C/title%3E%3Cg</a> stroke&#x3D;’none’ stroke-width&#x3D;’1’ fill&#x3D;’none’ fill-rule&#x3D;’evenodd’ fill-opacity&#x3D;’0’%3E%3Cg transform&#x3D;’translate(-249.000000, -126.000000)’ fill&#x3D;’%23FFFFFF’%3E%3Crect x&#x3D;’249’ y&#x3D;’126’ width&#x3D;’1’ height&#x3D;’1’%3E%3C&#x2F;rect%3E%3C&#x2F;g%3E%3C&#x2F;g%3E%3C&#x2F;svg%3E)wireshark 分析</p>
<p>在云主机上使用 <code>ping -s</code> 指定数据包大小，发现超过 1400 大小的数据包无法正常发送。结合以上情况，定位是云主机网卡配置的 MTU 是 1500， <em>tunl0</em> 配置的 MTU 是 1440，导致大数据包无法发送至 <em>tunl0</em> ，因此 Pod 没有收到报文，接口调用失败。</p>
<p>解决方法：修改云主机网卡 MTU 值为 1440，或者修改 calico 的 MTU 值为 1500，保持链路两端 MTU 值一致。</p>
<h3 id="集群-pod-访问对象存储超时"><a href="#集群-pod-访问对象存储超时" class="headerlink" title="集群 pod 访问对象存储超时"></a><strong>集群 pod 访问对象存储超时</strong></h3><p>环境信息：公有云环境，Kubernetes 集群节点和对象存储在同一私有网络下，网络链路无防火墙限制 k8s 集群开启了节点自动弹缩（CA）和 Pod 自动弹缩（HPA），通过域名访问对象存储，Pod 使用集群 DNS 服务，集群 DNS 服务配置了用户自建上游 DNS 服务器</p>
<p>排查过程：</p>
<ul>
<li>使用 nsenter 工具进入 pod 容器网络命名空间测试，ping 对象存储域名不通，报错 unknown server name，ping 对象存储 lP 可以连通。</li>
<li><code>telnet</code> 对象存储 80&#x2F;443 端口可以连通。</li>
<li><code>paping</code> 对象存储 80&#x2F;443 端口无丢包。</li>
<li>为了验证 Pod 创建好以后的初始阶段网络连通性，将以上测试动作写入 dockerfile，重新生成容器镜像并创 pod，测试结果一致。</li>
</ul>
<p>通过上述步骤，判断 Pod 网络连通性无异常，超时原因为域名解析失败，怀疑问题如下：</p>
<ul>
<li>集群 DNS 服务存在异常</li>
<li>上游 DNS 服务存在异常</li>
<li>集群 DNS 服务与上游 DNS 通讯异常</li>
<li>pod 访问集群 DNS 服务异常</li>
</ul>
<p>根据上述方向排查，集群 DNS 服务状态正常，无报错。测试 Pod 分别使用集群 DNS 服务和上游 DNS 服务解析域名，前者解析失败，后者解析成功。至此，证明上游 DNS 服务正常，并且集群 DNS 服务日志中没有与上游 DNS 通讯超时的报错。定位到的问题：Pod 访问集群 DNS 服务超时</p>
<p>此时发现，出现问题的 Pod 集中在新弹出的 Kubernetes 节点上。这些节点的 <code>kube-proxy</code> Pod 状态全部为<em>pending</em>，没有正常调度到节点上。因此导致该节点上其他 Pod 无法访问包括 dns 在内的所有 Kubernetes service。</p>
<p>再进一步排查发现 <code>kube-proxy</code> Pod 没有配置 priorityclass 为最高优先级，导致节点资源紧张时为了将高优先级的应用 Pod 调度到该节点，将原本已运行在该节点的 kube-proxy 驱逐。</p>
<p>解决方法：将 <code>kube-proxy</code> 设置 <code>priorityclass</code> 值为 <code>system-node-critical</code> 最高优先级，同时建议应用 Pod 配置就绪探针，测试可以正常连通对象存储域名后再分配任务。</p>
]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>kubectl的多样用法</title>
    <url>/2023/02/14/kubectl%E7%9A%84%E5%A4%9A%E6%A0%B7%E7%94%A8%E6%B3%95/</url>
    <content><![CDATA[<h2 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h2><p>kubectl是K8s官方附带的命令行工具, 可以方便的操作K8s集群. 这篇文章主要介绍一些kubectl的别样用法, 希望读者有基础的K8s使用经验.</p>
<h2 id="打印当前使用的API"><a href="#打印当前使用的API" class="headerlink" title="打印当前使用的API"></a>打印当前使用的API</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl 的主要作用就是与ApiServer进行交互, 而交互的过程, 我们可以通过下面的方式来打印, </span></span><br><span class="line"><span class="comment"># 这个命令尤其适合调试自己的api接口时使用.</span></span><br><span class="line">kubectl get ns -v=9</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302141434405.png" alt="图片"></p>
<h2 id="按状态筛选容器以及删除"><a href="#按状态筛选容器以及删除" class="headerlink" title="按状态筛选容器以及删除"></a>按状态筛选容器以及删除</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pods --all-namespaces --field-selector status.phase=Pending -o json | \</span><br><span class="line">  jq <span class="string">&#x27;.items[] | &quot;kubectl delete pods \(.metadata.name) -n \(.metadata.namespace)&quot;&#x27;</span> | \</span><br><span class="line">  xargs -n 1 bash -c</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个命令要拆开来看</span></span><br><span class="line"><span class="comment"># 首先, 获取所有ns中状态为Pending的pods, 并以json形式输出</span></span><br><span class="line"><span class="comment"># 这个语句其实由很多变体, 比如,我想查找Failed的状态, 或是某个deployment</span></span><br><span class="line">kubectl get pods --all-namespaces --field-selector status.phase=Pending -o json </span><br><span class="line"></span><br><span class="line"><span class="comment"># 针对json变量进行处理, 生成可用的脚本</span></span><br><span class="line"><span class="comment"># 这里是我想介绍的重点, 利用jq以及kubectl的输出, 构建出可用的命令</span></span><br><span class="line">jq <span class="string">&#x27;.items[] | &quot;kubectl delete pods \(.metadata.name) -n \(.metadata.namespace)&quot;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行每一条命令</span></span><br><span class="line"><span class="comment"># 注意, 这种命令一定要好好调试, 删掉预期之外的pod就不好了.</span></span><br><span class="line">xargs -n 1 bash -c</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 例如, 下面的语句可以找到所有的Pods并打印可以执行的语句</span></span><br><span class="line">kubectl get pods --all-namespaces --field-selector status.phase=Running -o json | \</span><br><span class="line">  jq <span class="string">&#x27;.items[] | &quot;kubectl get pods \(.metadata.name) -o wide -n \(.metadata.namespace)&quot;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;kubectl get pods metrics-server-6d684c7b5-gtd6q -o wide -n kube-system&quot;</span></span><br><span class="line"><span class="string">&quot;kubectl get pods local-path-provisioner-58fb86bdfd-98frc -o wide -n kube-system&quot;</span></span><br><span class="line"><span class="string">&quot;kubectl get pods nginx-deployment-574b87c764-xppmx -o wide -n default&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 当然, 如果只是删除单个NS下面的一些pods, 我会选择下面的方法, 但是它操作多个NS就很不方便了.</span></span><br><span class="line">kubectl -n default get pods  | grep Completed | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> | xargs kubectl -n default delete pods</span><br></pre></td></tr></table></figure>

<h2 id="统计具体某台机器上运行的所有pod"><a href="#统计具体某台机器上运行的所有pod" class="headerlink" title="统计具体某台机器上运行的所有pod"></a>统计具体某台机器上运行的所有pod</h2><blockquote>
<p>kubectl可以使用两种选择器, 一种是label, 一种是field, 可以看官网的介绍: Labels and Selectors Field Selectors</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 它是一种选择器, 可以与上面的awk或者xargs配合使用.</span></span><br><span class="line"><span class="comment"># 我个人平时都不喜欢用这个, 直接get全部pods, 然后grep查找感觉更快</span></span><br><span class="line">kubectl get pods --all-namespaces -o wide --field-selector spec.nodeName=pve-node1</span><br></pre></td></tr></table></figure>

<h2 id="统计Pod在不同机器的具体数量分布"><a href="#统计Pod在不同机器的具体数量分布" class="headerlink" title="统计Pod在不同机器的具体数量分布"></a>统计Pod在不同机器的具体数量分布</h2><p>不知道有读者看过我的这篇文章: 基于kubernetes的PaaS平台中细力度控制pods方案的实现. 均衡分布的工作前提是得知pod在各个机器的分布情况. 最好的办法就是我们得到pod信息之后进行简单的统计, 这个工作可以使用awk实现.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl -n default get pods -o wide -l app=<span class="string">&quot;nginx&quot;</span> | awk <span class="string">&#x27;&#123;print $7&#125;&#x27;</span>|\</span><br><span class="line"> awk <span class="string">&#x27;&#123; count[$0]++  &#125; </span></span><br><span class="line"><span class="string"> END &#123; </span></span><br><span class="line"><span class="string">   printf(&quot;%-35s: %s\n&quot;,&quot;Word&quot;,&quot;Count&quot;);</span></span><br><span class="line"><span class="string">   for(ind in count)&#123;</span></span><br><span class="line"><span class="string">    printf(&quot;%-35s: %d\n&quot;,ind,count[ind]);</span></span><br><span class="line"><span class="string">   &#125;</span></span><br><span class="line"><span class="string"> &#125;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行结果如下</span></span><br><span class="line">Word                               : Count</span><br><span class="line">NODE                               : 1</span><br><span class="line">pve-node1                          : 1</span><br><span class="line">pve-node2                          : 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># awk的语法我没深入了解, 有兴趣的读者可以研究看看, 这里我就不求甚解了.</span></span><br></pre></td></tr></table></figure>

<h2 id="kubectl-proxy的使用"><a href="#kubectl-proxy的使用" class="headerlink" title="kubectl proxy的使用"></a>kubectl proxy的使用</h2><p>你可以理解为这个命令为K8s的ApiServer做了一层代理, 使用该代理, 你可以直接调用API而不需要经过鉴权. 启动之后, 甚至可以实现kubectl套娃, 下面是一个例子:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 当你没有设置kubeconfig而直接调用kubectl时</span></span><br><span class="line">kubectl get ns -v=9</span><br><span class="line"><span class="comment"># 可以打印出下面类似的错误</span></span><br><span class="line">curl -k -v -XGET  -H <span class="string">&quot;Accept: application/json, */*&quot;</span> -H <span class="string">&quot;User-Agent: kubectl/v1.21.3 (linux/amd64) kubernetes/ca643a4&quot;</span> <span class="string">&#x27;http://localhost:8080/api?timeout=32s&#x27;</span></span><br><span class="line">skipped caching discovery info due to Get <span class="string">&quot;http://localhost:8080/api?timeout=32s&quot;</span>: dial tcp 127.0.0.1:8080: connect: connection refused                     </span><br><span class="line"><span class="comment"># 也就是说当你不指定kubeconfig文件时, kubectl会默认访问本机的8080端口</span></span><br><span class="line"><span class="comment"># 那么我们先启动一个kubectl proxy, 然后指定监听8080, 再使用kubectl直接访问, 是不是就可行了呢, </span></span><br><span class="line"><span class="comment"># 事实证明, 安全与预想一致.</span></span><br><span class="line">KUBECONFIG=~/.kube/config-symv3 kubectl proxy  -p 8080</span><br><span class="line">kubectl get ns</span><br><span class="line">NAME                           STATUS   AGE</span><br><span class="line">default                        Active   127d</span><br></pre></td></tr></table></figure>

<blockquote>
<p>默认启动的proxy是屏蔽了某些api的, 并且有一些限制, 例如无法使用exec进入pod之中 可以使用kubectl proxy –help来看, 例如</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 仅允许本机访问</span></span><br><span class="line">--accept-hosts=<span class="string">&#x27;^localhost$,^127\.0\.0\.1$,^\[::1\]$&#x27;</span>: Regular expression <span class="keyword">for</span> hosts that the proxy should accept.</span><br><span class="line"><span class="comment"># 不允许访问下面的api, 也就是说默认没法exec进入容器</span></span><br><span class="line">--reject-paths=<span class="string">&#x27;^/api/.*/pods/.*/exec,^/api/.*/pods/.*/attach&#x27;</span>: Regular expression <span class="keyword">for</span> paths that the proxy should reject. Paths specified here will be rejected even accepted by --accept-paths.</span><br><span class="line"></span><br><span class="line"><span class="comment"># 想跳过exec的限制也很简单, 把reject-paths去掉就可以了</span></span><br><span class="line">kubectl proxy -p 8080 --keepalive 3600s --reject-paths=<span class="string">&#x27;&#x27;</span> -v=9 </span><br></pre></td></tr></table></figure>

<p>有人说这个kubectl proxy可能没什么作用, 那可能仅仅是你还没有实际的应用场景. 例如当我想要调试K8s dashboard代码的时候. 如果直接使用kubeconfig文件, 我没法看到具体的请求过程, 如果你加上一层proxy转发, 并且设置-v&#x3D;9的时候, 你就自动获得了一个日志记录工具, 在调试时相当有用.</p>
]]></content>
      <tags>
        <tag>kubernetes</tag>
        <tag>kubectl</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s集群修改cidr</title>
    <url>/2022/12/30/k8s%E9%9B%86%E7%BE%A4%E4%BF%AE%E6%94%B9cidr/</url>
    <content><![CDATA[<p>当集群的pod地址和本地网络冲突时，会导致集群无法访问本地资源，这种情况可以使用防火墙的DNAT做映射来规避，但不是一劳永逸的方法，要想一劳永逸，则需更改其中一个环境的<code>cidr</code>，对于一个公司来说，更改集群的cidr比较实际，下面以集群的<code>10.244.0.0/16</code>更改为<code>10.245.0.0/16</code>为例</p>
<h2 id="kubeadm-config"><a href="#kubeadm-config" class="headerlink" title="kubeadm-config"></a>kubeadm-config</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@master1 ~]<span class="comment"># kubectl -n kube-system edit cm kubeadm-config</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Please edit the object below. Lines beginning with a &#x27;#&#x27; will be ignored,</span></span><br><span class="line"><span class="comment"># and an empty file will abort the edit. If an error occurs while saving this file will be</span></span><br><span class="line"><span class="comment"># reopened with the relevant failures.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">ClusterConfiguration:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    apiServer:</span></span><br><span class="line"><span class="string">      certSANs:</span></span><br><span class="line"><span class="string">      - kubernetes</span></span><br><span class="line"><span class="string">      - kubernetes.default</span></span><br><span class="line"><span class="string">      - kubernetes.default.svc</span></span><br><span class="line"><span class="string">      - kubernetes.default.svc.cluster.local</span></span><br><span class="line"><span class="string">      - localhost</span></span><br><span class="line"><span class="string">      - 127.0.0.1</span></span><br><span class="line"><span class="string">      - lb.kubesphere.local</span></span><br><span class="line"><span class="string">      - 11.1.100.131</span></span><br><span class="line"><span class="string">      - master1</span></span><br><span class="line"><span class="string">      - master1.cluster.local</span></span><br><span class="line"><span class="string">      - master2</span></span><br><span class="line"><span class="string">      - master2.cluster.local</span></span><br><span class="line"><span class="string">      - 11.1.100.132</span></span><br><span class="line"><span class="string">      - master3</span></span><br><span class="line"><span class="string">      - master3.cluster.local</span></span><br><span class="line"><span class="string">      - 11.1.100.133</span></span><br><span class="line"><span class="string">      - 10.96.0.1</span></span><br><span class="line"><span class="string">      extraArgs:</span></span><br><span class="line"><span class="string">        audit-log-maxage: &quot;30&quot;</span></span><br><span class="line"><span class="string">        audit-log-maxbackup: &quot;10&quot;</span></span><br><span class="line"><span class="string">        audit-log-maxsize: &quot;100&quot;</span></span><br><span class="line"><span class="string">        authorization-mode: Node,RBAC</span></span><br><span class="line"><span class="string">        bind-address: 0.0.0.0</span></span><br><span class="line"><span class="string">        feature-gates: TTLAfterFinished=true,ExpandCSIVolumes=true,CSIStorageCapacity=true,RotateKubeletServerCertificate=true</span></span><br><span class="line"><span class="string">      timeoutForControlPlane: 4m0s</span></span><br><span class="line"><span class="string">    apiVersion: kubeadm.k8s.io/v1beta3</span></span><br><span class="line"><span class="string">    certificatesDir: /etc/kubernetes/pki</span></span><br><span class="line"><span class="string">    clusterName: test</span></span><br><span class="line"><span class="string">    controlPlaneEndpoint: lb.kubesphere.local:6443</span></span><br><span class="line"><span class="string">    controllerManager:</span></span><br><span class="line"><span class="string">      extraArgs:</span></span><br><span class="line"><span class="string">        bind-address: 0.0.0.0</span></span><br><span class="line"><span class="string">        cluster-signing-duration: 87600h</span></span><br><span class="line"><span class="string">        feature-gates: TTLAfterFinished=true,ExpandCSIVolumes=true,CSIStorageCapacity=true,RotateKubeletServerCertificate=true</span></span><br><span class="line"><span class="string">        node-cidr-mask-size: &quot;24&quot;</span></span><br><span class="line"><span class="string">      extraVolumes:</span></span><br><span class="line"><span class="string">      - hostPath: /etc/localtime</span></span><br><span class="line"><span class="string">        mountPath: /etc/localtime</span></span><br><span class="line"><span class="string">        name: host-time</span></span><br><span class="line"><span class="string">        readOnly: true</span></span><br><span class="line"><span class="string">    dns:</span></span><br><span class="line"><span class="string">      imageRepository: coredns</span></span><br><span class="line"><span class="string">      imageTag: 1.8.6</span></span><br><span class="line"><span class="string">    etcd:</span></span><br><span class="line"><span class="string">      external:</span></span><br><span class="line"><span class="string">        caFile: /etc/ssl/etcd/ssl/ca.pem</span></span><br><span class="line"><span class="string">        certFile: /etc/ssl/etcd/ssl/node-master1.pem</span></span><br><span class="line"><span class="string">        endpoints:</span></span><br><span class="line"><span class="string">        - https://11.1.100.131:2379</span></span><br><span class="line"><span class="string">        - https://11.1.100.132:2379</span></span><br><span class="line"><span class="string">        - https://11.1.100.133:2379</span></span><br><span class="line"><span class="string">        keyFile: /etc/ssl/etcd/ssl/node-master1-key.pem</span></span><br><span class="line"><span class="string">    imageRepository: kubesphere</span></span><br><span class="line"><span class="string">    kind: ClusterConfiguration</span></span><br><span class="line"><span class="string">    kubernetesVersion: v1.23.10</span></span><br><span class="line"><span class="string">    networking:</span></span><br><span class="line"><span class="string">      dnsDomain: cluster.local</span></span><br><span class="line"><span class="string">      # pod网段</span></span><br><span class="line"><span class="string">      podSubnet: 10.244.0.0/16</span></span><br><span class="line"><span class="string">      #svc网段</span></span><br><span class="line"><span class="string">      serviceSubnet: 10.96.0.0/16</span></span><br><span class="line"><span class="string">    scheduler:</span></span><br><span class="line"><span class="string">      extraArgs:</span></span><br><span class="line"><span class="string">        bind-address: 0.0.0.0</span></span><br><span class="line"><span class="string">        feature-gates: TTLAfterFinished=true,ExpandCSIVolumes=true,CSIStorageCapacity=true,RotateKubeletServerCertificate=true</span></span><br><span class="line"><span class="string"></span><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="string">&quot;2022-12-01T15:04:55Z&quot;</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubeadm-config</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">resourceVersion:</span> <span class="string">&quot;211&quot;</span></span><br><span class="line">  <span class="attr">uid:</span> <span class="string">005ee25b-2121-4b53-8478-4e1eb28cfdef</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="kube-controller-manager"><a href="#kube-controller-manager" class="headerlink" title="kube-controller-manager"></a><a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kube-controller-manager/">kube-controller-manager</a></h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#是否应在云提供商上分配和设置 Pod 的 CIDR。</span></span><br><span class="line"><span class="string">--allocate-node-cidrs</span></span><br><span class="line"><span class="comment">#集群中 Pod 的 CIDR 范围。 要求 --allocate-node-cidrs 为true</span></span><br><span class="line"><span class="string">--cluster-cidr</span> <span class="string">string</span></span><br><span class="line"><span class="comment">#集群中svc的 CIDR 范围。 要求 --allocate-node-cidrs 为true</span></span><br><span class="line"><span class="string">--service-cluster-ip-range</span> <span class="string">string</span></span><br></pre></td></tr></table></figure>

<h2 id="calico"><a href="#calico" class="headerlink" title="calico"></a>calico</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#[root@master1 ~]# kubectl edit daemonset -n kube-system   calico-node</span></span><br><span class="line">    <span class="string">···</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">DATASTORE_TYPE</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">kubernetes</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">WAIT_FOR_DATASTORE</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NODENAME</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">spec.nodeName</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">CALICO_NETWORKING_BACKEND</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">configMapKeyRef:</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">calico_backend</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">calico-config</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">CLUSTER_TYPE</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">k8s,bgp</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NODEIP</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">status.hostIP</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">IP_AUTODETECTION_METHOD</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">can-reach=$(NODEIP)</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">IP</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">autodetect</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">CALICO_IPV4POOL_IPIP</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">Always</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">CALICO_IPV4POOL_VXLAN</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">Never</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">CALICO_IPV6POOL_VXLAN</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">Never</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">FELIX_IPINIPMTU</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">configMapKeyRef:</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">veth_mtu</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">calico-config</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">FELIX_VXLANMTU</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">configMapKeyRef:</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">veth_mtu</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">calico-config</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">FELIX_WIREGUARDMTU</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">configMapKeyRef:</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">veth_mtu</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">calico-config</span></span><br><span class="line">         <span class="comment">#calicoipv4range</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">CALICO_IPV4POOL_CIDR</span></span><br><span class="line">          <span class="attr">value:</span> <span class="number">10.244</span><span class="number">.0</span><span class="number">.0</span><span class="string">/16</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">CALICO_IPV4POOL_BLOCK_SIZE</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&quot;24&quot;</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">CALICO_DISABLE_FILE_LOGGING</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">FELIX_DEFAULTENDPOINTTOHOSTACTION</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">ACCEPT</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">FELIX_IPV6SUPPORT</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&quot;false&quot;</span></span><br></pre></td></tr></table></figure>

<h2 id="calico的ippool"><a href="#calico的ippool" class="headerlink" title="calico的ippool"></a>calico的ippool</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#旧ippool</span></span><br><span class="line">[<span class="string">root@master1</span> <span class="string">~</span>]<span class="comment"># kubectl get ippool -oyaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">items:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiVersion:</span> <span class="string">crd.projectcalico.org/v1</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">IPPool</span></span><br><span class="line">  <span class="attr">metadata:</span></span><br><span class="line">    <span class="attr">annotations:</span></span><br><span class="line">      <span class="attr">projectcalico.org/metadata:</span> <span class="string">&#x27;&#123;&quot;uid&quot;:&quot;4af9f499-8333-4995-90d7-fbbb639a7f74&quot;,&quot;creationTimestamp&quot;:&quot;2022-12-01T15:05:17Z&quot;&#125;&#x27;</span></span><br><span class="line">    <span class="attr">creationTimestamp:</span> <span class="string">&quot;2022-12-01T15:08:12Z&quot;</span></span><br><span class="line">    <span class="attr">generation:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">default-ipv4-ippool</span></span><br><span class="line">    <span class="attr">resourceVersion:</span> <span class="string">&quot;916&quot;</span></span><br><span class="line">    <span class="attr">uid:</span> <span class="string">5fc88ba0-86e0-4d68-82d4-412537d2d1d2</span></span><br><span class="line">  <span class="attr">spec:</span></span><br><span class="line">    <span class="attr">allowedUses:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">Workload</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">Tunnel</span></span><br><span class="line">    <span class="attr">blockSize:</span> <span class="number">24</span></span><br><span class="line">    <span class="attr">cidr:</span> <span class="number">10.244</span><span class="number">.0</span><span class="number">.0</span><span class="string">/16</span></span><br><span class="line">    <span class="attr">ipipMode:</span> <span class="string">Always</span></span><br><span class="line">    <span class="attr">natOutgoing:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">nodeSelector:</span> <span class="string">all()</span></span><br><span class="line">    <span class="attr">vxlanMode:</span> <span class="string">Never</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">List</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">resourceVersion:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">selfLink:</span> <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#新ippool</span></span><br><span class="line"><span class="comment"># Please edit the object below. Lines beginning with a &#x27;#&#x27; will be ignored,</span></span><br><span class="line"><span class="comment"># and an empty file will abort the edit. If an error occurs while saving this file will be</span></span><br><span class="line"><span class="comment"># reopened with the relevant failures.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">crd.projectcalico.org/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">IPPool</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">projectcalico.org/metadata:</span> <span class="string">&#x27;&#123;&quot;uid&quot;:&quot;4af9f499-8333-4995-90d7-fbbb639a7f74&quot;,&quot;creationTimestamp&quot;:&quot;2022-12-01T15:05:17Z&quot;&#125;&#x27;</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="string">&quot;2022-12-01T15:08:12Z&quot;</span></span><br><span class="line">  <span class="attr">generation:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">default-ipv4-ippool</span></span><br><span class="line">  <span class="attr">resourceVersion:</span> <span class="string">&quot;3977007&quot;</span></span><br><span class="line">  <span class="attr">uid:</span> <span class="string">5fc88ba0-86e0-4d68-82d4-412537d2d1d2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">allowedUses:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Workload</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Tunnel</span></span><br><span class="line">  <span class="attr">blockSize:</span> <span class="number">24</span></span><br><span class="line">  <span class="attr">cidr:</span> <span class="number">10.245</span><span class="number">.0</span><span class="number">.0</span><span class="string">/16</span></span><br><span class="line">  <span class="attr">ipipMode:</span> <span class="string">Always</span></span><br><span class="line">  <span class="attr">natOutgoing:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">nodeSelector:</span> <span class="string">all()</span></span><br><span class="line">  <span class="attr">vxlanMode:</span> <span class="string">Never</span></span><br></pre></td></tr></table></figure>

<p>刚改完重启节点 使用<code>route -n</code>查看节点分配的<code>IP range</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#重启后route -n 查看节点状态</span></span><br><span class="line">[root@master1 ~]<span class="comment"># route -n</span></span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">0.0.0.0         11.1.100.254    0.0.0.0         UG    100    0        0 ens192</span><br><span class="line">10.244.32.0     11.1.100.133    255.255.255.0   UG    0      0        0 ens192</span><br><span class="line">10.244.161.0    0.0.0.0         255.255.255.0   U     0      0        0 *</span><br><span class="line">10.244.161.11   0.0.0.0         255.255.255.255 UH    0      0        0 calicadba4a333e</span><br><span class="line">10.244.208.0    11.1.100.132    255.255.255.0   UG    0      0        0 ens192</span><br><span class="line">10.245.32.0     11.1.100.133    255.255.255.0   UG    0      0        0 tunl0</span><br><span class="line">10.245.161.0    0.0.0.0         255.255.255.0   U     0      0        0 *</span><br><span class="line">10.245.161.1    0.0.0.0         255.255.255.255 UH    0      0        0 calicadba4a333e</span><br><span class="line">10.245.208.0    11.1.100.132    255.255.255.0   UG    0      0        0 tunl0</span><br><span class="line">11.1.100.0      0.0.0.0         255.255.255.0   U     100    0        0 ens192</span><br><span class="line">172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0</span><br><span class="line">192.168.192.0   0.0.0.0         255.255.255.0   U     0      0        0 zt5u4rkdlr</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>kubelet垃圾回收机制</title>
    <url>/2022/12/29/kubelet%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<h3 id="一、Tips"><a href="#一、Tips" class="headerlink" title="一、Tips"></a><strong>一、Tips</strong></h3><ol>
<li>Kubernetes的垃圾回收由kubelet进行管理，每分钟会查询清理一次容器，每五分钟查询清理一次镜像。在kubelet刚启动时并不会立即进行GC，即第一次进行容器回收为kubelet启动一分钟后，第一次进行镜像回收为kubelet启动五分钟后。</li>
<li>不推荐使用其它管理工具或手工进行容器和镜像的清理，因为kubelet需要通过容器来判断pod的运行状态，如果使用其它方式清除容器有可能影响kubelet的正常工作。</li>
<li>镜像的回收针对node结点上由docker管理的所有镜像，无论该镜像是否是在创建pod时pull的。而容器的回收策略只应用于通过kubelet管理的容器。</li>
<li>Kubernetes通过kubelet集成的cadvisor进行镜像的回收，有两个参数可以设置：<code>--image-gc-high-threshold</code>和<code>--image-gc-low-threshold</code>。当用于存储镜像的磁盘使用率达到百分之–image-gc-high-threshold时将触发镜像回收，删除最近最久未使用（LRU，Least Recently Used）的镜像直到磁盘使用率降为百分之<code>--image-gc-low-threshold</code>或无镜像可删为止。默认<code>--image-gc-high-threshold</code>为90，&#96;&#96;–image-gc-low-threshold&#96;为80。</li>
<li>容器的回收有三个参数可设置：<code>--minimum-container-ttl-duration</code>，<code>--maximum-dead-containers-per-container</code>和<code>--maximum-dead-containers</code>。从容器停止运行时起经过<code>--minimum-container-ttl-duration</code>时间后，该容器标记为已过期将来可以被回收（只是标记，不是回收），默认值为1m0s。一般情况下每个pod最多可以保留<code>--maximum-dead-containers-per-container</code>个已停止运行的容器集，默认值为2。整个node节点可以保留<code>--maximum-dead-containers</code>个已停止运行的容器，默认值为100。</li>
<li>如果需要关闭容器的垃圾回收策略，可以将<code>--minimum-container-ttl-duration</code>设为0（表示无限制），<code>--maximum-dead-containers-per-container</code>和<code>--maximum-dead-containers</code>设为负数。</li>
<li><code>--minimum-container-ttl-duration</code>的值可以使用单位后缀，如h表示小时，m表示分钟，s表示秒。</li>
<li>当<code>--maximum-dead-containers-per-container</code>和<code>--maximum-dead-containers</code>冲突时，&#96;&#96;–maximum-dead-containers&#96;优先考虑。</li>
<li>对于那些由kubelet创建的但由于某些原因导致无名字（）的容器，会在到达GC时间点时被删除。</li>
<li>回收容器时，按创建时间排序，优先删除那些创建时间最早的容器。</li>
<li>到达GC时间点时，具体的GC过程如下：1）遍历所有pod，使其满足<code>--maximum-dead-containers-per-container</code>；2）经过上一步后如果不满足<code>--maximum-dead-containers</code>，计算值<code>X=（--maximum-dead-containers）/（pod总数）</code>，再遍历所有pod，使其满足已停止运行的容器集个数不大于X且至少为1；3）经过以上两步后如果还不满足<code>--maximum-dead-containers</code>，则对所有已停止的容器排序，优先删除创建时间最早的容器直到满足<code>--maximum-dead-containers</code>为止。</li>
<li>当某个镜像重新pull或启动某个pod用到该镜像时，该镜像的最近使用时间都会被更新。</li>
<li>Kubernetes的垃圾回收在1.1.4版本开始才渐渐完善，之前的版本存在比较多bug甚至不能发挥作用。</li>
<li>关于容器的回收需要特别注意pod的概念，比如，通过同一个yaml文件create一个pod，再delete这个pod，然后再create这个pod，此时之前的那个pod对应的容器并不会作为新创建pod的已停止容器集，因为这两个pod虽然同名，但已经不是同一个pod了。只有同一个pod中在运行过程中由于意外或其它情况停止的容器才算是这个pod的已停止容器集。</li>
</ol>
<h3 id="二、Experiments"><a href="#二、Experiments" class="headerlink" title="二、Experiments"></a><strong>二、Experiments</strong></h3><ol>
<li>镜像回收（使用docker默认 <code>--graph</code> 参数：<code>/var/lib/docker</code>）</li>
</ol>
<p>结点上运行的docker设置的参数 <code>--graph</code> 使用默认的<code>/var/lib/docker</code>，指向&#x2F;var文件系统，通过df -lh查看目前 &#x2F;var 磁盘使用率为30%，启动kubelet设置镜像回收相关参数如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">--image-gc-high-threshold=40</span> <span class="string">--image-gc-low-threshold=35</span></span><br></pre></td></tr></table></figure>

<p>此时任意创建两个使用不同镜像的pod，在node节点上可以看到新pull了三个images（pause镜像是启动pod必需的）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[@tc-151-100 /opt/domeos/openxxs/k8s-1.1.7-flannel]<span class="comment"># docker images</span></span><br><span class="line">REPOSITORY                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">10.11.150.76:5000/openxxs/iperf   1.2                 1783511c56f8        3 months ago        279 MB</span><br><span class="line">10.11.150.76:5000/centos          7                   5ddf34d4d69b        8 months ago        172.2 MB</span><br><span class="line">pub.domeos.org/kubernetes/pause   latest              f9d5de079539        20 months ago       239.8 kB</span><br></pre></td></tr></table></figure>

<p>此时查看&#x2F;var磁盘使用率达到了41%，然后将使用<code>10.11.150.76:5000/centos:7</code>镜像的pod删除，等待GC的镜像回收时间点。然而五分钟过去了，什么事情也没有发生&#x3D;_&#x3D;!!。还记得 docker rmi 镜像时有个前提条件是什么吗？没错，要求使用该镜像的容器都已经被删除了才可以。前面删除pod只是停止了容器，并没有将容器删除。因此手工将对应的容器docker rm掉，再等待五分钟后，可以看到镜像已经被删除回收了：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[@tc-151-100 /opt/domeos/openxxs/k8s-1.1.7-flannel]<span class="comment"># docker images</span></span><br><span class="line">REPOSITORY                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">10.11.150.76:5000/openxxs/iperf   1.2                 1783511c56f8        3 months ago        279 MB</span><br><span class="line">pub.domeos.org/kubernetes/pause   latest              f9d5de079539        20 months ago       239.8 kB</span><br></pre></td></tr></table></figure>

<blockquote>
<p>结论：只有相关联的容器都被停止并删除回收后，才能将Kubernetes的镜像垃圾回收策略应用到该镜像上。</p>
</blockquote>
<ol>
<li>镜像回收（使用自定义docker <code>--graph</code> 参数：<code>/opt/docker</code>）</li>
</ol>
<p>结点上运行的docker设置的参数<code>--graph</code>指向 &#x2F;opt 磁盘，通过 df -lh 查看目前 &#x2F;opt 磁盘使用率为 48% ，启动 kubelet 设置镜像回收相关参数如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">--image-gc-high-threshold=50</span> <span class="string">--image-gc-low-threshold=40</span></span><br></pre></td></tr></table></figure>

<p>此时任意创建两个使用不同镜像的pod，在node节点上可以看到新pull了三个images：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[@tc-151-100 /opt/domeos/openxxs/k8s-1.1.7-flannel]<span class="comment"># docker images</span></span><br><span class="line">REPOSITORY                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">10.11.150.76:5000/openxxs/iperf   1.2                 1783511c56f8        3 months ago        279 MB</span><br><span class="line">10.11.150.76:5000/centos          7                   5ddf34d4d69b        8 months ago        172.2 MB</span><br><span class="line">pub.domeos.org/kubernetes/pause   latest              f9d5de079539        20 months ago       239.8 kB</span><br></pre></td></tr></table></figure>

<p>此时查看&#x2F;opt磁盘使用率达到了51%，然后将使用10.11.150.76:5000&#x2F;centos:7镜像的pod删除，手工将对应的容器docker rm掉，等待GC的镜像回收时间点。然而五分钟过去了，十分钟过去了，docker images时centos镜像依旧顽固地坚守在阵地。</p>
<blockquote>
<p>结论：目前Kubernetes的镜像垃圾回收策略可以在docker  <code>--graph</code> 参数默认为 <code>/var/lib/docker</code> 时正常工作，当 <code>--graph</code> 设置为其它磁盘路径时还存在bug。</p>
</blockquote>
<p>问题反馈在 Github 的相关 issue 里：<a href="https://github.com/kubernetes/kubernetes/issues/17994">https://github.com/kubernetes/kubernetes/issues/17994</a>，可以继续跟进。</p>
<p>Append: 根据Github上的反馈，这个bug将在后续版本中解决，目前版本需要让设置了–graph的镜像垃圾回收生效，在启动kubelet时还需要加上参数 <code>--docker-root=&lt;docker --graph参数值&gt;</code>。</p>
<ol>
<li>容器回收之 <code>--maximum-dead-containers-per-container</code> 参数</li>
</ol>
<p>启动kubelet设置容器回收相关参数如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">--maximum-dead-containers-per-container=1</span> <span class="string">--minimum-container-ttl-duration=30s</span> <span class="string">--maximum-dead-containers=100</span></span><br></pre></td></tr></table></figure>

<p>创建一个只包含一个容器且该容器一运行就退出的pod，此时在node节点上可以看到该pod中的容器不断的创建退出创建退出：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[@tc-151-100 /home/domeos]<span class="comment"># docker ps -a</span></span><br><span class="line">CONTAINER ID        IMAGE                                    COMMAND             CREATED             STATUS                      PORTS               NAMES</span><br><span class="line">2fe969499164        10.11.150.76:5000/centos:7               <span class="string">&quot;/bin/bash&quot;</span>         4 seconds ago       Exited (0) 2 seconds ago                        k8s_iperf1.57dfe29d_test-gc-pod-exit_default_92e8bd05-e9e6-11e5-974c-782bcb2a316a_68cc6f03</span><br><span class="line">555b5e7a8550        10.11.150.76:5000/centos:7               <span class="string">&quot;/bin/bash&quot;</span>         24 seconds ago      Exited (0) 22 seconds ago                       k8s_iperf1.57dfe29d_test-gc-pod-exit_default_92e8bd05-e9e6-11e5-974c-782bcb2a316a_ad4a5e39</span><br><span class="line">94b30a0b32c2        10.11.150.76:5000/centos:7               <span class="string">&quot;/bin/bash&quot;</span>         34 seconds ago      Exited (0) 32 seconds ago                       k8s_iperf1.57dfe29d_test-gc-pod-exit_default_92e8bd05-e9e6-11e5-974c-782bcb2a316a_4027e3e1</span><br><span class="line">d458e6a7d396        pub.domeos.org/kubernetes/pause:latest   <span class="string">&quot;/pause&quot;</span>            34 seconds ago      Up 33 seconds                                   k8s_POD.bdb2e1f5_test-gc-pod-exit_default_92e8bd05-e9e6-11e5-974c-782bcb2a316a_09798975</span><br></pre></td></tr></table></figure>

<p>GC的容器回收时间点到达时，可以看到创建时间大于30秒的已退出容器只剩下一个（pause容器不计算），且先创建的容器被优先删除：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[@tc-151-100 /home/domeos]<span class="comment"># docker ps -a</span></span><br><span class="line">CONTAINER ID        IMAGE                                    COMMAND             CREATED             STATUS                      PORTS               NAMES</span><br><span class="line">5aae6157aeff        10.11.150.76:5000/centos:7               <span class="string">&quot;/bin/bash&quot;</span>         46 seconds ago      Exited (0) 45 seconds ago                       k8s_iperf1.57dfe29d_test-gc-pod-exit_default_92e8bd05-e9e6-11e5-974c-782bcb2a316a_f126d2a8</span><br><span class="line">d458e6a7d396        pub.domeos.org/kubernetes/pause:latest   <span class="string">&quot;/pause&quot;</span>            2 minutes ago       Up 2 minutes                                    k8s_POD.bdb2e1f5_test-gc-pod-exit_default_92e8bd05-e9e6-11e5-974c-782bcb2a316a_09798975</span><br></pre></td></tr></table></figure>

<blockquote>
<p>结论：Kubernetes容器垃圾回收的<code>--maximum-dead-containers-per-container</code>参数设置可正常工作。</p>
</blockquote>
<ol>
<li><code>--maximum-dead-containers-per-container</code> 针对容器还是容器集</li>
</ol>
<p>启动kubelet设置容器回收相关参数如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">--maximum-dead-containers-per-container=1</span> <span class="string">--minimum-container-ttl-duration=30s</span> <span class="string">--maximum-dead-containers=100</span></span><br></pre></td></tr></table></figure>

<p>创建一个包含三个容器且这些容器一运行就退出的pod，此时在node节点上可以看到该pod中的容器不断的创建退出创建退出：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[@tc-151-100 /home/domeos]<span class="comment"># docker ps -a</span></span><br><span class="line">CONTAINER ID        IMAGE                                    COMMAND             CREATED             STATUS                      PORTS               NAMES</span><br><span class="line">dec04bd28a03        10.11.150.76:5000/centos:7               <span class="string">&quot;/bin/bash&quot;</span>         7 seconds ago       Exited (0) 6 seconds ago                        k8s_iperf1.57dfe29d_test-gc-pod-exit_default_d1677c09-e9e7-11e5-974c-782bcb2a316a_830a9375</span><br><span class="line">7c94d4a963a7        10.11.150.76:5000/centos:7               <span class="string">&quot;/bin/bash&quot;</span>         7 seconds ago       Exited (0) 6 seconds ago                        k8s_iperf3.5c8de29f_test-gc-pod-exit_default_d1677c09-e9e7-11e5-974c-782bcb2a316a_975d44d3</span><br><span class="line">4f3e7e8ddfd5        10.11.150.76:5000/centos:7               <span class="string">&quot;/bin/bash&quot;</span>         8 seconds ago       Exited (0) 7 seconds ago                        k8s_iperf2.5a36e29e_test-gc-pod-exit_default_d1677c09-e9e7-11e5-974c-782bcb2a316a_d024eb06</span><br><span class="line">cb48cf2ba133        10.11.150.76:5000/centos:7               <span class="string">&quot;/bin/bash&quot;</span>         12 seconds ago      Exited (0) 11 seconds ago                       k8s_iperf3.5c8de29f_test-gc-pod-exit_default_d1677c09-e9e7-11e5-974c-782bcb2a316a_b5ff7373</span><br><span class="line">ec2941f046f0        10.11.150.76:5000/centos:7               <span class="string">&quot;/bin/bash&quot;</span>         13 seconds ago      Exited (0) 12 seconds ago                       k8s_iperf2.5a36e29e_test-gc-pod-exit_default_d1677c09-e9e7-11e5-974c-782bcb2a316a_69b1a996</span><br><span class="line">f831e8ed5687        10.11.150.76:5000/centos:7               <span class="string">&quot;/bin/bash&quot;</span>         13 seconds ago      Exited (0) 12 seconds ago                       k8s_iperf1.57dfe29d_test-gc-pod-exit_default_d1677c09-e9e7-11e5-974c-782bcb2a316a_fbc02e2e</span><br><span class="line">ee972a4537fc        pub.domeos.org/kubernetes/pause:latest   <span class="string">&quot;/pause&quot;</span>            14 seconds ago      Up 13 seconds                                   k8s_POD.bdb2e1f5_test-gc-pod-exit_default_d1677c09-e9e7-11e5-974c-782bcb2a316a_85b3c032</span><br></pre></td></tr></table></figure>

<p>GC的容器回收时间点到达时，可以看到创建时间大于30秒的已退出容器剩下三个（pause容器不计算），且这三个容器正好是一组：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[@tc-151-100 /home/domeos]<span class="comment"># docker ps -a</span></span><br><span class="line">CONTAINER ID        IMAGE                                    COMMAND             CREATED              STATUS                      PORTS               NAMES</span><br><span class="line">e4351e6855ae        10.11.150.76:5000/centos:7               <span class="string">&quot;/bin/bash&quot;</span>         51 seconds ago       Exited (0) 50 seconds ago                       k8s_iperf3.5c8de29f_test-gc-pod-exit_default_d1677c09-e9e7-11e5-974c-782bcb2a316a_263dd820</span><br><span class="line">990baa6e6a7a        10.11.150.76:5000/centos:7               <span class="string">&quot;/bin/bash&quot;</span>         52 seconds ago       Exited (0) 51 seconds ago                       k8s_iperf2.5a36e29e_test-gc-pod-exit_default_d1677c09-e9e7-11e5-974c-782bcb2a316a_b16b5eaa</span><br><span class="line">c6916fb06d65        10.11.150.76:5000/centos:7               <span class="string">&quot;/bin/bash&quot;</span>         53 seconds ago       Exited (0) 51 seconds ago                       k8s_iperf1.57dfe29d_test-gc-pod-exit_default_d1677c09-e9e7-11e5-974c-782bcb2a316a_1d8ea284</span><br><span class="line">ee972a4537fc        pub.domeos.org/kubernetes/pause:latest   <span class="string">&quot;/pause&quot;</span>            About a minute ago   Up About a minute                               k8s_POD.bdb2e1f5_test-gc-pod-exit_default_d1677c09-e9e7-11e5-974c-782bcb2a316a_85b3c032</span><br></pre></td></tr></table></figure>

<blockquote>
<p>结论：<code>--maximum-dead-containers-per-container</code> 的计数针对一个pod内的容器集而不是容器的个数。</p>
</blockquote>
<ol>
<li>容器回收之 <code>--maximum-dead-containers</code> 参数</li>
</ol>
<p>启动kubelet设置容器回收相关参数如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">--maximum-dead-containers-per-container=2</span> <span class="string">--minimum-container-ttl-duration=30s</span> <span class="string">--maximum-dead-containers=3</span></span><br></pre></td></tr></table></figure>

<p>创建一个包含三个容器的pod，再删除该pod，再创建该pod，再删除该pod，这样就产生了8个已退出容器（包括两个pause容器）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[@tc-151-100 /home/domeos]<span class="comment"># docker ps -a</span></span><br><span class="line">CONTAINER ID        IMAGE                                    COMMAND             CREATED             STATUS                              PORTS               NAMES</span><br><span class="line">a28625d189df        10.11.150.76:5000/centos:7               <span class="string">&quot;/bin/bash&quot;</span>         1 seconds ago       Exited (0) Less than a second ago                       k8s_iperf3.5c8de29f_test-gc-pod-exit_default_c7612b59-e9ee-11e5-974c-782bcb2a316a_48c11200</span><br><span class="line">97aca44f0deb        10.11.150.76:5000/centos:7               <span class="string">&quot;/bin/bash&quot;</span>         2 seconds ago       Exited (0) 1 seconds ago                                k8s_iperf2.5a36e29e_test-gc-pod-exit_default_c7612b59-e9ee-11e5-974c-782bcb2a316a_df34f48d</span><br><span class="line">4e57b6c839ae        10.11.150.76:5000/centos:7               <span class="string">&quot;/bin/bash&quot;</span>         3 seconds ago       Exited (0) 2 seconds ago                                k8s_iperf1.57dfe29d_test-gc-pod-exit_default_c7612b59-e9ee-11e5-974c-782bcb2a316a_afd622b2</span><br><span class="line">12588fce1433        pub.domeos.org/kubernetes/pause:latest   <span class="string">&quot;/pause&quot;</span>            3 seconds ago       Exited (2) Less than a second ago                       k8s_POD.bdb2e1f5_test-gc-pod-exit_default_c7612b59-e9ee-11e5-974c-782bcb2a316a_c9d4cbaa</span><br><span class="line">621ed207d452        10.11.150.76:5000/centos:7               <span class="string">&quot;/bin/bash&quot;</span>         4 seconds ago       Exited (0) 3 seconds ago                                k8s_iperf3.5c8de29f_test-gc-pod-exit_default_c5cbddbb-e9ee-11e5-974c-782bcb2a316a_a91278cd</span><br><span class="line">023c10fad4fd        10.11.150.76:5000/centos:7               <span class="string">&quot;/bin/bash&quot;</span>         5 seconds ago       Exited (0) 4 seconds ago                                k8s_iperf2.5a36e29e_test-gc-pod-exit_default_c5cbddbb-e9ee-11e5-974c-782bcb2a316a_6cc03f37</span><br><span class="line">756eb7bb4b53        10.11.150.76:5000/centos:7               <span class="string">&quot;/bin/bash&quot;</span>         5 seconds ago       Exited (0) 4 seconds ago                                k8s_iperf1.57dfe29d_test-gc-pod-exit_default_c5cbddbb-e9ee-11e5-974c-782bcb2a316a_83312ec2</span><br><span class="line">d54bdc22773e        pub.domeos.org/kubernetes/pause:latest   <span class="string">&quot;/pause&quot;</span>            6 seconds ago       Exited (2) 3 seconds ago                                k8s_POD.bdb2e1f5_test-gc-pod-exit_default_c5cbddbb-e9ee-11e5-974c-782bcb2a316a_ccb57220</span><br></pre></td></tr></table></figure>

<p>GC的容器回收时间点到达时，可以看到已退出容器只剩下了三个，pause容器也被回收了：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[@tc-151-100 /home/domeos]<span class="comment"># docker ps -a</span></span><br><span class="line">CONTAINER ID        IMAGE                        COMMAND             CREATED             STATUS                     PORTS               NAMES</span><br><span class="line">a28625d189df        10.11.150.76:5000/centos:7   <span class="string">&quot;/bin/bash&quot;</span>         2 minutes ago       Exited (0) 2 minutes ago                       k8s_iperf3.5c8de29f_test-gc-pod-exit_default_c7612b59-e9ee-11e5-974c-782bcb2a316a_48c11200</span><br><span class="line">97aca44f0deb        10.11.150.76:5000/centos:7   <span class="string">&quot;/bin/bash&quot;</span>         2 minutes ago       Exited (0) 2 minutes ago                       k8s_iperf2.5a36e29e_test-gc-pod-exit_default_c7612b59-e9ee-11e5-974c-782bcb2a316a_df34f48d</span><br><span class="line">4e57b6c839ae        10.11.150.76:5000/centos:7   <span class="string">&quot;/bin/bash&quot;</span>         2 minutes ago       Exited (0) 2 minutes ago                       k8s_iperf1.57dfe29d_test-gc-pod-exit_default_c7612b59-e9ee-11e5-974c-782bcb2a316a_afd622b2</span><br></pre></td></tr></table></figure>

<blockquote>
<p>结论：Kubernetes容器垃圾回收的 <code>--maximum-dead-containers</code> 参数设置可正常工作；pause容器也作为可回收容器被管理着；Tips第11条第3）点。</p>
</blockquote>
<ol>
<li><code>--maximum-dead-containers</code> 对于非kubelet管理的容器是否计数</li>
</ol>
<p>在第5个实验的基础上，手工创建一个container，等待GC的容器回收时间点到达，一分钟过去了，两分钟过去了，docker ps -a 显示的依然是4个容器：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[@tc-151-100 /home/domeos]<span class="comment"># docker run -it 10.11.150.76:5000/openxxs/iperf:1.2 /bin/sh</span></span><br><span class="line">sh-4.2<span class="comment"># exit</span></span><br><span class="line"><span class="built_in">exit</span></span><br><span class="line">[@tc-151-100 /home/domeos]<span class="comment"># docker ps -a</span></span><br><span class="line">CONTAINER ID        IMAGE                                 COMMAND             CREATED             STATUS                      PORTS               NAMES</span><br><span class="line">939b932dc7db        10.11.150.76:5000/openxxs/iperf:1.2   <span class="string">&quot;/bin/sh&quot;</span>           2 minutes ago       Exited (0) 2 minutes ago                        backstabbing_aryabhata</span><br><span class="line">a28625d189df        10.11.150.76:5000/centos:7            <span class="string">&quot;/bin/bash&quot;</span>         12 minutes ago      Exited (0) 12 minutes ago                       k8s_iperf3.5c8de29f_test-gc-pod-exit_default_c7612b59-e9ee-11e5-974c-782bcb2a316a_48c11200</span><br><span class="line">97aca44f0deb        10.11.150.76:5000/centos:7            <span class="string">&quot;/bin/bash&quot;</span>         12 minutes ago      Exited (0) 12 minutes ago                       k8s_iperf2.5a36e29e_test-gc-pod-exit_default_c7612b59-e9ee-11e5-974c-782bcb2a316a_df34f48d</span><br><span class="line">4e57b6c839ae        10.11.150.76:5000/centos:7            <span class="string">&quot;/bin/bash&quot;</span>         12 minutes ago      Exited (0) 12 minutes ago                       k8s_iperf1.57dfe29d_test-gc-pod-exit_default_c7612b59-e9ee-11e5-974c-782bcb2a316a_afd622b2</span><br></pre></td></tr></table></figure>

<blockquote>
<p>结论：Kubernetes容器垃圾回收的策略不适用于非kubelet管理的容器。</p>
</blockquote>
]]></content>
      <categories>
        <category>kubernetes</category>
        <category>Kubelet</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>Kubelet</tag>
      </tags>
  </entry>
  <entry>
    <title>kubernetes各名词缩写</title>
    <url>/2023/02/07/kubernetes%E5%90%8D%E8%AF%8D%E7%BC%A9%E5%86%99/</url>
    <content><![CDATA[<h2 id="kubernetes各名词缩写"><a href="#kubernetes各名词缩写" class="headerlink" title="kubernetes各名词缩写"></a>kubernetes各名词缩写</h2><table>
<thead>
<tr>
<th>NAME</th>
<th>SHORTNAMES</th>
<th>APIGROUP</th>
<th>NAMESPACED</th>
<th>KIND</th>
</tr>
</thead>
<tbody><tr>
<td>bindings</td>
<td></td>
<td></td>
<td>true</td>
<td>Binding</td>
</tr>
<tr>
<td>componentstatuses</td>
<td>cs</td>
<td></td>
<td>false</td>
<td>ComponentStatus</td>
</tr>
<tr>
<td>configmaps</td>
<td>cm</td>
<td></td>
<td>true</td>
<td>ConfigMap</td>
</tr>
<tr>
<td>endpoints</td>
<td>ep</td>
<td></td>
<td>true</td>
<td>Endpoints</td>
</tr>
<tr>
<td>events</td>
<td>ev</td>
<td></td>
<td>true</td>
<td>Event</td>
</tr>
<tr>
<td>limitranges</td>
<td>limits</td>
<td></td>
<td>true</td>
<td>LimitRange</td>
</tr>
<tr>
<td>namespaces</td>
<td>ns</td>
<td></td>
<td>false</td>
<td>Namespace</td>
</tr>
<tr>
<td>nodes</td>
<td>no</td>
<td></td>
<td>false</td>
<td>Node</td>
</tr>
<tr>
<td>persistentvolumeclaims</td>
<td>pvc</td>
<td></td>
<td>true</td>
<td>PersistentVolumeClaim</td>
</tr>
<tr>
<td>persistentvolumes</td>
<td>pv</td>
<td></td>
<td>false</td>
<td>PersistentVolume</td>
</tr>
<tr>
<td>pods</td>
<td>po</td>
<td></td>
<td>true</td>
<td>Pod</td>
</tr>
<tr>
<td>podtemplates</td>
<td></td>
<td></td>
<td>true</td>
<td>PodTemplate</td>
</tr>
<tr>
<td>replicationcontrollers</td>
<td>rc</td>
<td></td>
<td>true</td>
<td>ReplicationController</td>
</tr>
<tr>
<td>resourcequotas</td>
<td>quota</td>
<td></td>
<td>true</td>
<td>ResourceQuota</td>
</tr>
<tr>
<td>secrets</td>
<td></td>
<td></td>
<td>true</td>
<td>Secret</td>
</tr>
<tr>
<td>serviceaccounts</td>
<td>sa</td>
<td></td>
<td>true</td>
<td>ServiceAccount</td>
</tr>
<tr>
<td>services</td>
<td>svc</td>
<td></td>
<td>true</td>
<td>Service</td>
</tr>
<tr>
<td>mutatingwebhookconfigurations</td>
<td></td>
<td>admissionregistration.k8s.io</td>
<td>false</td>
<td>MutatingWebhookConfiguration</td>
</tr>
<tr>
<td>validatingwebhookconfigurations</td>
<td></td>
<td>admissionregistration.k8s.io</td>
<td>false</td>
<td>ValidatingWebhookConfiguration</td>
</tr>
<tr>
<td>customresourcedefinitions</td>
<td>crd,crds</td>
<td>apiextensions.k8s.io</td>
<td>false</td>
<td>CustomResourceDefinition</td>
</tr>
<tr>
<td>apiservices</td>
<td></td>
<td>apiregistration.k8s.io</td>
<td>false</td>
<td>APIService</td>
</tr>
<tr>
<td>controllerrevisions</td>
<td></td>
<td>apps</td>
<td>true</td>
<td>ControllerRevision</td>
</tr>
<tr>
<td>daemonsets</td>
<td>ds</td>
<td>apps</td>
<td>true</td>
<td>DaemonSet</td>
</tr>
<tr>
<td>deployments</td>
<td>deploy</td>
<td>apps</td>
<td>true</td>
<td>Deployment</td>
</tr>
<tr>
<td>replicasets</td>
<td>rs</td>
<td>apps</td>
<td>true</td>
<td>ReplicaSet</td>
</tr>
<tr>
<td>statefulsets</td>
<td>sts</td>
<td>apps</td>
<td>true</td>
<td>StatefulSet</td>
</tr>
<tr>
<td>tokenreviews</td>
<td></td>
<td>authentication.k8s.io</td>
<td>false</td>
<td>TokenReview</td>
</tr>
<tr>
<td>localsubjectaccessreviews</td>
<td></td>
<td>authorization.k8s.io</td>
<td>true</td>
<td>LocalSubjectAccessReview</td>
</tr>
<tr>
<td>selfsubjectaccessreviews</td>
<td></td>
<td>authorization.k8s.io</td>
<td>false</td>
<td>SelfSubjectAccessReview</td>
</tr>
<tr>
<td>selfsubjectrulesreviews</td>
<td></td>
<td>authorization.k8s.io</td>
<td>false</td>
<td>SelfSubjectRulesReview</td>
</tr>
<tr>
<td>subjectaccessreviews</td>
<td></td>
<td>authorization.k8s.io</td>
<td>false</td>
<td>SubjectAccessReview</td>
</tr>
<tr>
<td>horizontalpodautoscalers</td>
<td>hpa</td>
<td>autoscaling</td>
<td>true</td>
<td>HorizontalPodAutoscaler</td>
</tr>
<tr>
<td>cronjobs</td>
<td>cj</td>
<td>batch</td>
<td>true</td>
<td>CronJob</td>
</tr>
<tr>
<td>jobs</td>
<td></td>
<td>batch</td>
<td>true</td>
<td>Job</td>
</tr>
<tr>
<td>certificatesigningrequests</td>
<td>csr</td>
<td>certificates.k8s.io</td>
<td>false</td>
<td>CertificateSigningRequest</td>
</tr>
<tr>
<td>leases</td>
<td></td>
<td>coordination.k8s.io</td>
<td>true</td>
<td>Lease</td>
</tr>
<tr>
<td>bgpconfigurations</td>
<td></td>
<td>crd.projectcalico.org</td>
<td>false</td>
<td>BGPConfiguration</td>
</tr>
<tr>
<td>clusterinformations</td>
<td></td>
<td>crd.projectcalico.org</td>
<td>false</td>
<td>ClusterInformation</td>
</tr>
<tr>
<td>felixconfigurations</td>
<td></td>
<td>crd.projectcalico.org</td>
<td>false</td>
<td>FelixConfiguration</td>
</tr>
<tr>
<td>globalnetworkpolicies</td>
<td></td>
<td>crd.projectcalico.org</td>
<td>false</td>
<td>GlobalNetworkPolicy</td>
</tr>
<tr>
<td>globalnetworksets</td>
<td></td>
<td>crd.projectcalico.org</td>
<td>false</td>
<td>GlobalNetworkSet</td>
</tr>
<tr>
<td>hostendpoints</td>
<td></td>
<td>crd.projectcalico.org</td>
<td>false</td>
<td>HostEndpoint</td>
</tr>
<tr>
<td>ippools</td>
<td></td>
<td>crd.projectcalico.org</td>
<td>false</td>
<td>IPPool</td>
</tr>
<tr>
<td>networkpolicies</td>
<td></td>
<td>crd.projectcalico.org</td>
<td>true</td>
<td>NetworkPolicy</td>
</tr>
<tr>
<td>events</td>
<td>ev</td>
<td>events.k8s.io</td>
<td>true</td>
<td>Event</td>
</tr>
<tr>
<td>daemonsets</td>
<td>ds</td>
<td>extensions</td>
<td>true</td>
<td>DaemonSet</td>
</tr>
<tr>
<td>deployments</td>
<td>deploy</td>
<td>extensions</td>
<td>true</td>
<td>Deployment</td>
</tr>
<tr>
<td>ingresses</td>
<td>ing</td>
<td>extensions</td>
<td>true</td>
<td>Ingress</td>
</tr>
<tr>
<td>networkpolicies</td>
<td>netpol</td>
<td>extensions</td>
<td>true</td>
<td>NetworkPolicy</td>
</tr>
<tr>
<td>podsecuritypolicies</td>
<td>psp</td>
<td>extensions</td>
<td>false</td>
<td>PodSecurityPolicy</td>
</tr>
<tr>
<td>replicasets</td>
<td>rs</td>
<td>extensions</td>
<td>true</td>
<td>ReplicaSet</td>
</tr>
<tr>
<td>nodes</td>
<td></td>
<td>metrics.k8s.io</td>
<td>false</td>
<td>NodeMetrics</td>
</tr>
<tr>
<td>pods</td>
<td></td>
<td>metrics.k8s.io</td>
<td>true</td>
<td>PodMetrics</td>
</tr>
<tr>
<td>networkpolicies</td>
<td>netpol</td>
<td>networking.k8s.io</td>
<td>true</td>
<td>NetworkPolicy</td>
</tr>
<tr>
<td>poddisruptionbudgets</td>
<td>pdb</td>
<td>policy</td>
<td>true</td>
<td>PodDisruptionBudget</td>
</tr>
<tr>
<td>podsecuritypolicies</td>
<td>psp</td>
<td>policy</td>
<td>false</td>
<td>PodSecurityPolicy</td>
</tr>
<tr>
<td>clusterrolebindings</td>
<td></td>
<td>rbac.authorization.k8s.io</td>
<td>false</td>
<td>ClusterRoleBinding</td>
</tr>
<tr>
<td>clusterroles</td>
<td></td>
<td>rbac.authorization.k8s.io</td>
<td>false</td>
<td>ClusterRole</td>
</tr>
<tr>
<td>rolebindings</td>
<td></td>
<td>rbac.authorization.k8s.io</td>
<td>true</td>
<td>RoleBinding</td>
</tr>
<tr>
<td>roles</td>
<td></td>
<td>rbac.authorization.k8s.io</td>
<td>true</td>
<td>Role</td>
</tr>
<tr>
<td>priorityclasses</td>
<td>pc</td>
<td>scheduling.k8s.io</td>
<td>false</td>
<td>PriorityClass</td>
</tr>
<tr>
<td>storageclasses</td>
<td>sc</td>
<td>storage.k8s.io</td>
<td>false</td>
<td>StorageClass</td>
</tr>
<tr>
<td>volumeattachments</td>
<td></td>
<td>storage.k8s.io</td>
<td>false</td>
<td>VolumeAttachment</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>kubelet源码执行流程分析</title>
    <url>/2022/12/29/kubelet%E6%BA%90%E7%A0%81%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h2 id="k8s学习：kubelet源码执行流程分析"><a href="#k8s学习：kubelet源码执行流程分析" class="headerlink" title="k8s学习：kubelet源码执行流程分析"></a>k8s学习：kubelet源码执行流程分析</h2><p>容器技术应用范围越来越广，通过理解整个框架的执行流程，学习源码执行思路，对以后的编程很有帮助， kubernetes有很多组件，我们今天通过kubelet这个组件来进行深入的分析，来看看里面的执行流程，kubelet里面涉及的方法非常多且层层嵌套，通过我这一篇文章肯定是讲不全的，大家可以根据自己的情况不断深入来学习。我们这篇文章主要分析其执行流程，不深入底层的执行细节。抓主干。学习源码版本：1.19</p>
<h3 id="kubelet-主要功能"><a href="#kubelet-主要功能" class="headerlink" title="kubelet 主要功能"></a>kubelet 主要功能</h3><p>在kubernetes集群中，每个Node节点都会启动kubelet进程，用来处理Master节点下发到本节点的任务，管理Pod和其中的容器，并负责健康检查和监控信息提供。</p>
<h4 id="pod-管理"><a href="#pod-管理" class="headerlink" title="pod 管理"></a>pod 管理</h4><p>每个pod都有其对应的yaml文件，来描述其运行过程中的一些参数和配置信息，kubelet 采用一组通过各种机制来保证运行在此物理机上的容器，符合 PodSpecs 中描述的 Pod 状态，正常健康运行。</p>
<p>官方提供了4中方式来获取容器信息：</p>
<ol>
<li>apiserver：通过 API Server 监听 etcd 目录获取数据；</li>
<li>File：启动参数 –config 指定的配置目录下的文件；</li>
<li>通过 url 从网络上某个地址来获取信息</li>
</ol>
<p>拿apiserver来说，如果Kubelet 监听到etcd中有新的绑定到本节点的 Pod，则按照 Pod 清单的要求创建该 Pod；如果发现本地的 Pod 被修改，则 Kubelet 会做出相应的修改。</p>
<h4 id="容器健康检查"><a href="#容器健康检查" class="headerlink" title="容器健康检查"></a>容器健康检查</h4><p>容器健康检查，主要是通过LivenessProbe 与ReadinessProbe来判断容器是否健康。</p>
<ol>
<li>LivenessProbe ：用于判断容器是否健康，告诉 Kubelet 一个容器什么时候处于不健康的状态。如果 LivenessProbe 探针探测到容器不健康，则 Kubelet 将删除该容器，并根据容器的重启策略做相应的处理。如果一个容器不包含 LivenessProbe 探针，那么 Kubelet 认为该容器的 LivenessProbe 探针返回的值永远是 “Success”；</li>
<li>ReadinessProbe：用于判断容器是否启动完成且准备接收请求。如果 ReadinessProbe 探针探测到失败，则 Pod 的状态将被修改。Endpoint Controller 将从 Service 的 Endpoint 中删除包含该容器所在 Pod 的 IP 地址的 Endpoint 条目。</li>
</ol>
<h4 id="容器监控"><a href="#容器监控" class="headerlink" title="容器监控"></a>容器监控</h4><p>Kubelet 通过 cAdvisor 获取其所在节点及容器的数据。cAdvisor 是一个开源的分析容器资源使用率和性能特性的代理工具，集成到 Kubelet中，当Kubelet启动时会同时启动cAdvisor，且一个cAdvisor只监控一个Node节点的信息。cAdvisor 自动查找所有在其所在节点上的容器，自动采集 CPU、内存、文件系统和网络使用的统计信息。cAdvisor 通过它所在节点机的 Root 容器，采集并分析该节点机的全面使用情况。</p>
<h3 id="kubelet-工作原理"><a href="#kubelet-工作原理" class="headerlink" title="kubelet 工作原理"></a>kubelet 工作原理</h3><p>这里借用网上的一张图来说明情况：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202210111512447.png" alt="20210131-9142139592.png"></p>
<p>由图我们可以看到kubelet 的工作核心，就是一个控制循环，即：SyncLoop。驱动整个控制循环的事件有：pod更新事件、pod生命周期变化、kubelet本身设置的执行周期、定时清理事件等。</p>
<p>在SyncLoop循环上还有很多xxManager，例如probeManager 会定时去监控 pod 中容器的健康状况，当前支持两种类型的探针：livenessProbe 和readinessProbe；statusManager 负责维护状态信息，并把 pod 状态更新到 apiserver；containerRefManager 容器引用的管理，相对简单的Manager，用来报告容器的创建，失败等事件等等。</p>
<p>kubelet 调用下层容器运行时的执行过程，并不会直接调用 Docker 的 API，而是通过一组叫作 CRI（Container Runtime Interface，容器运行时接口）的 gRPC 接口来间接执行的。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202210111521889.png" alt="20210131-3878407432.png"></p>
<p>CRI是k8s对容器的操作抽离出的一系列的接口，kubelet 就只需要跟这个接口打交道，而不需要关注底层的容器时docker还是rkt，底层的容器只需要自己提供一个该接口的实现，然后对 kubelet 暴露出 gRPC 服务即可。有关CRI的可以内容可以看看这篇：Introducing Container Runtime Interface。</p>
<p>一般来说CRI接口可以分为两组：</p>
<ol>
<li>一组是ImageService，主要是容器镜像相关的操作，比如拉取镜像、删除镜像等。</li>
<li>一组是RuntimeService，主要是跟容器相关的操作，比如创建、启动、删除Container、Exec等。</li>
</ol>
<h3 id="kubelet执行源码分析"><a href="#kubelet执行源码分析" class="headerlink" title="kubelet执行源码分析"></a>kubelet执行源码分析</h3><p>Run</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202210111512279.png" alt="kubelet.png"></p>
<p>文件地址：kubernetes\pkg\kubelet\kubelet.go</p>
<pre><code>func (kl *Kubelet) Run(updates &lt;-chan kubetypes.PodUpdate) &#123;
    //注册 logServer
    if kl.logServer == nil &#123;
        kl.logServer = http.StripPrefix(&quot;/logs/&quot;, http.FileServer(http.Dir(&quot;/var/log/&quot;)))
    &#125;
    if kl.kubeClient == nil &#123;
        klog.Warning(&quot;No api server defined - no node status update will be sent.&quot;)
    &#125;

    //Cloud Provider 扩展相关：https://kubernetes.feisky.xyz/extension/cloud-provider
    if kl.cloudResourceSyncManager != nil &#123;
        go kl.cloudResourceSyncManager.Run(wait.NeverStop)
    &#125;
    //调用 kl.initializeModules 首先启动不依赖 container runtime 的一些模块
    if err := kl.initializeModules(); err != nil &#123;
        kl.recorder.Eventf(kl.nodeRef, v1.EventTypeWarning, events.KubeletSetupFailed, err.Error())
        klog.Fatal(err)
    &#125;

    //启动 volume manager
    go kl.volumeManager.Run(kl.sourcesReady, wait.NeverStop)

    if kl.kubeClient != nil &#123; 
        //执行 kl.syncNodeStatus 定时同步 Node 状态
        go wait.Until(kl.syncNodeStatus, kl.nodeStatusUpdateFrequency, wait.NeverStop)
        //调用 kl.fastStatusUpdateOnce 更新容器运行时启动时间以及执行首次状态同步
        go kl.fastStatusUpdateOnce()

        // start syncing lease
        //NodeLease 机制
        go kl.nodeLeaseController.Run(wait.NeverStop)
    &#125;
    //执行 kl.updateRuntimeUp 定时更新 Runtime 状态
    go wait.Until(kl.updateRuntimeUp, 5*time.Second, wait.NeverStop)

    // Set up iptables util rules
    //执行 kl.syncNetworkUtil 定时同步 iptables 规则
    if kl.makeIPTablesUtilChains &#123;
        kl.initNetworkUtil()
    &#125;

    //获取 pk.podKillingCh异常pod， 并定时清理异常 pod
    go wait.Until(kl.podKiller.PerformPodKillingWork, 1*time.Second, wait.NeverStop)

    // Start component sync loops.
    //启动 statusManager、probeManager、runtimeClassManager
    kl.statusManager.Start()
    kl.probeManager.Start()

    // Start syncing RuntimeClasses if enabled.
    if kl.runtimeClassManager != nil &#123;
        kl.runtimeClassManager.Start(wait.NeverStop)
    &#125;

    // Start the pod lifecycle event generator.
    //启动 pleg 该模块主要用于周期性地向 container runtime 刷新当前所有容器的状态
    //https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/pod-lifecycle-event-generator.md
    kl.pleg.Start()
    kl.syncLoop(updates, kl)&#125;
</code></pre>
<p>这个方法会做以下事情：</p>
<ol>
<li>注册logServer；</li>
<li>如果设置了Cloud Provider，那么会启动云资源管理器，具体的可以查看文章：cloud-provider；</li>
<li>调用kl.initializeModules启动不依赖 container runtime 的一些模块，这个方法我们下面再分析；</li>
<li>启动 volume manager；</li>
<li>执行 kl.syncNodeStatus 定时同步 Node 状态；</li>
<li>调用kl.fastStatusUpdateOnce启动一个循环更新pod CIDR、runtime状态以及node状态；</li>
<li>调用kl.nodeLeaseController.Run启动NodeLease机制，NodeLease机制是一种上报心跳的方式，可以通过更加轻量化节约资源的方式，并提升性能上报node的心跳信息，具体看： Lease object；</li>
<li>执行 kl.updateRuntimeUp 定时更新 Runtime 状态；</li>
<li>执行 kl.syncNetworkUtil 定时同步 iptables 规则；</li>
<li>获取 pk.podKillingCh异常pod， 并定时清理异常 pod；</li>
<li>然后启动 statusManager、probeManager、runtimeClassManager；</li>
<li>启动 pleg模块，该模块主要用于周期性地向 container runtime 上报当前所有容器的状态，具体可以看：Pod Lifecycle Event Generator (PLEG)；</li>
<li>调用kl.syncLoop启动kublet事件循环；</li>
</ol>
<h3 id="initializeModules"><a href="#initializeModules" class="headerlink" title="initializeModules"></a>initializeModules</h3><p>下面我们看看initializeModules方法做了些什么。</p>
<pre><code>func (kl *Kubelet) initializeModules() error &#123;
    ...
    //创建文件目录
    if err := kl.setupDataDirs(); err != nil &#123;
        return err    &#125;

    //创建 ContainerLogsDir
    if _, err := os.Stat(ContainerLogsDir); err != nil &#123;
        if err := kl.os.MkdirAll(ContainerLogsDir, 0755); err != nil &#123;
            return fmt.Errorf(&quot;failed to create directory %q: %v&quot;, ContainerLogsDir, err)
        &#125;
    &#125;

    //启动 imageManager
    kl.imageManager.Start()

    //启动 certificate manager ，证书相关
    if kl.serverCertificateManager != nil &#123;
        kl.serverCertificateManager.Start()
    &#125;

    //启动 oomWatcher.
    if err := kl.oomWatcher.Start(kl.nodeRef); err != nil &#123;
        return fmt.Errorf(&quot;failed to start OOM watcher %v&quot;, err)
    &#125;

    //启动 resource analyzer,刷新volume stats到缓存中
    kl.resourceAnalyzer.Start()

    return nil&#125;
</code></pre>
<p>initializeModules方法主要做了以下几件事：</p>
<ol>
<li>创建创建文件目录、Container的log目录；</li>
<li>启动 imageManager，这个管理器实际上是realImageGCManager，我们待会看；</li>
<li>启动 certificate manager ，证书相关；</li>
<li>启动 oomWatcher监视器；</li>
<li>启动 resource analyzer,定时刷新volume stats到缓存中；</li>
</ol>
<h3 id="realImageGCManager-Start"><a href="#realImageGCManager-Start" class="headerlink" title="realImageGCManager#Start"></a>realImageGCManager#Start</h3><p>文件路径：pkg&#x2F;kubelet&#x2F;images&#x2F;image_gc_manager.go</p>
<pre><code>func (im *realImageGCManager) Start() &#123;
    go wait.Until(func() &#123; 
        var ts time.Time        if im.initialized &#123;
            ts = time.Now()
        &#125;
        //找出所有的image，并删除不再使用的image
        _, err := im.detectImages(ts)
        if err != nil &#123;
            klog.Warningf(&quot;[imageGCManager] Failed to monitor images: %v&quot;, err)
        &#125; else &#123;
            im.initialized = true
        &#125;
    &#125;, 5*time.Minute, wait.NeverStop)

    //更新image的缓存
    go wait.Until(func() &#123;
        //调用容器接口，获取最新的image
        images, err := im.runtime.ListImages()
        if err != nil &#123;
            klog.Warningf(&quot;[imageGCManager] Failed to update image list: %v&quot;, err)
        &#125; else &#123;
            im.imageCache.set(images)
        &#125;
    &#125;, 30*time.Second, wait.NeverStop)&#125;
</code></pre>
<p>realImageGCManager的start方法会启动两个协程，然后分别定时调用detectImages方法与imageCache的set方法。detectImages方法里面主要就是调用ImageService和RuntimeService的方法找出所有正在使用的image，然后删除不再使用的image。</p>
<p>这里ListImages和detectImages里面用到的GetPods方法都是调用了CRI的方法，</p>
<h3 id="fastStatusUpdateOnce"><a href="#fastStatusUpdateOnce" class="headerlink" title="fastStatusUpdateOnce"></a>fastStatusUpdateOnce</h3><pre><code>func (kl *Kubelet) fastStatusUpdateOnce() &#123;
    for &#123;
        time.Sleep(100 * time.Millisecond)
        node, err := kl.GetNode()
        if err != nil &#123;
            klog.Errorf(err.Error())
            continue
        &#125;
        if len(node.Spec.PodCIDRs) != 0 &#123;
            podCIDRs := strings.Join(node.Spec.PodCIDRs, &quot;,&quot;)
            if _, err := kl.updatePodCIDR(podCIDRs); err != nil &#123;
                klog.Errorf(&quot;Pod CIDR update to %v failed %v&quot;, podCIDRs, err)
                continue
            &#125;
            //更新 Runtime 状态
            kl.updateRuntimeUp()
            //更新 节点 状态
            kl.syncNodeStatus()
            return
        &#125;
    &#125;&#125;
</code></pre>
<p>FastStatusUpdateOnce 函数启动一个循环，尝试立即更新POD CIDR。更新pod CIDR后，它会触发运行时更新和节点状态更新。函数在一次成功的节点状态更新后直接返回。该功能仅在 kubelet 启动期间执行，通过尽快更新 pod cidr、运行时状态和节点状态来提高准备就绪节点的延迟。</p>
<h3 id="updateRuntimeUp"><a href="#updateRuntimeUp" class="headerlink" title="updateRuntimeUp"></a>updateRuntimeUp</h3><p>&#x2F;&#x2F;首次执行的时候会初始化runtime依赖模块，然后更新runtimeState</p>
<pre><code>//首次执行的时候会初始化runtime依赖模块，然后更新runtimeStatefunc (kl *Kubelet) updateRuntimeUp() &#123;
    kl.updateRuntimeMux.Lock()
    defer kl.updateRuntimeMux.Unlock()
    //获取 containerRuntime Status
    s, err := kl.containerRuntime.Status()
    if err != nil &#123;
        klog.Errorf(&quot;Container runtime sanity check failed: %v&quot;, err)
        return
    &#125;
    if s == nil &#123;
        klog.Errorf(&quot;Container runtime status is nil&quot;)
        return
    &#125; 
    klog.V(4).Infof(&quot;Container runtime status: %v&quot;, s)
    //检查 network 和 runtime 是否处于 ready 状态
    networkReady := s.GetRuntimeCondition(kubecontainer.NetworkReady)
    if networkReady == nil || !networkReady.Status &#123;
        klog.Errorf(&quot;Container runtime network not ready: %v&quot;, networkReady)
        kl.runtimeState.setNetworkState(fmt.Errorf(&quot;runtime network not ready: %v&quot;, networkReady))
    &#125; else &#123;
        // Set nil if the container runtime network is ready.
        kl.runtimeState.setNetworkState(nil)
    &#125;
    // information in RuntimeReady condition will be propagated to NodeReady condition.
    //获取运行时状态
    runtimeReady := s.GetRuntimeCondition(kubecontainer.RuntimeReady)
    // If RuntimeReady is not set or is false, report an error.
    if runtimeReady == nil || !runtimeReady.Status &#123;
        err := fmt.Errorf(&quot;Container runtime not ready: %v&quot;, runtimeReady)
        klog.Error(err)
        kl.runtimeState.setRuntimeState(err)
        return
    &#125;
    kl.runtimeState.setRuntimeState(nil)
    //调用 kl.initializeRuntimeDependentModules 启动依赖模块
    kl.oneTimeInitializer.Do(kl.initializeRuntimeDependentModules)
    kl.runtimeState.setRuntimeSync(kl.clock.Now())&#125;
</code></pre>
<p>updateRuntimeUp会获取container运行状态信息，然后根据返回RuntimeStatus检查网络、runtime是不是已经处于ready状态；接着调用kl.initializeRuntimeDependentModules初始化依赖模块，这里会启动cadvisor、containerManager、evictionManager、containerLogManager、pluginManager；最后设置Runtime同步时间。</p>
<h3 id="最后看看syncLoop方法"><a href="#最后看看syncLoop方法" class="headerlink" title="最后看看syncLoop方法"></a>最后看看syncLoop方法</h3><pre><code>func (kl *Kubelet) syncLoop(updates &lt;-chan kubetypes.PodUpdate, handler SyncHandler) &#123;
    ...
    syncTicker := time.NewTicker(time.Second)
    defer syncTicker.Stop()
    housekeepingTicker := time.NewTicker(housekeepingPeriod)
    defer housekeepingTicker.Stop()
    plegCh := kl.pleg.Watch()
    for &#123;
        ...
        kl.syncLoopMonitor.Store(kl.clock.Now())
        if !kl.syncLoopIteration(updates, handler, syncTicker.C, housekeepingTicker.C, plegCh) &#123;
            break
        &#125;
        kl.syncLoopMonitor.Store(kl.clock.Now())
    &#125;&#125;
</code></pre>
<p>syncLoop方法在一个循环中不断的调用syncLoopIteration方法执行主要逻辑。</p>
<h3 id="syncLoopIteration方法比较长，拆开来看"><a href="#syncLoopIteration方法比较长，拆开来看" class="headerlink" title="syncLoopIteration方法比较长，拆开来看"></a>syncLoopIteration方法比较长，拆开来看</h3><pre><code>func (kl *Kubelet) syncLoopIteration(configCh &lt;-chan kubetypes.PodUpdate, handler SyncHandler,
    //方法会监听多个 channel，当发现任何一个 channel 有数据就交给 handler 去处理，在 handler 中通过调用 dispatchWork 分发任务
    syncCh &lt;-chan time.Time, housekeepingCh &lt;-chan time.Time, plegCh &lt;-chan *pleg.PodLifecycleEvent) bool &#123;
    select &#123;
        //该模块将同时 watch 3 个不同来源的 pod 信息的变化（file，http，apiserver），
        //一旦某个来源的 pod 信息发生了更新（创建/更新/删除），这个 channel 中就会出现被更新的 pod 信息和更新的具体操作；
    case u, open := &lt;-configCh: 
        if !open &#123;
            klog.Errorf(&quot;Update channel is closed. Exiting the sync loop.&quot;)
            return false
        &#125;

        switch u.Op &#123;
        case kubetypes.ADD:
            klog.V(2).Infof(&quot;SyncLoop (ADD, %q): %q&quot;, u.Source, format.Pods(u.Pods)) 
            handler.HandlePodAdditions(u.Pods)
        case kubetypes.UPDATE:
            klog.V(2).Infof(&quot;SyncLoop (UPDATE, %q): %q&quot;, u.Source, format.PodsWithDeletionTimestamps(u.Pods))
            handler.HandlePodUpdates(u.Pods)
        case kubetypes.REMOVE:
            klog.V(2).Infof(&quot;SyncLoop (REMOVE, %q): %q&quot;, u.Source, format.Pods(u.Pods))
            handler.HandlePodRemoves(u.Pods)
        case kubetypes.RECONCILE:
            klog.V(4).Infof(&quot;SyncLoop (RECONCILE, %q): %q&quot;, u.Source, format.Pods(u.Pods))
            handler.HandlePodReconcile(u.Pods)
        case kubetypes.DELETE:
            klog.V(2).Infof(&quot;SyncLoop (DELETE, %q): %q&quot;, u.Source, format.Pods(u.Pods)) 
            handler.HandlePodUpdates(u.Pods)
        case kubetypes.SET: 
            klog.Errorf(&quot;Kubelet does not support snapshot update&quot;)
        default:
            klog.Errorf(&quot;Invalid event type received: %d.&quot;, u.Op)
        &#125;

        kl.sourcesReady.AddSource(u.Source)

     ...&#125;
</code></pre>
<p>configCh读取配置事件的管道，该模块将同时 watch 3 个不同来源的 pod 信息的变化（file，http，apiserver），一旦某个来源的 pod 信息发生了更新（创建&#x2F;更新&#x2F;删除），这个 channel 中就会出现被更新的 pod 信息和更新的具体操作。这里对于pod的操作我们下一篇再讲。</p>
<p>plegCh</p>
<pre><code>func (kl *Kubelet) syncLoopIteration(configCh &lt;-chan kubetypes.PodUpdate, handler SyncHandler,
    //方法会监听多个 channel，当发现任何一个 channel 有数据就交给 handler 去处理，在 handler 中通过调用 dispatchWork 分发任务
    syncCh &lt;-chan time.Time, housekeepingCh &lt;-chan time.Time, plegCh &lt;-chan *pleg.PodLifecycleEvent) bool &#123;
    ...
    case e := &lt;-plegCh:
        if e.Type == pleg.ContainerStarted &#123;
            kl.lastContainerStartedTime.Add(e.ID, time.Now())
        &#125;
        if isSyncPodWorthy(e) &#123; 
            if pod, ok := kl.podManager.GetPodByUID(e.ID); ok &#123;
                klog.V(2).Infof(&quot;SyncLoop (PLEG): %q, event: %#v&quot;, format.Pod(pod), e)
                handler.HandlePodSyncs([]*v1.Pod&#123;pod&#125;)
            &#125; else &#123; 
                klog.V(4).Infof(&quot;SyncLoop (PLEG): ignore irrelevant event: %#v&quot;, e)
            &#125;
        &#125; 
        if e.Type == pleg.ContainerDied &#123;
            if containerID, ok := e.Data.(string); ok &#123;
                kl.cleanUpContainersInPod(e.ID, containerID)
            &#125;
        &#125;
    ...&#125;
</code></pre>
<p>PLEG.Start的时候会每秒钟启动调用一次relist，根据最新的PodStatus生成PodLiftCycleEvent，然后存入到PLE Channel中。</p>
<p>syncLoop会调用pleg.Watch方法获取PLE Channel管道，然后传给syncLoopIteration方法，在syncLoopIteration方法中也就是plegCh这个管道，syncLoopIteration会消费plegCh中的数据，在 handler 中通过调用 dispatchWork 分发任务。</p>
<p>syncCh</p>
<pre><code>func (kl *Kubelet) syncLoopIteration(configCh &lt;-chan kubetypes.PodUpdate, handler SyncHandler,
    syncCh &lt;-chan time.Time, housekeepingCh &lt;-chan time.Time, plegCh &lt;-chan *pleg.PodLifecycleEvent) bool &#123;
    ...
    //  每秒钟会执行到一次
    case &lt;-syncCh:
        // Sync pods waiting for sync
        podsToSync := kl.getPodsToSync()
        if len(podsToSync) == 0 &#123;
            break
        &#125;
        klog.V(4).Infof(&quot;SyncLoop (SYNC): %d pods; %s&quot;, len(podsToSync), format.Pods(podsToSync))
        //同步最新保存的 pod 状态
        handler.HandlePodSyncs(podsToSync)
    ...&#125;
</code></pre>
<p>syncCh是由syncLoop方法里面创建的一个定时任务，每秒钟会向syncCh添加一个数据，然后就会执行到这里。这个方法会同步所有等待同步的pod。</p>
<p>livenessManager.Updates</p>
<pre><code>func (kl *Kubelet) syncLoopIteration(configCh &lt;-chan kubetypes.PodUpdate, handler SyncHandler,
    syncCh &lt;-chan time.Time, housekeepingCh &lt;-chan time.Time, plegCh &lt;-chan *pleg.PodLifecycleEvent) bool &#123;
    ...
    case update := &lt;-kl.livenessManager.Updates():
        //如果探针检测失败，需要更新pod的状态
        if update.Result == proberesults.Failure &#123; 
            pod, ok := kl.podManager.GetPodByUID(update.PodUID)
            if !ok &#123; 
                klog.V(4).Infof(&quot;SyncLoop (container unhealthy): ignore irrelevant update: %#v&quot;, update)
                break
            &#125;
            klog.V(1).Infof(&quot;SyncLoop (container unhealthy): %q&quot;, format.Pod(pod))
            handler.HandlePodSyncs([]*v1.Pod&#123;pod&#125;)
        &#125;
    ...&#125;
</code></pre>
<p>对失败的pod或者liveness检查失败的pod进行sync操作。</p>
<p>housekeepingCh</p>
<pre><code>func (kl *Kubelet) syncLoopIteration(configCh &lt;-chan kubetypes.PodUpdate, handler SyncHandler,
    syncCh &lt;-chan time.Time, housekeepingCh &lt;-chan time.Time, plegCh &lt;-chan *pleg.PodLifecycleEvent) bool &#123;
    ...
    //  每两秒钟执行一次
    case &lt;-housekeepingCh:
        if !kl.sourcesReady.AllReady() &#123; 
            klog.V(4).Infof(&quot;SyncLoop (housekeeping, skipped): sources aren&#39;t ready yet.&quot;)
        &#125; else &#123;
            klog.V(4).Infof(&quot;SyncLoop (housekeeping)&quot;)
            //执行一些清理工作，包括终止pod workers、删除不想要的pod，移除volumes、pod目录
            if err := handler.HandlePodCleanups(); err != nil &#123;
                klog.Errorf(&quot;Failed cleaning pods: %v&quot;, err)
            &#125;
        &#125;
    ...&#125;
</code></pre>
<p>housekeepingCh这个管道也是由syncLoop创建，每两秒钟会触发清理。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>kubelet.Run部分主要执行kubelet包含的各种manager的运行，大部分会以一部线程的方式定时运行。了解了CRI是怎么一回事，通过CRI接口可以做什么。</p>
<p>接下来看了syncLoop主函数，这个函数主要对pod的生命周期进行管理，包括对pod进行add 、update、remove、delete等操作，这些具体的代码执行过程大家有兴趣的可以自己了解。</p>
]]></content>
      <categories>
        <category>kubernetes</category>
        <category>Kubelet</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>Kubelet</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux SSH 登录错误超时次数自动加入ip黑名单</title>
    <url>/2023/01/29/linux%E7%99%BB%E5%BD%95%E8%B6%85%E6%AC%A1%E6%95%B0%E8%87%AA%E5%8A%A8%E6%8B%89%E9%BB%91/</url>
    <content><![CDATA[<p>Linux 系统SSH 登录失败的内容会记录到&#x2F;var&#x2F;log&#x2F;secure文件，通过查找关键字 Failed，可以定位到这些异常的IP地址，比如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@ghost ~]<span class="comment"># cat /var/log/secure |grep Failed               #查看所有的异常IP</span></span><br><span class="line">[root@ghost ~]<span class="comment"># cat /var/log/secure |grep 181.204.166.58       #查看指定的异常IP</span></span><br></pre></td></tr></table></figure>

<p>相关文件 ：&#x2F;etc&#x2F;hosts.deny 禁止哪些IP访问主机:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@ghost ~]<span class="comment"># cat /etc/hosts.deny</span></span><br></pre></td></tr></table></figure>

<p>因此，我们只需要从&#x2F;var&#x2F;log&#x2F;secure文件中提取IP地址，如果次数达到10次则将该IP写到 &#x2F;etc&#x2F;hosts.deny中，禁止这些IP访问主机。</p>
<p>脚本如下secure_ssh.sh：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@ghost tmp]<span class="comment"># vim secure_ssh.sh #创建脚本文件</span></span><br><span class="line"><span class="comment">#! /bin/bash</span></span><br><span class="line"><span class="built_in">cat</span> /var/log/secure|awk <span class="string">&#x27;/Failed/&#123;print $(NF-3)&#125;&#x27;</span>|<span class="built_in">sort</span>|<span class="built_in">uniq</span> -c|awk <span class="string">&#x27;&#123;print $2&quot;=&quot;$1;&#125;&#x27;</span> &gt; /tmp/black.list</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> `<span class="built_in">cat</span>  /tmp/black.list`</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  IP=`<span class="built_in">echo</span> <span class="variable">$i</span> |awk -F= <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>`</span><br><span class="line">  NUM=`<span class="built_in">echo</span> <span class="variable">$i</span>|awk -F= <span class="string">&#x27;&#123;print $2&#125;&#x27;</span>`</span><br><span class="line">  <span class="built_in">echo</span> <span class="variable">$IP</span>=<span class="variable">$NUM</span></span><br><span class="line">  <span class="keyword">if</span> [ <span class="variable">$NUM</span> -gt 10 ]; <span class="keyword">then</span></span><br><span class="line">    grep <span class="variable">$IP</span> /etc/hosts.deny &gt; /dev/null</span><br><span class="line">    <span class="keyword">if</span> [ $? -gt 0 ];<span class="keyword">then</span></span><br><span class="line">      <span class="built_in">echo</span> <span class="string">&quot;sshd:<span class="variable">$IP</span>:deny&quot;</span> &gt;&gt; /etc/hosts.deny</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@ghost tmp]<span class="comment"># chmod +x secure_ssh.sh   #给文件添加执行权限</span></span><br></pre></td></tr></table></figure>

<p>将secure_ssh.sh脚本放入cron计划任务，每1小时执行一次。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@ghost tmp]<span class="comment"># crontab -e</span></span><br><span class="line">0 */1 * * *  sh /sjd/secure_ssh.sh</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Nginx高可用方案</title>
    <url>/2023/01/31/nginx%E9%AB%98%E5%8F%AF%E7%94%A8%E6%96%B9%E6%A1%88/</url>
    <content><![CDATA[<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>192.168.16.128</p>
<p>192.168.16.129</p>
<p>两台虚拟机。安装好Nginx</p>
<h2 id="安装Nginx"><a href="#安装Nginx" class="headerlink" title="安装Nginx"></a>安装Nginx</h2><p>更新yum源文件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -ivh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm</span><br><span class="line">wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</span><br></pre></td></tr></table></figure>

<p>安装Nginx:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum -y install  nginx</span><br></pre></td></tr></table></figure>

<p>操作命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start nginx; <span class="comment">#启动Nginx</span></span><br><span class="line">systemctl stop nginx; <span class="comment">#停止Nginx</span></span><br></pre></td></tr></table></figure>

<h2 id="什么是高可用？"><a href="#什么是高可用？" class="headerlink" title="什么是高可用？"></a>什么是高可用？</h2><p>高可用HA（High Availability）是分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计减少系统不能提供服务的时间。如果一个系统能够一直提供服务，那么这个可用性则是百分之百，但是天有不测风云。所以我们只能尽可能的去减少服务的故障。</p>
<h2 id="解决的问题？"><a href="#解决的问题？" class="headerlink" title="解决的问题？"></a>解决的问题？</h2><p>在生产环境上很多时候是以Nginx做反向代理对外提供服务，但是一天Nginx难免遇见故障，如：服务器宕机。当Nginx宕机那么所有对外提供的接口都将导致无法访问。</p>
<p>虽然我们无法保证服务器百分之百可用，但是也得想办法避免这种悲剧，今天我们使用keepalived来实现Nginx的高可用。</p>
<h2 id="双机热备方案"><a href="#双机热备方案" class="headerlink" title="双机热备方案"></a>双机热备方案</h2><p>这种方案是国内企业中最为普遍的一种高可用方案，双机热备其实就是指一台服务器在提供服务，另一台为某服务的备用状态，当一台服务器不可用另外一台就会顶替上去。</p>
<h3 id="keepalived是什么？"><a href="#keepalived是什么？" class="headerlink" title="keepalived是什么？"></a>keepalived是什么？</h3><p>Keepalived软件起初是专为LVS负载均衡软件设计的，用来管理并监控LVS集群系统中各个服务节点的状态，后来又加入了可以实现高可用的VRRP (Virtual Router Redundancy Protocol ,虚拟路由器冗余协议）功能。因此，Keepalived除了能够管理LVS软件外，还可以作为其他服务（例如：Nginx、Haproxy、MySQL等）的高可用解决方案软件</p>
<h3 id="故障转移机制"><a href="#故障转移机制" class="headerlink" title="故障转移机制"></a>故障转移机制</h3><p>Keepalived高可用服务之间的故障切换转移，是通过VRRP 来实现的。在 Keepalived服务正常工作时，主 Master节点会不断地向备节点发送（多播的方式）心跳消息，用以告诉备Backup节点自己还活着，当主 Master节点发生故障时，就无法发送心跳消息，备节点也就因此无法继续检测到来自主 Master节点的心跳了，于是调用自身的接管程序，接管主Master节点的 IP资源及服务。而当主 Master节点恢复时，备Backup节点又会释放主节点故障时自身接管的IP资源及服务，恢复到原来的备用角色。</p>
<h2 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h2><h3 id="安装keepalived"><a href="#安装keepalived" class="headerlink" title="安装keepalived"></a>安装keepalived</h3><p>yum方式直接安装即可，该方式会自动安装依赖：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum -y install keepalived</span><br></pre></td></tr></table></figure>

<p>修改主机（192.168.16.128）keepalived配置文件</p>
<p>yum方式安装的会生产配置文件在&#x2F;etc&#x2F;keepalived下：</p>
<p>keepalived.conf:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#检测脚本</span></span><br><span class="line">vrrp_script chk_http_port &#123;</span><br><span class="line">    script <span class="string">&quot;/usr/local/src/check_nginx_pid.sh&quot;</span> <span class="comment">#心跳执行的脚本，检测nginx是否启动</span></span><br><span class="line">    interval 2                          <span class="comment">#（检测脚本执行的间隔，单位是秒）</span></span><br><span class="line">    weight 2                            <span class="comment">#权重</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#vrrp 实例定义部分</span></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER            <span class="comment"># 指定keepalived的角色，MASTER为主，BACKUP为备</span></span><br><span class="line">    interface ens33         <span class="comment"># 当前进行vrrp通讯的网络接口卡(当前centos的网卡) 用ifconfig查看你具体的网卡</span></span><br><span class="line">    virtual_router_id 66    <span class="comment"># 虚拟路由编号，主从要一致</span></span><br><span class="line">    priority 100            <span class="comment"># 优先级，数值越大，获取处理请求的优先级越高</span></span><br><span class="line">    advert_int 1            <span class="comment"># 检查间隔，默认为1s(vrrp组播周期秒数)</span></span><br><span class="line">    <span class="comment">#授权访问</span></span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS <span class="comment">#设置验证类型和密码，MASTER和BACKUP必须使用相同的密码才能正常通信</span></span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">        chk_http_port            <span class="comment">#（调用检测脚本）</span></span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.16.130            <span class="comment"># 定义虚拟ip(VIP)，可多设，每行一个</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>virtual_ipaddress 里面可以配置vip,在线上通过vip来访问服务。</p>
<p>interface需要根据服务器网卡进行设置通常查看方式ip addr</p>
<p>authentication配置授权访问后备机也需要相同配置</p>
<p>修改备机（192.168.16.129）keepalived配置文件</p>
<p>keepalived.conf:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#检测脚本</span></span><br><span class="line">vrrp_script chk_http_port &#123;</span><br><span class="line">    script <span class="string">&quot;/usr/local/src/check_nginx_pid.sh&quot;</span> <span class="comment">#心跳执行的脚本，检测nginx是否启动</span></span><br><span class="line">    interval 2                          <span class="comment">#（检测脚本执行的间隔）</span></span><br><span class="line">    weight 2                            <span class="comment">#权重</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#vrrp 实例定义部分</span></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP                        <span class="comment"># 指定keepalived的角色，MASTER为主，BACKUP为备</span></span><br><span class="line">    interface ens33                      <span class="comment"># 当前进行vrrp通讯的网络接口卡(当前centos的网卡) 用ifconfig查看你具体的网卡</span></span><br><span class="line">    virtual_router_id 66                <span class="comment"># 虚拟路由编号，主从要一直</span></span><br><span class="line">    priority 99                         <span class="comment"># 优先级，数值越大，获取处理请求的优先级越高</span></span><br><span class="line">    advert_int 1                        <span class="comment"># 检查间隔，默认为1s(vrrp组播周期秒数)</span></span><br><span class="line">    <span class="comment">#授权访问</span></span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS <span class="comment">#设置验证类型和密码，MASTER和BACKUP必须使用相同的密码才能正常通信</span></span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">        chk_http_port                   <span class="comment">#（调用检测脚本）</span></span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.16.130                   <span class="comment"># 定义虚拟ip(VIP)，可多设，每行一个</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>检测脚本：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#检测nginx是否启动了</span></span><br><span class="line">A=`ps -C nginx --no-header |<span class="built_in">wc</span> -l`        </span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$A</span> -eq 0 ];<span class="keyword">then</span>    <span class="comment">#如果nginx没有启动就启动nginx                        </span></span><br><span class="line">      systemctl start nginx                <span class="comment">#重启nginx</span></span><br><span class="line">      <span class="keyword">if</span> [ `ps -C nginx --no-header |<span class="built_in">wc</span> -l` -eq 0 ];<span class="keyword">then</span>    <span class="comment">#nginx重启失败，则停掉keepalived服务，进行VIP转移</span></span><br><span class="line">              killall keepalived                    </span><br><span class="line">      <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>

<p>脚本授权:chmod 775 check_nginx_pid.sh</p>
<p>说明：脚本必须通过授权，不然没权限访问啊，在这里我们两条服务器执行、VIP(virtual_ipaddress:192.168.16.130),我们在生产环境是直接通过vip来访问服务。</p>
<p>模拟nginx故障：</p>
<p>修改两个服务器默认访问的Nginx的html页面作为区别。</p>
<p>首先访问192.168.16.130,通过vip进行访问，页面显示192.168.16.128；说明当前是主服务器提供的服务。</p>
<p>这个时候192.168.16.128主服务器执行命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl stop nginx; <span class="comment">#停止nginx</span></span><br></pre></td></tr></table></figure>

<p>再次访问vip(192.168.16.130)发现这个时候页面显示的还是：192.168.16.128，这是脚本里面自动重启。</p>
<p>现在直接将192.168.16.128服务器关闭，在此访问vip(192.168.16.130)现在发现页面显示192.168.16.129这个时候keepalived就自动故障转移了，一套企业级生产环境的高可用方案就搭建好了。</p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>pdns高可用高并发部署</title>
    <url>/2023/01/04/pdns%E9%AB%98%E5%8F%AF%E7%94%A8%E9%AB%98%E5%B9%B6%E5%8F%91%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<h2 id="企业DNS系列一-PowerDNS-Authoritative和Recursor搭建"><a href="#企业DNS系列一-PowerDNS-Authoritative和Recursor搭建" class="headerlink" title="企业DNS系列一]PowerDNS Authoritative和Recursor搭建"></a>企业DNS系列一]PowerDNS Authoritative和Recursor搭建</h2><p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202210131012603.png" alt="img">在企业私有云和公有云环境中，DNS服务的重要性不言而喻，企业往往需要搭建一套稳定可靠的DNS系统，本系列Blog将通过开源的PowerDNS全家桶搭建基于Linux平台的、具备高性能、高可靠性的企业DNS系统。</p>
<p>2022年月8月12日更新：在企业使用GSLB（全局负载均衡）进行应用保护时，PowerDNS权威服务器CNAME和NS解析正常，但PowerDNS递归服务器无法正常工作，这是由于递归服务器默认不对私有IP地址进行二次解析，需要修改PowerDNS递归服务器的“dont-query&#x3D;127.0.0.1&#x2F;8”</p>
<h2 id="基于PowerDNS构建的企业DNS架构概述"><a href="#基于PowerDNS构建的企业DNS架构概述" class="headerlink" title="基于PowerDNS构建的企业DNS架构概述"></a>基于PowerDNS构建的企业DNS架构概述</h2><p>PowerDNS全家桶中包含PowerDNS Authoritative、Recursor、DNSList（暂不使用）三个组件。</p>
<ul>
<li>PowerDNS Authoritative：DNS权威服务器，用于提供企业私有域名的管理和解析；</li>
<li>PowerDNS Recursor：DNS递归服务器，用于接受客户端DNS查询请求，并根据目标域转发配置转发到不同的上游DNS服务器进行解析，并对DNS解析记录进行缓存；</li>
<li>PowerDNS-Admin：DNS权威服务器的Web管理页面；</li>
<li>PowerDNS-Monitor：使用Grafana提供权威服务器和递归服务器的监控页面</li>
</ul>
<p>PowerDNS权威服务器支持多种复制模式，本架构采用MySQL作为后端存储，并通过MySQL复制实现主备数据同步。</p>
<p>本系列文章一共包含四部分：</p>
<ul>
<li>[企业DNS系列一]PowerDNS Authoritative和Recursor搭建</li>
<li>[企业DNS系列二]通过Grafana监控PowerDNS</li>
<li>[企业DNS系列三]通过Anycast技术实现DNS高可用</li>
<li>[企业DNS系列四]通过Terraform管理PowerDNS</li>
</ul>
<h2 id="服务器规划"><a href="#服务器规划" class="headerlink" title="服务器规划"></a>服务器规划</h2><table>
<thead>
<tr>
<th>服务器名称</th>
<th>IP地址</th>
<th>硬件配置</th>
<th>用途</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>pdns-auth01</td>
<td>10.208.0.101</td>
<td>2C&#x2F;4G&#x2F;80G</td>
<td>权威服务器</td>
<td>主服务器，用于管理企业私有域名</td>
</tr>
<tr>
<td>pdns-auth02</td>
<td>10.208.0.102</td>
<td>2C&#x2F;4G&#x2F;80G</td>
<td>权威服务器</td>
<td>备服务器，用于管理企业私有域名</td>
</tr>
<tr>
<td>pdns-rec01</td>
<td>10.208.0.111</td>
<td>4C&#x2F;8G&#x2F;80G</td>
<td>递归服务器</td>
<td>用于DNS解析转发、缓存</td>
</tr>
<tr>
<td>pdns-rec02</td>
<td>10.208.0.112</td>
<td>4C&#x2F;8G&#x2F;80G</td>
<td>递归服务器</td>
<td>用于DNS解析转发、缓存</td>
</tr>
<tr>
<td>pdns-admin</td>
<td>10.208.0.100</td>
<td>2C&#x2F;4G&#x2F;80G</td>
<td>Web管理服务器</td>
<td>用于提供权威服务器的Web管理</td>
</tr>
<tr>
<td>pdns-monitor</td>
<td>10.208.0.99</td>
<td>4C&#x2F;8G&#x2F;80G</td>
<td>Grafana监控服务器</td>
<td>用于监控DNS服务器状态</td>
</tr>
</tbody></table>
<h2 id="部署步骤概述"><a href="#部署步骤概述" class="headerlink" title="部署步骤概述"></a>部署步骤概述</h2><ol>
<li>pdns-auth01和pdns-auth02部署MySQL数据库，并配置主从复制；</li>
<li>pdns-auth01和pdns-auth02创建powerdns数据库，并初始化数据库表；</li>
<li>pdns-auth01和pdns-auth02部署Pdns和Pdns-backend-mysql软件；</li>
<li>pdns-auth01和pdns-auth02准备pdns配置文件，并启动服务；</li>
<li>pdns-admin安装Docker环境，并启动PowerDNS-Admin；</li>
<li>pdns-admin修改连接配置、默认配置、创建Domain和解析记录；</li>
<li>pdns-rec01和pdns-sec02部署pdns-recursor；</li>
<li>pdns-rec01和pdns-sec02准备pdns-recursor配置文件，并启动服务；</li>
<li>DNS解析测试。</li>
</ol>
<h2 id="MySQL数据库部署"><a href="#MySQL数据库部署" class="headerlink" title="MySQL数据库部署"></a>MySQL数据库部署</h2><p>安装MySQL5.7源，并安装MySQL最新的社区版本。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm</span><br><span class="line">rpm -Uvh mysql57-community-release-el7-11.noarch.rpm</span><br><span class="line"></span><br><span class="line">yum makecache</span><br><span class="line"></span><br><span class="line">yum install -y mysql-community-server</span><br><span class="line"></span><br><span class="line">systemctl <span class="built_in">enable</span> mysqld</span><br><span class="line">systemctl start mysqld</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">##安装失败报错如下</span></span><br><span class="line">Retrieving key from file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mys</span><br><span class="line">Importing GPG key 0x5072E1F5:</span><br><span class="line"> Userid     : <span class="string">&quot;MySQL Release Engineering &lt;mysql-build@oss.o</span></span><br><span class="line"><span class="string"> Fingerprint: a4a9 4068 76fc bd3c 4567 70c8 8c71 8d3b 5072</span></span><br><span class="line"><span class="string"> Package    : mysql57-community-release-el7-11.noarch (inst</span></span><br><span class="line"><span class="string"> From       : /etc/pki/rpm-gpg/RPM-GPG-KEY-mysql</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Public key for mysql-community-server-5.7.40-1.el7.x86_64.r</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> Failing package is: mysql-community-server-5.7.40-1.el7.x8</span></span><br><span class="line"><span class="string"> GPG Keys are configured as: file:///etc/pki/rpm-gpg/RPM-GP</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">##此为密钥过期，升级密钥即可，执行以下命令</span></span><br><span class="line"><span class="string">rpm --import https://repo.mysql.com/RPM-GPG-KEY-mysql-2022</span></span><br></pre></td></tr></table></figure>

<p>通过日志获取mysql root@localhost密码，并设置新密码。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">grep &#x27;temporary password&#x27; /var/log/mysqld.log</span><br><span class="line"></span><br><span class="line">mysql -uroot -p</span><br><span class="line"></span><br><span class="line">ALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;新密码&#x27;;</span><br></pre></td></tr></table></figure>

<p>修改pdns-auth01（主）服务器的MySQL配置文件。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /etc/my.cnf </span><br><span class="line">在[mysqld]之前添加 </span><br><span class="line">[client] </span><br><span class="line">default-character-set=utf8 </span><br><span class="line">在[mysqld]之后添加 </span><br><span class="line">character-set-server=utf8</span><br><span class="line">log-bin=mysql-bin</span><br><span class="line">server-id=1</span><br><span class="line">binlog-do-db=powerdns</span><br></pre></td></tr></table></figure>

<p>修改pdns-auth02（从）服务器的MySQL配置文件。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /etc/my.cnf </span><br><span class="line">在[mysqld]之前添加 </span><br><span class="line">[client] </span><br><span class="line">default-character-set=utf8 </span><br><span class="line">在[mysqld]之后添加 </span><br><span class="line">character-set-server=utf8</span><br><span class="line">server-id=2</span><br></pre></td></tr></table></figure>

<p>重新启动MySQL数据库服务。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl restart mysql</span><br></pre></td></tr></table></figure>

<p>配置数据库允许root远程访问，root账户同时用于主从复制。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">use mysql;</span><br><span class="line">update user set host = &#x27;%&#x27; where user = &#x27;root&#x27;;</span><br><span class="line">Grant all on *.* to &#x27;root&#x27;@&#x27;%&#x27; identified by &#x27;root用户的密码&#x27; with grant option;</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure>

<p>再次重启MySQL数据库服务。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl restart mysql</span><br></pre></td></tr></table></figure>

<p>登录到pdns-auth01（主）MySQL数据库，记录binlog文件名和position，稍后再MySQL从复制配置中使用。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql -uroot -p</span><br><span class="line">show master status;</span><br></pre></td></tr></table></figure>

<p>登录到pdns-auth02（从）MySQL数据库，配置并启动主从复制。</p>
<blockquote>
<p>注意1：master_port不用加引号； 注意2：master_log_file和master_log_pos需要从主数据库获取；</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql -uroot -p</span><br><span class="line">change master to</span><br><span class="line">master_host=&#x27;10.208.0.101&#x27;,</span><br><span class="line">master_port=3306,</span><br><span class="line">master_user=&#x27;root&#x27;,</span><br><span class="line">master_password=&#x27;root用户的密码&#x27;,</span><br><span class="line">master_log_file=&#x27;主binlog名称&#x27;,</span><br><span class="line">master_log_pos=154;</span><br><span class="line"></span><br><span class="line">start slave;</span><br><span class="line">show slave status \G</span><br></pre></td></tr></table></figure>

<p>登录到pdns-auth01（主）创建<strong>powerdns</strong>数据库(需要在主从配置完成后创建)。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql -uroot -p</span><br><span class="line">CREATE DATABASE powerdns;</span><br><span class="line">GRANT ALL ON powerdns.* TO &#x27;powerdns&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;VMware1!&#x27;;</span><br><span class="line">FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure>

<p>创建pdns数据库表。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CREATE TABLE domains (</span><br><span class="line">  id                    INT AUTO_INCREMENT,</span><br><span class="line">  name                  VARCHAR(255) NOT NULL,</span><br><span class="line">  master                VARCHAR(128) DEFAULT NULL,</span><br><span class="line">  last_check            INT DEFAULT NULL,</span><br><span class="line">  type                  VARCHAR(6) NOT NULL,</span><br><span class="line">  notified_serial       INT UNSIGNED DEFAULT NULL,</span><br><span class="line">  account               VARCHAR(40) CHARACTER SET &#x27;utf8&#x27; DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (id)</span><br><span class="line">) Engine=InnoDB CHARACTER SET &#x27;latin1&#x27;;</span><br><span class="line"></span><br><span class="line">CREATE UNIQUE INDEX name_index ON domains(name);</span><br><span class="line"></span><br><span class="line">CREATE TABLE records (</span><br><span class="line">  id                    BIGINT AUTO_INCREMENT,</span><br><span class="line">  domain_id             INT DEFAULT NULL,</span><br><span class="line">  name                  VARCHAR(255) DEFAULT NULL,</span><br><span class="line">  type                  VARCHAR(10) DEFAULT NULL,</span><br><span class="line">  content               VARCHAR(64000) DEFAULT NULL,</span><br><span class="line">  ttl                   INT DEFAULT NULL,</span><br><span class="line">  prio                  INT DEFAULT NULL,</span><br><span class="line">  disabled              TINYINT(1) DEFAULT 0,</span><br><span class="line">  ordername             VARCHAR(255) BINARY DEFAULT NULL,</span><br><span class="line">  auth                  TINYINT(1) DEFAULT 1,</span><br><span class="line">  PRIMARY KEY (id)</span><br><span class="line">) Engine=InnoDB CHARACTER SET &#x27;latin1&#x27;;</span><br><span class="line"></span><br><span class="line">CREATE INDEX nametype_index ON records(name,type);</span><br><span class="line">CREATE INDEX domain_id ON records(domain_id);</span><br><span class="line">CREATE INDEX ordername ON records (ordername);</span><br><span class="line"></span><br><span class="line">CREATE TABLE supermasters (</span><br><span class="line">  ip                    VARCHAR(64) NOT NULL,</span><br><span class="line">  nameserver            VARCHAR(255) NOT NULL,</span><br><span class="line">  account               VARCHAR(40) CHARACTER SET &#x27;utf8&#x27; NOT NULL,</span><br><span class="line">  PRIMARY KEY (ip, nameserver)</span><br><span class="line">) Engine=InnoDB CHARACTER SET &#x27;latin1&#x27;;</span><br><span class="line"></span><br><span class="line">CREATE TABLE comments (</span><br><span class="line">  id                    INT AUTO_INCREMENT,</span><br><span class="line">  domain_id             INT NOT NULL,</span><br><span class="line">  name                  VARCHAR(255) NOT NULL,</span><br><span class="line">  type                  VARCHAR(10) NOT NULL,</span><br><span class="line">  modified_at           INT NOT NULL,</span><br><span class="line">  account               VARCHAR(40) CHARACTER SET &#x27;utf8&#x27; DEFAULT NULL,</span><br><span class="line">  comment               TEXT CHARACTER SET &#x27;utf8&#x27; NOT NULL,</span><br><span class="line">  PRIMARY KEY (id)</span><br><span class="line">) Engine=InnoDB CHARACTER SET &#x27;latin1&#x27;;</span><br><span class="line"></span><br><span class="line">CREATE INDEX comments_name_type_idx ON comments (name, type);</span><br><span class="line">CREATE INDEX comments_order_idx ON comments (domain_id, modified_at);</span><br><span class="line"></span><br><span class="line">CREATE TABLE domainmetadata (</span><br><span class="line">  id                    INT AUTO_INCREMENT,</span><br><span class="line">  domain_id             INT NOT NULL,</span><br><span class="line">  kind                  VARCHAR(32),</span><br><span class="line">  content               TEXT,</span><br><span class="line">  PRIMARY KEY (id)</span><br><span class="line">) Engine=InnoDB CHARACTER SET &#x27;latin1&#x27;;</span><br><span class="line"></span><br><span class="line">CREATE INDEX domainmetadata_idx ON domainmetadata (domain_id, kind);</span><br><span class="line"></span><br><span class="line">CREATE TABLE cryptokeys (</span><br><span class="line">  id                    INT AUTO_INCREMENT,</span><br><span class="line">  domain_id             INT NOT NULL,</span><br><span class="line">  flags                 INT NOT NULL,</span><br><span class="line">  active                BOOL,</span><br><span class="line">  published             BOOL DEFAULT 1,</span><br><span class="line">  content               TEXT,</span><br><span class="line">  PRIMARY KEY(id)</span><br><span class="line">) Engine=InnoDB CHARACTER SET &#x27;latin1&#x27;;</span><br><span class="line"></span><br><span class="line">CREATE INDEX domainidindex ON cryptokeys(domain_id);</span><br><span class="line"></span><br><span class="line">CREATE TABLE tsigkeys (</span><br><span class="line">  id                    INT AUTO_INCREMENT,</span><br><span class="line">  name                  VARCHAR(255),</span><br><span class="line">  algorithm             VARCHAR(50),</span><br><span class="line">  secret                VARCHAR(255),</span><br><span class="line">  PRIMARY KEY (id)</span><br><span class="line">) Engine=InnoDB CHARACTER SET &#x27;latin1&#x27;;</span><br><span class="line"></span><br><span class="line">CREATE UNIQUE INDEX namealgoindex ON tsigkeys(name, algorithm);</span><br></pre></td></tr></table></figure>

<p>此步骤完成了MySQL数据库的主从复制环境和powerdns数据库的置备，您可以查看powerdns数据库是否复制成功。</p>
<h2 id="安装PowerDNS权威服务器"><a href="#安装PowerDNS权威服务器" class="headerlink" title="安装PowerDNS权威服务器"></a>安装PowerDNS权威服务器</h2><p>安装PowerDNS Authoritative源和安装PowerDNS Authoritative。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install epel-release yum-plugin-priorities &amp;&amp;</span><br><span class="line">curl -o /etc/yum.repos.d/powerdns-auth-45.repo https://repo.powerdns.com/repo-files/centos-auth-45.repo &amp;&amp;</span><br><span class="line">yum install pdns pdns-backend-mysql</span><br></pre></td></tr></table></figure>

<p>生成权威服务器配置（采用Native复制模式（基于后端MySQL复制），两台权威服务器配置相同）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mv</span> /etc/pdns/pdns.conf /etc/pdns/pdns.conf.bak</span><br><span class="line">vm /etc/pdns/pdns.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># backend</span></span><br><span class="line">launch=gmysql</span><br><span class="line">gmysql-host=localhost</span><br><span class="line">gmysql-port=3306</span><br><span class="line">gmysql-dbname=powerdns</span><br><span class="line">gmysql-user=powerdns</span><br><span class="line">gmysql-password=powerdns用户密码</span><br><span class="line"></span><br><span class="line"><span class="comment"># pdns API</span></span><br><span class="line">webserver=<span class="built_in">yes</span></span><br><span class="line">webserver-address=0.0.0.0</span><br><span class="line">webserver-allow-from=0.0.0.0/0</span><br><span class="line">webserver-port=8081</span><br><span class="line">api=<span class="built_in">yes</span></span><br><span class="line">api-key=vmware</span><br><span class="line"></span><br><span class="line"><span class="comment"># pdns config</span></span><br><span class="line">daemon=<span class="built_in">yes</span></span><br><span class="line">guardian=<span class="built_in">yes</span></span><br><span class="line">local-address=0.0.0.0</span><br></pre></td></tr></table></figure>

<p>更改配置文件权限</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">chown</span> pdns. /etc/pdns/pdns.conf</span><br></pre></td></tr></table></figure>

<p>启动两台权威服务器</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span> pdns</span><br><span class="line">systemctl start pdns</span><br></pre></td></tr></table></figure>

<h2 id="部署PowerDNS-Admin管理控制台"><a href="#部署PowerDNS-Admin管理控制台" class="headerlink" title="部署PowerDNS-Admin管理控制台"></a>部署PowerDNS-Admin管理控制台</h2><p>参考上面部署安装MySQL数据库（无需主从复制），此数据库仅用于PowerDNS-Admin自己使用。</p>
<p>安装Docker和Docker-Compose环境。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line"></span><br><span class="line">yum list docker-ce --showduplicates |<span class="built_in">sort</span> -r</span><br><span class="line"></span><br><span class="line">yum install -y docker-ce-20.10.8 docker-compose</span><br><span class="line"></span><br><span class="line">systemctl <span class="built_in">enable</span> docker</span><br><span class="line">systemctl start docker</span><br></pre></td></tr></table></figure>

<p>准备PowerDNS-Admin的docker-compse文件。</p>
<blockquote>
<p>注意：IP地址不能是Localhost或者127.0.0.1</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /usr/local/powerdns-admin/docker-compose.yml</span><br><span class="line"></span><br><span class="line">version: <span class="string">&quot;3&quot;</span></span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  app:</span><br><span class="line">    image: ngoduykhanh/powerdns-admin:latest</span><br><span class="line">    container_name: powerdns_admin</span><br><span class="line">    ports:</span><br><span class="line">      - <span class="string">&quot;80:80&quot;</span></span><br><span class="line">    logging:</span><br><span class="line">      driver: json-file</span><br><span class="line">      options:</span><br><span class="line">        max-size: 50m</span><br><span class="line">    environment:</span><br><span class="line">      - SQLALCHEMY_DATABASE_URI=mysql://root:VMware1!@10.208.0.100/pda</span><br><span class="line">      - GUNICORN_TIMEOUT=60</span><br><span class="line">      - GUNICORN_WORKERS=2</span><br><span class="line">      - GUNICORN_LOGLEVEL=DEBUG</span><br><span class="line">      - OFFLINE_MODE=False <span class="comment"># True for offline, False for external resources</span></span><br></pre></td></tr></table></figure>

<p>在本地MySQL数据库中创建powerdns-admin数据库</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql -uroot -p</span><br><span class="line">CREATE DATABASE pda CHARACTER SET utf8 COLLATE utf8_general_ci;</span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO &#x27;root&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;VMware1!&#x27;;</span><br><span class="line">FLUSH PRIVILEGES;</span><br><span class="line">exit</span><br></pre></td></tr></table></figure>

<p>启动powerdns-admin</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/local/powerdns-admin</span><br><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure>

<p>访问管理页面，创建新用户，第一次创建的新用户默认为管理员，使用此用户登录，登录成功后，进行如下初始化配置：</p>
<ol>
<li>Settings-&gt;PDNS：PDNS API URL&#x3D;<a href="http://10.208.0.101:8081/">http://10.208.0.101:8081</a> PDNS API KEY&#x3D;vmware PDNS VERSION&#x3D;4.5.1</li>
<li>Settings-&gt;Records：选中Forward Zone列的SOA选项，Update保存。</li>
<li>Settings-&gt;Basic：修改auto_ptr为ON。</li>
<li>Settings-&gt;Authentication：取消选中Allow users to sign up。</li>
</ol>
<p>新建权威域，输入域名后，其他保持默认，并提交。<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202210131011384.png" alt="img"></p>
<p>点击域名，进行解析记录管理。<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202210131011360.png" alt="img">首先修改默认SOA配置，主Name Server为Pdns-auth01的域名。<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202210131013326.png" alt="img">再创建相应的A记录和NS记录。<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202210131013220.png" alt="img"></p>
<h2 id="部署PowerDNS递归服务器"><a href="#部署PowerDNS递归服务器" class="headerlink" title="部署PowerDNS递归服务器"></a>部署PowerDNS递归服务器</h2><p>PowerDNS权威服务器（Authoritative）不应该直接响应客户的DNS解析请求，因为PowerDNS中递归（Recursor）服务器能够提供DNS缓存、高并发、转发等能力。</p>
<blockquote>
<p>注意：如果为了节约服务器数量和满足小环境需求，PowerDNS Recursor也可以部署到PowerDNS Authoritative中，只需要修改使用不同的监听端口即可（例如：pdns监听5353，pdns-recursor监听53）。</p>
</blockquote>
<p>安装PowerDNS Recursor源和pdns-recursor</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># yum install epel-release yum-plugin-priorities </span></span><br><span class="line"><span class="comment"># curl -o /etc/yum.repos.d/powerdns-rec-42.repo https://repo.powerdns.com/repo-files/centos-rec-42.repo </span></span><br><span class="line"><span class="comment"># yum install pdns-recursor</span></span><br><span class="line"><span class="comment"># systemctl restart pdns-recursor.service</span></span><br><span class="line"><span class="comment"># systemctl enable pdns.service</span></span><br><span class="line"></span><br><span class="line">curl -o /etc/yum.repos.d/powerdns-rec-45.repo https://repo.powerdns.com/repo-files/centos-rec-45.repo &amp;&amp;</span><br><span class="line">yum install pdns-recursor</span><br></pre></td></tr></table></figure>

<p>（可选）进行操作系统内核参数优化</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;root soft nofile 65535&quot;</span> &gt;&gt; /etc/security/limits.conf</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;root hard nofile 65535&quot;</span> &gt;&gt; /etc/security/limits.conf</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;root soft nproc 65535&quot;</span>  &gt;&gt; /etc/security/limits.conf</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;root hard nproc 65535&quot;</span>  &gt;&gt; /etc/security/limits.conf</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;root soft  memlock  unlimited&quot;</span>  &gt;&gt; /etc/security/limits.conf</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;root hard memlock  unlimited&quot;</span>  &gt;&gt; /etc/security/limits.conf</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;* soft nofile 65535&quot;</span> &gt;&gt; /etc/security/limits.conf</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;* hard nofile 65535&quot;</span> &gt;&gt; /etc/security/limits.conf</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;* soft nproc 65535&quot;</span>  &gt;&gt; /etc/security/limits.conf</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;* hard nproc 65535&quot;</span>  &gt;&gt; /etc/security/limits.conf</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;* soft memlock unlimited&quot;</span>  &gt;&gt; /etc/security/limits.conf</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;* hard memlock  unlimited&quot;</span>  &gt;&gt; /etc/security/limits.conf</span><br><span class="line"></span><br><span class="line"><span class="built_in">cp</span> /etc/sysctl.conf /etc/sysctl.conf.bak</span><br><span class="line"><span class="built_in">cat</span> &gt; /etc/sysctl.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">net.ipv4.conf.default.accept_redirects = 0</span></span><br><span class="line"><span class="string">net.ipv4.conf.all.send_redirects = 0</span></span><br><span class="line"><span class="string">net.ipv4.conf.default.send_redirects = 0</span></span><br><span class="line"><span class="string">net.ipv4.conf.all.secure_redirects = 0</span></span><br><span class="line"><span class="string">net.ipv4.conf.default.secure_redirects = 0</span></span><br><span class="line"><span class="string">net.ipv4.conf.all.log_martians = 1</span></span><br><span class="line"><span class="string">net.ipv4.conf.default.log_martians = 1</span></span><br><span class="line"><span class="string">net.ipv4.ip_forward = 1</span></span><br><span class="line"><span class="string">net.ipv6.conf.all.accept_redirects = 0</span></span><br><span class="line"><span class="string">net.ipv6.conf.default.accept_redirects = 0</span></span><br><span class="line"><span class="string">net.ipv6.conf.all.router_solicitations = 0</span></span><br><span class="line"><span class="string">net.ipv6.conf.default.router_solicitations = 0</span></span><br><span class="line"><span class="string">net.ipv6.conf.all.dad_transmits = 0</span></span><br><span class="line"><span class="string">net.ipv6.conf.default.dad_transmits = 0</span></span><br><span class="line"><span class="string">net.ipv6.conf.all.max_addresses = 1</span></span><br><span class="line"><span class="string">net.ipv6.conf.default.max_addresses = 1</span></span><br><span class="line"><span class="string">kernel.panic_on_oops = 1</span></span><br><span class="line"><span class="string">kernel.panic = 10</span></span><br><span class="line"><span class="string">vm.overcommit_memory = 1</span></span><br><span class="line"><span class="string">net.core.somaxconn= 65535</span></span><br><span class="line"><span class="string">fs.file-max= 1048576</span></span><br><span class="line"><span class="string">fs.nr_open = 10000000</span></span><br><span class="line"><span class="string">net.ipv4.conf.default.rp_filter = 1</span></span><br><span class="line"><span class="string">net.ipv4.conf.default.accept_source_route = 0</span></span><br><span class="line"><span class="string">kernel.sysrq = 0</span></span><br><span class="line"><span class="string">kernel.core_uses_pid = 1</span></span><br><span class="line"><span class="string">net.ipv4.tcp_syncookies = 1</span></span><br><span class="line"><span class="string">kernel.msgmnb = 65536</span></span><br><span class="line"><span class="string">kernel.msgmax = 65536</span></span><br><span class="line"><span class="string">kernel.shmmax = 68719476736</span></span><br><span class="line"><span class="string">kernel.shmall = 4294967296</span></span><br><span class="line"><span class="string">net.ipv4.tcp_max_tw_buckets = 6000</span></span><br><span class="line"><span class="string">net.ipv4.tcp_sack = 1</span></span><br><span class="line"><span class="string">net.ipv4.tcp_window_scaling = 1</span></span><br><span class="line"><span class="string">net.ipv4.tcp_rmem = 10240 87380 12582912</span></span><br><span class="line"><span class="string">net.ipv4.tcp_wmem = 10240 87380 12582912</span></span><br><span class="line"><span class="string">net.core.wmem_default = 8388608</span></span><br><span class="line"><span class="string">net.core.rmem_default = 8388608</span></span><br><span class="line"><span class="string">net.core.rmem_max = 16777216</span></span><br><span class="line"><span class="string">net.core.wmem_max = 16777216</span></span><br><span class="line"><span class="string">net.core.netdev_max_backlog = 262144</span></span><br><span class="line"><span class="string">net.ipv4.tcp_max_orphans = 3276800</span></span><br><span class="line"><span class="string">net.ipv4.tcp_max_syn_backlog = 262144</span></span><br><span class="line"><span class="string">net.ipv4.tcp_timestamps = 0</span></span><br><span class="line"><span class="string">net.ipv4.tcp_synack_retries = 1</span></span><br><span class="line"><span class="string">net.ipv4.tcp_syn_retries = 1</span></span><br><span class="line"><span class="string">net.ipv4.tcp_tw_recycle = 1</span></span><br><span class="line"><span class="string">net.ipv4.tcp_tw_reuse = 1</span></span><br><span class="line"><span class="string">net.ipv4.tcp_mem = 94500000 915000000 927000000</span></span><br><span class="line"><span class="string">net.ipv4.tcp_fin_timeout = 1</span></span><br><span class="line"><span class="string">net.ipv4.tcp_keepalive_time = 30</span></span><br><span class="line"><span class="string">net.ipv4.ip_local_port_range = 35000 65000</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>（可选）Ulimit优化。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /etc/systemd/system.conf</span><br><span class="line">DefaultLimitNOFILE=65535</span><br><span class="line">DefaultLimitNPROC=65535</span><br></pre></td></tr></table></figure>

<p>重启服务器，生效内核参数配置。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure>

<p>pdns-rec01生成配置文件 &#x2F;etc&#x2F;pdns-recursor&#x2F;recursor.conf</p>
<blockquote>
<p>注意1：Loacl-address为pdns-recursor监听地址，请根据实际情况修改。 注意2：forward-zones-recurse选项，用于转发所有未匹配域名的解析。 注意3：mac-negative-ttl参数用于缩短无应答域名的缓存时间，例如：a.test.local解析记录尚未创建时，如果请求该记录解析，pdns-recursor会缓存空解析记录（时间默认为1小时），再缓存未被清除前，1小时内的解析都是空。配置此参数后，空解析记录默认缓存10秒钟。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">daemon=<span class="built_in">yes</span></span><br><span class="line">local-address=10.208.0.112,127.0.0.1</span><br><span class="line">allow-from=0.0.0.0/0</span><br><span class="line">local-port=53</span><br><span class="line">etc-hosts-file=/etc/pdns-recursor/dns-hosts.local</span><br><span class="line">export-etc-hosts=on</span><br><span class="line">forward-zones-file=/etc/pdns-recursor/zones</span><br><span class="line">forward-zones-recurse=.=114.114.114.114;115.115.115.115</span><br><span class="line"><span class="comment">#hint-file=/etc/pdns-recursor/named.ca</span></span><br><span class="line">pdns-distributes-queries=no</span><br><span class="line">reuseport=<span class="built_in">yes</span></span><br><span class="line">max-cache-entries=2000000</span><br><span class="line"><span class="comment">#When the record does not return results, the maximum cache time is 10 seconds</span></span><br><span class="line">max-negative-ttl=10</span><br><span class="line"></span><br><span class="line">dnssec=off</span><br><span class="line"></span><br><span class="line">webserver=<span class="built_in">yes</span></span><br><span class="line">webserver-address=10.208.0.112</span><br><span class="line">webserver-port=8081</span><br><span class="line">webserver-allow-from=0.0.0.0/0</span><br><span class="line">api-key=vmware</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fix CNAME and NS reslution issues.</span></span><br><span class="line">dont-query=172.0.0.1/8</span><br></pre></td></tr></table></figure>

<p>生成相关zone文件。</p>
<blockquote>
<p>dns-hosts.local：用于通过本地文件解析域名；例如，业务系统同时对内和对外提供服务，公网域名为www.guoqiangli.com（11.11.11.11），内网服务器地址为10.208.0.66，最佳方法是内网请求www.guoqiangli.com解析到内网IP地址（10.208.0.66），此场景下就可以通过此文件声明解析记录。 zones：用于声明指定域名解析转发，例如：企业内部域名为test.local，权威服务器为10.208.0.101和10.208.0.102.</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">touch</span> /etc/pdns-recursor/dns-hosts.local</span><br><span class="line"><span class="built_in">touch</span> /etc/pdns-recursor/zones</span><br></pre></td></tr></table></figure>

<p>配置本地转发配置文件。</p>
<blockquote>
<p>注意：反向解析记录必须按IP地址段添加后才能实现反向解析。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /etc/pdns-recursor/zones</span><br><span class="line"><span class="comment"># for test.local</span></span><br><span class="line">+test.local=10.208.0.101;10.208.0.102</span><br><span class="line">+0.208.10.in-addr.arpa=10.208.0.101;10.208.0.102</span><br></pre></td></tr></table></figure>

<p>配置本地Host解析记录。</p>
<blockquote>
<p>注意：此配置用于强制解析非权威域名；</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /etc/pdns-recursor/dns-hosts.local</span><br><span class="line">10.208.0.66 www.guoqiangli.com</span><br></pre></td></tr></table></figure>

<p>启动pdns-recursor服务。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span> pdns-recursor</span><br><span class="line">systemctl start pdns-recursor</span><br></pre></td></tr></table></figure>

<p>最后，执行DNS解析测试：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">dig -t a www.test.local @10.208.0.111</span><br><span class="line">dig -x 10.208.0.98 @10.208.0.111</span><br><span class="line">dig -t a www.guoqiangli.com @10.208.0.111</span><br></pre></td></tr></table></figure>

<h2 id="使用QueryPerf工具进行压力测试"><a href="#使用QueryPerf工具进行压力测试" class="headerlink" title="使用QueryPerf工具进行压力测试"></a>使用QueryPerf工具进行压力测试</h2><p>下载queryperf源码，并编译；</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/local/src</span><br><span class="line">wget http://ftp.isc.org/isc/bind9/9.7.3/bind-9.7.3.tar.gz</span><br><span class="line">tar xf bind-9.7.3.tar.gz</span><br><span class="line"></span><br><span class="line">yum install gcc</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /usr/local/src/bind-9.7.3/contrib/queryperf</span><br><span class="line">./configure</span><br><span class="line">make</span><br><span class="line"></span><br><span class="line"><span class="built_in">cp</span> queryperf /usr/local/bin</span><br><span class="line"></span><br><span class="line">queryperf -h</span><br></pre></td></tr></table></figure>

<p>按如下格式准备测试文件，尽量多的记录（10万条），可以重复是重复记录。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> /root/querytest.txt</span><br><span class="line"></span><br><span class="line">www.vmware.com  A</span><br><span class="line">www.toutiao.com A</span><br><span class="line">www.baidu.com   A</span><br><span class="line">www.sohu.com    A</span><br><span class="line">www.test.local  A</span><br><span class="line">ns1.test.local  A</span><br><span class="line">ns2.test.local  A</span><br><span class="line">www.guoqiangli.com  A</span><br><span class="line">…………</span><br></pre></td></tr></table></figure>

<p>执行压力测试，结果会直接显示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">queryperf -d querytest.txt -s 10.208.0.111</span><br><span class="line"></span><br><span class="line">queryperf -d querytest.txt -s 10.208.0.112</span><br></pre></td></tr></table></figure>

<p>登录Powerdns Recursor监控页面，查看服务器负载情况。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">http://10.208.0.111:8081</span><br><span class="line">http://10.208.0.112:8081</span><br></pre></td></tr></table></figure>

<p>至此，我们完成了企业DNS的高可用架构搭建，本文章中的配置参数仅供参考，实际生产环境中根据需要进行优化。</p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>DNS</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>PDNS</tag>
      </tags>
  </entry>
  <entry>
    <title>二进制部署一套完整的企业级K8s集群</title>
    <url>/2022/12/29/%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2%E4%B8%80%E5%A5%97%E5%AE%8C%E6%95%B4%E7%9A%84%E4%BC%81%E4%B8%9A%E7%BA%A7K8s%E9%9B%86%E7%BE%A4/</url>
    <content><![CDATA[<p><strong>v1.22</strong>**，二进制方式**</p>
<table>
<thead>
<tr>
<th>说明</th>
<th>  该文档有导航窗格，方便阅读，如果左侧没有显示，请检查word是否启用。    文档中涉及涉及文件都下载好了，如果有需要可私信阿良获取最新包。     转载请注明作者，拒绝不道德行为！</th>
</tr>
</thead>
<tbody><tr>
<td>一键部署脚本</td>
<td><a href="https://github.com/lizhenliang/ansible-install-k8s">https://github.com/lizhenliang/ansible-install-k8s</a></td>
</tr>
<tr>
<td>最后更新时间</td>
<td>2021-11-25</td>
</tr>
</tbody></table>
<h2 id="一、前置知识点"><a href="#一、前置知识点" class="headerlink" title="一、前置知识点"></a>一、前置知识点</h2><h3 id="1-1-生产环境部署K8s集群的两种方式"><a href="#1-1-生产环境部署K8s集群的两种方式" class="headerlink" title="1.1 生产环境部署K8s集群的两种方式"></a>1.1 生产环境部署K8s集群的两种方式</h3><p>•   <strong>kubeadm</strong></p>
<p>Kubeadm是一个K8s部署工具，提供kubeadm init和kubeadm join，用于快速部署Kubernetes集群。</p>
<p>•   <strong>二进制包</strong></p>
<p>从github下载发行版的二进制包，手动部署每个组件，组成Kubernetes集群。</p>
<p>小结：Kubeadm降低部署门槛，但屏蔽了很多细节，遇到问题很难排查。如果想更容易可控，推荐使用二进制包部署Kubernetes集群，虽然手动部署麻烦点，期间可以学习很多工作原理，也利于后期维护。</p>
<h3 id="1-2-准备环境"><a href="#1-2-准备环境" class="headerlink" title="1.2 准备环境"></a>1.2 准备环境</h3><p>服务器要求：</p>
<p>•   建议最小硬件配置：2核CPU、2G内存、30G硬盘</p>
<p>•   服务器最好可以访问外网，会有从网上拉取镜像需求，如果服务器不能上网，需要提前下载对应镜像并导入节点，或者替换国内源</p>
<p>软件环境：</p>
<table>
<thead>
<tr>
<th><strong>软件</strong></th>
<th><strong>版本</strong></th>
</tr>
</thead>
<tbody><tr>
<td>操作系统</td>
<td>CentOS7.x_x64  （mini）</td>
</tr>
<tr>
<td>容器引擎</td>
<td>Docker  CE 19</td>
</tr>
<tr>
<td>Kubernetes</td>
<td>Kubernetes  v1.20</td>
</tr>
</tbody></table>
<p>服务器整体规划：</p>
<table>
<thead>
<tr>
<th><strong>角色</strong></th>
<th><strong>IP</strong></th>
<th><strong>组件</strong></th>
</tr>
</thead>
<tbody><tr>
<td>k8s-master1</td>
<td>192.168.31.71</td>
<td>kube-apiserver，kube-controller-manager，kube-scheduler，kubelet，kube-proxy，docker，etcd，  nginx，keepalived</td>
</tr>
<tr>
<td>k8s-master2</td>
<td>192.168.31.74</td>
<td>kube-apiserver，kube-controller-manager，kube-scheduler，kubelet，kube-proxy，docker，  nginx，keepalived</td>
</tr>
<tr>
<td>k8s-node1</td>
<td>192.168.31.72</td>
<td>kubelet，kube-proxy，docker，etcd</td>
</tr>
<tr>
<td>k8s-node2</td>
<td>192.168.31.73</td>
<td>kubelet，kube-proxy，docker，etcd</td>
</tr>
<tr>
<td>负载均衡器IP</td>
<td>192.168.31.88 (VIP)</td>
<td></td>
</tr>
</tbody></table>
<p>须知：考虑到有些朋友电脑配置较低，一次性开四台机器会跑不动，所以搭建这套K8s高可用集群分两部分实施，先部署一套单Master架构（3台），再扩容为多Master架构（4台或6台），顺便再熟悉下Master扩容流程。</p>
<p>单Master架构图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202209051505469.png" alt="image-20220905150320750"></p>
<p>单Master服务器规划：</p>
<table>
<thead>
<tr>
<th><strong>角色</strong></th>
<th><strong>IP</strong></th>
<th><strong>组件</strong></th>
</tr>
</thead>
<tbody><tr>
<td>k8s-master</td>
<td>192.168.31.71</td>
<td>kube-apiserver，kube-controller-manager，kube-scheduler，etcd</td>
</tr>
<tr>
<td>k8s-node1</td>
<td>192.168.31.72</td>
<td>kubelet，kube-proxy，docker，etcd</td>
</tr>
<tr>
<td>k8s-node2</td>
<td>192.168.31.73</td>
<td>kubelet，kube-proxy，docker，etcd</td>
</tr>
</tbody></table>
<h3 id="1-3-操作系统初始化配置"><a href="#1-3-操作系统初始化配置" class="headerlink" title="1.3 操作系统初始化配置"></a>1.3 操作系统初始化配置</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 关闭防火墙 </span></span><br><span class="line">systemctl stop firewalld </span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 关闭selinux </span></span><br><span class="line">sed -i <span class="string">&#x27;s/enforcing/disabled/&#x27;</span> /etc/selinux/config  <span class="comment"># 永久</span></span><br><span class="line">setenforce 0  <span class="comment"># 临时 </span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 关闭swap </span></span><br><span class="line">swapoff -a  <span class="comment"># 临时 </span></span><br><span class="line">sed -ri <span class="string">&#x27;s/.*swap.*/#&amp;/&#x27;</span> /etc/fstab    <span class="comment"># 永久</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 根据规划设置主机名 </span></span><br><span class="line">hostnamectl set-hostname &lt;hostname&gt; </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 在master添加hosts </span></span><br><span class="line"><span class="built_in">cat</span> &gt;&gt; /etc/hosts &lt;&lt; <span class="string">EOF </span></span><br><span class="line"><span class="string">192.168.31.71 k8s-master1 </span></span><br><span class="line"><span class="string">192.168.31.72 k8s-node1 </span></span><br><span class="line"><span class="string">192.168.31.73 k8s-node2 </span></span><br><span class="line"><span class="string">EOF</span> </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 将桥接的IPv4流量传递到iptables的链 </span></span><br><span class="line"><span class="built_in">cat</span> &gt; /etc/sysctl.d/k8s.conf &lt;&lt; <span class="string">EOF </span></span><br><span class="line"><span class="string">net.bridge.bridge-nf-call-ip6tables = 1 </span></span><br><span class="line"><span class="string">net.bridge.bridge-nf-call-iptables = 1 </span></span><br><span class="line"><span class="string">EOF</span> </span><br><span class="line">sysctl --system  <span class="comment"># 生效 </span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 时间同步 </span></span><br><span class="line">yum install ntpdate -y </span><br><span class="line">ntpdate time.windows.com</span><br></pre></td></tr></table></figure>

<h2 id="二、部署Etcd集群"><a href="#二、部署Etcd集群" class="headerlink" title="二、部署Etcd集群"></a>二、部署Etcd集群</h2><p>Etcd 是一个分布式键值存储系统，Kubernetes使用Etcd进行数据存储，所以先准备一个Etcd数据库，为解决Etcd单点故障，应采用集群方式部署，这里使用3台组建集群，可容忍1台机器故障，当然，你也可以使用5台组建集群，可容忍2台机器故障。</p>
<table>
<thead>
<tr>
<th><strong>节点名称</strong></th>
<th><strong>IP</strong></th>
</tr>
</thead>
<tbody><tr>
<td>etcd-1</td>
<td>192.168.31.71</td>
</tr>
<tr>
<td>etcd-2</td>
<td>192.168.31.72</td>
</tr>
<tr>
<td>etcd-3</td>
<td>192.168.31.73</td>
</tr>
</tbody></table>
<p>注：为了节省机器，这里与K8s节点机器复用。也可以独立于k8s集群之外部署，只要apiserver能连接到就行。</p>
<h3 id="2-1-准备cfssl证书生成工具"><a href="#2-1-准备cfssl证书生成工具" class="headerlink" title="2.1 准备cfssl证书生成工具"></a>2.1 准备cfssl证书生成工具</h3><p>cfssl是一个开源的证书管理工具，使用json文件生成证书，相比openssl更方便使用。</p>
<p>找任意一台服务器操作，这里用Master节点。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64</span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64</span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64</span><br><span class="line"><span class="built_in">chmod</span> +x cfssl_linux-amd64 cfssljson_linux-amd64 cfssl-certinfo_linux-amd64</span><br><span class="line"><span class="built_in">mv</span> cfssl_linux-amd64 /usr/local/bin/cfssl</span><br><span class="line"><span class="built_in">mv</span> cfssljson_linux-amd64 /usr/local/bin/cfssljson</span><br><span class="line"><span class="built_in">mv</span> cfssl-certinfo_linux-amd64 /usr/bin/cfssl-certinfo</span><br></pre></td></tr></table></figure>

<h3 id="2-2-生成Etcd证书"><a href="#2-2-生成Etcd证书" class="headerlink" title="2.2 生成Etcd证书"></a>2.2 生成Etcd证书</h3><h4 id="1-Etcd自签证书颁发机构（CA）"><a href="#1-Etcd自签证书颁发机构（CA）" class="headerlink" title="1. Etcd自签证书颁发机构（CA）"></a>1. Etcd自签证书颁发机构（CA）</h4><p>创建工作目录：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p ~/TLS/&#123;etcd,k8s&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> ~/TLS/etcd</span><br></pre></td></tr></table></figure>

<p>自签CA：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; ca-config.json &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">  &quot;signing&quot;: &#123;</span></span><br><span class="line"><span class="string">    &quot;default&quot;: &#123;</span></span><br><span class="line"><span class="string">      &quot;expiry&quot;: &quot;87600h&quot;</span></span><br><span class="line"><span class="string">    &#125;,</span></span><br><span class="line"><span class="string">    &quot;profiles&quot;: &#123;</span></span><br><span class="line"><span class="string">      &quot;www&quot;: &#123;</span></span><br><span class="line"><span class="string">         &quot;expiry&quot;: &quot;87600h&quot;,</span></span><br><span class="line"><span class="string">         &quot;usages&quot;: [</span></span><br><span class="line"><span class="string">            &quot;signing&quot;,</span></span><br><span class="line"><span class="string">            &quot;key encipherment&quot;,</span></span><br><span class="line"><span class="string">            &quot;server auth&quot;,</span></span><br><span class="line"><span class="string">            &quot;client auth&quot;</span></span><br><span class="line"><span class="string">        ]</span></span><br><span class="line"><span class="string">      &#125;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">  &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> &gt; ca-csr.json &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">    &quot;CN&quot;: &quot;etcd CA&quot;,</span></span><br><span class="line"><span class="string">    &quot;key&quot;: &#123;</span></span><br><span class="line"><span class="string">        &quot;algo&quot;: &quot;rsa&quot;,</span></span><br><span class="line"><span class="string">        &quot;size&quot;: 2048</span></span><br><span class="line"><span class="string">    &#125;,</span></span><br><span class="line"><span class="string">    &quot;names&quot;: [</span></span><br><span class="line"><span class="string">        &#123;</span></span><br><span class="line"><span class="string">            &quot;C&quot;: &quot;CN&quot;,</span></span><br><span class="line"><span class="string">            &quot;L&quot;: &quot;Beijing&quot;,</span></span><br><span class="line"><span class="string">            &quot;ST&quot;: &quot;Beijing&quot;</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    ]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>生成证书：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare ca -</span><br></pre></td></tr></table></figure>

<p>会生成ca.pem和ca-key.pem文件。</p>
<h4 id="2-使用自签CA签发Etcd-HTTPS证书"><a href="#2-使用自签CA签发Etcd-HTTPS证书" class="headerlink" title="2. 使用自签CA签发Etcd HTTPS证书"></a>2. 使用自签CA签发Etcd HTTPS证书</h4><p>创建证书申请文件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; server-csr.json &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">    &quot;CN&quot;: &quot;etcd&quot;,</span></span><br><span class="line"><span class="string">    &quot;hosts&quot;: [</span></span><br><span class="line"><span class="string">    &quot;192.168.31.71&quot;,</span></span><br><span class="line"><span class="string">    &quot;192.168.31.72&quot;,</span></span><br><span class="line"><span class="string">    &quot;192.168.31.73&quot;</span></span><br><span class="line"><span class="string">    ],</span></span><br><span class="line"><span class="string">    &quot;key&quot;: &#123;</span></span><br><span class="line"><span class="string">        &quot;algo&quot;: &quot;rsa&quot;,</span></span><br><span class="line"><span class="string">        &quot;size&quot;: 2048</span></span><br><span class="line"><span class="string">    &#125;,</span></span><br><span class="line"><span class="string">    &quot;names&quot;: [</span></span><br><span class="line"><span class="string">        &#123;</span></span><br><span class="line"><span class="string">            &quot;C&quot;: &quot;CN&quot;,</span></span><br><span class="line"><span class="string">            &quot;L&quot;: &quot;BeiJing&quot;,</span></span><br><span class="line"><span class="string">            &quot;ST&quot;: &quot;BeiJing&quot;</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    ]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>注：上述文件hosts字段中IP为所有etcd节点的集群内部通信IP，一个都不能少！为了方便后期扩容可以多写几个预留的IP。</p>
<p>生成证书：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=www server-csr.json | cfssljson -bare server</span><br></pre></td></tr></table></figure>

<p>会生成server.pem和server-key.pem文件。</p>
<h3 id="2-3-从Github下载二进制文件"><a href="#2-3-从Github下载二进制文件" class="headerlink" title="2.3 从Github下载二进制文件"></a>2.3 从Github下载二进制文件</h3><p>下载地址：<a href="https://github.com/etcd-io/etcd/releases/download/v3.4.9/etcd-v3.4.9-linux-amd64.tar.gz">https://github.com/etcd-io/etcd/releases/download/v3.4.9/etcd-v3.4.9-linux-amd64.tar.gz</a></p>
<h3 id="2-4-部署Etcd集群"><a href="#2-4-部署Etcd集群" class="headerlink" title="2.4 部署Etcd集群"></a>2.4 部署Etcd集群</h3><p>以下在节点1上操作，为简化操作，待会将节点1生成的所有文件拷贝到节点2和节点3.</p>
<h4 id="1-创建工作目录并解压二进制包"><a href="#1-创建工作目录并解压二进制包" class="headerlink" title="1. 创建工作目录并解压二进制包"></a>1. 创建工作目录并解压二进制包</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /opt/etcd/&#123;bin,cfg,ssl&#125; -p</span><br><span class="line">tar zxvf etcd-v3.4.9-linux-amd64.tar.gz</span><br><span class="line"><span class="built_in">mv</span> etcd-v3.4.9-linux-amd64/&#123;etcd,etcdctl&#125; /opt/etcd/bin/</span><br></pre></td></tr></table></figure>

<h4 id="2-创建etcd配置文件"><a href="#2-创建etcd配置文件" class="headerlink" title="2. 创建etcd配置文件"></a>2. 创建etcd配置文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /opt/etcd/cfg/etcd.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">#[Member]</span></span><br><span class="line"><span class="string">ETCD_NAME=&quot;etcd-1&quot;</span></span><br><span class="line"><span class="string">ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;</span></span><br><span class="line"><span class="string">ETCD_LISTEN_PEER_URLS=&quot;https://192.168.31.71:2380&quot;</span></span><br><span class="line"><span class="string">ETCD_LISTEN_CLIENT_URLS=&quot;https://192.168.31.71:2379&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#[Clustering]</span></span><br><span class="line"><span class="string">ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;https://192.168.31.71:2380&quot;</span></span><br><span class="line"><span class="string">ETCD_ADVERTISE_CLIENT_URLS=&quot;https://192.168.31.71:2379&quot;</span></span><br><span class="line"><span class="string">ETCD_INITIAL_CLUSTER=&quot;etcd-1=https://192.168.31.71:2380,etcd-2=https://192.168.31.72:2380,etcd-3=https://192.168.31.73:2380&quot;</span></span><br><span class="line"><span class="string">ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot;</span></span><br><span class="line"><span class="string">ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>•   ETCD_NAME：节点名称，集群中唯一</p>
<p>•   ETCD_DATA_DIR：数据目录</p>
<p>•   ETCD_LISTEN_PEER_URLS：集群通信监听地址</p>
<p>•   ETCD_LISTEN_CLIENT_URLS：客户端访问监听地址</p>
<p>•   ETCD_INITIAL_ADVERTISE_PEERURLS：集群通告地址</p>
<p>•   ETCD_ADVERTISE_CLIENT_URLS：客户端通告地址</p>
<p>•   ETCD_INITIAL_CLUSTER：集群节点地址</p>
<p>•   ETCD_INITIALCLUSTER_TOKEN：集群Token</p>
<p>•   ETCD_INITIALCLUSTER_STATE：加入集群的当前状态，new是新集群，existing表示加入已有集群</p>
<h4 id="3-systemd管理etcd"><a href="#3-systemd管理etcd" class="headerlink" title="3. systemd管理etcd"></a>3. systemd管理etcd</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/etcd.service &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[Unit]</span></span><br><span class="line"><span class="string">Description=Etcd Server</span></span><br><span class="line"><span class="string">After=network.target</span></span><br><span class="line"><span class="string">After=network-online.target</span></span><br><span class="line"><span class="string">Wants=network-online.target</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">Type=notify</span></span><br><span class="line"><span class="string">EnvironmentFile=/opt/etcd/cfg/etcd.conf</span></span><br><span class="line"><span class="string">ExecStart=/opt/etcd/bin/etcd \</span></span><br><span class="line"><span class="string">--cert-file=/opt/etcd/ssl/server.pem \</span></span><br><span class="line"><span class="string">--key-file=/opt/etcd/ssl/server-key.pem \</span></span><br><span class="line"><span class="string">--peer-cert-file=/opt/etcd/ssl/server.pem \</span></span><br><span class="line"><span class="string">--peer-key-file=/opt/etcd/ssl/server-key.pem \</span></span><br><span class="line"><span class="string">--trusted-ca-file=/opt/etcd/ssl/ca.pem \</span></span><br><span class="line"><span class="string">--peer-trusted-ca-file=/opt/etcd/ssl/ca.pem \</span></span><br><span class="line"><span class="string">--logger=zap</span></span><br><span class="line"><span class="string">Restart=on-failure</span></span><br><span class="line"><span class="string">LimitNOFILE=65536</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Install]</span></span><br><span class="line"><span class="string">WantedBy=multi-user.target</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<h4 id="4-拷贝刚才生成的证书"><a href="#4-拷贝刚才生成的证书" class="headerlink" title="4. 拷贝刚才生成的证书"></a>4. 拷贝刚才生成的证书</h4><p>把刚才生成的证书拷贝到配置文件中的路径：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cp</span> ~/TLS/etcd/ca*pem ~/TLS/etcd/server*pem /opt/etcd/ssl/</span><br></pre></td></tr></table></figure>

<h4 id="5-启动并设置开机启动"><a href="#5-启动并设置开机启动" class="headerlink" title="5. 启动并设置开机启动"></a>5. 启动并设置开机启动</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start etcd</span><br><span class="line">systemctl <span class="built_in">enable</span> etcd</span><br></pre></td></tr></table></figure>

<h4 id="6-将上面节点1所有生成的文件拷贝到节点2和节点3"><a href="#6-将上面节点1所有生成的文件拷贝到节点2和节点3" class="headerlink" title="6. 将上面节点1所有生成的文件拷贝到节点2和节点3"></a>6. 将上面节点1所有生成的文件拷贝到节点2和节点3</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">scp -r /opt/etcd/ root@192.168.31.72:/opt/</span><br><span class="line">scp /usr/lib/systemd/system/etcd.service root@192.168.31.72:/usr/lib/systemd/system/</span><br><span class="line">scp -r /opt/etcd/ root@192.168.31.73:/opt/</span><br><span class="line">scp /usr/lib/systemd/system/etcd.service root@192.168.31.73:/usr/lib/systemd/system/</span><br></pre></td></tr></table></figure>

<p>然后在节点2和节点3分别修改etcd.conf配置文件中的节点名称和当前服务器IP：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /opt/etcd/cfg/etcd.conf</span><br><span class="line"><span class="comment">#[Member]</span></span><br><span class="line">ETCD_NAME=<span class="string">&quot;etcd-1&quot;</span>   <span class="comment"># 修改此处，节点2改为etcd-2，节点3改为etcd-3</span></span><br><span class="line">ETCD_DATA_DIR=<span class="string">&quot;/var/lib/etcd/default.etcd&quot;</span></span><br><span class="line">ETCD_LISTEN_PEER_URLS=<span class="string">&quot;https://192.168.31.71:2380&quot;</span>   <span class="comment"># 修改此处为当前服务器IP</span></span><br><span class="line">ETCD_LISTEN_CLIENT_URLS=<span class="string">&quot;https://192.168.31.71:2379&quot;</span> <span class="comment"># 修改此处为当前服务器IP</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#[Clustering]</span></span><br><span class="line">ETCD_INITIAL_ADVERTISE_PEER_URLS=<span class="string">&quot;https://192.168.31.71:2380&quot;</span> <span class="comment"># 修改此处为当前服务器IP</span></span><br><span class="line">ETCD_ADVERTISE_CLIENT_URLS=<span class="string">&quot;https://192.168.31.71:2379&quot;</span> <span class="comment"># 修改此处为当前服务器IP</span></span><br><span class="line">ETCD_INITIAL_CLUSTER=<span class="string">&quot;etcd-1=https://192.168.31.71:2380,etcd-2=https://192.168.31.72:2380,etcd-3=https://192.168.31.73:2380&quot;</span></span><br><span class="line">ETCD_INITIAL_CLUSTER_TOKEN=<span class="string">&quot;etcd-cluster&quot;</span></span><br><span class="line">ETCD_INITIAL_CLUSTER_STATE=<span class="string">&quot;new&quot;</span></span><br></pre></td></tr></table></figure>

<p>最后启动etcd并设置开机启动，同上。</p>
<h4 id="7-查看集群状态"><a href="#7-查看集群状态" class="headerlink" title="7. 查看集群状态"></a>7. 查看集群状态</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ETCDCTL_API=3 /opt/etcd/bin/etcdctl --cacert=/opt/etcd/ssl/ca.pem --cert=/opt/etcd/ssl/server.pem --key=/opt/etcd/ssl/server-key.pem --endpoints=<span class="string">&quot;https://192.168.31.71:2379,https://192.168.31.72:2379,https://192.168.31.73:2379&quot;</span> endpoint health --write-out=table</span><br><span class="line"></span><br><span class="line">+----------------------------+--------+-------------+-------+</span><br><span class="line">|          ENDPOINT    | HEALTH |    TOOK     | ERROR |</span><br><span class="line">+----------------------------+--------+-------------+-------+</span><br><span class="line">| https://192.168.31.71:2379 |   <span class="literal">true</span> | 10.301506ms |    |</span><br><span class="line">| https://192.168.31.73:2379 |   <span class="literal">true</span> | 12.87467ms |     |</span><br><span class="line">| https://192.168.31.72:2379 |   <span class="literal">true</span> | 13.225954ms |    |</span><br><span class="line">+----------------------------+--------+-------------+-------+</span><br></pre></td></tr></table></figure>

<p>如果输出上面信息，就说明集群部署成功。</p>
<p>如果有问题第一步先看日志：&#x2F;var&#x2F;log&#x2F;message 或 journalctl -u etcd</p>
<h2 id="三、安装Docker"><a href="#三、安装Docker" class="headerlink" title="三、安装Docker"></a>三、安装Docker</h2><p>这里使用Docker作为容器引擎，也可以换成别的，例如containerd</p>
<p>下载地址：<a href="https://download.docker.com/linux/static/stable/x86_64/docker-19.03.9.tgz">https://download.docker.com/linux/static/stable/x86_64/docker-19.03.9.tgz</a></p>
<p>以下在所有节点操作。这里采用二进制安装，用yum安装也一样。</p>
<h3 id="3-1-解压二进制包"><a href="#3-1-解压二进制包" class="headerlink" title="3.1 解压二进制包"></a>3.1 解压二进制包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar zxvf docker-19.03.9.tgz</span><br><span class="line"><span class="built_in">mv</span> docker/* /usr/bin</span><br></pre></td></tr></table></figure>

<h3 id="3-2-systemd管理docker"><a href="#3-2-systemd管理docker" class="headerlink" title="3.2 systemd管理docker"></a>3.2 systemd管理docker</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/docker.service &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[Unit]</span></span><br><span class="line"><span class="string">Description=Docker Application Container Engine</span></span><br><span class="line"><span class="string">Documentation=https://docs.docker.com</span></span><br><span class="line"><span class="string">After=network-online.target firewalld.service</span></span><br><span class="line"><span class="string">Wants=network-online.target</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">Type=notify</span></span><br><span class="line"><span class="string">ExecStart=/usr/bin/dockerd</span></span><br><span class="line"><span class="string">ExecReload=/bin/kill -s HUP $MAINPID</span></span><br><span class="line"><span class="string">LimitNOFILE=infinity</span></span><br><span class="line"><span class="string">LimitNPROC=infinity</span></span><br><span class="line"><span class="string">LimitCORE=infinity</span></span><br><span class="line"><span class="string">TimeoutStartSec=0</span></span><br><span class="line"><span class="string">Delegate=yes</span></span><br><span class="line"><span class="string">KillMode=process</span></span><br><span class="line"><span class="string">Restart=on-failure</span></span><br><span class="line"><span class="string">StartLimitBurst=3</span></span><br><span class="line"><span class="string">StartLimitInterval=60s</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Install]</span></span><br><span class="line"><span class="string">WantedBy=multi-user.target</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<h3 id="3-3-创建配置文件"><a href="#3-3-创建配置文件" class="headerlink" title="3.3 创建配置文件"></a>3.3 创建配置文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /etc/docker</span><br><span class="line"><span class="built_in">cat</span> &gt; /etc/docker/daemon.json &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">  &quot;registry-mirrors&quot;: [&quot;https://b9pmyelo.mirror.aliyuncs.com&quot;]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>•   registry-mirrors 阿里云镜像加速器</p>
<h3 id="3-4-启动并设置开机启动"><a href="#3-4-启动并设置开机启动" class="headerlink" title="3.4 启动并设置开机启动"></a>3.4 启动并设置开机启动</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start docker</span><br><span class="line">systemctl <span class="built_in">enable</span> docker</span><br></pre></td></tr></table></figure>

<h2 id="四、部署Master-Node"><a href="#四、部署Master-Node" class="headerlink" title="四、部署Master Node"></a>四、部署Master Node</h2><p>如果你在学习中遇到问题或者文档有误可联系阿良~ 微信: k8init</p>
<h3 id="4-1-生成kube-apiserver证书"><a href="#4-1-生成kube-apiserver证书" class="headerlink" title="4.1 生成kube-apiserver证书"></a>4.1 生成kube-apiserver证书</h3><h4 id="1-kube-apiserver自签证书颁发机构（CA）"><a href="#1-kube-apiserver自签证书颁发机构（CA）" class="headerlink" title="1. kube-apiserver自签证书颁发机构（CA）"></a>1. kube-apiserver自签证书颁发机构（CA）</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/TLS/k8s</span><br><span class="line"><span class="built_in">cat</span> &gt; ca-config.json &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">  &quot;signing&quot;: &#123;</span></span><br><span class="line"><span class="string">    &quot;default&quot;: &#123;</span></span><br><span class="line"><span class="string">      &quot;expiry&quot;: &quot;87600h&quot;</span></span><br><span class="line"><span class="string">    &#125;,</span></span><br><span class="line"><span class="string">    &quot;profiles&quot;: &#123;</span></span><br><span class="line"><span class="string">      &quot;kubernetes&quot;: &#123;</span></span><br><span class="line"><span class="string">         &quot;expiry&quot;: &quot;87600h&quot;,</span></span><br><span class="line"><span class="string">         &quot;usages&quot;: [</span></span><br><span class="line"><span class="string">            &quot;signing&quot;,</span></span><br><span class="line"><span class="string">            &quot;key encipherment&quot;,</span></span><br><span class="line"><span class="string">            &quot;server auth&quot;,</span></span><br><span class="line"><span class="string">            &quot;client auth&quot;</span></span><br><span class="line"><span class="string">        ]</span></span><br><span class="line"><span class="string">      &#125;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">  &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="built_in">cat</span> &gt; ca-csr.json &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">    &quot;CN&quot;: &quot;kubernetes&quot;,</span></span><br><span class="line"><span class="string">    &quot;key&quot;: &#123;</span></span><br><span class="line"><span class="string">        &quot;algo&quot;: &quot;rsa&quot;,</span></span><br><span class="line"><span class="string">        &quot;size&quot;: 2048</span></span><br><span class="line"><span class="string">    &#125;,</span></span><br><span class="line"><span class="string">    &quot;names&quot;: [</span></span><br><span class="line"><span class="string">        &#123;</span></span><br><span class="line"><span class="string">            &quot;C&quot;: &quot;CN&quot;,</span></span><br><span class="line"><span class="string">            &quot;L&quot;: &quot;Beijing&quot;,</span></span><br><span class="line"><span class="string">            &quot;ST&quot;: &quot;Beijing&quot;,</span></span><br><span class="line"><span class="string">            &quot;O&quot;: &quot;k8s&quot;,</span></span><br><span class="line"><span class="string">            &quot;OU&quot;: &quot;System&quot;</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    ]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>生成证书：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare ca -</span><br></pre></td></tr></table></figure>

<p>会生成ca.pem和ca-key.pem文件。</p>
<h4 id="2-使用自签CA签发kube-apiserver-HTTPS证书"><a href="#2-使用自签CA签发kube-apiserver-HTTPS证书" class="headerlink" title="2. 使用自签CA签发kube-apiserver HTTPS证书"></a>2. 使用自签CA签发kube-apiserver HTTPS证书</h4><p>创建证书申请文件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; server-csr.json &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">    &quot;CN&quot;: &quot;kubernetes&quot;,</span></span><br><span class="line"><span class="string">    &quot;hosts&quot;: [</span></span><br><span class="line"><span class="string">      &quot;10.0.0.1&quot;,</span></span><br><span class="line"><span class="string">      &quot;127.0.0.1&quot;,</span></span><br><span class="line"><span class="string">      &quot;192.168.31.71&quot;,</span></span><br><span class="line"><span class="string">      &quot;192.168.31.72&quot;,</span></span><br><span class="line"><span class="string">      &quot;192.168.31.73&quot;,</span></span><br><span class="line"><span class="string">&quot;192.168.31.74&quot;,</span></span><br><span class="line"><span class="string">      &quot;192.168.31.88&quot;,</span></span><br><span class="line"><span class="string">      &quot;kubernetes&quot;,</span></span><br><span class="line"><span class="string">      &quot;kubernetes.default&quot;,</span></span><br><span class="line"><span class="string">      &quot;kubernetes.default.svc&quot;,</span></span><br><span class="line"><span class="string">      &quot;kubernetes.default.svc.cluster&quot;,</span></span><br><span class="line"><span class="string">      &quot;kubernetes.default.svc.cluster.local&quot;</span></span><br><span class="line"><span class="string">    ],</span></span><br><span class="line"><span class="string">    &quot;key&quot;: &#123;</span></span><br><span class="line"><span class="string">        &quot;algo&quot;: &quot;rsa&quot;,</span></span><br><span class="line"><span class="string">        &quot;size&quot;: 2048</span></span><br><span class="line"><span class="string">    &#125;,</span></span><br><span class="line"><span class="string">    &quot;names&quot;: [</span></span><br><span class="line"><span class="string">        &#123;</span></span><br><span class="line"><span class="string">            &quot;C&quot;: &quot;CN&quot;,</span></span><br><span class="line"><span class="string">            &quot;L&quot;: &quot;BeiJing&quot;,</span></span><br><span class="line"><span class="string">            &quot;ST&quot;: &quot;BeiJing&quot;,</span></span><br><span class="line"><span class="string">            &quot;O&quot;: &quot;k8s&quot;,</span></span><br><span class="line"><span class="string">            &quot;OU&quot;: &quot;System&quot;</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    ]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>注：上述文件hosts字段中IP为所有Master&#x2F;LB&#x2F;VIP IP，一个都不能少！为了方便后期扩容可以多写几个预留的IP。</p>
<p>生成证书：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes server-csr.json | cfssljson -bare server</span><br></pre></td></tr></table></figure>

<p>会生成server.pem和server-key.pem文件。</p>
<h3 id="4-2-从Github下载二进制文件"><a href="#4-2-从Github下载二进制文件" class="headerlink" title="4.2 从Github下载二进制文件"></a>4.2 从Github下载二进制文件</h3><p>下载地址： <a href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.20.md">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.20.md</a></p>
<p>注：打开链接你会发现里面有很多包，下载一个server包就够了，包含了Master和Worker Node二进制文件。</p>
<h3 id="4-3-解压二进制包"><a href="#4-3-解压二进制包" class="headerlink" title="4.3 解压二进制包"></a>4.3 解压二进制包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /opt/kubernetes/&#123;bin,cfg,ssl,logs&#125; </span><br><span class="line">tar zxvf kubernetes-server-linux-amd64.tar.gz</span><br><span class="line"><span class="built_in">cd</span> kubernetes/server/bin</span><br><span class="line"><span class="built_in">cp</span> kube-apiserver kube-scheduler kube-controller-manager /opt/kubernetes/bin</span><br><span class="line"><span class="built_in">cp</span> kubectl /usr/bin/</span><br></pre></td></tr></table></figure>

<h3 id="4-4-部署kube-apiserver"><a href="#4-4-部署kube-apiserver" class="headerlink" title="4.4 部署kube-apiserver"></a>4.4 部署kube-apiserver</h3><h4 id="1-创建配置文件"><a href="#1-创建配置文件" class="headerlink" title="1. 创建配置文件"></a>1. 创建配置文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /opt/kubernetes/cfg/kube-apiserver.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">KUBE_APISERVER_OPTS=&quot;--logtostderr=false \\</span></span><br><span class="line"><span class="string">--v=2 \\</span></span><br><span class="line"><span class="string">--log-dir=/opt/kubernetes/logs \\</span></span><br><span class="line"><span class="string">--etcd-servers=https://192.168.31.71:2379,https://192.168.31.72:2379,https://192.168.31.73:2379 \\</span></span><br><span class="line"><span class="string">--bind-address=192.168.31.71 \\</span></span><br><span class="line"><span class="string">--secure-port=6443 \\</span></span><br><span class="line"><span class="string">--advertise-address=192.168.31.71 \\</span></span><br><span class="line"><span class="string">--allow-privileged=true \\</span></span><br><span class="line"><span class="string">--service-cluster-ip-range=10.0.0.0/24 \\</span></span><br><span class="line"><span class="string">--enable-admission-plugins=NodeRestriction \\</span></span><br><span class="line"><span class="string">--authorization-mode=RBAC,Node \\</span></span><br><span class="line"><span class="string">--enable-bootstrap-token-auth=true \\</span></span><br><span class="line"><span class="string">--token-auth-file=/opt/kubernetes/cfg/token.csv \\</span></span><br><span class="line"><span class="string">--service-node-port-range=30000-32767 \\</span></span><br><span class="line"><span class="string">--kubelet-client-certificate=/opt/kubernetes/ssl/server.pem \\</span></span><br><span class="line"><span class="string">--kubelet-client-key=/opt/kubernetes/ssl/server-key.pem \\</span></span><br><span class="line"><span class="string">--tls-cert-file=/opt/kubernetes/ssl/server.pem  \\</span></span><br><span class="line"><span class="string">--tls-private-key-file=/opt/kubernetes/ssl/server-key.pem \\</span></span><br><span class="line"><span class="string">--client-ca-file=/opt/kubernetes/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--service-account-key-file=/opt/kubernetes/ssl/ca-key.pem \\</span></span><br><span class="line"><span class="string">--service-account-issuer=api \\</span></span><br><span class="line"><span class="string">--service-account-signing-key-file=/opt/kubernetes/ssl/ca-key.pem \\</span></span><br><span class="line"><span class="string">--etcd-cafile=/opt/etcd/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--etcd-certfile=/opt/etcd/ssl/server.pem \\</span></span><br><span class="line"><span class="string">--etcd-keyfile=/opt/etcd/ssl/server-key.pem \\</span></span><br><span class="line"><span class="string">--requestheader-client-ca-file=/opt/kubernetes/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--proxy-client-cert-file=/opt/kubernetes/ssl/server.pem \\</span></span><br><span class="line"><span class="string">--proxy-client-key-file=/opt/kubernetes/ssl/server-key.pem \\</span></span><br><span class="line"><span class="string">--requestheader-allowed-names=kubernetes \\</span></span><br><span class="line"><span class="string">--requestheader-extra-headers-prefix=X-Remote-Extra- \\</span></span><br><span class="line"><span class="string">--requestheader-group-headers=X-Remote-Group \\</span></span><br><span class="line"><span class="string">--requestheader-username-headers=X-Remote-User \\</span></span><br><span class="line"><span class="string">--enable-aggregator-routing=true \\</span></span><br><span class="line"><span class="string">--audit-log-maxage=30 \\</span></span><br><span class="line"><span class="string">--audit-log-maxbackup=3 \\</span></span><br><span class="line"><span class="string">--audit-log-maxsize=100 \\</span></span><br><span class="line"><span class="string">--audit-log-path=/opt/kubernetes/logs/k8s-audit.log&quot;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>注：上面两个\ \ 第一个是转义符，第二个是换行符，使用转义符是为了使用EOF保留换行符。</p>
<p>•   –logtostderr：启用日志</p>
<p>•   —v：日志等级</p>
<p>•   –log-dir：日志目录</p>
<p>•   –etcd-servers：etcd集群地址</p>
<p>•   –bind-address：监听地址</p>
<p>•   –secure-port：https安全端口</p>
<p>•   –advertise-address：集群通告地址</p>
<p>•   –allow-privileged：启用授权</p>
<p>•   –service-cluster-ip-range：Service虚拟IP地址段</p>
<p>•   –enable-admission-plugins：准入控制模块</p>
<p>•   –authorization-mode：认证授权，启用RBAC授权和节点自管理</p>
<p>•   –enable-bootstrap-token-auth：启用TLS bootstrap机制</p>
<p>•   –token-auth-file：bootstrap token文件</p>
<p>•   –service-node-port-range：Service nodeport类型默认分配端口范围</p>
<p>•   –kubelet-client-xxx：apiserver访问kubelet客户端证书</p>
<p>•   –tls-xxx-file：apiserver https证书</p>
<p>•   1.20版本必须加的参数：–service-account-issuer，–service-account-signing-key-file</p>
<p>•   –etcd-xxxfile：连接Etcd集群证书</p>
<p>•   –audit-log-xxx：审计日志</p>
<p>•   启动聚合层相关配置：–requestheader-client-ca-file，–proxy-client-cert-file，–proxy-client-key-file，–requestheader-allowed-names，–requestheader-extra-headers-prefix，–requestheader-group-headers，–requestheader-username-headers，–enable-aggregator-routing</p>
<h4 id="2-拷贝刚才生成的证书"><a href="#2-拷贝刚才生成的证书" class="headerlink" title="2. 拷贝刚才生成的证书"></a>2. 拷贝刚才生成的证书</h4><p>把刚才生成的证书拷贝到配置文件中的路径：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cp</span> ~/TLS/k8s/ca*pem ~/TLS/k8s/server*pem /opt/kubernetes/ssl/</span><br></pre></td></tr></table></figure>

<h4 id="3-启用-TLS-Bootstrapping-机制"><a href="#3-启用-TLS-Bootstrapping-机制" class="headerlink" title="3. 启用 TLS Bootstrapping 机制"></a>3. 启用 TLS Bootstrapping 机制</h4><p>TLS Bootstraping：Master apiserver启用TLS认证后，Node节点kubelet和kube-proxy要与kube-apiserver进行通信，必须使用CA签发的有效证书才可以，当Node节点很多时，这种客户端证书颁发需要大量工作，同样也会增加集群扩展复杂度。为了简化流程，Kubernetes引入了TLS bootstraping机制来自动颁发客户端证书，kubelet会以一个低权限用户自动向apiserver申请证书，kubelet的证书由apiserver动态签署。所以强烈建议在Node上使用这种方式，目前主要用于kubelet，kube-proxy还是由我们统一颁发一个证书。</p>
<p>TLS bootstraping 工作流程：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202209051507161.png" alt="image-20220905150724039"></p>
<p>创建上述配置文件中token文件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /opt/kubernetes/cfg/token.csv &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">c47ffb939f5ca36231d9e3121a252940,kubelet-bootstrap,10001,&quot;system:node-bootstrapper&quot;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>格式：token，用户名，UID，用户组</p>
<p>token也可自行生成替换：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">head</span> -c 16 /dev/urandom | <span class="built_in">od</span> -An -t x | <span class="built_in">tr</span> -d <span class="string">&#x27; &#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="4-systemd管理apiserver"><a href="#4-systemd管理apiserver" class="headerlink" title="4. systemd管理apiserver"></a>4. systemd管理apiserver</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[Unit]</span></span><br><span class="line"><span class="string">Description=Kubernetes API Server</span></span><br><span class="line"><span class="string">Documentation=https://github.com/kubernetes/kubernetes</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">EnvironmentFile=/opt/kubernetes/cfg/kube-apiserver.conf</span></span><br><span class="line"><span class="string">ExecStart=/opt/kubernetes/bin/kube-apiserver \$KUBE_APISERVER_OPTS</span></span><br><span class="line"><span class="string">Restart=on-failure</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Install]</span></span><br><span class="line"><span class="string">WantedBy=multi-user.target</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<h4 id="5-启动并设置开机启动-1"><a href="#5-启动并设置开机启动-1" class="headerlink" title="5. 启动并设置开机启动"></a>5. 启动并设置开机启动</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kube-apiserver </span><br><span class="line">systemctl <span class="built_in">enable</span> kube-apiserver</span><br></pre></td></tr></table></figure>

<h3 id="4-5-部署kube-controller-manager"><a href="#4-5-部署kube-controller-manager" class="headerlink" title="4.5 部署kube-controller-manager"></a>4.5 部署kube-controller-manager</h3><h4 id="1-创建配置文件-1"><a href="#1-创建配置文件-1" class="headerlink" title="1. 创建配置文件"></a>1. 创建配置文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /opt/kubernetes/cfg/kube-controller-manager.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">KUBE_CONTROLLER_MANAGER_OPTS=&quot;--logtostderr=false \\</span></span><br><span class="line"><span class="string">--v=2 \\</span></span><br><span class="line"><span class="string">--log-dir=/opt/kubernetes/logs \\</span></span><br><span class="line"><span class="string">--leader-elect=true \\</span></span><br><span class="line"><span class="string">--kubeconfig=/opt/kubernetes/cfg/kube-controller-manager.kubeconfig \\</span></span><br><span class="line"><span class="string">--bind-address=127.0.0.1 \\</span></span><br><span class="line"><span class="string">--allocate-node-cidrs=true \\</span></span><br><span class="line"><span class="string">--cluster-cidr=10.244.0.0/16 \\</span></span><br><span class="line"><span class="string">--service-cluster-ip-range=10.0.0.0/24 \\</span></span><br><span class="line"><span class="string">--cluster-signing-cert-file=/opt/kubernetes/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--cluster-signing-key-file=/opt/kubernetes/ssl/ca-key.pem  \\</span></span><br><span class="line"><span class="string">--root-ca-file=/opt/kubernetes/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--service-account-private-key-file=/opt/kubernetes/ssl/ca-key.pem \\</span></span><br><span class="line"><span class="string">--cluster-signing-duration=87600h0m0s&quot;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>•   –kubeconfig：连接apiserver配置文件</p>
<p>•   –leader-elect：当该组件启动多个时，自动选举（HA）</p>
<p>•   –cluster-signing-cert-file&#x2F;–cluster-signing-key-file：自动为kubelet颁发证书的CA，与apiserver保持一致</p>
<h4 id="2-生成kubeconfig文件"><a href="#2-生成kubeconfig文件" class="headerlink" title="2. 生成kubeconfig文件"></a>2. 生成kubeconfig文件</h4><p>生成kube-controller-manager证书：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 切换工作目录</span></span><br><span class="line"><span class="built_in">cd</span> ~/TLS/k8s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建证书请求文件</span></span><br><span class="line"><span class="built_in">cat</span> &gt; kube-controller-manager-csr.json &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">  &quot;CN&quot;: &quot;system:kube-controller-manager&quot;,</span></span><br><span class="line"><span class="string">  &quot;hosts&quot;: [],</span></span><br><span class="line"><span class="string">  &quot;key&quot;: &#123;</span></span><br><span class="line"><span class="string">    &quot;algo&quot;: &quot;rsa&quot;,</span></span><br><span class="line"><span class="string">    &quot;size&quot;: 2048</span></span><br><span class="line"><span class="string">  &#125;,</span></span><br><span class="line"><span class="string">  &quot;names&quot;: [</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">      &quot;C&quot;: &quot;CN&quot;,</span></span><br><span class="line"><span class="string">      &quot;L&quot;: &quot;BeiJing&quot;, </span></span><br><span class="line"><span class="string">      &quot;ST&quot;: &quot;BeiJing&quot;,</span></span><br><span class="line"><span class="string">      &quot;O&quot;: &quot;system:masters&quot;,</span></span><br><span class="line"><span class="string">      &quot;OU&quot;: &quot;System&quot;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">  ]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成证书</span></span><br><span class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-controller-manager-csr.json | cfssljson -bare kube-controller-manager</span><br></pre></td></tr></table></figure>

<p>生成kubeconfig文件（以下是shell命令，直接在终端执行）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">KUBE_CONFIG=<span class="string">&quot;/opt/kubernetes/cfg/kube-controller-manager.kubeconfig&quot;</span></span><br><span class="line">KUBE_APISERVER=<span class="string">&quot;https://192.168.31.71:6443&quot;</span></span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=/opt/kubernetes/ssl/ca.pem \</span><br><span class="line">  --embed-certs=<span class="literal">true</span> \</span><br><span class="line">  --server=<span class="variable">$&#123;KUBE_APISERVER&#125;</span> \</span><br><span class="line">  --kubeconfig=<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line">kubectl config set-credentials kube-controller-manager \</span><br><span class="line">  --client-certificate=./kube-controller-manager.pem \</span><br><span class="line">  --client-key=./kube-controller-manager-key.pem \</span><br><span class="line">  --embed-certs=<span class="literal">true</span> \</span><br><span class="line">  --kubeconfig=<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=kube-controller-manager \</span><br><span class="line">  --kubeconfig=<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line">kubectl config use-context default --kubeconfig=<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br></pre></td></tr></table></figure>

<h4 id="3-systemd管理controller-manager"><a href="#3-systemd管理controller-manager" class="headerlink" title="3. systemd管理controller-manager"></a>3. systemd管理controller-manager</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kube-controller-manager.service &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[Unit]</span></span><br><span class="line"><span class="string">Description=Kubernetes Controller Manager</span></span><br><span class="line"><span class="string">Documentation=https://github.com/kubernetes/kubernetes</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">EnvironmentFile=/opt/kubernetes/cfg/kube-controller-manager.conf</span></span><br><span class="line"><span class="string">ExecStart=/opt/kubernetes/bin/kube-controller-manager \$KUBE_CONTROLLER_MANAGER_OPTS</span></span><br><span class="line"><span class="string">Restart=on-failure</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Install]</span></span><br><span class="line"><span class="string">WantedBy=multi-user.target</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<h4 id="4-重启守护进程启动并设置开机启动"><a href="#4-重启守护进程启动并设置开机启动" class="headerlink" title="4. 重启守护进程启动并设置开机启动"></a>4. 重启守护进程启动并设置开机启动</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kube-controller-manager</span><br><span class="line">systemctl <span class="built_in">enable</span> kube-controller-manager</span><br></pre></td></tr></table></figure>

<h3 id="4-6-部署kube-scheduler"><a href="#4-6-部署kube-scheduler" class="headerlink" title="4.6 部署kube-scheduler"></a>4.6 部署kube-scheduler</h3><h4 id="1-创建配置文件-2"><a href="#1-创建配置文件-2" class="headerlink" title="1. 创建配置文件"></a>1. 创建配置文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /opt/kubernetes/cfg/kube-scheduler.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">KUBE_SCHEDULER_OPTS=&quot;--logtostderr=false \\</span></span><br><span class="line"><span class="string">--v=2 \\</span></span><br><span class="line"><span class="string">--log-dir=/opt/kubernetes/logs \\</span></span><br><span class="line"><span class="string">--leader-elect \\</span></span><br><span class="line"><span class="string">--kubeconfig=/opt/kubernetes/cfg/kube-scheduler.kubeconfig \\</span></span><br><span class="line"><span class="string">--bind-address=127.0.0.1&quot;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>•   –kubeconfig：连接apiserver配置文件</p>
<p>•   –leader-elect：当该组件启动多个时，自动选举（HA）</p>
<h4 id="2-生成kubeconfig文件-1"><a href="#2-生成kubeconfig文件-1" class="headerlink" title="2. 生成kubeconfig文件"></a>2. 生成kubeconfig文件</h4><p>生成kube-scheduler证书：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 切换工作目录</span></span><br><span class="line"><span class="built_in">cd</span> ~/TLS/k8s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建证书请求文件</span></span><br><span class="line"><span class="built_in">cat</span> &gt; kube-scheduler-csr.json &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">  &quot;CN&quot;: &quot;system:kube-scheduler&quot;,</span></span><br><span class="line"><span class="string">  &quot;hosts&quot;: [],</span></span><br><span class="line"><span class="string">  &quot;key&quot;: &#123;</span></span><br><span class="line"><span class="string">    &quot;algo&quot;: &quot;rsa&quot;,</span></span><br><span class="line"><span class="string">    &quot;size&quot;: 2048</span></span><br><span class="line"><span class="string">  &#125;,</span></span><br><span class="line"><span class="string">  &quot;names&quot;: [</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">      &quot;C&quot;: &quot;CN&quot;,</span></span><br><span class="line"><span class="string">      &quot;L&quot;: &quot;BeiJing&quot;,</span></span><br><span class="line"><span class="string">      &quot;ST&quot;: &quot;BeiJing&quot;,</span></span><br><span class="line"><span class="string">      &quot;O&quot;: &quot;system:masters&quot;,</span></span><br><span class="line"><span class="string">      &quot;OU&quot;: &quot;System&quot;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">  ]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成证书</span></span><br><span class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-scheduler-csr.json | cfssljson -bare kube-scheduler</span><br></pre></td></tr></table></figure>

<p>生成kubeconfig文件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">KUBE_CONFIG=<span class="string">&quot;/opt/kubernetes/cfg/kube-scheduler.kubeconfig&quot;</span></span><br><span class="line">KUBE_APISERVER=<span class="string">&quot;https://192.168.31.71:6443&quot;</span></span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=/opt/kubernetes/ssl/ca.pem \</span><br><span class="line">  --embed-certs=<span class="literal">true</span> \</span><br><span class="line">  --server=<span class="variable">$&#123;KUBE_APISERVER&#125;</span> \</span><br><span class="line">  --kubeconfig=<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line">kubectl config set-credentials kube-scheduler \</span><br><span class="line">  --client-certificate=./kube-scheduler.pem \</span><br><span class="line">  --client-key=./kube-scheduler-key.pem \</span><br><span class="line">  --embed-certs=<span class="literal">true</span> \</span><br><span class="line">  --kubeconfig=<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=kube-scheduler \</span><br><span class="line">  --kubeconfig=<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line">kubectl config use-context default --kubeconfig=<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br></pre></td></tr></table></figure>

<h4 id="3-systemd管理scheduler"><a href="#3-systemd管理scheduler" class="headerlink" title="3. systemd管理scheduler"></a>3. systemd管理scheduler</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kube-scheduler.service &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[Unit]</span></span><br><span class="line"><span class="string">Description=Kubernetes Scheduler</span></span><br><span class="line"><span class="string">Documentation=https://github.com/kubernetes/kubernetes</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">EnvironmentFile=/opt/kubernetes/cfg/kube-scheduler.conf</span></span><br><span class="line"><span class="string">ExecStart=/opt/kubernetes/bin/kube-scheduler \$KUBE_SCHEDULER_OPTS</span></span><br><span class="line"><span class="string">Restart=on-failure</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Install]</span></span><br><span class="line"><span class="string">WantedBy=multi-user.target</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<h4 id="4-启动并设置开机启动"><a href="#4-启动并设置开机启动" class="headerlink" title="4. 启动并设置开机启动"></a>4. 启动并设置开机启动</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kube-scheduler</span><br><span class="line">systemctl <span class="built_in">enable</span> kube-scheduler</span><br></pre></td></tr></table></figure>

<h4 id="5-查看集群状态"><a href="#5-查看集群状态" class="headerlink" title="5. 查看集群状态"></a>5. 查看集群状态</h4><p>生成kubectl连接集群的证书：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; admin-csr.json &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">  &quot;CN&quot;: &quot;admin&quot;,</span></span><br><span class="line"><span class="string">  &quot;hosts&quot;: [],</span></span><br><span class="line"><span class="string">  &quot;key&quot;: &#123;</span></span><br><span class="line"><span class="string">    &quot;algo&quot;: &quot;rsa&quot;,</span></span><br><span class="line"><span class="string">    &quot;size&quot;: 2048</span></span><br><span class="line"><span class="string">  &#125;,</span></span><br><span class="line"><span class="string">  &quot;names&quot;: [</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">      &quot;C&quot;: &quot;CN&quot;,</span></span><br><span class="line"><span class="string">      &quot;L&quot;: &quot;BeiJing&quot;,</span></span><br><span class="line"><span class="string">      &quot;ST&quot;: &quot;BeiJing&quot;,</span></span><br><span class="line"><span class="string">      &quot;O&quot;: &quot;system:masters&quot;,</span></span><br><span class="line"><span class="string">      &quot;OU&quot;: &quot;System&quot;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">  ]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes admin-csr.json | cfssljson -bare admin</span><br></pre></td></tr></table></figure>

<p>生成kubeconfig文件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /root/.kube</span><br><span class="line">KUBE_CONFIG=<span class="string">&quot;/root/.kube/config&quot;</span></span><br><span class="line">KUBE_APISERVER=<span class="string">&quot;https://192.168.31.71:6443&quot;</span></span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=/opt/kubernetes/ssl/ca.pem \</span><br><span class="line">  --embed-certs=<span class="literal">true</span> \</span><br><span class="line">  --server=<span class="variable">$&#123;KUBE_APISERVER&#125;</span> \</span><br><span class="line">  --kubeconfig=<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line">kubectl config set-credentials cluster-admin \</span><br><span class="line">  --client-certificate=./admin.pem \</span><br><span class="line">  --client-key=./admin-key.pem \</span><br><span class="line">  --embed-certs=<span class="literal">true</span> \</span><br><span class="line">  --kubeconfig=<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=cluster-admin \</span><br><span class="line">  --kubeconfig=<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line">kubectl config use-context default --kubeconfig=<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br></pre></td></tr></table></figure>

<p>通过kubectl工具查看当前集群组件状态：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get cs</span><br><span class="line">NAME                STATUS    MESSAGE             ERROR</span><br><span class="line">scheduler             Healthy   ok                  </span><br><span class="line">controller-manager       Healthy   ok                  </span><br><span class="line">etcd-2               Healthy   &#123;<span class="string">&quot;health&quot;</span>:<span class="string">&quot;true&quot;</span>&#125;   </span><br><span class="line">etcd-1               Healthy   &#123;<span class="string">&quot;health&quot;</span>:<span class="string">&quot;true&quot;</span>&#125;   </span><br><span class="line">etcd-0               Healthy   &#123;<span class="string">&quot;health&quot;</span>:<span class="string">&quot;true&quot;</span>&#125;  </span><br></pre></td></tr></table></figure>

<p>如上输出说明Master节点组件运行正常。</p>
<h4 id="6-授权kubelet-bootstrap用户允许请求证书"><a href="#6-授权kubelet-bootstrap用户允许请求证书" class="headerlink" title="6. 授权kubelet-bootstrap用户允许请求证书"></a>6. 授权kubelet-bootstrap用户允许请求证书</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create clusterrolebinding kubelet-bootstrap \</span><br><span class="line">--clusterrole=system:node-bootstrapper \</span><br><span class="line">--user=kubelet-bootstrap</span><br></pre></td></tr></table></figure>

<h2 id="五、部署Worker-Node"><a href="#五、部署Worker-Node" class="headerlink" title="五、部署Worker Node"></a>五、部署Worker Node</h2><p>如果你在学习中遇到问题或者文档有误可联系阿良~ 微信: k8init</p>
<blockquote>
<p>下面还是在Master Node上操作，即同时作为Worker Node</p>
</blockquote>
<h3 id="5-1-创建工作目录并拷贝二进制文件"><a href="#5-1-创建工作目录并拷贝二进制文件" class="headerlink" title="5.1 创建工作目录并拷贝二进制文件"></a>5.1 创建工作目录并拷贝二进制文件</h3><p>在所有worker node创建工作目录：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /opt/kubernetes/&#123;bin,cfg,ssl,logs&#125; </span><br></pre></td></tr></table></figure>

<p>从master节点拷贝：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> kubernetes/server/bin</span><br><span class="line"><span class="built_in">cp</span> kubelet kube-proxy /opt/kubernetes/bin   <span class="comment"># 本地拷贝</span></span><br></pre></td></tr></table></figure>

<h3 id="5-2-部署kubelet"><a href="#5-2-部署kubelet" class="headerlink" title="5.2 部署kubelet"></a>5.2 部署kubelet</h3><h4 id="1-创建配置文件-3"><a href="#1-创建配置文件-3" class="headerlink" title="1. 创建配置文件"></a>1. 创建配置文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /opt/kubernetes/cfg/kubelet.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">KUBELET_OPTS=&quot;--logtostderr=false \\</span></span><br><span class="line"><span class="string">--v=2 \\</span></span><br><span class="line"><span class="string">--log-dir=/opt/kubernetes/logs \\</span></span><br><span class="line"><span class="string">--hostname-override=k8s-master1 \\</span></span><br><span class="line"><span class="string">--network-plugin=cni \\</span></span><br><span class="line"><span class="string">--kubeconfig=/opt/kubernetes/cfg/kubelet.kubeconfig \\</span></span><br><span class="line"><span class="string">--bootstrap-kubeconfig=/opt/kubernetes/cfg/bootstrap.kubeconfig \\</span></span><br><span class="line"><span class="string">--config=/opt/kubernetes/cfg/kubelet-config.yml \\</span></span><br><span class="line"><span class="string">--cert-dir=/opt/kubernetes/ssl \\</span></span><br><span class="line"><span class="string">--pod-infra-container-image=lizhenliang/pause-amd64:3.0&quot;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>•   –hostname-override：显示名称，集群中唯一</p>
<p>•   –network-plugin：启用CNI</p>
<p>•   –kubeconfig：空路径，会自动生成，后面用于连接apiserver</p>
<p>•   –bootstrap-kubeconfig：首次启动向apiserver申请证书</p>
<p>•   –config：配置参数文件</p>
<p>•   –cert-dir：kubelet证书生成目录</p>
<p>•   –pod-infra-container-image：管理Pod网络容器的镜像</p>
<h4 id="2-配置参数文件"><a href="#2-配置参数文件" class="headerlink" title="2. 配置参数文件"></a>2. 配置参数文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /opt/kubernetes/cfg/kubelet-config.yml &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">kind: KubeletConfiguration</span></span><br><span class="line"><span class="string">apiVersion: kubelet.config.k8s.io/v1beta1</span></span><br><span class="line"><span class="string">address: 0.0.0.0</span></span><br><span class="line"><span class="string">port: 10250</span></span><br><span class="line"><span class="string">readOnlyPort: 10255</span></span><br><span class="line"><span class="string">cgroupDriver: cgroupfs</span></span><br><span class="line"><span class="string">clusterDNS:</span></span><br><span class="line"><span class="string">- 10.0.0.2</span></span><br><span class="line"><span class="string">clusterDomain: cluster.local </span></span><br><span class="line"><span class="string">failSwapOn: false</span></span><br><span class="line"><span class="string">authentication:</span></span><br><span class="line"><span class="string">  anonymous:</span></span><br><span class="line"><span class="string">    enabled: false</span></span><br><span class="line"><span class="string">  webhook:</span></span><br><span class="line"><span class="string">    cacheTTL: 2m0s</span></span><br><span class="line"><span class="string">    enabled: true</span></span><br><span class="line"><span class="string">  x509:</span></span><br><span class="line"><span class="string">    clientCAFile: /opt/kubernetes/ssl/ca.pem </span></span><br><span class="line"><span class="string">authorization:</span></span><br><span class="line"><span class="string">  mode: Webhook</span></span><br><span class="line"><span class="string">  webhook:</span></span><br><span class="line"><span class="string">    cacheAuthorizedTTL: 5m0s</span></span><br><span class="line"><span class="string">    cacheUnauthorizedTTL: 30s</span></span><br><span class="line"><span class="string">evictionHard:</span></span><br><span class="line"><span class="string">  imagefs.available: 15%</span></span><br><span class="line"><span class="string">  memory.available: 100Mi</span></span><br><span class="line"><span class="string">  nodefs.available: 10%</span></span><br><span class="line"><span class="string">  nodefs.inodesFree: 5%</span></span><br><span class="line"><span class="string">maxOpenFiles: 1000000</span></span><br><span class="line"><span class="string">maxPods: 110</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<h4 id="3-生成kubelet初次加入集群引导kubeconfig文件"><a href="#3-生成kubelet初次加入集群引导kubeconfig文件" class="headerlink" title="3. 生成kubelet初次加入集群引导kubeconfig文件"></a>3. 生成kubelet初次加入集群引导kubeconfig文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">KUBE_CONFIG=<span class="string">&quot;/opt/kubernetes/cfg/bootstrap.kubeconfig&quot;</span></span><br><span class="line">KUBE_APISERVER=<span class="string">&quot;https://192.168.31.71:6443&quot;</span> <span class="comment"># apiserver IP:PORT</span></span><br><span class="line">TOKEN=<span class="string">&quot;c47ffb939f5ca36231d9e3121a252940&quot;</span> <span class="comment"># 与token.csv里保持一致</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成 kubelet bootstrap kubeconfig 配置文件</span></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=/opt/kubernetes/ssl/ca.pem \</span><br><span class="line">  --embed-certs=<span class="literal">true</span> \</span><br><span class="line">  --server=<span class="variable">$&#123;KUBE_APISERVER&#125;</span> \</span><br><span class="line">  --kubeconfig=<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line">kubectl config set-credentials <span class="string">&quot;kubelet-bootstrap&quot;</span> \</span><br><span class="line">  --token=<span class="variable">$&#123;TOKEN&#125;</span> \</span><br><span class="line">  --kubeconfig=<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=<span class="string">&quot;kubelet-bootstrap&quot;</span> \</span><br><span class="line">  --kubeconfig=<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line">kubectl config use-context default --kubeconfig=<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br></pre></td></tr></table></figure>

<h4 id="4-systemd管理kubelet"><a href="#4-systemd管理kubelet" class="headerlink" title="4. systemd管理kubelet"></a>4. systemd管理kubelet</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kubelet.service &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[Unit]</span></span><br><span class="line"><span class="string">Description=Kubernetes Kubelet</span></span><br><span class="line"><span class="string">After=docker.service</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">EnvironmentFile=/opt/kubernetes/cfg/kubelet.conf</span></span><br><span class="line"><span class="string">ExecStart=/opt/kubernetes/bin/kubelet \$KUBELET_OPTS</span></span><br><span class="line"><span class="string">Restart=on-failure</span></span><br><span class="line"><span class="string">LimitNOFILE=65536</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Install]</span></span><br><span class="line"><span class="string">WantedBy=multi-user.target</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<h4 id="5-启动设置开机启动"><a href="#5-启动设置开机启动" class="headerlink" title="5. 启动设置开机启动"></a>5. 启动设置开机启动</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kubelet</span><br><span class="line">systemctl <span class="built_in">enable</span> kubelet</span><br></pre></td></tr></table></figure>

<h3 id="5-3-批准kubelet证书申请并加入集群"><a href="#5-3-批准kubelet证书申请并加入集群" class="headerlink" title="5.3 批准kubelet证书申请并加入集群"></a>5.3 批准kubelet证书申请并加入集群</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看kubelet证书请求</span></span><br><span class="line">kubectl get csr</span><br><span class="line">NAME                                                   AGE    SIGNERNAME                                    REQUESTOR           CONDITION</span><br><span class="line">node-csr-uCEGPOIiDdlLODKts8J658HrFq9CZ--K6M4G7bjhk8A   6m3s   kubernetes.io/kube-apiserver-client-kubelet   kubelet-bootstrap   Pending</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批准申请</span></span><br><span class="line">kubectl certificate approve node-csr-uCEGPOIiDdlLODKts8J658HrFq9CZ--K6M4G7bjhk8A</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看节点</span></span><br><span class="line">kubectl get node</span><br><span class="line">NAME         STATUS     ROLES    AGE   VERSION</span><br><span class="line">k8s-master1   NotReady   &lt;none&gt;   7s    v1.18.3</span><br></pre></td></tr></table></figure>

<p>注：由于网络插件还没有部署，节点会没有准备就绪 NotReady</p>
<h3 id="5-4-部署kube-proxy"><a href="#5-4-部署kube-proxy" class="headerlink" title="5.4 部署kube-proxy"></a>5.4 部署kube-proxy</h3><h4 id="1-创建配置文件-4"><a href="#1-创建配置文件-4" class="headerlink" title="1. 创建配置文件"></a>1. 创建配置文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /opt/kubernetes/cfg/kube-proxy.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">KUBE_PROXY_OPTS=&quot;--logtostderr=false \\</span></span><br><span class="line"><span class="string">--v=2 \\</span></span><br><span class="line"><span class="string">--log-dir=/opt/kubernetes/logs \\</span></span><br><span class="line"><span class="string">--config=/opt/kubernetes/cfg/kube-proxy-config.yml&quot;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<h4 id="2-配置参数文件-1"><a href="#2-配置参数文件-1" class="headerlink" title="2. 配置参数文件"></a>2. 配置参数文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /opt/kubernetes/cfg/kube-proxy-config.yml &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">kind: KubeProxyConfiguration</span></span><br><span class="line"><span class="string">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span></span><br><span class="line"><span class="string">bindAddress: 0.0.0.0</span></span><br><span class="line"><span class="string">metricsBindAddress: 0.0.0.0:10249</span></span><br><span class="line"><span class="string">clientConnection:</span></span><br><span class="line"><span class="string">  kubeconfig: /opt/kubernetes/cfg/kube-proxy.kubeconfig</span></span><br><span class="line"><span class="string">hostnameOverride: k8s-master1</span></span><br><span class="line"><span class="string">clusterCIDR: 10.244.0.0/16</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<h4 id="3-生成kube-proxy-kubeconfig文件"><a href="#3-生成kube-proxy-kubeconfig文件" class="headerlink" title="3. 生成kube-proxy.kubeconfig文件"></a>3. 生成kube-proxy.kubeconfig文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 切换工作目录</span></span><br><span class="line"><span class="built_in">cd</span> ~/TLS/k8s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建证书请求文件</span></span><br><span class="line"><span class="built_in">cat</span> &gt; kube-proxy-csr.json &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">  &quot;CN&quot;: &quot;system:kube-proxy&quot;,</span></span><br><span class="line"><span class="string">  &quot;hosts&quot;: [],</span></span><br><span class="line"><span class="string">  &quot;key&quot;: &#123;</span></span><br><span class="line"><span class="string">    &quot;algo&quot;: &quot;rsa&quot;,</span></span><br><span class="line"><span class="string">    &quot;size&quot;: 2048</span></span><br><span class="line"><span class="string">  &#125;,</span></span><br><span class="line"><span class="string">  &quot;names&quot;: [</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">      &quot;C&quot;: &quot;CN&quot;,</span></span><br><span class="line"><span class="string">      &quot;L&quot;: &quot;BeiJing&quot;,</span></span><br><span class="line"><span class="string">      &quot;ST&quot;: &quot;BeiJing&quot;,</span></span><br><span class="line"><span class="string">      &quot;O&quot;: &quot;k8s&quot;,</span></span><br><span class="line"><span class="string">      &quot;OU&quot;: &quot;System&quot;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">  ]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成证书</span></span><br><span class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy</span><br><span class="line">生成kubeconfig文件：</span><br><span class="line">KUBE_CONFIG=<span class="string">&quot;/opt/kubernetes/cfg/kube-proxy.kubeconfig&quot;</span></span><br><span class="line">KUBE_APISERVER=<span class="string">&quot;https://192.168.31.71:6443&quot;</span></span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=/opt/kubernetes/ssl/ca.pem \</span><br><span class="line">  --embed-certs=<span class="literal">true</span> \</span><br><span class="line">  --server=<span class="variable">$&#123;KUBE_APISERVER&#125;</span> \</span><br><span class="line">  --kubeconfig=<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line">kubectl config set-credentials kube-proxy \</span><br><span class="line">  --client-certificate=./kube-proxy.pem \</span><br><span class="line">  --client-key=./kube-proxy-key.pem \</span><br><span class="line">  --embed-certs=<span class="literal">true</span> \</span><br><span class="line">  --kubeconfig=<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=kube-proxy \</span><br><span class="line">  --kubeconfig=<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br><span class="line">kubectl config use-context default --kubeconfig=<span class="variable">$&#123;KUBE_CONFIG&#125;</span></span><br></pre></td></tr></table></figure>

<h4 id="4-systemd管理kube-proxy"><a href="#4-systemd管理kube-proxy" class="headerlink" title="4. systemd管理kube-proxy"></a>4. systemd管理kube-proxy</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kube-proxy.service &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[Unit]</span></span><br><span class="line"><span class="string">Description=Kubernetes Proxy</span></span><br><span class="line"><span class="string">After=network.target</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">EnvironmentFile=/opt/kubernetes/cfg/kube-proxy.conf</span></span><br><span class="line"><span class="string">ExecStart=/opt/kubernetes/bin/kube-proxy \$KUBE_PROXY_OPTS</span></span><br><span class="line"><span class="string">Restart=on-failure</span></span><br><span class="line"><span class="string">LimitNOFILE=65536</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Install]</span></span><br><span class="line"><span class="string">WantedBy=multi-user.target</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<h4 id="5-启动并设置开机启动-2"><a href="#5-启动并设置开机启动-2" class="headerlink" title="5. 启动并设置开机启动"></a>5. 启动并设置开机启动</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kube-proxy</span><br><span class="line">systemctl <span class="built_in">enable</span> kube-proxy</span><br></pre></td></tr></table></figure>

<h3 id="5-5-部署网络组件"><a href="#5-5-部署网络组件" class="headerlink" title="5.5 部署网络组件"></a>5.5 部署网络组件</h3><p>Calico是一个纯三层的数据中心网络方案，是目前Kubernetes主流的网络方案。</p>
<p>部署Calico：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f calico.yaml</span><br><span class="line">kubectl get pods -n kube-system</span><br></pre></td></tr></table></figure>

<p>等Calico Pod都Running，节点也会准备就绪：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get node</span><br><span class="line">NAME         STATUS   ROLES    AGE   VERSION</span><br><span class="line">k8s-master   Ready    &lt;none&gt;   37m   v1.22.4</span><br></pre></td></tr></table></figure>

<h3 id="5-6-授权apiserver访问kubelet"><a href="#5-6-授权apiserver访问kubelet" class="headerlink" title="5.6 授权apiserver访问kubelet"></a>5.6 授权apiserver访问kubelet</h3><p>应用场景：例如kubectl logs</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; apiserver-to-kubelet-rbac.yaml &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">apiVersion: rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="string">kind: ClusterRole</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  annotations:</span></span><br><span class="line"><span class="string">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span></span><br><span class="line"><span class="string">  labels:</span></span><br><span class="line"><span class="string">    kubernetes.io/bootstrapping: rbac-defaults</span></span><br><span class="line"><span class="string">  name: system:kube-apiserver-to-kubelet</span></span><br><span class="line"><span class="string">rules:</span></span><br><span class="line"><span class="string">  - apiGroups:</span></span><br><span class="line"><span class="string">      - &quot;&quot;</span></span><br><span class="line"><span class="string">    resources:</span></span><br><span class="line"><span class="string">      - nodes/proxy</span></span><br><span class="line"><span class="string">      - nodes/stats</span></span><br><span class="line"><span class="string">      - nodes/log</span></span><br><span class="line"><span class="string">      - nodes/spec</span></span><br><span class="line"><span class="string">      - nodes/metrics</span></span><br><span class="line"><span class="string">      - pods/log</span></span><br><span class="line"><span class="string">    verbs:</span></span><br><span class="line"><span class="string">      - &quot;*&quot;</span></span><br><span class="line"><span class="string">---</span></span><br><span class="line"><span class="string">apiVersion: rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="string">kind: ClusterRoleBinding</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: system:kube-apiserver</span></span><br><span class="line"><span class="string">  namespace: &quot;&quot;</span></span><br><span class="line"><span class="string">roleRef:</span></span><br><span class="line"><span class="string">  apiGroup: rbac.authorization.k8s.io</span></span><br><span class="line"><span class="string">  kind: ClusterRole</span></span><br><span class="line"><span class="string">  name: system:kube-apiserver-to-kubelet</span></span><br><span class="line"><span class="string">subjects:</span></span><br><span class="line"><span class="string">  - apiGroup: rbac.authorization.k8s.io</span></span><br><span class="line"><span class="string">    kind: User</span></span><br><span class="line"><span class="string">    name: kubernetes</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">kubectl apply -f apiserver-to-kubelet-rbac.yaml</span><br></pre></td></tr></table></figure>

<h3 id="5-7-新增加Worker-Node"><a href="#5-7-新增加Worker-Node" class="headerlink" title="5.7 新增加Worker Node"></a>5.7 新增加Worker Node</h3><h4 id="1-拷贝已部署好的Node相关文件到新节点"><a href="#1-拷贝已部署好的Node相关文件到新节点" class="headerlink" title="1. 拷贝已部署好的Node相关文件到新节点"></a>1. 拷贝已部署好的Node相关文件到新节点</h4><p>在Master节点将Worker Node涉及文件拷贝到新节点192.168.31.72&#x2F;73</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">scp -r /opt/kubernetes root@192.168.31.72:/opt/</span><br><span class="line"></span><br><span class="line">scp -r /usr/lib/systemd/system/&#123;kubelet,kube-proxy&#125;.service root@192.168.31.72:/usr/lib/systemd/system</span><br><span class="line"></span><br><span class="line">scp /opt/kubernetes/ssl/ca.pem root@192.168.31.72:/opt/kubernetes/ssl</span><br></pre></td></tr></table></figure>

<h4 id="2-删除kubelet证书和kubeconfig文件"><a href="#2-删除kubelet证书和kubeconfig文件" class="headerlink" title="2. 删除kubelet证书和kubeconfig文件"></a>2. 删除kubelet证书和kubeconfig文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">rm</span> -f /opt/kubernetes/cfg/kubelet.kubeconfig </span><br><span class="line"><span class="built_in">rm</span> -f /opt/kubernetes/ssl/kubelet*</span><br></pre></td></tr></table></figure>

<p>注：这几个文件是证书申请审批后自动生成的，每个Node不同，必须删除</p>
<h4 id="3-修改主机名"><a href="#3-修改主机名" class="headerlink" title="3. 修改主机名"></a>3. 修改主机名</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /opt/kubernetes/cfg/kubelet.conf</span><br><span class="line">--hostname-override=k8s-node1</span><br><span class="line"></span><br><span class="line">vi /opt/kubernetes/cfg/kube-proxy-config.yml</span><br><span class="line">hostnameOverride: k8s-node1</span><br></pre></td></tr></table></figure>

<h4 id="4-启动并设置开机启动-1"><a href="#4-启动并设置开机启动-1" class="headerlink" title="4. 启动并设置开机启动"></a>4. 启动并设置开机启动</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kubelet kube-proxy</span><br><span class="line">systemctl <span class="built_in">enable</span> kubelet kube-proxy</span><br></pre></td></tr></table></figure>

<h4 id="5-在Master上批准新Node-kubelet证书申请"><a href="#5-在Master上批准新Node-kubelet证书申请" class="headerlink" title="5. 在Master上批准新Node kubelet证书申请"></a>5. 在Master上批准新Node kubelet证书申请</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看证书请求</span></span><br><span class="line">kubectl get csr</span><br><span class="line">NAME           AGE   SIGNERNAME                    REQUESTOR           CONDITION</span><br><span class="line">node-csr-4zTjsaVSrhuyhIGqsefxzVoZDCNKei-aE2jyTP81Uro   89s   kubernetes.io/kube-apiserver-client-kubelet   kubelet-bootstrap   Pending</span><br><span class="line"></span><br><span class="line"><span class="comment"># 授权请求</span></span><br><span class="line">kubectl certificate approve node-csr-4zTjsaVSrhuyhIGqsefxzVoZDCNKei-aE2jyTP81Uro</span><br></pre></td></tr></table></figure>

<h4 id="6-查看Node状态"><a href="#6-查看Node状态" class="headerlink" title="6. 查看Node状态"></a>6. 查看Node状态</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get node</span><br><span class="line">NAME       STATUS   ROLES    AGE     VERSION</span><br><span class="line">k8s-master1   Ready    &lt;none&gt;   47m     v1.22.4</span><br><span class="line">k8s-node1    Ready    &lt;none&gt;   6m49s   v1.22.4</span><br></pre></td></tr></table></figure>

<p>Node2（192.168.31.73 ）节点同上。记得修改主机名！</p>
<h2 id="六、部署Dashboard和CoreDNS"><a href="#六、部署Dashboard和CoreDNS" class="headerlink" title="六、部署Dashboard和CoreDNS"></a>六、部署Dashboard和CoreDNS</h2><h3 id="6-1-部署Dashboard"><a href="#6-1-部署Dashboard" class="headerlink" title="6.1 部署Dashboard"></a>6.1 部署Dashboard</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f kubernetes-dashboard.yaml</span><br><span class="line"><span class="comment"># 查看部署</span></span><br><span class="line">kubectl get pods,svc -n kubernetes-dashboard</span><br></pre></td></tr></table></figure>

<p>访问地址：<a href="https://nodeip:30001/">https://NodeIP:30001</a></p>
<p>创建service account并绑定默认cluster-admin管理员集群角色：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create serviceaccount dashboard-admin -n kube-system</span><br><span class="line">kubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin</span><br><span class="line">kubectl describe secrets -n kube-system $(kubectl -n kube-system get secret | awk <span class="string">&#x27;/dashboard-admin/&#123;print $1&#125;&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>使用输出的token登录Dashboard。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202209051508149.png" alt="image-20220905150833928"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202209051508947.png" alt="image-20220905150845743"></p>
<h3 id="6-2-部署CoreDNS"><a href="#6-2-部署CoreDNS" class="headerlink" title="6.2 部署CoreDNS"></a>6.2 部署CoreDNS</h3><p>CoreDNS用于集群内部Service名称解析。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f coredns.yaml </span><br><span class="line"> </span><br><span class="line">kubectl get pods -n kube-system  </span><br><span class="line">NAME                          READY   STATUS    RESTARTS   AGE </span><br><span class="line">coredns-5ffbfd976d-j6shb      1/1     Running   0          32s</span><br></pre></td></tr></table></figure>

<p>DNS解析测试：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl run -it --<span class="built_in">rm</span> dns-test --image=busybox:1.28.4 sh </span><br><span class="line">If you don<span class="string">&#x27;t see a command prompt, try pressing enter. </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">/ # nslookup kubernetes </span></span><br><span class="line"><span class="string">Server:    10.0.0.2 </span></span><br><span class="line"><span class="string">Address 1: 10.0.0.2 kube-dns.kube-system.svc.cluster.local </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">Name:      kubernetes </span></span><br><span class="line"><span class="string">Address 1: 10.0.0.1 kubernetes.default.svc.cluster.local</span></span><br></pre></td></tr></table></figure>

<p>解析没问题。</p>
<p>至此一个单Master集群就搭建完成了！这个环境就足以满足学习实验了，如果你的服务器配置较高，可继续扩容多Master集群！</p>
<h2 id="七、扩容多Master（高可用架构）"><a href="#七、扩容多Master（高可用架构）" class="headerlink" title="七、扩容多Master（高可用架构）"></a>七、扩容多Master（高可用架构）</h2><p>Kubernetes作为容器集群系统，通过健康检查+重启策略实现了Pod故障自我修复能力，通过调度算法实现将Pod分布式部署，并保持预期副本数，根据Node失效状态自动在其他Node拉起Pod，实现了应用层的高可用性。</p>
<p>针对Kubernetes集群，高可用性还应包含以下两个层面的考虑：Etcd数据库的高可用性和Kubernetes Master组件的高可用性。 而Etcd我们已经采用3个节点组建集群实现高可用，本节将对Master节点高可用进行说明和实施。</p>
<p>Master节点扮演着总控中心的角色，通过不断与工作节点上的Kubelet和kube-proxy进行通信来维护整个集群的健康工作状态。如果Master节点故障，将无法使用kubectl工具或者API做任何集群管理。</p>
<p>Master节点主要有三个服务kube-apiserver、kube-controller-manager和kube-scheduler，其中kube-controller-manager和kube-scheduler组件自身通过选择机制已经实现了高可用，所以Master高可用主要针对kube-apiserver组件，而该组件是以HTTP API提供服务，因此对他高可用与Web服务器类似，增加负载均衡器对其负载均衡即可，并且可水平扩容。</p>
<p>多Master架构图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202209051509415.png" alt="image-20220905150900095"></p>
<h3 id="7-1-部署Master2-Node"><a href="#7-1-部署Master2-Node" class="headerlink" title="7.1 部署Master2 Node"></a>7.1 部署Master2 Node</h3><p>现在需要再增加一台新服务器，作为Master2 Node，IP是192.168.31.74。</p>
<p>为了节省资源你也可以将之前部署好的Worker Node1复用为Master2 Node角色（即部署Master组件）</p>
<p>Master2 与已部署的Master1所有操作一致。所以我们只需将Master1所有K8s文件拷贝过来，再修改下服务器IP和主机名启动即可。</p>
<h4 id="1-安装Docker"><a href="#1-安装Docker" class="headerlink" title="1. 安装Docker"></a>1. 安装Docker</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">scp /usr/bin/docker* root@192.168.31.74:/usr/bin</span><br><span class="line">scp /usr/bin/runc root@192.168.31.74:/usr/bin</span><br><span class="line">scp /usr/bin/containerd* root@192.168.31.74:/usr/bin</span><br><span class="line">scp /usr/lib/systemd/system/docker.service root@192.168.31.74:/usr/lib/systemd/system</span><br><span class="line">scp -r /etc/docker root@192.168.31.74:/etc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在Master2启动Docker</span></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start docker</span><br><span class="line">systemctl <span class="built_in">enable</span> docker</span><br></pre></td></tr></table></figure>

<h4 id="2-创建etcd证书目录"><a href="#2-创建etcd证书目录" class="headerlink" title="2. 创建etcd证书目录"></a>2. 创建etcd证书目录</h4><p>在Master2创建etcd证书目录：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /opt/etcd/ssl</span><br></pre></td></tr></table></figure>

<h4 id="3-拷贝文件（Master1操作）"><a href="#3-拷贝文件（Master1操作）" class="headerlink" title="3. 拷贝文件（Master1操作）"></a>3. 拷贝文件（Master1操作）</h4><p>拷贝Master1上所有K8s文件和etcd证书到Master2：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">scp -r /opt/kubernetes root@192.168.31.74:/opt</span><br><span class="line">scp -r /opt/etcd/ssl root@192.168.31.74:/opt/etcd</span><br><span class="line">scp /usr/lib/systemd/system/kube* root@192.168.31.74:/usr/lib/systemd/system</span><br><span class="line">scp /usr/bin/kubectl  root@192.168.31.74:/usr/bin</span><br><span class="line">scp -r ~/.kube root@192.168.31.74:~</span><br></pre></td></tr></table></figure>

<h4 id="4-删除证书文件"><a href="#4-删除证书文件" class="headerlink" title="4. 删除证书文件"></a>4. 删除证书文件</h4><p>删除kubelet证书和kubeconfig文件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">rm</span> -f /opt/kubernetes/cfg/kubelet.kubeconfig </span><br><span class="line"><span class="built_in">rm</span> -f /opt/kubernetes/ssl/kubelet*</span><br></pre></td></tr></table></figure>

<h4 id="5-修改配置文件IP和主机名"><a href="#5-修改配置文件IP和主机名" class="headerlink" title="5. 修改配置文件IP和主机名"></a>5. 修改配置文件IP和主机名</h4><p>修改apiserver、kubelet和kube-proxy配置文件为本地IP：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /opt/kubernetes/cfg/kube-apiserver.conf </span><br><span class="line">...</span><br><span class="line">--bind-address=192.168.31.74 \</span><br><span class="line">--advertise-address=192.168.31.74 \</span><br><span class="line">...</span><br><span class="line">vi /opt/kubernetes/cfg/kube-controller-manager.kubeconfig</span><br><span class="line">server: https://192.168.31.74:6443</span><br><span class="line"> </span><br><span class="line">vi /opt/kubernetes/cfg/kube-scheduler.kubeconfig</span><br><span class="line">server: https://192.168.31.74:6443</span><br><span class="line">vi /opt/kubernetes/cfg/kubelet.conf</span><br><span class="line">--hostname-override=k8s-master2</span><br><span class="line"></span><br><span class="line">vi /opt/kubernetes/cfg/kube-proxy-config.yml</span><br><span class="line">hostnameOverride: k8s-master2</span><br><span class="line"> </span><br><span class="line">vi ~/.kube/config</span><br><span class="line">...</span><br><span class="line">server: https://192.168.31.74:6443</span><br></pre></td></tr></table></figure>

<h4 id="6-启动设置开机启动"><a href="#6-启动设置开机启动" class="headerlink" title="6. 启动设置开机启动"></a>6. 启动设置开机启动</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxy</span><br><span class="line">systemctl <span class="built_in">enable</span> kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxy</span><br></pre></td></tr></table></figure>

<h4 id="7-查看集群状态-1"><a href="#7-查看集群状态-1" class="headerlink" title="7. 查看集群状态"></a>7. 查看集群状态</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get cs</span><br><span class="line">NAME                STATUS    MESSAGE             ERROR</span><br><span class="line">scheduler             Healthy   ok                  </span><br><span class="line">controller-manager       Healthy   ok                  </span><br><span class="line">etcd-1               Healthy   &#123;<span class="string">&quot;health&quot;</span>:<span class="string">&quot;true&quot;</span>&#125;   </span><br><span class="line">etcd-2               Healthy   &#123;<span class="string">&quot;health&quot;</span>:<span class="string">&quot;true&quot;</span>&#125;   </span><br><span class="line">etcd-0               Healthy   &#123;<span class="string">&quot;health&quot;</span>:<span class="string">&quot;true&quot;</span>&#125;</span><br></pre></td></tr></table></figure>

<h4 id="8-批准kubelet证书申请"><a href="#8-批准kubelet证书申请" class="headerlink" title="8. 批准kubelet证书申请"></a>8. 批准kubelet证书申请</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看证书请求</span></span><br><span class="line">kubectl get csr</span><br><span class="line">NAME                      AGE          SIGNERNAME          REQUESTOR           CONDITION</span><br><span class="line">node-csr-JYNknakEa_YpHz797oKaN-ZTk43nD51Zc9CJkBLcASU   85m   kubernetes.io/kube-apiserver-client-kubelet   kubelet-bootstrap   Pending</span><br><span class="line"><span class="comment"># 授权请求</span></span><br><span class="line">kubectl certificate approve node-csr-JYNknakEa_YpHz797oKaN-ZTk43nD51Zc9CJkBLcASU</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Node</span></span><br><span class="line">kubectl get node</span><br><span class="line">NAME        STATUS   ROLES    AGE   VERSION</span><br><span class="line">k8s-master1    Ready    &lt;none&gt;   34h   v1.22.4</span><br><span class="line">k8s-master2    Ready    &lt;none&gt;   2m   v1.22.4</span><br><span class="line">k8s-node1     Ready    &lt;none&gt;   33h   v1.22.4</span><br><span class="line">k8s-node2     Ready    &lt;none&gt;   33h   v1.22.4</span><br></pre></td></tr></table></figure>

<p>如果你在学习中遇到问题或者文档有误可联系阿良~ 微信: k8init</p>
<h3 id="7-2-部署Nginx-Keepalived高可用负载均衡器"><a href="#7-2-部署Nginx-Keepalived高可用负载均衡器" class="headerlink" title="7.2 部署Nginx+Keepalived高可用负载均衡器"></a>7.2 部署Nginx+Keepalived高可用负载均衡器</h3><p>kube-apiserver高可用架构图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202209051509281.png" alt="image-20220905150918121"></p>
<p>•   Nginx是一个主流Web服务和反向代理服务器，这里用四层实现对apiserver实现负载均衡。</p>
<p>•   Keepalived是一个主流高可用软件，基于VIP绑定实现服务器双机热备，在上述拓扑中，Keepalived主要根据Nginx运行状态判断是否需要故障转移（漂移VIP），例如当Nginx主节点挂掉，VIP会自动绑定在Nginx备节点，从而保证VIP一直可用，实现Nginx高可用。</p>
<p>注1：为了节省机器，这里与K8s Master节点机器复用。也可以独立于k8s集群之外部署，只要nginx与apiserver能通信就行。</p>
<p>注2：如果你是在公有云上，一般都不支持keepalived，那么你可以直接用它们的负载均衡器产品，直接负载均衡多台Master kube-apiserver，架构与上面一样。</p>
<p>在两台Master节点操作。</p>
<h4 id="1-安装软件包（主-x2F-备）"><a href="#1-安装软件包（主-x2F-备）" class="headerlink" title="1. 安装软件包（主&#x2F;备）"></a>1. 安装软件包（主&#x2F;备）</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install epel-release -y</span><br><span class="line">yum install nginx keepalived -y</span><br></pre></td></tr></table></figure>

<h4 id="2-Nginx配置文件（主-x2F-备一样）"><a href="#2-Nginx配置文件（主-x2F-备一样）" class="headerlink" title="2. Nginx配置文件（主&#x2F;备一样）"></a>2. Nginx配置文件（主&#x2F;备一样）</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/nginx/nginx.conf &lt;&lt; <span class="string">&quot;EOF&quot;</span></span><br><span class="line">user nginx;</span><br><span class="line">worker_processes auto;</span><br><span class="line">error_log /var/log/nginx/error.log;</span><br><span class="line">pid /run/nginx.pid;</span><br><span class="line"></span><br><span class="line">include /usr/share/nginx/modules/*.conf;</span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections 1024;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 四层负载均衡，为两台Master apiserver组件提供负载均衡</span></span><br><span class="line">stream &#123;</span><br><span class="line"></span><br><span class="line">    log_format  main  <span class="string">&#x27;$remote_addr $upstream_addr - [$time_local] $status $upstream_bytes_sent&#x27;</span>;</span><br><span class="line"></span><br><span class="line">    access_log  /var/log/nginx/k8s-access.log  main;</span><br><span class="line"></span><br><span class="line">    upstream k8s-apiserver &#123;</span><br><span class="line">       server 192.168.31.71:6443;   <span class="comment"># Master1 APISERVER IP:PORT</span></span><br><span class="line">       server 192.168.31.74:6443;   <span class="comment"># Master2 APISERVER IP:PORT</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    server &#123;</span><br><span class="line">       listen 16443; <span class="comment"># 由于nginx与master节点复用，这个监听端口不能是6443，否则会冲突</span></span><br><span class="line">       proxy_pass k8s-apiserver;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    log_format  main  <span class="string">&#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;</span>;</span><br><span class="line"></span><br><span class="line">    access_log  /var/log/nginx/access.log  main;</span><br><span class="line"></span><br><span class="line">    sendfile            on;</span><br><span class="line">    tcp_nopush          on;</span><br><span class="line">    tcp_nodelay         on;</span><br><span class="line">    keepalive_timeout   65;</span><br><span class="line">    types_hash_max_size 2048;</span><br><span class="line"></span><br><span class="line">    include             /etc/nginx/mime.types;</span><br><span class="line">    default_type        application/octet-stream;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        listen       80 default_server;</span><br><span class="line">        server_name  _;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h4 id="3-keepalived配置文件（Nginx-Master）"><a href="#3-keepalived配置文件（Nginx-Master）" class="headerlink" title="3. keepalived配置文件（Nginx Master）"></a>3. keepalived配置文件（Nginx Master）</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/keepalived/keepalived.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">global_defs &#123; </span></span><br><span class="line"><span class="string">   notification_email &#123; </span></span><br><span class="line"><span class="string">     acassen@firewall.loc </span></span><br><span class="line"><span class="string">     failover@firewall.loc </span></span><br><span class="line"><span class="string">     sysadmin@firewall.loc </span></span><br><span class="line"><span class="string">   &#125; </span></span><br><span class="line"><span class="string">   notification_email_from Alexandre.Cassen@firewall.loc  </span></span><br><span class="line"><span class="string">   smtp_server 127.0.0.1 </span></span><br><span class="line"><span class="string">   smtp_connect_timeout 30 </span></span><br><span class="line"><span class="string">   router_id NGINX_MASTER</span></span><br><span class="line"><span class="string">&#125; </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">vrrp_script check_nginx &#123;</span></span><br><span class="line"><span class="string">    script &quot;/etc/keepalived/check_nginx.sh&quot;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">vrrp_instance VI_1 &#123; </span></span><br><span class="line"><span class="string">    state MASTER </span></span><br><span class="line"><span class="string">    interface ens33  # 修改为实际网卡名</span></span><br><span class="line"><span class="string">    virtual_router_id 51 # VRRP 路由 ID实例，每个实例是唯一的 </span></span><br><span class="line"><span class="string">    priority 100    # 优先级，备服务器设置 90 </span></span><br><span class="line"><span class="string">    advert_int 1    # 指定VRRP 心跳包通告间隔时间，默认1秒 </span></span><br><span class="line"><span class="string">    authentication &#123; </span></span><br><span class="line"><span class="string">        auth_type PASS      </span></span><br><span class="line"><span class="string">        auth_pass 1111 </span></span><br><span class="line"><span class="string">    &#125;  </span></span><br><span class="line"><span class="string">    # 虚拟IP</span></span><br><span class="line"><span class="string">    virtual_ipaddress &#123; </span></span><br><span class="line"><span class="string">        192.168.31.88/24</span></span><br><span class="line"><span class="string">    &#125; </span></span><br><span class="line"><span class="string">    track_script &#123;</span></span><br><span class="line"><span class="string">        check_nginx</span></span><br><span class="line"><span class="string">    &#125; </span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>•   vrrp_script：指定检查nginx工作状态脚本（根据nginx状态判断是否故障转移）</p>
<p>•   virtual_ipaddress：虚拟IP（VIP）</p>
<p>准备上述配置文件中检查nginx运行状态的脚本：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/keepalived/check_nginx.sh  &lt;&lt; <span class="string">&quot;EOF&quot;</span></span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line">count=$(ss -antp |grep 16443 |egrep -cv <span class="string">&quot;grep|$$&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$count</span>&quot;</span> -eq 0 ];<span class="keyword">then</span></span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">EOF</span><br><span class="line"><span class="built_in">chmod</span> +x /etc/keepalived/check_nginx.sh</span><br></pre></td></tr></table></figure>

<h4 id="4-keepalived配置文件（Nginx-Backup）"><a href="#4-keepalived配置文件（Nginx-Backup）" class="headerlink" title="4. keepalived配置文件（Nginx Backup）"></a>4. keepalived配置文件（Nginx Backup）</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/keepalived/keepalived.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">global_defs &#123; </span></span><br><span class="line"><span class="string">   notification_email &#123; </span></span><br><span class="line"><span class="string">     acassen@firewall.loc </span></span><br><span class="line"><span class="string">     failover@firewall.loc </span></span><br><span class="line"><span class="string">     sysadmin@firewall.loc </span></span><br><span class="line"><span class="string">   &#125; </span></span><br><span class="line"><span class="string">   notification_email_from Alexandre.Cassen@firewall.loc  </span></span><br><span class="line"><span class="string">   smtp_server 127.0.0.1 </span></span><br><span class="line"><span class="string">   smtp_connect_timeout 30 </span></span><br><span class="line"><span class="string">   router_id NGINX_BACKUP</span></span><br><span class="line"><span class="string">&#125; </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">vrrp_script check_nginx &#123;</span></span><br><span class="line"><span class="string">    script &quot;/etc/keepalived/check_nginx.sh&quot;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">vrrp_instance VI_1 &#123; </span></span><br><span class="line"><span class="string">    state BACKUP </span></span><br><span class="line"><span class="string">    interface ens33</span></span><br><span class="line"><span class="string">    virtual_router_id 51 # VRRP 路由 ID实例，每个实例是唯一的 </span></span><br><span class="line"><span class="string">    priority 90</span></span><br><span class="line"><span class="string">    advert_int 1</span></span><br><span class="line"><span class="string">    authentication &#123; </span></span><br><span class="line"><span class="string">        auth_type PASS      </span></span><br><span class="line"><span class="string">        auth_pass 1111 </span></span><br><span class="line"><span class="string">    &#125;  </span></span><br><span class="line"><span class="string">    virtual_ipaddress &#123; </span></span><br><span class="line"><span class="string">        192.168.31.88/24</span></span><br><span class="line"><span class="string">    &#125; </span></span><br><span class="line"><span class="string">    track_script &#123;</span></span><br><span class="line"><span class="string">        check_nginx</span></span><br><span class="line"><span class="string">    &#125; </span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>准备上述配置文件中检查nginx运行状态的脚本：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/keepalived/check_nginx.sh  &lt;&lt; <span class="string">&quot;EOF&quot;</span></span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line">count=$(ss -antp |grep 16443 |egrep -cv <span class="string">&quot;grep|$$&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$count</span>&quot;</span> -eq 0 ];<span class="keyword">then</span></span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">EOF</span><br><span class="line"><span class="built_in">chmod</span> +x /etc/keepalived/check_nginx.sh</span><br></pre></td></tr></table></figure>

<p>注：keepalived根据脚本返回状态码（0为工作正常，非0不正常）判断是否故障转移。</p>
<h4 id="5-启动并设置开机启动-3"><a href="#5-启动并设置开机启动-3" class="headerlink" title="5. 启动并设置开机启动"></a>5. 启动并设置开机启动</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start nginx keepalived</span><br><span class="line">systemctl <span class="built_in">enable</span> nginx keepalived</span><br></pre></td></tr></table></figure>

<h4 id="6-查看keepalived工作状态"><a href="#6-查看keepalived工作状态" class="headerlink" title="6. 查看keepalived工作状态"></a>6. 查看keepalived工作状态</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip addr</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    <span class="built_in">link</span>/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    <span class="built_in">link</span>/ether 00:0c:29:04:f7:2c brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.31.80/24 brd 192.168.31.255 scope global noprefixroute ens33</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet 192.168.31.88/24 scope global secondary ens33</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::20c:29ff:fe04:f72c/64 scope <span class="built_in">link</span> </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure>

<p>可以看到，在ens33网卡绑定了192.168.31.88 虚拟IP，说明工作正常。</p>
<h4 id="7-Nginx-Keepalived高可用测试"><a href="#7-Nginx-Keepalived高可用测试" class="headerlink" title="7. Nginx+Keepalived高可用测试"></a>7. Nginx+Keepalived高可用测试</h4><p>关闭主节点Nginx，测试VIP是否漂移到备节点服务器。</p>
<p>在Nginx Master执行 pkill nginx;<br>在Nginx Backup，ip addr命令查看已成功绑定VIP。</p>
<h4 id="8-访问负载均衡器测试"><a href="#8-访问负载均衡器测试" class="headerlink" title="8. 访问负载均衡器测试"></a>8. 访问负载均衡器测试</h4><p>找K8s集群中任意一个节点，使用curl查看K8s版本测试，使用VIP访问：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -k https://192.168.31.88:16443/version</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;major&quot;</span>: <span class="string">&quot;1&quot;</span>,</span><br><span class="line">  <span class="string">&quot;minor&quot;</span>: <span class="string">&quot;20&quot;</span>,</span><br><span class="line">  <span class="string">&quot;gitVersion&quot;</span>: <span class="string">&quot;v1.22.4&quot;</span>,</span><br><span class="line">  <span class="string">&quot;gitCommit&quot;</span>: <span class="string">&quot;e87da0bd6e03ec3fea7933c4b5263d151aafd07c&quot;</span>,</span><br><span class="line">  <span class="string">&quot;gitTreeState&quot;</span>: <span class="string">&quot;clean&quot;</span>,</span><br><span class="line">  <span class="string">&quot;buildDate&quot;</span>: <span class="string">&quot;2021-02-18T16:03:00Z&quot;</span>,</span><br><span class="line">  <span class="string">&quot;goVersion&quot;</span>: <span class="string">&quot;go1.15.8&quot;</span>,</span><br><span class="line">  <span class="string">&quot;compiler&quot;</span>: <span class="string">&quot;gc&quot;</span>,</span><br><span class="line">  <span class="string">&quot;platform&quot;</span>: <span class="string">&quot;linux/amd64&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以正确获取到K8s版本信息，说明负载均衡器搭建正常。该请求数据流程：curl -&gt; vip(nginx) -&gt; apiserver</p>
<p>通过查看Nginx日志也可以看到转发apiserver IP：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">tail</span> /var/log/nginx/k8s-access.log -f</span><br><span class="line">192.168.31.71 192.168.31.71:6443 - [02/Apr/2021:19:17:57 +0800] 200 423</span><br><span class="line">192.168.31.71 192.168.31.72:6443 - [02/Apr/2021:19:18:50 +0800] 200 423</span><br></pre></td></tr></table></figure>

<p>到此还没结束，还有下面最关键的一步。</p>
<h3 id="7-3-修改所有Worker-Node连接LB-VIP"><a href="#7-3-修改所有Worker-Node连接LB-VIP" class="headerlink" title="7.3 修改所有Worker Node连接LB VIP"></a>7.3 修改所有Worker Node连接LB VIP</h3><p>试想下，虽然我们增加了Master2 Node和负载均衡器，但是我们是从单Master架构扩容的，也就是说目前所有的Worker Node组件连接都还是Master1 Node，如果不改为连接VIP走负载均衡器，那么Master还是单点故障。</p>
<p>因此接下来就是要改所有Worker Node（kubectl get node命令查看到的节点）组件配置文件，由原来192.168.31.71修改为192.168.31.88（VIP）。</p>
<p>在所有Worker Node执行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i <span class="string">&#x27;s#192.168.31.71:6443#192.168.31.88:16443#&#x27;</span> /opt/kubernetes/cfg/*</span><br><span class="line">systemctl restart kubelet kube-proxy</span><br></pre></td></tr></table></figure>

<p>检查节点状态：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get node </span><br><span class="line">NAME         STATUS   ROLES    AGE   VERSION </span><br><span class="line">k8s-master1   Ready    &lt;none&gt;   32d   v1.22.4 </span><br><span class="line">k8s-master2   Ready    &lt;none&gt;   10m   v1.22.4 </span><br><span class="line">k8s-node1    Ready    &lt;none&gt;   31d   v1.22.4 </span><br><span class="line">k8s-node2    Ready    &lt;none&gt;   31d   v1.22.4</span><br></pre></td></tr></table></figure>

<p>至此，一套完整的 Kubernetes 高可用集群就部署完成了！</p>
]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>优化Docker镜像的10个技巧</title>
    <url>/2023/02/14/%E4%BC%98%E5%8C%96Docker%E9%95%9C%E5%83%8F%E5%A4%A7%E5%B0%8F/</url>
    <content><![CDATA[<h2 id="什么是-docker？"><a href="#什么是-docker？" class="headerlink" title="什么是 docker？"></a>什么是 docker？</h2><p>Docker 是一种容器引擎，可以在容器内运行一段代码。Docker 镜像是在任何地方运行您的应用程序而无需担心应用程序依赖性的方式。</p>
<p>要构建镜像，docker 使用一个名为 Dockerfile 的文件。Dockerfile 是一个包含许多指令（RUN、COPY、EXPOSE 等）的文件。成功执行这些命令后，docker 将创建一个镜像供我们在任何地方使用。</p>
<h2 id="为什么要减小-docker-镜像大小？"><a href="#为什么要减小-docker-镜像大小？" class="headerlink" title="为什么要减小 docker 镜像大小？"></a>为什么要减小 docker 镜像大小？</h2><ol>
<li>安装不必要的软件包会增加攻击面，从而增加安全风险。</li>
<li>镜像传输需要更多时间。</li>
<li>部署大镜像需要更多时间。</li>
</ol>
<p>我们必须以某种方式创建我们的 Dockerfile，以便从该 Dockerfile 构建的镜像在大小方面得到优化。</p>
<p>在本文中，我们将讨论 10 种减少 docker 镜像大小的有效方法。</p>
<h2 id="1：最小化镜像层"><a href="#1：最小化镜像层" class="headerlink" title="1：最小化镜像层"></a>1：最小化镜像层</h2><p>我们可以减少 Dockerfile 中的层数。</p>
<p>dockerfile 中的每个 FROM、RUN、COPY 命令都会创建一个单独的层，并增加镜像的整体大小和构建时间。</p>
<p>要减小 docker 镜像大小，请在单个 RUN 或 COPY 指令中执行多个命令来最小化 Dockerfile 中的层数。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM ubuntu:latest</span><br><span class="line">RUN apt update  - y</span><br><span class="line">RUN apt install unzip - y</span><br><span class="line">RUN apt install curl - y</span><br><span class="line">RUN apt install python3 - y</span><br></pre></td></tr></table></figure>

<p>与其对每个命令使用单独的指令，不如将它们组合起来：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM ubuntu:latest</span><br><span class="line">RUN apt update  -y &amp;&amp; \</span><br><span class="line">apt install unzip -y &amp;&amp; \</span><br><span class="line">apt install curl -y &amp;&amp; \</span><br><span class="line">apt install python3 -y</span><br></pre></td></tr></table></figure>

<p>从下图中可以看出，通过减少层数，可以减少一些 MB 的大小。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302141442467.png" alt="图片"></p>
<h2 id="2：使用-Docker-Squash-减小镜像大小"><a href="#2：使用-Docker-Squash-减小镜像大小" class="headerlink" title="2：使用 Docker Squash 减小镜像大小"></a>2：使用 Docker Squash 减小镜像大小</h2><p>Docker 在构建镜像时创建了很多层。压缩有助于在逻辑层中组织镜像。我们可以控制镜像的结构，而不是让镜像具有多个不必要的层。</p>
<p>您可以使用以下命令安装 docker-squash。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install docker-squash</span><br></pre></td></tr></table></figure>

<p>您可以运行以下命令来减小镜像的大小。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker-squash image:old -t image:new</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302141442495.png" alt="图片"></p>
<h2 id="3：使用较小的基础镜像"><a href="#3：使用较小的基础镜像" class="headerlink" title="3：使用较小的基础镜像"></a>3：使用较小的基础镜像</h2><p>减小 docker 镜像大小最明显的方法是使用较小的基础镜像。</p>
<p>如果希望为 python 应用程序创建镜像，请考虑使用 python:3.9-slim 镜像而不是 python:3.9。</p>
<p>python:3.9 的大小约为 1.3 GB，而 python:3.9-slim 的大小仅为 1 GB 左右。</p>
<p>您可以使用 alpine 版本进一步减少镜像。alpine 镜像是专门为作为容器运行而设计的，而且体积非常小。python:3.9-alpine 镜像只有 49 MB。</p>
<h2 id="4：使用多阶段构建来减小大小"><a href="#4：使用多阶段构建来减小大小" class="headerlink" title="4：使用多阶段构建来减小大小"></a>4：使用多阶段构建来减小大小</h2><p>为了显着减小大小，我们可以使用 docker 多阶段构建的概念。这里我们使用不同的 images&#x2F;Dockerfile 来构建和打包应用代码。</p>
<p>它将 Dockerfile 分成多个阶段，并将所需的工件从一个阶段传递到另一个阶段，然后在最后一个阶段交付缩小镜像大小的最终镜像。它显着减小镜像尺寸。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Official docker build image, Using  node:14.17-alpine3.14 image for stage-1.</span></span><br><span class="line"><span class="comment"># Stage-1</span></span><br><span class="line">FROM node:14.17-alpine3.14 as build</span><br><span class="line"><span class="comment"># Copy Required files</span></span><br><span class="line">COPY public /home/app/public/</span><br><span class="line">COPY src /home/app/src/</span><br><span class="line"><span class="comment"># dockerfile install multiple packages</span></span><br><span class="line">RUN apk add g++ make python2</span><br><span class="line">RUN npm install --silent</span><br><span class="line"><span class="comment"># Create Build</span></span><br><span class="line">RUN npm run build</span><br><span class="line">RUN apk --purge del python2</span><br><span class="line"><span class="comment">#Run the build by copying the files form previous stage.</span></span><br><span class="line"><span class="comment"># Stage-2</span></span><br><span class="line">FROM nginx:stable-alpine</span><br><span class="line">COPY nginx.conf /etc/nginx/conf.d/default.conf</span><br><span class="line">COPY --from=build /home/app/build /usr/share/nginx/html</span><br><span class="line">EXPOSE 80</span><br><span class="line">CMD [<span class="string">&quot;nginx&quot;</span>, <span class="string">&quot;-g&quot;</span>, <span class="string">&quot;daemon off;&quot;</span>]</span><br></pre></td></tr></table></figure>

<p>这里我们使用两个阶段从 docker 文件创建镜像。在 Stage-1 中，我们复制代码并构建它，在 stage-2 中，我们使用在 stage-1 中构建的代码在 Nginx 中运行。</p>
<h2 id="5：apt-安装中使用-–no-install-recommends-标志"><a href="#5：apt-安装中使用-–no-install-recommends-标志" class="headerlink" title="5：apt 安装中使用 –no-install-recommends 标志"></a>5：apt 安装中使用 –no-install-recommends 标志</h2><p>当我们运行 apt install 命令来安装某些包时，它会安装一些不需要的推荐包。使用 –no-install-recommends 标志可以显着减小镜像大小。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM ubuntu:latest</span><br><span class="line">RUN apt update -y &amp;&amp; \</span><br><span class="line">apt install unzip -y --no-install-recommends &amp;&amp; \</span><br><span class="line">apt install curl --no-install-recommends -y &amp;&amp; \</span><br><span class="line">apt install python3 -y --no-install-recommends</span><br></pre></td></tr></table></figure>

<p>如下图所示，带有 new 标签的镜像由于添加了此标志而减少了 5MB。当我们要安装多个包时，这将非常有帮助。<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302141442519.png" alt="图片"></p>
<p>您可以在 apk add 命令中添加 –no-cache。</p>
<h2 id="6：在-apt-install-命令后添加-rm-rf-x2F-var-x2F-lib-x2F-apt-x2F-lists-x2F"><a href="#6：在-apt-install-命令后添加-rm-rf-x2F-var-x2F-lib-x2F-apt-x2F-lists-x2F" class="headerlink" title="6：在 apt install 命令后添加 rm -rf &#x2F;var&#x2F;lib&#x2F;apt&#x2F;lists&#x2F;*"></a>6：在 apt install 命令后添加 rm -rf &#x2F;var&#x2F;lib&#x2F;apt&#x2F;lists&#x2F;*</h2><p>我们可以在 apt install 之后添加这个命令来减少 docker 镜像的大小。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM ubuntu:latest</span><br><span class="line">RUN apt update -y &amp;&amp; \</span><br><span class="line">apt install unzip -y --no-install-recommends &amp;&amp; \</span><br><span class="line">apt install curl --no-install-recommends -y &amp;&amp; \</span><br><span class="line">apt install python3 -y --no-install-recommends &amp;&amp; \</span><br><span class="line"><span class="built_in">rm</span> -rf /var/lib/apt/lists/*</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302141442844.png" alt="图片"></p>
<p>从上图中可以看出，我们已将 docker 镜像的大小减少了约 41 MB。</p>
<h2 id="7：使用-dockerignore-文件"><a href="#7：使用-dockerignore-文件" class="headerlink" title="7：使用 .dockerignore 文件"></a>7：使用 .dockerignore 文件</h2><p>如果您不想将某些文件复制到 docker 镜像，那么使用 .dockerignore 文件可以为您节省一些空间。</p>
<p>在构建上下文中有一些隐藏的文件&#x2F;文件夹，您可以使用 ADD 或 COPY 命令（如 .git 等）将其传输到镜像。包含一个 .dockerignore 文件以减小 docker 镜像大小是一个很好的做法。</p>
<p><code>.dockerignore</code> 文件示例。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ignorethisfile.txt</span><br><span class="line">logs/</span><br><span class="line">ignorethisfolder/</span><br><span class="line">.git</span><br><span class="line">.cache</span><br><span class="line">*.md</span><br></pre></td></tr></table></figure>

<h2 id="8：在-RUN-之后放置-COPY"><a href="#8：在-RUN-之后放置-COPY" class="headerlink" title="8：在 RUN 之后放置 COPY"></a>8：在 RUN 之后放置 COPY</h2><p>在某些情况下，您对代码进行了细微的更改，并且需要反复从 dockerfile 构建镜像。<br>在这种情况下，将 COPY 命令放在 RUN 命令之后将有助于减小镜像大小，因为在这种情况下 docker 将能够更好地使用缓存功能。</p>
<p>它将为安装了依赖项的镜像创建缓存，每次更改代码时，docker 都会使用该缓存并创建镜像。它还将减少 docker 构建时间。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Dockerfile-1</span></span><br><span class="line">FROM ubuntu:latest</span><br><span class="line">RUN apt update -y &amp;&amp; \</span><br><span class="line">apt install unzip -y --no-install-recommends &amp;&amp; \</span><br><span class="line">apt install curl --no-install-recommends -y &amp;&amp; \</span><br><span class="line">apt install python3 -y --no-install-recommends &amp;&amp; \</span><br><span class="line"><span class="built_in">rm</span> -rf /var/lib/apt/lists/*</span><br><span class="line">COPY file /home/ubuntu</span><br><span class="line"><span class="comment">#Dockerfile-2</span></span><br><span class="line">FROM ubuntu:latest</span><br><span class="line">COPY file /home/ubuntu</span><br><span class="line">RUN apt update -y &amp;&amp; \</span><br><span class="line">apt install unzip -y --no-install-recommends &amp;&amp; \</span><br><span class="line">apt install curl --no-install-recommends -y &amp;&amp; \</span><br><span class="line">apt install python3 -y --no-install-recommends &amp;&amp; \</span><br><span class="line"><span class="built_in">rm</span> -rf /var/lib/apt/lists/*</span><br></pre></td></tr></table></figure>

<p>在上述情况下，dockerfile-1 将能够比 dockerfile-2 表现得更好。</p>
<h2 id="9：安装后删除软件包"><a href="#9：安装后删除软件包" class="headerlink" title="9：安装后删除软件包"></a>9：安装后删除软件包</h2><p>如果您需要在 docker 镜像中安装一些包，并且您是从外部下载它们，那么最好在安装后删除这些包。</p>
<p>例如，如果您希望从 zip 文件安装 AWS CLI V2，那么在成功安装后请记住也删除该 zip 文件。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM ubuntu:latest</span><br><span class="line">RUN curl <span class="string">&quot;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip&quot;</span> -o <span class="string">&quot;awscliv2.zip&quot;</span> &amp;&amp; \</span><br><span class="line">unzip awscliv2.zip &amp;&amp; \</span><br><span class="line">sudo ./aws/install &amp;&amp; \</span><br><span class="line"><span class="built_in">rm</span> awscliv2.zip</span><br></pre></td></tr></table></figure>

<h2 id="10：使用-Docker-镜像缩容工具"><a href="#10：使用-Docker-镜像缩容工具" class="headerlink" title="10：使用 Docker 镜像缩容工具"></a>10：使用 Docker 镜像缩容工具</h2><p>有几个<strong>dockerfile 优化工具</strong>可以帮助你减少 docker 镜像的大小。下面列出了其中一些。</p>
<ol>
<li><p><strong>Dive</strong>：Dive 是一个开源工具，用于探索 Docker 镜像及其层内容，然后发现缩小 Docker&#x2F;OCI 镜像大小的方法。</p>
<blockquote>
<p><a href="https://github.com/wagoodman/dive">https://github.com/wagoodman/dive</a></p>
</blockquote>
</li>
<li><p><strong>fromlatest.io</strong>：此工具将检查您的 Dockerfile 并检查可以执行的更多步骤以减小镜像大小。</p>
<blockquote>
<p><a href="https://www.fromlatest.io/">https://www.fromlatest.io/</a></p>
</blockquote>
</li>
<li><p>Docker Slim：它让你的容器更好、更小、更安全。您可以使用<strong>dockerslim 来最小化容器镜像</strong>。</p>
<blockquote>
<p><a href="https://github.com/slimtoolkit/slim">https://github.com/slimtoolkit/slim</a></p>
</blockquote>
</li>
</ol>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 Dockerfile 定制镜像</title>
    <url>/2022/12/29/%E4%BD%BF%E7%94%A8%20Dockerfile%20%E5%AE%9A%E5%88%B6%E9%95%9C%E5%83%8F/</url>
    <content><![CDATA[<h2 id="一、使用-Dockerfile-定制镜像"><a href="#一、使用-Dockerfile-定制镜像" class="headerlink" title="一、使用 Dockerfile 定制镜像"></a>一、使用 Dockerfile 定制镜像</h2><h3 id="1-1、Dockerfile-定制镜像"><a href="#1-1、Dockerfile-定制镜像" class="headerlink" title="1.1、Dockerfile 定制镜像"></a>1.1、Dockerfile 定制镜像</h3><p>镜像的定制实际上就是定制每一层所添加的配置、文件。如果我们可以把每一层修改、安装、构建、操作的命令都写入一个脚本，用这个脚本来构建、定制镜像，无法重复的问题、镜像构建透明性的问题、体积的问题就都会解决。这个脚本就是 Dockerfile。</p>
<p>Dockerfile 是一个文本文件，其内包含了一条条的指令(Instruction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。</p>
<p>以 nginx 镜像为例，这次我们使用 Dockerfile 来定制。</p>
<p>在一个空白目录中，建立一个文本文件，并命名为 Dockerfile：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> mynginx</span><br><span class="line"><span class="built_in">cd</span> mynginx</span><br><span class="line"><span class="built_in">touch</span> Dockerfile</span><br></pre></td></tr></table></figure>

<p>其内容为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM nginx</span><br><span class="line">RUN <span class="built_in">echo</span> <span class="string">&#x27;&lt;h1&gt;Hello, Docker!&lt;/h1&gt;&#x27;</span> &gt; /usr/share/nginx/html/index.html</span><br></pre></td></tr></table></figure>

<p>这个 Dockerfile 很简单，一共就两行。涉及到了两条指令，<code>FROM</code> 和 <code>RUN</code>。</p>
<h3 id="1-2、FROM-指定基础镜像"><a href="#1-2、FROM-指定基础镜像" class="headerlink" title="1.2、FROM 指定基础镜像"></a>1.2、FROM 指定基础镜像</h3><p>所谓定制镜像，那一定是以一个镜像为基础，在其上进行定制。就像我们之前运行了一个 nginx 镜像的容器，再进行修改一样，基础镜像是必须指定的。而 FROM 就是指定基础镜像，因此一个 Dockerfile 中 FROM是必备的指令，并且必须是第一条指令。</p>
<p>在 Docker Store 上有非常多的高质量的官方镜像，有可以直接拿来使用的服务类的镜像，如 <code>nginx</code>、<code>redis</code>、<code>mongo</code>、<code>mysql</code>、<code>httpd</code>、<code>php</code>、<code>tomcat</code> 等；也有一些方便开发、构建、运行各种语言应用的镜像，如<code>node</code>、<code>openjdk</code>、<code>python</code>、<code>ruby</code>、<code>golang</code>等。可以在其中寻找一个最符合我们最终目标的镜像为基础镜像进行定制。</p>
<p>如果没有找到对应服务的镜像，官方镜像中还提供了一些更为基础的操作系统镜像，如<code>ubuntu</code>、<code>debian</code>、<code>centos</code>、<code>fedora</code>、<code>alpine</code> 等，这些操作系统的软件库为我们提供了更广阔的扩展空间。</p>
<p>除了选择现有镜像为基础镜像外，Docker 还存在一个特殊的镜像，名为 scratch。这个镜像是虚拟的概念，并不实际存在，它表示一个空白的镜像。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM scratch</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>如果你以 scratch 为基础镜像的话，意味着你不以任何镜像为基础，接下来所写的指令将作为镜像第一层开始存在。</p>
<p>不以任何系统为基础，直接将可执行文件复制进镜像的做法并不罕见，比如<code>swarm</code>、coreos&#x2F;etcd。对于 Linux 下静态编译的程序来说，并不需要有操作系统提供运行时支持，所需的一切库都已经在可执行文件里了，因此直接 <code>FROM scratch</code> 会让镜像体积更加小巧。使用 Go 语言开发的应用很多会使用这种方式来制作镜像，这也是为什么有人认为 Go 是特别适合容器微服务架构的语言的原因之一。</p>
<h3 id="1-3、RUN-执行命令"><a href="#1-3、RUN-执行命令" class="headerlink" title="1.3、RUN 执行命令"></a>1.3、RUN 执行命令</h3><p>RUN 指令是用来执行命令行命令的。由于命令行的强大能力，RUN 指令在定制镜像时是最常用的指令之一。其格式有两种：</p>
<p>shell 格式：RUN &lt;命令&gt;，就像直接在命令行中输入的命令一样。刚才写的 Dockerfile 中的 RUN 指令就是这种格式。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">RUN <span class="built_in">echo</span> <span class="string">&#x27;&lt;h1&gt;Hello, Docker!&lt;/h1&gt;&#x27;</span> &gt; /usr/share/nginx/html/index.html</span><br></pre></td></tr></table></figure>

<p>exec 格式：RUN [“可执行文件”, “参数1”, “参数2”]，这更像是函数调用中的格式。<br>既然 RUN 就像 Shell 脚本一样可以执行命令，那么我们是否就可以像 Shell 脚本一样把每个命令对应一个 RUN 呢？比如这样：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM debian:jessie</span><br><span class="line"></span><br><span class="line">RUN apt-get update</span><br><span class="line">RUN apt-get install -y gcc libc6-dev make</span><br><span class="line">RUN wget -O redis.tar.gz <span class="string">&quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot;</span></span><br><span class="line">RUN <span class="built_in">mkdir</span> -p /usr/src/redis</span><br><span class="line">RUN tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1</span><br><span class="line">RUN make -C /usr/src/redis</span><br><span class="line">RUN make -C /usr/src/redis install</span><br></pre></td></tr></table></figure>

<p>之前说过，Dockerfile 中每一个指令都会建立一层，<code>RUN</code> 也不例外。每一个 <code>RUN</code> 的行为，就和刚才我们手工建立镜像的过程一样：新建立一层，在其上执行这些命令，执行结束后，<code>commit</code> 这一层的修改，构成新的镜像。</p>
<p>而上面的这种写法，创建了 7 层镜像。这是完全没有意义的，而且很多运行时不需要的东西，都被装进了镜像里，比如编译环境、更新的软件包等等。结果就是产生非常臃肿、非常多层的镜像，不仅仅增加了构建部署的时间，也很容易出错。这是很多初学 Docker 的人常犯的一个错误。</p>
<p><code>Union FS</code> 是有最大层数限制的，比如 AUFS，曾经是最大不能超过 42 层，现在是不能超过 127 层。</p>
<p>上面的 Dockerfile 正确的写法应该是这样：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM debian:jessie</span><br><span class="line"></span><br><span class="line">RUN buildDeps=<span class="string">&#x27;gcc libc6-dev make&#x27;</span> \</span><br><span class="line">    &amp;&amp; apt-get update \</span><br><span class="line">    &amp;&amp; apt-get install -y <span class="variable">$buildDeps</span> \</span><br><span class="line">    &amp;&amp; wget -O redis.tar.gz <span class="string">&quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot;</span> \</span><br><span class="line">    &amp;&amp; <span class="built_in">mkdir</span> -p /usr/src/redis \</span><br><span class="line">    &amp;&amp; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \</span><br><span class="line">    &amp;&amp; make -C /usr/src/redis \</span><br><span class="line">    &amp;&amp; make -C /usr/src/redis install \</span><br><span class="line">    &amp;&amp; <span class="built_in">rm</span> -rf /var/lib/apt/lists/* \</span><br><span class="line">    &amp;&amp; <span class="built_in">rm</span> redis.tar.gz \</span><br><span class="line">    &amp;&amp; <span class="built_in">rm</span> -r /usr/src/redis \</span><br><span class="line">    &amp;&amp; apt-get purge -y --auto-remove <span class="variable">$buildDeps</span></span><br></pre></td></tr></table></figure>

<p>首先，之前所有的命令只有一个目的，就是编译、安装 Redis 可执行文件。因此没有必要建立很多层，这只是一层的事情。因此，这里没有使用很多个 RUN 对一一对应不同的命令，而是仅仅使用一个 RUN 指令，并使用 &amp;&amp; 将各个所需命令串联起来。将之前的 7 层，简化为了 1 层。在撰写 Dockerfile 的时候，要经常提醒自己，这并不是在写 <code>Shell</code> 脚本，而是在定义每一层该如何构建。</p>
<p>并且，这里为了格式化还进行了换行。Dockerfile 支持 Shell 类的行尾添加 \ 的命令换行方式，以及行首 # 进行注释的格式。良好的格式，比如换行、缩进、注释等，会让维护、排障更为容易，这是一个比较好的习惯。</p>
<p>此外，还可以看到这一组命令的最后添加了清理工作的命令，删除了为了编译构建所需要的软件，清理了所有下载、展开的文件，并且还清理了 apt 缓存文件。这是很重要的一步，我们之前说过，镜像是多层存储，每一层的东西并不会在下一层被删除，会一直跟随着镜像。因此镜像构建时，一定要确保每一层只添加真正需要添加的东西，任何无关的东西都应该清理掉。</p>
<p>很多人初学 Docker 制作出了很臃肿的镜像的原因之一，就是忘记了每一层构建的最后一定要清理掉无关文件。</p>
<h3 id="1-4、构建镜像"><a href="#1-4、构建镜像" class="headerlink" title="1.4、构建镜像"></a>1.4、构建镜像</h3><p>再回到之前定制的 Nginx 镜像的 Dockerfile 来。现在我们明白了这个 Dockerfile 的内容，那么让我们来构建这个镜像吧。</p>
<p>在 Dockerfile 文件所在目录执行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker build -t nginx:v3 .</span><br><span class="line">Sending build context to Docker daemon 2.048 kB</span><br><span class="line">Step 1 : FROM nginx</span><br><span class="line"> ---&gt; e43d811ce2f4</span><br><span class="line">Step 2 : RUN <span class="built_in">echo</span> <span class="string">&#x27;&lt;h1&gt;Hello, Docker!&lt;/h1&gt;&#x27;</span> &gt; /usr/share/nginx/html/index.html</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 9cdc27646c7b</span><br><span class="line"> ---&gt; 44aa4490ce2c</span><br><span class="line">Removing intermediate container 9cdc27646c7b</span><br><span class="line">Successfully built 44aa4490ce2c</span><br></pre></td></tr></table></figure>

<p>从命令的输出结果中，我们可以清晰的看到镜像的构建过程。在 Step 2中，如同我们之前所说的那样，<code>RUN</code> 指令启动了一个容器 <code>9cdc27646c7b</code>，执行了所要求的命令，并最后提交了这一层 <code>44aa4490ce2c</code>，随后删除了所用到的这个容器 <code>9cdc27646c7b</code>。</p>
<p>这里我们使用了 <code>docker build</code> 命令进行镜像构建。其格式为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker build [选项] &lt;上下文路径/URL/-&gt;</span><br></pre></td></tr></table></figure>

<p>在这里我们指定了最终镜像的名称 -t nginx:v3，构建成功后，我们可以像之前运行 nginx:v2 那样来运行这个镜像，其结果会和 nginx:v2一样。</p>
<h3 id="1-5、镜像构建上下文（Context）"><a href="#1-5、镜像构建上下文（Context）" class="headerlink" title="1.5、镜像构建上下文（Context）"></a>1.5、镜像构建上下文（Context）</h3><p>如果注意，会看到 docker build 命令最后有一个 .，. 表示当前目录，而 Dockerfile 就在当前目录，因此不少初学者以为这个路径是在指定 Dockerfile 所在路径，这么理解其实是不准确的。如果对应上面的命令格式，你可能会发现，这是在指定上下文路径。那么什么是上下文呢？</p>
<p>首先我们要理解 docker build 的工作原理。Docker 在运行时分为 Docker 引擎（也就是服务端守护进程）和客户端工具。Docker 的引擎提供了一组 REST API，被称为 Docker Remote API，而如 docker 命令这样的客户端工具，则是通过这组 API 与 Docker 引擎交互，从而完成各种功能。因此，虽然表面上我们好像是在本机执行各种 docker 功能，但实际上，一切都是使用的远程调用形式在服务端（Docker 引擎）完成。也因为这种 C&#x2F;S 设计，让我们操作远程服务器的 Docker 引擎变得轻而易举。</p>
<p>当我们进行镜像构建的时候，并非所有定制都会通过 RUN 指令完成，经常会需要将一些本地文件复制进镜像，比如通过 <code>COPY</code> 指令、<code>ADD</code> 指令等。而 <code>docker build</code> 命令构建镜像，其实并非在本地构建，而是在服务端，也就是 Docker 引擎中构建的。那么在这种客户端&#x2F;服务端的架构中，如何才能让服务端获得本地文件呢？</p>
<p>这就引入了上下文的概念。当构建的时候，用户会指定构建镜像上下文的路径，docker build 命令得知这个路径后，会将路径下的所有内容打包，然后上传给 Docker 引擎。这样 Docker 引擎收到这个上下文包后，展开就会获得构建镜像所需的一切文件。</p>
<p>如果在 Dockerfile 中这么写：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">COPY ./package.json /app/</span><br></pre></td></tr></table></figure>

<p>这并不是要复制执行 docker build 命令所在的目录下的 <code>package.json</code>，也不是复制 Dockerfile 所在目录下的 <code>package.json</code>，而是复制 上下文（context） 目录下的 <code>package.json</code>。</p>
<p>因此，<code>COPY</code> 这类指令中的源文件的路径都是相对路径。这也是初学者经常会问的为什么 <code>COPY ../package.json /app</code> 或者 <code>COPY /opt/xxxx /app</code> 无法工作的原因，因为这些路径已经超出了上下文的范围，Docker 引擎无法获得这些位置的文件。如果真的需要那些文件，应该将它们复制到上下文目录中去。</p>
<p>现在就可以理解刚才的命令 <code>docker build -t nginx:v3 .</code> 中的这个 .，实际上是在指定上下文的目录，<code>docker build</code> 命令会将该目录下的内容打包交给 Docker 引擎以帮助构建镜像。</p>
<p>如果观察 docker build 输出，我们其实已经看到了这个发送上下文的过程：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker build -t nginx:v3 .</span><br><span class="line">Sending build context to Docker daemon 2.048 kB</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>理解构建上下文对于镜像构建是很重要的，避免犯一些不应该的错误。比如有些初学者在发现 <code>COPY /opt/xxxx /app</code> 不工作后，于是干脆将 Dockerfile 放到了硬盘根目录去构建，结果发现 docker build 执行后，在发送一个几十 GB 的东西，极为缓慢而且很容易构建失败。那是因为这种做法是在让 <code>docker build</code> 打包整个硬盘，这显然是使用错误。</p>
<p>一般来说，应该会将 Dockerfile 置于一个空目录下，或者项目根目录下。如果该目录下没有所需文件，那么应该把所需文件复制一份过来。如果目录下有些东西确实不希望构建时传给 Docker 引擎，那么可以用 <code>.gitignore</code> 一样的语法写一个 <code>.dockerignore</code>，该文件是用于剔除不需要作为上下文传递给 Docker 引擎的。</p>
<p>那么为什么会有人误以为 . 是指定 Dockerfile 所在目录呢？这是因为在默认情况下，如果不额外指定 Dockerfile 的话，会将上下文目录下的名为 Dockerfile 的文件作为 Dockerfile。</p>
<p>这只是默认行为，实际上 Dockerfile 的文件名并不要求必须为 Dockerfile，而且并不要求必须位于上下文目录中，比如可以用 <code>-f ../Dockerfile.php</code> 参数指定某个文件作为 Dockerfile。</p>
<p>当然，一般大家习惯性的会使用默认的文件名 Dockerfile，以及会将其置于镜像构建上下文目录中。</p>
<h3 id="1-6、其他-docker-build-的用法"><a href="#1-6、其他-docker-build-的用法" class="headerlink" title="1.6、其他 docker build 的用法"></a>1.6、其他 docker build 的用法</h3><h4 id="1-6-1、直接用-Git-repo-进行构建"><a href="#1-6-1、直接用-Git-repo-进行构建" class="headerlink" title="1.6.1、直接用 Git repo 进行构建"></a>1.6.1、直接用 Git repo 进行构建</h4><p>docker build 还支持从 URL 构建，比如可以直接从 Git repo 中构建：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker build https://github.com/twang2218/gitlab-ce-zh.git<span class="comment">#:8.14</span></span><br><span class="line">docker build https://github.com/twang2218/gitlab-ce-zh.git\<span class="comment">#:8.14</span></span><br><span class="line">Sending build context to Docker daemon 2.048 kB</span><br><span class="line">Step 1 : FROM gitlab/gitlab-ce:8.14.0-ce.0</span><br><span class="line">8.14.0-ce.0: Pulling from gitlab/gitlab-ce</span><br><span class="line">aed15891ba52: Already exists</span><br><span class="line">773ae8583d14: Already exists</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>这行命令指定了构建所需的 Git repo，并且指定默认的 master 分支，构建目录为 &#x2F;8.14&#x2F;，然后 Docker 就会自己去 <code>git clone</code> 这个项目、切换到指定分支、并进入到指定目录后开始构建。</p>
<h4 id="1-6-2、用给定的-tar-压缩包构建"><a href="#1-6-2、用给定的-tar-压缩包构建" class="headerlink" title="1.6.2、用给定的 tar 压缩包构建"></a>1.6.2、用给定的 tar 压缩包构建</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker build http://server/context.tar.gz</span><br></pre></td></tr></table></figure>

<p>如果所给出的 URL 不是个 Git repo，而是个 tar 压缩包，那么 Docker 引擎会下载这个包，并自动解压缩，以其作为上下文，开始构建。</p>
<h4 id="1-6-3、从标准输入中读取-Dockerfile-进行构建"><a href="#1-6-3、从标准输入中读取-Dockerfile-进行构建" class="headerlink" title="1.6.3、从标准输入中读取 Dockerfile 进行构建"></a>1.6.3、从标准输入中读取 Dockerfile 进行构建</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker build - &lt; Dockerfile</span><br></pre></td></tr></table></figure>

<p>或</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> Dockerfile | docker build -</span><br></pre></td></tr></table></figure>

<p>如果标准输入传入的是文本文件，则将其视为 Dockerfile，并开始构建。这种形式由于直接从标准输入中读取 Dockerfile 的内容，它没有上下文，因此不可以像其他方法那样可以将本地文件 <code>COPY</code> 进镜像之类的事情。</p>
<h4 id="1-6-4、从标准输入中读取上下文压缩包进行构建"><a href="#1-6-4、从标准输入中读取上下文压缩包进行构建" class="headerlink" title="1.6.4、从标准输入中读取上下文压缩包进行构建"></a>1.6.4、从标准输入中读取上下文压缩包进行构建</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker build - &lt; context.tar.gz</span><br></pre></td></tr></table></figure>

<p>如果发现标准输入的文件格式是 <code>gzip</code>、<code>bzip2</code> 以及 xz 的话，将会使其为上下文压缩包，直接将其展开，将里面视为上下文，并开始构建。</p>
<h2 id="二、Dockerfile-指令"><a href="#二、Dockerfile-指令" class="headerlink" title="二、Dockerfile 指令"></a>二、Dockerfile 指令</h2><p>我们已经介绍了 <code>FROM</code>，<code>RUN</code>，还提及了 <code>COPY</code>, <code>ADD</code>，其实 Dockerfile 功能很强大，它提供了十多个指令。下面我们继续讲解其他的指令。</p>
<h3 id="2-1、COPY"><a href="#2-1、COPY" class="headerlink" title="2.1、COPY"></a>2.1、COPY</h3><p>格式：</p>
<p><code>COPY &lt;源路径&gt;... &lt;目标路径&gt;</code><br><code>COPY [&quot;&lt;源路径1&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;]</code><br>和 <code>RUN</code> 指令一样，也有两种格式，一种类似于命令行，一种类似于函数调用。</p>
<p><code>COPY</code> 指令将从构建上下文目录中 &lt;源路径&gt; 的文件&#x2F;目录复制到新的一层的镜像内的 &lt;目标路径&gt; 位置。比如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">COPY package.json /usr/src/app/</span><br></pre></td></tr></table></figure>

<p><code>&lt;源路径&gt;</code> 可以是多个，甚至可以是通配符，其通配符规则要满足 Go 的 <code>filepath.Match</code> 规则，如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">COPY hom* /mydir/</span><br><span class="line">COPY hom?.txt /mydir/</span><br></pre></td></tr></table></figure>

<p><code>&lt;目标路径&gt;</code> 可以是容器内的绝对路径，也可以是相对于工作目录的相对路径（工作目录可以用 <code>WORKDIR</code> 指令来指定）。目标路径不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录。</p>
<p>此外，还需要注意一点，使用 <code>COPY</code> 指令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。这个特性对于镜像定制很有用。特别是构建相关文件都在使用 Git 进行管理的时候。</p>
<h3 id="2-2、ADD"><a href="#2-2、ADD" class="headerlink" title="2.2、ADD"></a>2.2、ADD</h3><p><code>ADD</code> 指令和 <code>COPY</code> 的格式和性质基本一致。但是在 <code>COPY</code> 基础上增加了一些功能。</p>
<p>比如 &lt;源路径&gt; 可以是一个 URL，这种情况下，Docker 引擎会试图去下载这个链接的文件放到 &lt;目标路径&gt; 去。下载后的文件权限自动设置为 600，如果这并不是想要的权限，那么还需要增加额外的一层 RUN 进行权限调整，另外，如果下载的是个压缩包，需要解压缩，也一样还需要额外的一层 RUN 指令进行解压缩。所以不如直接使用 <code>RUN</code> 指令，然后使用 wget 或者 curl 工具下载，处理权限、解压缩、然后清理无用文件更合理。因此，这个功能其实并不实用，而且不推荐使用。</p>
<p>如果 &lt;源路径&gt; 为一个 tar 压缩文件的话，压缩格式为 <code>gzip</code>, <code>bzip2</code>以及 <code>xz</code> 的情况下，<code>ADD</code> 指令将会自动解压缩这个压缩文件到 <code>&lt;目标路径&gt;</code> 去。</p>
<p>在某些情况下，这个自动解压缩的功能非常有用，比如官方镜像 ubuntu中：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM scratch</span><br><span class="line">ADD ubuntu-xenial-core-cloudimg-amd64-root.tar.gz /</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>但在某些情况下，如果我们真的是希望复制个压缩文件进去，而不解压缩，这时就不可以使用 <code>ADD</code> 命令了。</p>
<p>在 Docker 官方的 Dockerfile 最佳实践文档 中要求，尽可能的使用 <code>COPY</code>，因为 <code>COPY</code> 的语义很明确，就是复制文件而已，而 <code>ADD</code> 则包含了更复杂的功能，其行为也不一定很清晰。最适合使用 <code>ADD</code> 的场合，就是所提及的需要自动解压缩的场合。</p>
<p>另外需要注意的是，<code>ADD</code> 指令会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。</p>
<p>因此在 <code>COPY</code> 和 <code>ADD</code> 指令中选择的时候，可以遵循这样的原则，所有的文件复制均使用 COPY 指令，仅在需要自动解压缩的场合使用 ADD。</p>
<h3 id="2-3、CMD"><a href="#2-3、CMD" class="headerlink" title="2.3、CMD"></a>2.3、CMD</h3><p><code>CMD</code> 指令的格式和 <code>RUN</code> 相似，也是两种格式：</p>
<p><code>shell 格式：CMD &lt;命令&gt;</code><br><code>exec 格式：CMD [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;...]</code><br>参数列表格式：<code>CMD [&quot;参数1&quot;, &quot;参数2&quot;...]</code>。在指定了 <code>ENTRYPOINT</code>指令后，用 CMD 指定具体的参数。<br>之前介绍容器的时候曾经说过，Docker 不是虚拟机，容器就是进程。既然是进程，那么在启动容器的时候，需要指定所运行的程序及参数。CMD 指令就是用于指定默认的容器主进程的启动命令的。</p>
<p>在运行时可以指定新的命令来替代镜像设置中的这个默认命令，比如，ubuntu 镜像默认的 CMD 是 &#x2F;bin&#x2F;bash，如果我们直接 <code>docker run -it ubuntu</code> 的话，会直接进入 bash。我们也可以在运行时指定运行别的命令，如 <code>docker run -it ubuntu cat /etc/os-release</code>。这就是用 <code>cat /etc/os-release</code> 命令替换了默认的 <code>/bin/bash</code> 命令了，输出了系统版本信息。</p>
<p>在指令格式上，一般推荐使用 exec 格式，这类格式在解析时会被解析为 JSON 数组，因此一定要使用双引号 “，而不要使用单引号。</p>
<p>如果使用 shell 格式的话，实际的命令会被包装为 sh -c 的参数的形式进行执行。比如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CMD <span class="built_in">echo</span> <span class="variable">$HOME</span></span><br></pre></td></tr></table></figure>

<p>在实际执行中，会将其变更为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; ]</span><br></pre></td></tr></table></figure>

<p>这就是为什么我们可以使用环境变量的原因，因为这些环境变量会被 shell 进行解析处理。</p>
<p>提到 <code>CMD</code> 就不得不提容器中应用在前台执行和后台执行的问题。这是初学者常出现的一个混淆。</p>
<p>Docker 不是虚拟机，容器中的应用都应该以前台执行，而不是像虚拟机、物理机里面那样，用 upstart&#x2F;systemd 去启动后台服务，容器内没有后台服务的概念。</p>
<p>一些初学者将 <code>CMD</code> 写为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CMD service nginx start</span><br></pre></td></tr></table></figure>

<p>然后发现容器执行后就立即退出了。甚至在容器内去使用 <code>systemctl</code> 命令结果却发现根本执行不了。这就是因为没有搞明白前台、后台的概念，没有区分容器和虚拟机的差异，依旧在以传统虚拟机的角度去理解容器。</p>
<p>对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。</p>
<p>而使用 <code>service nginx start</code> 命令，则是希望 upstart 来以后台守护进程形式启动 nginx 服务。而刚才说了 <code>CMD service nginx start</code> 会被理解为 <code>CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;service nginx start&quot;]</code>，因此主进程实际上是 sh。那么当 <code>service nginx start</code> 命令结束后，<code>sh</code> 也就结束了，sh 作为主进程退出了，自然就会令容器退出。</p>
<p>正确的做法是直接执行 <code>nginx</code> 可执行文件，并且要求以前台形式运行。比如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CMD [<span class="string">&quot;nginx&quot;</span>, <span class="string">&quot;-g&quot;</span>, <span class="string">&quot;daemon off;&quot;</span>]</span><br></pre></td></tr></table></figure>

<h3 id="2-4、ENTRYPOINT"><a href="#2-4、ENTRYPOINT" class="headerlink" title="2.4、ENTRYPOINT"></a>2.4、ENTRYPOINT</h3><p><code>ENTRYPOINT</code> 的格式和 RUN 指令格式一样，分为 exec 格式和 shell格式。</p>
<p><code>ENTRYPOINT</code> 的目的和 <code>CMD</code> 一样，都是在指定容器启动程序及参数。<code>ENTRYPOINT</code> 在运行时也可以替代，不过比 <code>CMD</code> 要略显繁琐，需要通过 <code>docker run</code> 的参数 –entrypoint 来指定。</p>
<p>当指定了 ENTRYPOINT 后，CMD 的含义就发生了改变，不再是直接的运行其命令，而是将 CMD 的内容作为参数传给 ENTRYPOINT 指令，换句话说实际执行时，将变为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;ENTRYPOINT&gt; <span class="string">&quot;&lt;CMD&gt;&quot;</span></span><br></pre></td></tr></table></figure>

<p>那么有了 CMD 后，为什么还要有 ENTRYPOINT 呢？这种 &lt;ENTRYPOINT&gt; “&lt;CMD&gt;” 有什么好处么？让我们来看几个场景。</p>
<h4 id="2-4-1、场景一：让镜像变成像命令一样使用"><a href="#2-4-1、场景一：让镜像变成像命令一样使用" class="headerlink" title="2.4.1、场景一：让镜像变成像命令一样使用"></a>2.4.1、场景一：让镜像变成像命令一样使用</h4><p>假设我们需要一个得知自己当前公网 IP 的镜像，那么可以先用 <code>CMD</code> 来实现：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM ubuntu:16.04</span><br><span class="line">RUN apt-get update \</span><br><span class="line">    &amp;&amp; apt-get install -y curl \</span><br><span class="line">    &amp;&amp; <span class="built_in">rm</span> -rf /var/lib/apt/lists/*</span><br><span class="line">CMD [ <span class="string">&quot;curl&quot;</span>, <span class="string">&quot;-s&quot;</span>, <span class="string">&quot;http://ip.cn&quot;</span> ]</span><br></pre></td></tr></table></figure>

<p>假如我们使用 <code>docker build -t myip .</code> 来构建镜像的话，如果我们需要查询当前公网 IP，只需要执行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker run myip</span><br><span class="line">当前 IP：160.155.224.xx 来自：XX市 联通</span><br></pre></td></tr></table></figure>

<p>这么看起来好像可以直接把镜像当做命令使用了，不过命令总有参数，如果我们希望加参数呢？比如从上面的 <code>CMD</code> 中可以看到实质的命令是 <code>curl</code>，那么如果我们希望显示 <code>HTTP</code> 头信息，就需要加上 <code>-i</code> 参数。那么我们可以直接加 <code>-i</code> 参数给 docker run myip 么？</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker run myip -i</span><br><span class="line">docker: Error response from daemon: invalid header field value <span class="string">&quot;oci runtime error: container_linux.go:247: starting container process caused \&quot;exec: \\\&quot;-i\\\&quot;: executable file not found in <span class="variable">$PATH</span>\&quot;\n&quot;</span>.</span><br></pre></td></tr></table></figure>

<p>我们可以看到可执行文件找不到的报错，<code>executable file not found</code>。之前我们说过，跟在镜像名后面的是 command，运行时会替换 <code>CMD</code> 的默认值。因此这里的 <code>-i</code> 替换了原来的 <code>CMD</code>，而不是添加在原来的 <code>curl -s http://ip.cn</code> 后面。而 -i 根本不是命令，所以自然找不到。</p>
<p>那么如果我们希望加入 -i 这参数，我们就必须重新完整的输入这个命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run myip curl -s http://ip.cn -i</span><br></pre></td></tr></table></figure>

<p>这显然不是很好的解决方案，而使用 ENTRYPOINT 就可以解决这个问题。现在我们重新用 ENTRYPOINT 来实现这个镜像：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM ubuntu:16.04</span><br><span class="line">RUN apt-get update \</span><br><span class="line">    &amp;&amp; apt-get install -y curl \</span><br><span class="line">    &amp;&amp; <span class="built_in">rm</span> -rf /var/lib/apt/lists/*</span><br><span class="line">ENTRYPOINT [ <span class="string">&quot;curl&quot;</span>, <span class="string">&quot;-s&quot;</span>, <span class="string">&quot;http://ip.cn&quot;</span> ]</span><br></pre></td></tr></table></figure>

<p>这次我们再来尝试直接使用 docker run myip -i：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker run myip</span><br><span class="line">当前 IP：160.155.224.xx 来自：XX市 联通</span><br><span class="line"></span><br><span class="line">$ docker run myip -i</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.8.0</span><br><span class="line">Date: Tue, 22 Nov 2016 05:12:40 GMT</span><br><span class="line">Content-Type: text/html; charset=UTF-8</span><br><span class="line">Vary: Accept-Encoding</span><br><span class="line">X-Powered-By: PHP/5.6.24-1~dotdeb+7.1</span><br><span class="line">X-Cache: MISS from cache-2</span><br><span class="line">X-Cache-Lookup: MISS from cache-2:80</span><br><span class="line">X-Cache: MISS from proxy-2_6</span><br><span class="line">Transfer-Encoding: chunked</span><br><span class="line">Via: 1.1 cache-2:80, 1.1 proxy-2_6:8006</span><br><span class="line">Connection: keep-alive</span><br><span class="line"></span><br><span class="line">当前 IP：160.155.224.xx 来自：XX市 联通</span><br></pre></td></tr></table></figure>

<p>可以看到，这次成功了。这是因为当存在 <code>ENTRYPOINT</code> 后，<code>CMD</code> 的内容将会作为参数传给 ENTRYPOINT，而这里 <code>-i</code> 就是新的 <code>CMD</code>，因此会作为参数传给 <code>curl</code>，从而达到了我们预期的效果。</p>
<h4 id="2-4-2、场景二：应用运行前的准备工作"><a href="#2-4-2、场景二：应用运行前的准备工作" class="headerlink" title="2.4.2、场景二：应用运行前的准备工作"></a>2.4.2、场景二：应用运行前的准备工作</h4><p>启动容器就是启动主进程，但有些时候，启动主进程前，需要一些准备工作。</p>
<p>比如 mysql 类的数据库，可能需要一些数据库配置、初始化的工作，这些工作要在最终的 mysql 服务器运行之前解决。</p>
<p>此外，可能希望避免使用 root 用户去启动服务，从而提高安全性，而在启动服务前还需要以 root 身份执行一些必要的准备工作，最后切换到服务用户身份启动服务。或者除了服务外，其它命令依旧可以使用 root 身份执行，方便调试等。</p>
<p>这些准备工作是和容器 <code>CMD</code> 无关的，无论 <code>CMD</code> 为什么，都需要事先进行一个预处理的工作。这种情况下，可以写一个脚本，然后放入 ENTRYPOINT 中去执行，而这个脚本会将接到的参数（也就是 &lt;CMD&gt;）作为命令，在脚本最后执行。比如官方镜像 redis 中就是这么做的：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM alpine:3.4</span><br><span class="line">...</span><br><span class="line">RUN addgroup -S redis &amp;&amp; adduser -S -G redis redis</span><br><span class="line">...</span><br><span class="line">ENTRYPOINT [<span class="string">&quot;docker-entrypoint.sh&quot;</span>]</span><br><span class="line"></span><br><span class="line">EXPOSE 6379</span><br><span class="line">CMD [ <span class="string">&quot;redis-server&quot;</span> ]</span><br></pre></td></tr></table></figure>

<p>可以看到其中为了 Redis 服务创建了 Redis 用户，并在最后指定了 ENTRYPOINT 为 docker-entrypoint.sh 脚本。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line">...</span><br><span class="line"><span class="comment"># allow the container to be started with `--user`</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$1</span>&quot;</span> = <span class="string">&#x27;redis-server&#x27;</span> -a <span class="string">&quot;<span class="subst">$(id -u)</span>&quot;</span> = <span class="string">&#x27;0&#x27;</span> ]; <span class="keyword">then</span></span><br><span class="line"> <span class="built_in">chown</span> -R redis .</span><br><span class="line"> <span class="built_in">exec</span> su-exec redis <span class="string">&quot;<span class="variable">$0</span>&quot;</span> <span class="string">&quot;<span class="variable">$@</span>&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">exec</span> <span class="string">&quot;<span class="variable">$@</span>&quot;</span></span><br></pre></td></tr></table></figure>

<p>该脚本的内容就是根据 CMD 的内容来判断，如果是 redis-server 的话，则切换到 redis 用户身份启动服务器，否则依旧使用 root 身份执行。比如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker run -it redis <span class="built_in">id</span></span><br><span class="line">uid=0(root) gid=0(root) <span class="built_in">groups</span>=0(root)</span><br></pre></td></tr></table></figure>

<h3 id="2-5、ENV"><a href="#2-5、ENV" class="headerlink" title="2.5、ENV"></a>2.5、ENV</h3><p>格式有两种：</p>
<p><code>ENV &lt;key&gt; &lt;value&gt;</code><br><code>ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;...</code><br>这个指令很简单，就是设置环境变量而已，无论是后面的其它指令，如 RUN，还是运行时的应用，都可以直接使用这里定义的环境变量。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ENV VERSION=1.0 DEBUG=on \</span><br><span class="line">    NAME=<span class="string">&quot;Happy Feet&quot;</span></span><br></pre></td></tr></table></figure>

<p>这个例子中演示了如何换行，以及对含有空格的值用双引号括起来的办法，这和 Shell 下的行为是一致的。</p>
<p>定义了环境变量，那么在后续的指令中，就可以使用这个环境变量。比如在官方 node 镜像 Dockerfile 中，就有类似这样的代码：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ENV NODE_VERSION 7.2.0</span><br><span class="line"></span><br><span class="line">RUN curl -SLO <span class="string">&quot;https://nodejs.org/dist/v<span class="variable">$NODE_VERSION</span>/node-v<span class="variable">$NODE_VERSION</span>-linux-x64.tar.xz&quot;</span> \</span><br><span class="line">  &amp;&amp; curl -SLO <span class="string">&quot;https://nodejs.org/dist/v<span class="variable">$NODE_VERSION</span>/SHASUMS256.txt.asc&quot;</span> \</span><br><span class="line">  &amp;&amp; gpg --batch --decrypt --output SHASUMS256.txt SHASUMS256.txt.asc \</span><br><span class="line">  &amp;&amp; grep <span class="string">&quot; node-v<span class="variable">$NODE_VERSION</span>-linux-x64.tar.xz\$&quot;</span> SHASUMS256.txt | <span class="built_in">sha256sum</span> -c - \</span><br><span class="line">  &amp;&amp; tar -xJf <span class="string">&quot;node-v<span class="variable">$NODE_VERSION</span>-linux-x64.tar.xz&quot;</span> -C /usr/local --strip-components=1 \</span><br><span class="line">  &amp;&amp; <span class="built_in">rm</span> <span class="string">&quot;node-v<span class="variable">$NODE_VERSION</span>-linux-x64.tar.xz&quot;</span> SHASUMS256.txt.asc SHASUMS256.txt \</span><br><span class="line">  &amp;&amp; <span class="built_in">ln</span> -s /usr/local/bin/node /usr/local/bin/nodejs</span><br></pre></td></tr></table></figure>

<p>在这里先定义了环境变量 <code>NODE_VERSION</code>，其后的 <code>RUN</code> 这层里，多次使用 <code>$NODE_VERSION</code> 来进行操作定制。可以看到，将来升级镜像构建版本的时候，只需要更新 7.2.0 即可，Dockerfile 构建维护变得更轻松了。</p>
<p>下列指令可以支持环境变量展开：<code>ADD</code>、<code>COPY</code>、<code>ENV</code>、<code>EXPOSE</code>、<code>LABEL</code>、<code>USER</code>、<code>WORKDIR</code>、<code>VOLUME</code>、<code>STOPSIGNAL</code>、<code>ONBUILD</code>。</p>
<p>可以从这个指令列表里感觉到，环境变量可以使用的地方很多，很强大。通过环境变量，我们可以让一份 Dockerfile 制作更多的镜像，只需使用不同的环境变量即可。</p>
<h3 id="2-6、VOLUME"><a href="#2-6、VOLUME" class="headerlink" title="2.6、VOLUME"></a>2.6、VOLUME</h3><p>格式为：</p>
<p><code>VOLUME [&quot;&lt;路径1&gt;&quot;, &quot;&lt;路径2&gt;&quot;...]</code><br><code>VOLUME &lt;路径&gt;</code><br>之前我们说过，容器运行时应该尽量保持容器存储层不发生写操作，对于数据库类需要保存动态数据的应用，其数据库文件应该保存于卷(volume)中，后面的章节我们会进一步介绍 Docker 卷的概念。为了防止运行时用户忘记将动态文件所保存目录挂载为卷，在 Dockerfile 中，我们可以事先指定某些目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运行，不会向容器存储层写入大量数据。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">VOLUME /data</span><br></pre></td></tr></table></figure>

<p>这里的 &#x2F;data 目录就会在运行时自动挂载为匿名卷，任何向 &#x2F;data 中写入的信息都不会记录进容器存储层，从而保证了容器存储层的无状态化。当然，运行时可以覆盖这个挂载设置。比如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d -v mydata:/data xxxx</span><br></pre></td></tr></table></figure>

<p>在这行命令中，就使用了 mydata 这个命名卷挂载到了 &#x2F;data 这个位置，替代了 Dockerfile 中定义的匿名卷的挂载配置。</p>
<h3 id="2-7、EXPOSE"><a href="#2-7、EXPOSE" class="headerlink" title="2.7、EXPOSE"></a>2.7、EXPOSE</h3><p>格式为 <code>EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...]</code>。</p>
<p><code>EXPOSE</code> 指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。在 Dockerfile 中写入这样的声明有两个好处，一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射；另一个用处则是在运行时使用随机端口映射时，也就是 <code>docker run -P</code> 时，会自动随机映射 <code>EXPOSE</code> 的端口。</p>
<p>此外，在早期 Docker 版本中还有一个特殊的用处。以前所有容器都运行于默认桥接网络中，因此所有容器互相之间都可以直接访问，这样存在一定的安全性问题。于是有了一个 Docker 引擎参数 –icc&#x3D;false，当指定该参数后，容器间将默认无法互访，除非互相间使用了 –links 参数的容器才可以互通，并且只有镜像中 EXPOSE 所声明的端口才可以被访问。这个 –icc&#x3D;false 的用法，在引入了 docker network 后已经基本不用了，通过自定义网络可以很轻松的实现容器间的互联与隔离。</p>
<p>要将 EXPOSE 和在运行时使用 <code>-p &lt;宿主端口&gt;:&lt;容器端口&gt;</code> 区分开来。-p，是映射宿主端口和容器端口，换句话说，就是将容器的对应端口服务公开给外界访问，而 EXPOSE 仅仅是声明容器打算使用什么端口而已，并不会自动在宿主进行端口映射。</p>
<h3 id="2-8、WORKDIR"><a href="#2-8、WORKDIR" class="headerlink" title="2.8、WORKDIR"></a>2.8、WORKDIR</h3><p>格式为 <code>WORKDIR &lt;工作目录路径&gt;</code>。</p>
<p>使用 WORKDIR 指令可以来指定工作目录（或者称为当前目录），以后各层的当前目录就被改为指定的目录，如该目录不存在，WORKDIR 会帮你建立目录。</p>
<p>之前提到一些初学者常犯的错误是把 Dockerfile 等同于 <code>Shell</code> 脚本来书写，这种错误的理解还可能会导致出现下面这样的错误：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">UN <span class="built_in">cd</span> /app</span><br><span class="line">RUN <span class="built_in">echo</span> <span class="string">&quot;hello&quot;</span> &gt; world.txt</span><br></pre></td></tr></table></figure>

<p>如果将这个 Dockerfile 进行构建镜像运行后，会发现找不到 &#x2F;app&#x2F;world.txt 文件，或者其内容不是 hello。原因其实很简单，在 Shell 中，连续两行是同一个进程执行环境，因此前一个命令修改的内存状态，会直接影响后一个命令；而在 Dockerfile 中，这两行 RUN 命令的执行环境根本不同，是两个完全不同的容器。这就是对 Dockerfile 构建分层存储的概念不了解所导致的错误。</p>
<p>之前说过每一个 <code>RUN</code> 都是启动一个容器、执行命令、然后提交存储层文件变更。第一层 <code>RUN cd /app</code> 的执行仅仅是当前进程的工作目录变更，一个内存上的变化而已，其结果不会造成任何文件变更。而到第二层的时候，启动的是一个全新的容器，跟第一层的容器更完全没关系，自然不可能继承前一层构建过程中的内存变化。</p>
<p>因此如果需要改变以后各层的工作目录的位置，那么应该使用 WORKDIR指令。</p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 Kaniko 构建镜像</title>
    <url>/2023/01/04/%E4%BD%BF%E7%94%A8%20Kaniko%20%E6%9E%84%E5%BB%BA%E9%95%9C%E5%83%8F/</url>
    <content><![CDATA[<h2 id="1-什么是-kaniko"><a href="#1-什么是-kaniko" class="headerlink" title="1. 什么是 kaniko"></a>1. 什么是 kaniko</h2><p>Google 2018 年发布的 kaniko 是一种在容器或 Kubernetes 集群内无需特权<br>从 Dockerfile 构建容器镜像的工具。</p>
<p>kaniko 不依赖于 Docker 守护进程，而是完全在用户空间中执行 Dockerfile 中的每个命令，并对所构建的文件系统更改做快照。</p>
<h2 id="2-kaniko-是如何工作的"><a href="#2-kaniko-是如何工作的" class="headerlink" title="2. kaniko 是如何工作的"></a>2. kaniko 是如何工作的</h2><ul>
<li>• 1.读取指定的<code>Dockerfile</code>。</li>
<li>• 2.将基本映像（在FROM指令中指定）提取到容器文件系统中。</li>
<li>• 3.在独立的<code>Dockerfile</code>中分别运行每个命令。</li>
<li>• 4.每次运行后都会对用户空间文件系统的做快照。</li>
<li>• 5.每次运行时，将快照层附加到基础层。</li>
</ul>
<h2 id="3-工作原理"><a href="#3-工作原理" class="headerlink" title="3. 工作原理"></a>3. 工作原理</h2><p><code>kaniko</code>作为一个容器镜像运行，它接受三个参数：<strong>一个 Dockerfile</strong> ，<strong>一个构建上下文（context）</strong>以及<strong>将镜像推送到的镜像仓库</strong>。它在执行程序镜像中提取基本镜像的文件系统。然后，在Dockerfile中执行任何命令，快照用户空间中的文件系统。Kaniko在每个命令后都会将一层已更改的文件附加到基本镜像。最后，执行程序将新镜像推送到指定的注册表。由于Kaniko在执行程序镜像的用户空间中完全执行了这些操作，因此它完全避免了在用户计算机上需要任何特权访问。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202212131541296.png" alt="图片"></p>
<h2 id="4-kaniko-构建上下文"><a href="#4-kaniko-构建上下文" class="headerlink" title="4. kaniko 构建上下文"></a>4. kaniko 构建上下文</h2><p>kaniko 的构建上下文与您将发送 Docker 守护程序以进行映像构建的构建上下文非常相似；它代表一个包含 Dockerfile 的目录，kaniko 将使用该目录构建您的映像。例如，COPY Dockerfile 中的命令应该引用构建上下文中的文件。</p>
<p>您需要将构建上下文存储在 kaniko 可以访问的地方。运行 <code>kaniko</code> 时，使用<code>--context</code>带有适当前缀的标志来指定构建上下文的位置：</p>
<table>
<thead>
<tr>
<th>Source</th>
<th>Prefix</th>
<th>Example</th>
</tr>
</thead>
<tbody><tr>
<td>Local Directory</td>
<td>dir:&#x2F;&#x2F;[path to a directory in the kaniko container]</td>
<td>dir:&#x2F;&#x2F;&#x2F;workspace</td>
</tr>
<tr>
<td>Local Tar Gz</td>
<td>tar:&#x2F;&#x2F;[path to a .tar.gz in the kaniko container]</td>
<td>tar:&#x2F;&#x2F;path&#x2F;to&#x2F;context.tar.gz</td>
</tr>
<tr>
<td>Standard Input</td>
<td>tar:&#x2F;&#x2F;[stdin]</td>
<td>tar:&#x2F;&#x2F;stdin</td>
</tr>
<tr>
<td>GCS Bucket</td>
<td>gs:&#x2F;&#x2F;[bucket name]&#x2F;[path to .tar.gz]</td>
<td>gs:&#x2F;&#x2F;kaniko-bucket&#x2F;path&#x2F;to&#x2F;context.tar.gz</td>
</tr>
<tr>
<td>S3 Bucket</td>
<td>s3:&#x2F;&#x2F;[bucket name]&#x2F;[path to .tar.gz]</td>
<td>s3:&#x2F;&#x2F;kaniko-bucket&#x2F;path&#x2F;to&#x2F;context.tar.gz</td>
</tr>
<tr>
<td>Azure Blob Storage</td>
<td><a href="https://[account]">https://[account]</a>.[azureblobhostsuffix]&#x2F;[container]&#x2F;[path to .tar.gz]</td>
<td><a href="https://myaccount.blob.core.windows.net/container/path/to/context.tar.gz">https://myaccount.blob.core.windows.net/container/path/to/context.tar.gz</a></td>
</tr>
<tr>
<td>Git Repository</td>
<td>git:&#x2F;&#x2F;[repository url]&#x2F;[#reference]&#x2F;[#commit-id]</td>
<td>&lt;git:&#x2F;&#x2F;github.com&#x2F;acme&#x2F;myproject.git#refs&#x2F;heads&#x2F;mybranch# &gt;</td>
</tr>
</tbody></table>
<blockquote>
<p>关于 <code>Local Directory</code>的注意事项：此选项是指 kaniko 容器内的目录。如果您希望使用此选项，则需要在构建上下文中将其作为目录挂载到容器中。关于本地 Tar 的注意事项：此选项指的是 <code>kaniko</code> 容器中的 <code>tar gz</code>文件。如果您希望使用此选项，则需要在构建上下文中将其作为文件挂载到容器中。</p>
</blockquote>
<p>关于标准输入的注意事项：<code>kaniko 允许的唯一标准输入是.tar.gz格式。</code></p>
<p>如果使用 <code>GCS</code> 或 <code>S3</code> 存储桶，您首先需要创建构建上下文的压缩 tar 并将其上传到您的存储桶。运行后，kaniko 将在开始映像构建之前下载并解压构建上下文的压缩 tar。</p>
<p>要创建压缩的 tar，您可以运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar -C &lt;path to build context&gt; -zcvf context.tar.gz .</span><br></pre></td></tr></table></figure>

<p>然后，将压缩的 tar 复制到您的存储桶中。例如，我们可以使用 <code>gsutil</code> 将压缩的 tar 复制到 GCS 存储桶：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gsutil <span class="built_in">cp</span> context.tar.gz gs://&lt;bucket name&gt;</span><br></pre></td></tr></table></figure>

<h2 id="5-准备"><a href="#5-准备" class="headerlink" title="5. 准备"></a>5. 准备</h2><ul>
<li>• minikube &amp; kubernetes</li>
</ul>
<h2 id="6-下载-kaniko-demo"><a href="#6-下载-kaniko-demo" class="headerlink" title="6. 下载 kaniko-demo"></a>6. 下载 kaniko-demo</h2><ul>
<li>• 安装最新 git</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /root/kaniko &amp;&amp; <span class="built_in">cd</span> /root/kaniko</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/Ghostwritten/kaniko-demo.git</span><br><span class="line"><span class="built_in">cd</span> kaniko-demo</span><br></pre></td></tr></table></figure>

<h2 id="7-常用的-docker-构建方式"><a href="#7-常用的-docker-构建方式" class="headerlink" title="7. 常用的 docker 构建方式"></a>7. 常用的 docker 构建方式</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#cat Dockerfile </span></span><br><span class="line">FROM klakegg/hugo:0.78.2-alpine AS build</span><br><span class="line">RUN apk add -U git</span><br><span class="line">COPY . /src</span><br><span class="line">RUN make init</span><br><span class="line">RUN make build</span><br><span class="line"></span><br><span class="line">FROM nginx:1.19.4-alpine</span><br><span class="line">RUN <span class="built_in">mv</span> /usr/share/nginx/html/index.html /usr/share/nginx/html/old-index.html</span><br><span class="line">COPY --from=build /src/public /usr/share/nginx/html</span><br><span class="line">EXPOSE 80</span><br></pre></td></tr></table></figure>

<p><code>docker build</code>构建镜像最常见的方式</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker build --tag devops-toolkit .</span></span><br><span class="line">Sending build context to Docker daemon  18.24MB</span><br><span class="line">Step 1/9 : FROM klakegg/hugo:0.78.2-alpine AS build</span><br><span class="line"> ---&gt; 5729af47368d</span><br><span class="line">Step 2/9 : RUN apk add -U git</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> db30d5d0eb9c</span><br><span class="line">fetch http://dl-cdn.alpinelinux.org/alpine/v3.12/main/x86_64/APKINDEX.tar.gz</span><br><span class="line">fetch http://dl-cdn.alpinelinux.org/alpine/v3.12/community/x86_64/APKINDEX.tar.gz</span><br><span class="line">(1/7) Installing ca-certificates (20191127-r4)</span><br><span class="line">(2/7) Installing nghttp2-libs (1.41.0-r0)</span><br><span class="line">(3/7) Installing libcurl (7.79.1-r0)</span><br><span class="line">(4/7) Installing expat (2.2.9-r1)</span><br><span class="line">(5/7) Installing pcre2 (10.35-r0)</span><br><span class="line">(6/7) Installing git (2.26.3-r0)</span><br><span class="line">(7/7) Installing git-bash-completion (2.26.3-r0)</span><br><span class="line">Executing busybox-1.31.1-r19.trigger</span><br><span class="line">Executing ca-certificates-20191127-r4.trigger</span><br><span class="line">OK: 30 MiB <span class="keyword">in</span> 30 packages</span><br><span class="line">Removing intermediate container db30d5d0eb9c</span><br><span class="line"> ---&gt; 576762099db7</span><br><span class="line">Step 3/9 : COPY . /src</span><br><span class="line"> ---&gt; 1c3e3ef910a4</span><br><span class="line">Step 4/9 : RUN make init</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> ff17237c7169</span><br><span class="line">git submodule init</span><br><span class="line">Submodule <span class="string">&#x27;themes/forty&#x27;</span> (https://github.com/MarcusVirg/forty) registered <span class="keyword">for</span> path <span class="string">&#x27;themes/forty&#x27;</span></span><br><span class="line">git submodule update</span><br><span class="line">Cloning into <span class="string">&#x27;/src/themes/forty&#x27;</span>...</span><br><span class="line">Submodule path <span class="string">&#x27;themes/forty&#x27;</span>: checked out <span class="string">&#x27;dccea57bd2ed194942080d650671b47b6df4183c&#x27;</span></span><br><span class="line"><span class="built_in">cp</span> content/img/banner.jpg themes/forty/static/img/.</span><br><span class="line">Removing intermediate container ff17237c7169</span><br><span class="line"> ---&gt; 32545a924c20</span><br><span class="line">Step 5/9 : RUN make build</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> d8e1b856a983</span><br><span class="line">hugo</span><br><span class="line">Start building sites … </span><br><span class="line"></span><br><span class="line">                   | EN  </span><br><span class="line">-------------------+-----</span><br><span class="line">  Pages            | 19  </span><br><span class="line">  Paginator pages  |  0  </span><br><span class="line">  Non-page files   | 24  </span><br><span class="line">  Static files     | 97  </span><br><span class="line">  Processed images |  0  </span><br><span class="line">  Aliases          |  0  </span><br><span class="line">  Sitemaps         |  1  </span><br><span class="line">  Cleaned          |  0  </span><br><span class="line"></span><br><span class="line">Total <span class="keyword">in</span> 98 ms</span><br><span class="line">Removing intermediate container d8e1b856a983</span><br><span class="line"> ---&gt; 9d667ded40c1</span><br><span class="line">Step 6/9 : FROM nginx:1.19.4-alpine</span><br><span class="line">1.19.4-alpine: Pulling from library/nginx</span><br><span class="line">188c0c94c7c5: Already exists </span><br><span class="line">0ca72de6f957: Pull complete </span><br><span class="line">9dd8e8e54998: Pull complete </span><br><span class="line">f2dc206a393c: Pull complete </span><br><span class="line">85defa007a8b: Pull complete </span><br><span class="line">Digest: sha256:9b22bb6d703d52b079ae4262081f3b850009e80cd2fc53cdcb8795f3a7b452ee</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> nginx:1.19.4-alpine</span><br><span class="line"> ---&gt; e5dcd7aa4b5e</span><br><span class="line">Step 7/9 : RUN <span class="built_in">mv</span> /usr/share/nginx/html/index.html /usr/share/nginx/html/old-index.html</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 6b8ba00cb3ac</span><br><span class="line">Removing intermediate container 6b8ba00cb3ac</span><br><span class="line"> ---&gt; 3824704d7e36</span><br><span class="line">Step 8/9 : COPY --from=build /src/public /usr/share/nginx/html</span><br><span class="line"> ---&gt; cf9e66eb77bd</span><br><span class="line">Step 9/9 : EXPOSE 80</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 3599fcdb4646</span><br><span class="line">Removing intermediate container 3599fcdb4646</span><br><span class="line"> ---&gt; 04a5e24fa53e</span><br><span class="line">Successfully built 04a5e24fa53e</span><br><span class="line">Successfully tagged devops-toolkit:latest</span><br></pre></td></tr></table></figure>

<h2 id="8-验证-docker-构建镜像的条件是什么"><a href="#8-验证-docker-构建镜像的条件是什么" class="headerlink" title="8. 验证 docker 构建镜像的条件是什么"></a>8. 验证 docker 构建镜像的条件是什么</h2><p>我们创建一个关于 docker 的 pod，并尝试在容器内进行构建镜像。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat docker.yaml </span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">docker</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">docker</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">docker</span></span><br><span class="line">    <span class="attr">args:</span> [<span class="string">&quot;sleep&quot;</span>, <span class="string">&quot;10000&quot;</span>]</span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br></pre></td></tr></table></figure>

<p>创建一个名为 docker 的 pod</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl apply --filename docker.yaml </span><br><span class="line">pod/docker created</span><br><span class="line"></span><br><span class="line"><span class="comment">#等待</span></span><br><span class="line">$ kubectl <span class="built_in">wait</span> --<span class="keyword">for</span> condition=containersready pod docker</span><br><span class="line">pod/docker condition met</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看</span></span><br><span class="line">$ kubectl  get pods</span><br><span class="line">NAME                              READY   STATUS    RESTARTS   AGE</span><br><span class="line">docker                            1/1     Running   0          111s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$  kubectl  <span class="built_in">exec</span> -ti docker -- sh</span><br><span class="line">/ <span class="comment"># apk add -U git</span></span><br><span class="line">fetch https://dl-cdn.alpinelinux.org/alpine/v3.14/main/x86_64/APKINDEX.tar.gz</span><br><span class="line">fetch https://dl-cdn.alpinelinux.org/alpine/v3.14/community/x86_64/APKINDEX.tar.gz</span><br><span class="line">(1/6) Installing brotli-libs (1.0.9-r5)</span><br><span class="line">(2/6) Installing nghttp2-libs (1.43.0-r0)</span><br><span class="line">(3/6) Installing libcurl (7.79.1-r0)</span><br><span class="line">(4/6) Installing expat (2.4.1-r0)</span><br><span class="line">(5/6) Installing pcre2 (10.36-r0)</span><br><span class="line">(6/6) Installing git (2.32.0-r0)</span><br><span class="line">Executing busybox-1.33.1-r6.trigger</span><br><span class="line">OK: 23 MiB <span class="keyword">in</span> 28 packages</span><br><span class="line"></span><br><span class="line">/ <span class="comment"># git clone https://github.com/vfarcic/kaniko-demo.git</span></span><br><span class="line">Cloning into <span class="string">&#x27;kaniko-demo&#x27;</span>...</span><br><span class="line">remote: Enumerating objects: 193, <span class="keyword">done</span>.</span><br><span class="line">remote: Counting objects: 100% (193/193), <span class="keyword">done</span>.</span><br><span class="line">remote: Compressing objects: 100% (154/154), <span class="keyword">done</span>.</span><br><span class="line">remote: Total 193 (delta 36), reused 189 (delta 32), pack-reused 0</span><br><span class="line">Receiving objects: 100% (193/193), 5.92 MiB | 6.96 MiB/s, <span class="keyword">done</span>.</span><br><span class="line">Resolving deltas: 100% (36/36), <span class="keyword">done</span>.</span><br><span class="line"></span><br><span class="line">/ <span class="comment">#cd kaniko-demo</span></span><br><span class="line">/kaniko-demo <span class="comment"># docker image  build --tag devops-toolkit .</span></span><br><span class="line">Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/kaniko-demo <span class="comment"># exit</span></span><br><span class="line">$ kubectl delete -f docker.yaml</span><br></pre></td></tr></table></figure>

<p>结果验证，没有<code>/var/run/docker.sock</code>无法运行。</p>
<h2 id="9-验证-docker-容器内可行的构建方式"><a href="#9-验证-docker-容器内可行的构建方式" class="headerlink" title="9. 验证 docker 容器内可行的构建方式"></a>9. 验证 docker 容器内可行的构建方式</h2><p>接下来，将本地<code>/var/run/docker.sock</code>挂载至容器内再次尝试。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat docker-socket.yaml </span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">docker</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">docker</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">docker</span></span><br><span class="line">    <span class="attr">args:</span> [<span class="string">&quot;sleep&quot;</span>, <span class="string">&quot;10000&quot;</span>]</span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/var/run/docker.sock</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">docker-socket</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">docker-socket</span></span><br><span class="line">    <span class="attr">hostPath:</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/var/run/docker.sock</span></span><br></pre></td></tr></table></figure>

<p>再次创建名为 docker 的 pod</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl  apply -f docker-socket.yaml </span><br><span class="line">$ kubectl  get pods </span><br><span class="line">NAME                              READY   STATUS    RESTARTS      AGE</span><br><span class="line">docker                            1/1     Running   0             5s</span><br><span class="line"></span><br><span class="line"><span class="comment">#进入容器</span></span><br><span class="line">$ kubectl  <span class="built_in">exec</span> -ti docker -- sh</span><br><span class="line"><span class="comment">#安装git工具</span></span><br><span class="line">/ <span class="comment"># apk add -U git</span></span><br><span class="line">fetch https://dl-cdn.alpinelinux.org/alpine/v3.14/main/x86_64/APKINDEX.tar.gz</span><br><span class="line">fetch https://dl-cdn.alpinelinux.org/alpine/v3.14/community/x86_64/APKINDEX.tar.gz</span><br><span class="line">(1/6) Installing brotli-libs (1.0.9-r5)</span><br><span class="line">(2/6) Installing nghttp2-libs (1.43.0-r0)</span><br><span class="line">(3/6) Installing libcurl (7.79.1-r0)</span><br><span class="line">(4/6) Installing expat (2.4.1-r0)</span><br><span class="line">(5/6) Installing pcre2 (10.36-r0)</span><br><span class="line">(6/6) Installing git (2.32.0-r0)</span><br><span class="line">Executing busybox-1.33.1-r6.trigger</span><br><span class="line">OK: 23 MiB <span class="keyword">in</span> 28 packages</span><br><span class="line"></span><br><span class="line"><span class="comment">#下载 kaniko-demo</span></span><br><span class="line">/ <span class="comment"># git clone https://github.com/vfarcic/kaniko-demo.git</span></span><br><span class="line">Cloning into <span class="string">&#x27;kaniko-demo&#x27;</span>...</span><br><span class="line">remote: Enumerating objects: 193, <span class="keyword">done</span>.</span><br><span class="line">remote: Counting objects: 100% (193/193), <span class="keyword">done</span>.</span><br><span class="line">remote: Compressing objects: 100% (154/154), <span class="keyword">done</span>.</span><br><span class="line">remote: Total 193 (delta 36), reused 189 (delta 32), pack-reused 0</span><br><span class="line">Receiving objects: 100% (193/193), 5.92 MiB | 1.40 MiB/s, <span class="keyword">done</span>.</span><br><span class="line">Resolving deltas: 100% (36/36), <span class="keyword">done</span>.</span><br><span class="line"></span><br><span class="line"><span class="comment">#docker pod 构建镜像</span></span><br><span class="line">/kaniko-demo <span class="comment"># docker image  build --tag devops-toolkit .</span></span><br><span class="line">Sending build context to Docker daemon  17.46MB</span><br><span class="line">Step 1/9 : FROM klakegg/hugo:0.78.2-alpine AS build</span><br><span class="line"> ---&gt; 5729af47368d</span><br><span class="line">Step 2/9 : RUN apk add -U git</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 576762099db7</span><br><span class="line">Step 3/9 : COPY . /src</span><br><span class="line"> ---&gt; ebc824abfb73</span><br><span class="line">Step 4/9 : RUN make init</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 09c194a5e09c</span><br><span class="line">git submodule init</span><br><span class="line">Submodule <span class="string">&#x27;themes/forty&#x27;</span> (https://github.com/MarcusVirg/forty) registered <span class="keyword">for</span> path <span class="string">&#x27;themes/forty&#x27;</span></span><br><span class="line">git submodule update</span><br><span class="line">Cloning into <span class="string">&#x27;/src/themes/forty&#x27;</span>...</span><br><span class="line">Submodule path <span class="string">&#x27;themes/forty&#x27;</span>: checked out <span class="string">&#x27;dccea57bd2ed194942080d650671b47b6df4183c&#x27;</span></span><br><span class="line"><span class="built_in">cp</span> content/img/banner.jpg themes/forty/static/img/.</span><br><span class="line">Removing intermediate container 09c194a5e09c</span><br><span class="line"> ---&gt; 53a8ae3671db</span><br><span class="line">Step 5/9 : RUN make build</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 621916c3c908</span><br><span class="line">hugo</span><br><span class="line">Start building sites … </span><br><span class="line"></span><br><span class="line">                   | EN  </span><br><span class="line">-------------------+-----</span><br><span class="line">  Pages            | 19  </span><br><span class="line">  Paginator pages  |  0  </span><br><span class="line">  Non-page files   | 24  </span><br><span class="line">  Static files     | 97  </span><br><span class="line">  Processed images |  0  </span><br><span class="line">  Aliases          |  0  </span><br><span class="line">  Sitemaps         |  1  </span><br><span class="line">  Cleaned          |  0  </span><br><span class="line"></span><br><span class="line">Total <span class="keyword">in</span> 168 ms</span><br><span class="line">Removing intermediate container 621916c3c908</span><br><span class="line"> ---&gt; 23802d60ff30</span><br><span class="line">Step 6/9 : FROM nginx:1.19.4-alpine</span><br><span class="line"> ---&gt; e5dcd7aa4b5e</span><br><span class="line">Step 7/9 : RUN <span class="built_in">mv</span> /usr/share/nginx/html/index.html /usr/share/nginx/html/old-index.html</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 20bef7997cf5</span><br><span class="line">Step 8/9 : COPY --from=build /src/public /usr/share/nginx/html</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 09c4165acba5</span><br><span class="line">Step 9/9 : EXPOSE 80</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; d31aae51a63a</span><br><span class="line">Successfully built d31aae51a63a</span><br><span class="line">Successfully tagged devops-toolkit:latest</span><br><span class="line"></span><br><span class="line"><span class="comment">#登陆 docker.io 仓库</span></span><br><span class="line">/kaniko-demo <span class="comment"># docker login docker.io</span></span><br><span class="line">Login with your Docker ID to push and pull images from Docker Hub. If you don<span class="string">&#x27;t have a Docker ID, head over to https://hub.docker.com to create one.</span></span><br><span class="line"><span class="string">Username: ghostwritten</span></span><br><span class="line"><span class="string">Password:</span></span><br><span class="line"><span class="string">WARNING! Your password will be stored unencrypted in /root/.docker/config.json.</span></span><br><span class="line"><span class="string">Configure a credential helper to remove this warning. See</span></span><br><span class="line"><span class="string">https://docs.docker.com/engine/reference/commandline/login/#credentials-store</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Login Succeeded</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#推送镜像入库</span></span><br><span class="line"><span class="string">/kaniko-demo # docker tag  devops-toolkit:latest docker.io/ghostwritten/devops-toolkit:latest</span></span><br><span class="line"><span class="string">/kaniko-demo # docker pull docker.io/ghostwritten/devops-toolkit:latest</span></span><br><span class="line"><span class="string">latest: Pulling from ghostwritten/devops-toolkit</span></span><br><span class="line"><span class="string">Digest: sha256:f8255a312bc2cdcefa118b21f2f4f67877e7031426e2b96505e2a5a29fd6d8a0</span></span><br><span class="line"><span class="string">Status: Image is up to date for ghostwritten/devops-toolkit:latest</span></span><br><span class="line"><span class="string">docker.io/ghostwritten/devops-toolkit:latest</span></span><br><span class="line"><span class="string">/kaniko-demo # exit</span></span><br><span class="line"><span class="string">$ kubectl delete -f docker-socket.yaml</span></span><br></pre></td></tr></table></figure>

<p>这次，我们在docker pod内实现了构建镜像并推送入<code>docker.io</code>仓库。</p>
<p>接下来用 <code>kaniko</code> 工具 将以上过程实现自动化。</p>
<h2 id="10-Kaniko-构建推送入库"><a href="#10-Kaniko-构建推送入库" class="headerlink" title="10.Kaniko 构建推送入库"></a>10.Kaniko 构建推送入库</h2><h3 id="10-1-Git-Repository-推送-Docker-hub"><a href="#10-1-Git-Repository-推送-Docker-hub" class="headerlink" title="10.1 Git Repository 推送 Docker hub"></a>10.1 Git Repository 推送 Docker hub</h3><p>创建 secrets，关于仓库登陆认证</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">export</span> REGISTRY_SERVER=https://index.docker.io/v1/</span><br><span class="line">$ <span class="built_in">export</span> REGISTRY_USER=[xxx]</span><br><span class="line">$ <span class="built_in">export</span> REGISTRY_PASS=[xxx]</span><br><span class="line">$ <span class="built_in">export</span> REGISTRY_EMAIL=[xxx]</span><br><span class="line">$ kubectl --namespace=default create secret     docker-registry regcred     --docker-server=<span class="variable">$REGISTRY_SERVER</span>     --docker-username=<span class="variable">$REGISTRY_USER</span>     --docker-password=<span class="variable">$REGISTRY_PASS</span>     --docker-email=<span class="variable">$REGISTRY_EMAIL</span></span><br><span class="line">secret/regcred created</span><br></pre></td></tr></table></figure>

<p>编写<code>kaniko-git.yaml</code></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kaniko</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kaniko</span></span><br><span class="line">    <span class="comment">#image: gcr.io/kaniko-project/executor:debug</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">ghostwritten/kaniko-project-executor:debug</span></span><br><span class="line">    <span class="attr">args:</span> [<span class="string">&quot;--context=git://github.com/ghostwritten/kaniko-demo&quot;</span>,</span><br><span class="line">            <span class="string">&quot;--destination=ghostwritten/devops-toolkit:1.0.0&quot;</span>]</span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kaniko-secret</span></span><br><span class="line">        <span class="attr">mountPath:</span> <span class="string">/kaniko/.docker</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kaniko-secret</span></span><br><span class="line">      <span class="attr">secret:</span></span><br><span class="line">        <span class="attr">secretName:</span> <span class="string">regcred</span></span><br><span class="line">        <span class="attr">items:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">.dockerconfigjson</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">config.json</span></span><br><span class="line"><span class="string">$</span> <span class="string">k</span> <span class="string">apply</span> <span class="string">-f</span> <span class="string">kaniko-git.yaml</span></span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ k logs -f kaniko</span><br><span class="line">Enumerating objects: 193, <span class="keyword">done</span>.</span><br><span class="line">Counting objects: 100% (15/15), <span class="keyword">done</span>.</span><br><span class="line">Compressing objects: 100% (11/11), <span class="keyword">done</span>.</span><br><span class="line">Total 193 (delta 9), reused 4 (delta 4), pack-reused 178</span><br><span class="line">INFO[0005] Resolved base name klakegg/hugo:0.78.2-alpine to build</span><br><span class="line">INFO[0005] Using dockerignore file: /kaniko/buildcontext/.dockerignore</span><br><span class="line">INFO[0005] Retrieving image manifest klakegg/hugo:0.78.2-alpine</span><br><span class="line">INFO[0005] Retrieving image klakegg/hugo:0.78.2-alpine from registry index.docker.io</span><br><span class="line">INFO[0008] Retrieving image manifest nginx:1.19.4-alpine</span><br><span class="line">INFO[0008] Retrieving image nginx:1.19.4-alpine from registry index.docker.io</span><br><span class="line">INFO[0011] Built cross stage deps: map[0:[/src/public]]</span><br><span class="line">INFO[0011] Retrieving image manifest klakegg/hugo:0.78.2-alpine</span><br><span class="line">INFO[0011] Returning cached image manifest</span><br><span class="line">INFO[0011] Executing 0 build triggers</span><br><span class="line">INFO[0011] Building stage <span class="string">&#x27;klakegg/hugo:0.78.2-alpine&#x27;</span> [idx: <span class="string">&#x27;0&#x27;</span>, base-idx: <span class="string">&#x27;-1&#x27;</span>]</span><br><span class="line">INFO[0011] Unpacking rootfs as cmd RUN apk add -U git requires it.</span><br><span class="line">INFO[0019] RUN apk add -U git</span><br><span class="line">INFO[0019] Initializing snapshotter ...</span><br><span class="line">INFO[0019] Taking snapshot of full filesystem...</span><br><span class="line">INFO[0026] Cmd: /bin/sh</span><br><span class="line">INFO[0026] Args: [-c apk add -U git]</span><br><span class="line">INFO[0026] Running: [/bin/sh -c apk add -U git]</span><br><span class="line">fetch http://dl-cdn.alpinelinux.org/alpine/v3.12/main/x86_64/APKINDEX.tar.gz</span><br><span class="line">fetch http://dl-cdn.alpinelinux.org/alpine/v3.12/community/x86_64/APKINDEX.tar.gz</span><br><span class="line">(1/7) Installing ca-certificates (20220614-r0)</span><br><span class="line">(2/7) Installing nghttp2-libs (1.41.0-r0)</span><br><span class="line">(3/7) Installing libcurl (7.79.1-r1)</span><br><span class="line">(4/7) Installing expat (2.2.10-r4)</span><br><span class="line">(5/7) Installing pcre2 (10.35-r0)</span><br><span class="line">(6/7) Installing git (2.26.3-r1)</span><br><span class="line">(7/7) Installing git-bash-completion (2.26.3-r1)</span><br><span class="line">Executing busybox-1.31.1-r19.trigger</span><br><span class="line">Executing ca-certificates-20220614-r0.trigger</span><br><span class="line">OK: 30 MiB <span class="keyword">in</span> 30 packages</span><br><span class="line">INFO[0033] Taking snapshot of full filesystem...</span><br><span class="line">INFO[0037] COPY . /src</span><br><span class="line">INFO[0037] Taking snapshot of files...</span><br><span class="line">INFO[0038] RUN make init</span><br><span class="line">INFO[0038] Cmd: /bin/sh</span><br><span class="line">INFO[0038] Args: [-c make init]</span><br><span class="line">INFO[0038] Running: [/bin/sh -c make init]</span><br><span class="line">git submodule init</span><br><span class="line">Submodule <span class="string">&#x27;themes/forty&#x27;</span> (https://github.com/MarcusVirg/forty) registered <span class="keyword">for</span> path <span class="string">&#x27;themes/forty&#x27;</span></span><br><span class="line">git submodule update</span><br><span class="line">Cloning into <span class="string">&#x27;/src/themes/forty&#x27;</span>...</span><br><span class="line">Submodule path <span class="string">&#x27;themes/forty&#x27;</span>: checked out <span class="string">&#x27;dccea57bd2ed194942080d650671b47b6df4183c&#x27;</span></span><br><span class="line"><span class="built_in">cp</span> content/img/banner.jpg themes/forty/static/img/.</span><br><span class="line">INFO[0043] Taking snapshot of full filesystem...</span><br><span class="line">INFO[0048] RUN make build</span><br><span class="line">INFO[0048] Cmd: /bin/sh</span><br><span class="line">INFO[0048] Args: [-c make build]</span><br><span class="line">INFO[0048] Running: [/bin/sh -c make build]</span><br><span class="line">hugo</span><br><span class="line">Start building sites …</span><br><span class="line"></span><br><span class="line">                   | EN</span><br><span class="line">-------------------+-----</span><br><span class="line">  Pages            | 19</span><br><span class="line">  Paginator pages  |  0</span><br><span class="line">  Non-page files   | 24</span><br><span class="line">  Static files     | 97</span><br><span class="line">  Processed images |  0</span><br><span class="line">  Aliases          |  0</span><br><span class="line">  Sitemaps         |  1</span><br><span class="line">  Cleaned          |  0</span><br><span class="line"></span><br><span class="line">Total <span class="keyword">in</span> 195 ms</span><br><span class="line">INFO[0048] Taking snapshot of full filesystem...</span><br><span class="line">INFO[0052] Saving file src/public <span class="keyword">for</span> later use</span><br><span class="line">INFO[0052] Deleting filesystem...</span><br><span class="line">INFO[0052] Retrieving image manifest nginx:1.19.4-alpine</span><br><span class="line">INFO[0052] Returning cached image manifest</span><br><span class="line">INFO[0052] Executing 0 build triggers</span><br><span class="line">INFO[0052] Building stage <span class="string">&#x27;nginx:1.19.4-alpine&#x27;</span> [idx: <span class="string">&#x27;1&#x27;</span>, base-idx: <span class="string">&#x27;-1&#x27;</span>]</span><br><span class="line">INFO[0052] Unpacking rootfs as cmd RUN <span class="built_in">mv</span> /usr/share/nginx/html/index.html /usr/share/nginx/html/old-index.html requires it.</span><br><span class="line">INFO[0062] RUN <span class="built_in">mv</span> /usr/share/nginx/html/index.html /usr/share/nginx/html/old-index.html</span><br><span class="line">INFO[0062] Initializing snapshotter ...</span><br><span class="line">INFO[0062] Taking snapshot of full filesystem...</span><br><span class="line">INFO[0064] Cmd: /bin/sh</span><br><span class="line">INFO[0064] Args: [-c <span class="built_in">mv</span> /usr/share/nginx/html/index.html /usr/share/nginx/html/old-index.html]</span><br><span class="line">INFO[0064] Running: [/bin/sh -c <span class="built_in">mv</span> /usr/share/nginx/html/index.html /usr/share/nginx/html/old-index.html]</span><br><span class="line">INFO[0064] Taking snapshot of full filesystem...</span><br><span class="line">INFO[0064] COPY --from=build /src/public /usr/share/nginx/html</span><br><span class="line">INFO[0064] Taking snapshot of files...</span><br><span class="line">INFO[0065] EXPOSE 80</span><br><span class="line">INFO[0065] Cmd: EXPOSE</span><br><span class="line">INFO[0065] Adding exposed port: 80/tcp</span><br><span class="line">INFO[0065] Pushing image to ghostwritten/devops-toolkit:1.0.0</span><br><span class="line">INFO[0084] Pushed index.docker.io/ghostwritten/devops-toolkit@sha256:5fd0a9d47fa14e2dcb702497542992a9a180e67505fd858f02c7359bdc34bd68</span><br></pre></td></tr></table></figure>

<p>推送成功。</p>
<p>清理</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">k delete -f kaniko-git.yaml</span><br></pre></td></tr></table></figure>

<h3 id="10-2-Local-Directory-推送-Docker-hub"><a href="#10-2-Local-Directory-推送-Docker-hub" class="headerlink" title="10.2 Local Directory 推送 Docker hub"></a>10.2 Local Directory 推送 Docker hub</h3><p>创建 <code>secrets</code>，关于仓库登陆认证,步骤同上。</p>
<p>本地目录<code>/root/kaniko/kaniko-demo</code> 作为构建空间（workspace）</p>
<ul>
<li>• <code>kaniko-dir.yaml</code></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kaniko</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kaniko</span></span><br><span class="line"><span class="comment">#    image: gcr.io/kaniko-project/executor:debug</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">ghostwritten/kaniko-project-executor:latest</span></span><br><span class="line">    <span class="attr">args:</span> [<span class="string">&quot;--dockerfile=/workspace/Dockerfile&quot;</span>,</span><br><span class="line">            <span class="string">&quot;--context=dir://workspace&quot;</span>,</span><br><span class="line">            <span class="string">&quot;--destination=ghostwritten/devops-toolkit:1.0.0&quot;</span>]</span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kaniko-secret</span></span><br><span class="line">        <span class="attr">mountPath:</span> <span class="string">/kaniko/.docker</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">workspace</span></span><br><span class="line">        <span class="attr">mountPath:</span> <span class="string">/workspace</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kaniko-secret</span></span><br><span class="line">      <span class="attr">secret:</span></span><br><span class="line">        <span class="attr">secretName:</span> <span class="string">regcred</span></span><br><span class="line">        <span class="attr">items:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">.dockerconfigjson</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">config.json</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">workspace</span></span><br><span class="line">      <span class="attr">hostPath:</span> </span><br><span class="line">        <span class="attr">path:</span> <span class="string">/root/kaniko/kaniko-demo</span> </span><br></pre></td></tr></table></figure>

<p>创建 kaniko pod</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ k apply -f kaniko-dir.yaml </span><br><span class="line">pod/kaniko created</span><br></pre></td></tr></table></figure>

<p>跟踪<code>kaniko</code>构建镜像全部日志流程</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ k logs kaniko -f</span><br><span class="line">INFO[0000] Downloading base image klakegg/hugo:0.78.2-alpine</span><br><span class="line">INFO[0005] Extracting layer 0</span><br><span class="line">INFO[0010] Extracting layer 1</span><br><span class="line">INFO[0014] Extracting layer 2</span><br><span class="line">INFO[0015] Taking snapshot of full filesystem...</span><br><span class="line">INFO[0020] RUN apk add -U git</span><br><span class="line">INFO[0020] cmd: /bin/sh</span><br><span class="line">INFO[0020] args: [-c apk add -U git]</span><br><span class="line">fetch http://dl-cdn.alpinelinux.org/alpine/v3.12/main/x86_64/APKINDEX.tar.gz</span><br><span class="line">fetch http://dl-cdn.alpinelinux.org/alpine/v3.12/community/x86_64/APKINDEX.tar.gz</span><br><span class="line">(1/7) Installing ca-certificates (20220614-r0)</span><br><span class="line">(2/7) Installing nghttp2-libs (1.41.0-r0)</span><br><span class="line">(3/7) Installing libcurl (7.79.1-r1)</span><br><span class="line">(4/7) Installing expat (2.2.10-r4)</span><br><span class="line">(5/7) Installing pcre2 (10.35-r0)</span><br><span class="line">(6/7) Installing git (2.26.3-r1)</span><br><span class="line">(7/7) Installing git-bash-completion (2.26.3-r1)</span><br><span class="line">Executing busybox-1.31.1-r19.trigger</span><br><span class="line">Executing ca-certificates-20220614-r0.trigger</span><br><span class="line">OK: 30 MiB <span class="keyword">in</span> 30 packages</span><br><span class="line">INFO[0057] No files were changed, appending empty layer to config. No layer added to image.</span><br><span class="line">INFO[0057] COPY . /src</span><br><span class="line">INFO[0057] Creating directory /src</span><br><span class="line">INFO[0057] Copying file workspace/.dockerignore to /src/.dockerignore</span><br><span class="line">INFO[0057] Creating directory /src/.git</span><br><span class="line">INFO[0057] Copying file workspace/.git/HEAD to /src/.git/HEAD</span><br><span class="line">INFO[0057] Creating directory /src/.git/branches</span><br><span class="line">INFO[0057] Copying file workspace/.git/config to /src/.git/config</span><br><span class="line">INFO[0057] Copying file workspace/.git/description to /src/.git/description</span><br><span class="line">INFO[0057] Creating directory /src/.git/hooks</span><br><span class="line">...</span><br><span class="line">INFO[0058] Creating directory /src/themes</span><br><span class="line">INFO[0058] Copying file workspace/themes/.DS_Store to /src/themes/.DS_Store</span><br><span class="line">INFO[0058] Creating directory /src/themes/forty</span><br><span class="line">INFO[0058] No files were changed, appending empty layer to config. No layer added to image.</span><br><span class="line">INFO[0058] RUN make init</span><br><span class="line">INFO[0058] cmd: /bin/sh</span><br><span class="line">INFO[0058] args: [-c make init]</span><br><span class="line">git submodule init</span><br><span class="line">Submodule <span class="string">&#x27;themes/forty&#x27;</span> (https://github.com/MarcusVirg/forty) registered <span class="keyword">for</span> path <span class="string">&#x27;themes/forty&#x27;</span></span><br><span class="line">git submodule update</span><br><span class="line">Cloning into <span class="string">&#x27;/src/themes/forty&#x27;</span>...</span><br><span class="line">Submodule path <span class="string">&#x27;themes/forty&#x27;</span>: checked out <span class="string">&#x27;dccea57bd2ed194942080d650671b47b6df4183c&#x27;</span></span><br><span class="line"><span class="built_in">cp</span> content/img/banner.jpg themes/forty/static/img/.</span><br><span class="line">INFO[0063] No files were changed, appending empty layer to config. No layer added to image.</span><br><span class="line">INFO[0063] RUN make build</span><br><span class="line">INFO[0063] cmd: /bin/sh</span><br><span class="line">INFO[0063] args: [-c make build]</span><br><span class="line">hugo</span><br><span class="line">Start building sites …</span><br><span class="line"></span><br><span class="line">                   | EN</span><br><span class="line">-------------------+-----</span><br><span class="line">  Pages            | 19</span><br><span class="line">  Paginator pages  |  0</span><br><span class="line">  Non-page files   | 24</span><br><span class="line">  Static files     | 97</span><br><span class="line">  Processed images |  0</span><br><span class="line">  Aliases          |  0</span><br><span class="line">  Sitemaps         |  1</span><br><span class="line">  Cleaned          |  0</span><br><span class="line"></span><br><span class="line">Total <span class="keyword">in</span> 196 ms</span><br><span class="line">INFO[0064] Taking snapshot of full filesystem...</span><br><span class="line">INFO[0068] Adding whiteout <span class="keyword">for</span> /etc/ssl/certs/ca-cert-Verisign_Class_3_Public_Primary_Certification_Authority_-_G3.pem</span><br><span class="line">INFO[0068] Adding whiteout <span class="keyword">for</span> /etc/ssl/certs/ca-cert-GeoTrust_Universal_CA.pem</span><br><span class="line">INFO[0068] Adding whiteout <span class="keyword">for</span> /etc/ssl/certs/ca-cert-Staat_der_Nederlanden_Root_CA_-_G2.pem</span><br><span class="line">......</span><br><span class="line">INFO[0068] Adding whiteout <span class="keyword">for</span> /etc/ssl/certs/ca-cert-GeoTrust_Primary_Certification_Authority.pem</span><br><span class="line">INFO[0068] Adding whiteout <span class="keyword">for</span> /etc/ssl/certs/ca-cert-Chambers_of_Commerce_Root_-_2008.pem</span><br><span class="line">INFO[0078] Storing <span class="built_in">source</span> image from stage 0 at path /kaniko/stages/0</span><br><span class="line">INFO[0094] trying to extract to /kaniko/0</span><br><span class="line">INFO[0094] Extracting layer 0</span><br><span class="line">INFO[0096] Extracting layer 1</span><br><span class="line">INFO[0102] Extracting layer 2</span><br><span class="line">INFO[0105] Extracting layer 3</span><br><span class="line">INFO[0106] Deleting filesystem...</span><br><span class="line">INFO[0108] Downloading base image nginx:1.19.4-alpine</span><br><span class="line">INFO[0112] Extracting layer 0</span><br><span class="line">INFO[0114] Extracting layer 1</span><br><span class="line">INFO[0117] Extracting layer 2</span><br><span class="line">INFO[0118] Extracting layer 3</span><br><span class="line">INFO[0119] Extracting layer 4</span><br><span class="line">INFO[0120] Taking snapshot of full filesystem...</span><br><span class="line">INFO[0129] RUN <span class="built_in">mv</span> /usr/share/nginx/html/index.html /usr/share/nginx/html/old-index.html</span><br><span class="line">INFO[0129] cmd: /bin/sh</span><br><span class="line">INFO[0129] args: [-c <span class="built_in">mv</span> /usr/share/nginx/html/index.html /usr/share/nginx/html/old-index.html]</span><br><span class="line">INFO[0129] Taking snapshot of full filesystem...</span><br><span class="line">INFO[0130] Adding whiteout <span class="keyword">for</span> /usr/share/nginx/html/index.html</span><br><span class="line">INFO[0132] COPY --from=build /src/public /usr/share/nginx/html</span><br><span class="line">INFO[0132] Creating directory /usr/share/nginx/html</span><br><span class="line">INFO[0132] Copying file /kaniko/0/src/public/.DS_Store to /usr/share/nginx/html/.DS_Store</span><br><span class="line">INFO[0132] Copying file /kaniko/0/src/public/404.html to /usr/share/nginx/html/404.html</span><br><span class="line">INFO[0132] Creating directory /usr/share/nginx/html/categories</span><br><span class="line">INFO[0132] Copying file /kaniko/0/src/public/categories/index.html to /usr/share/nginx/html/categories/index.html</span><br><span class="line">......</span><br><span class="line">INFO[0132] Copying file /kaniko/0/src/public/tags/index.html to /usr/share/nginx/html/tags/index.html</span><br><span class="line">INFO[0132] Copying file /kaniko/0/src/public/tags/index.xml to /usr/share/nginx/html/tags/index.xml</span><br><span class="line">INFO[0132] Taking snapshot of files...</span><br><span class="line">INFO[0133] EXPOSE 80</span><br><span class="line">INFO[0133] cmd: EXPOSE</span><br><span class="line">INFO[0133] Adding exposed port: 80/tcp</span><br><span class="line">INFO[0133] No files changed <span class="keyword">in</span> this <span class="built_in">command</span>, skipping snapshotting.</span><br><span class="line">INFO[0133] No files were changed, appending empty layer to config. No layer added to image.</span><br><span class="line">2022/11/29 17:05:20 existing blob: sha256:f2dc206a393cd74df3fea6d4c1d3cefe209979e8dbcceb4893ec9eadcc10bc14</span><br><span class="line">2022/11/29 17:05:20 existing blob: sha256:188c0c94c7c576fff0792aca7ec73d67a2f7f4cb3a6e53a84559337260b36964</span><br><span class="line">2022/11/29 17:05:20 existing blob: sha256:85defa007a8b33f817a5113210cca4aca6681b721d4b44dc94928c265959d7d5</span><br><span class="line">2022/11/29 17:05:20 existing blob: sha256:0ca72de6f95718a4bd36e45f03fffa98e53819be7e75cb8cd1bcb0705b845939</span><br><span class="line">2022/11/29 17:05:20 existing blob: sha256:9dd8e8e549988a3e2c521f27f805b7a03d909d185bb01cdb4a4029e5a6702919</span><br><span class="line">2022/11/29 17:05:21 pushed blob sha256:424ba847df207f6ca013a0dfe3b10d028e0d1e52513c77bcbdd8083e64f7a2c8</span><br><span class="line">2022/11/29 17:05:22 pushed blob sha256:1c9dc8a83a9b96fb8d0c177eb4d0f72d0599430874321649c53b5a04bcab85eb</span><br><span class="line">2022/11/29 17:05:34 pushed blob sha256:359b4565665ba87176c012a844b8bd20947ae8c16ebcc3ac2ac5e754fb13ad28</span><br><span class="line">2022/11/29 17:05:34 index.docker.io/ghostwritten/devops-toolkit:1.0.0: digest: sha256:194a89239732f85f23d30ce516edd61177eb0c602cc59369001de9482ae64028 size: 1397</span><br></pre></td></tr></table></figure>

<p>构建并推送成功。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202212131540246.png" alt="图片"></p>
<h3 id="10-3Local-Directory-推送私有-Regsitry"><a href="#10-3Local-Directory-推送私有-Regsitry" class="headerlink" title="10.3Local Directory 推送私有 Regsitry"></a>10.3Local Directory 推送私有 Regsitry</h3><p>创建关于登陆认证的secret（regcred2）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ harbor-secret-regcred.sh</span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line">REGISTRY_SERVER=https://192.168.10.80:5000/v2/</span><br><span class="line">REGISTRY_USER=registryuser</span><br><span class="line">REGISTRY_PASS=registryuserpassword</span><br><span class="line">REGISTRY_EMAIL=1zoxun1@gmail.com</span><br><span class="line">kubectl --namespace=default create secret   docker-registry  regcred2     --docker-server=<span class="variable">$REGISTRY_SERVER</span>     --docker-username=<span class="variable">$REGISTRY_USER</span>     --docker-password=<span class="variable">$REGISTRY_PASS</span>     --docker-email=<span class="variable">$REGISTRY_EMAIL</span></span><br><span class="line"></span><br><span class="line">$ bash harbor-secret-regcred.sh</span><br></pre></td></tr></table></figure>

<p>创建 <code>kaniko-dir-registry.yaml</code></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kaniko2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kaniko</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">ghostwritten/kaniko-project-executor:latest</span></span><br><span class="line">    <span class="attr">args:</span> [<span class="string">&quot;--dockerfile=/workspace/Dockerfile&quot;</span>,</span><br><span class="line">            <span class="string">&quot;--context=dir://workspace&quot;</span>,</span><br><span class="line">            <span class="string">&quot;--skip-tls-verify&quot;</span>,</span><br><span class="line">            <span class="string">&quot;--destination=192.168.10.80:5000/devops-toolkit:1.0.0&quot;</span>]</span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kaniko-secret</span></span><br><span class="line">        <span class="attr">mountPath:</span> <span class="string">/kaniko/.docker</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">workspace</span></span><br><span class="line">        <span class="attr">mountPath:</span> <span class="string">/workspace</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kaniko-secret</span></span><br><span class="line">      <span class="attr">secret:</span></span><br><span class="line">        <span class="attr">secretName:</span> <span class="string">regcred2</span></span><br><span class="line">        <span class="attr">items:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">.dockerconfigjson</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">config.json</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">workspace</span></span><br><span class="line">      <span class="attr">hostPath:</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/root/kaniko/kaniko-demo</span></span><br></pre></td></tr></table></figure>

<p>创建：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">k apply -f  kaniko-dir-registry.yaml</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ k logs -f kaniko2</span><br><span class="line">......</span><br><span class="line">INFO[0275] EXPOSE 80</span><br><span class="line">INFO[0275] cmd: EXPOSE</span><br><span class="line">INFO[0275] Adding exposed port: 80/tcp</span><br><span class="line">INFO[0275] No files changed <span class="keyword">in</span> this <span class="built_in">command</span>, skipping snapshotting.</span><br><span class="line">INFO[0275] No files were changed, appending empty layer to config. No layer added to image.</span><br><span class="line">2022/12/01 17:21:09 pushed blob sha256:fc8330beeb9ffb5c51a92d48766c252658bbf88461597a63ba97c46faaa78d9b</span><br><span class="line">2022/12/01 17:21:09 pushed blob sha256:ad4f04e8f8bd4ced092141d586ebad5ae549dc84967efc92317377fdf1e7a46a</span><br><span class="line">2022/12/01 17:21:10 pushed blob sha256:85defa007a8b33f817a5113210cca4aca6681b721d4b44dc94928c265959d7d5</span><br><span class="line">2022/12/01 17:21:11 pushed blob sha256:9dd8e8e549988a3e2c521f27f805b7a03d909d185bb01cdb4a4029e5a6702919</span><br><span class="line">2022/12/01 17:21:11 pushed blob sha256:f2dc206a393cd74df3fea6d4c1d3cefe209979e8dbcceb4893ec9eadcc10bc14</span><br><span class="line">2022/12/01 17:21:11 pushed blob sha256:cdf31037b0faf780c5a5d7f385d64fb6144b0518733a033d181b964b372fe391</span><br><span class="line">2022/12/01 17:21:11 pushed blob sha256:188c0c94c7c576fff0792aca7ec73d67a2f7f4cb3a6e53a84559337260b36964</span><br><span class="line">2022/12/01 17:21:13 pushed blob sha256:0ca72de6f95718a4bd36e45f03fffa98e53819be7e75cb8cd1bcb0705b845939</span><br><span class="line">2022/12/01 17:21:13 192.168.10.80:5000/devops-toolkit:1.0.0: digest: sha256:7b2d0899f9b374eb69f92ec8ce578496509d75a804ea39694d55046aa10a9e15 size: 1397</span><br></pre></td></tr></table></figure>

<p>验证是否构建入库</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ curl  -k -u <span class="string">&quot;registryuser:registryuserpassword&quot;</span> https://192.168.10.80:5000/v2/_catalog</span><br><span class="line">&#123;<span class="string">&quot;repositories&quot;</span>:[<span class="string">&quot;alpine&quot;</span>,<span class="string">&quot;busybox&quot;</span>,<span class="string">&quot;devops-toolkit&quot;</span>,<span class="string">&quot;redis&quot;</span>,<span class="string">&quot;testuser/fedora-myhttpd&quot;</span>]&#125;</span><br><span class="line"></span><br><span class="line">curl  -k -u <span class="string">&quot;registryuser:registryuserpassword&quot;</span> https://192.168.10.80:5000/v2/devops-toolkit/tags/list</span><br><span class="line">&#123;<span class="string">&quot;name&quot;</span>:<span class="string">&quot;devops-toolkit&quot;</span>,<span class="string">&quot;tags&quot;</span>:[<span class="string">&quot;1.0.0&quot;</span>]&#125;</span><br></pre></td></tr></table></figure>

<p>推送成功。</p>
<h3 id="10-4-Local-Directory-推送镜像至私有-Harbor"><a href="#10-4-Local-Directory-推送镜像至私有-Harbor" class="headerlink" title="10.4 Local Directory 推送镜像至私有 Harbor"></a>10.4 Local Directory 推送镜像至私有 Harbor</h3><ul>
<li>Centos 7.9 部署 Harbor 镜像仓库实践</li>
</ul>
<p>考虑到 <code>CI/CD</code> 的业务特性，这里选用机器人用户，创建推送机器人。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202212131541744.png" alt="图片"></p>
<p>测试登陆</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker login -u <span class="string">&#x27;robot$kaniko-user&#x27;</span> -p YxJ3Bje3dKWoHy9EWfQ1PApzijCfvG5m https://harbor.k8s.com</span><br></pre></td></tr></table></figure>

<p>创建 <code>secret</code>，名为<code>harbor-regcred</code> ,脚本<code>harbor-secret-rgcred.sh</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">REGISTRY_SERVER=https:harbor.fumai.com/v2/</span><br><span class="line">REGISTRY_USER=<span class="string">&#x27;robot$kaniko-user&#x27;</span></span><br><span class="line">REGISTRY_PASS=zRPfq79SYQeJtzYDo1radbZYDAqfPa4L</span><br><span class="line">REGISTRY_EMAIL=1zoxun1@gmail.com</span><br><span class="line">kubectl --namespace=default create secret   docker-registry  harbor-regcred     --docker-server=<span class="variable">$REGISTRY_SERVER</span>     --docker-username=<span class="variable">$REGISTRY_USER</span>     --docker-password=<span class="variable">$REGISTRY_PASS</span>     --docker-email=<span class="variable">$REGISTRY_EMAIL</span></span><br></pre></td></tr></table></figure>

<p>创建 <code>secret</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sh harbor-secret-regcred.sh</span><br><span class="line">$ k get secret harbor-regcred</span><br><span class="line">NAME             TYPE                             DATA   AGE</span><br><span class="line">harbor-regcred   kubernetes.io/dockerconfigjson   1      3m30s</span><br><span class="line"></span><br><span class="line">$ kubectl get secret harbor-regcred --output=<span class="string">&quot;jsonpath=&#123;.data.\.dockerconfigjson&#125;&quot;</span> | <span class="built_in">base64</span> -d</span><br><span class="line">&#123;<span class="string">&quot;auths&quot;</span>:&#123;<span class="string">&quot;https:harbor.fumai.com/v2/&quot;</span>:&#123;<span class="string">&quot;username&quot;</span>:<span class="string">&quot;admin&quot;</span>,<span class="string">&quot;password&quot;</span>:<span class="string">&quot;Harbor12345&quot;</span>,<span class="string">&quot;email&quot;</span>:<span class="string">&quot;1zoxun1@gmail.com&quot;</span>,<span class="string">&quot;auth&quot;</span>:<span class="string">&quot;YWRtaW46SGFyYm9yMTIzNDU=&quot;</span>&#125;&#125;&#125;</span><br></pre></td></tr></table></figure>

<p>这里还需要给 通过CoreDNS[9] 给 <code>harbor.fumai.com</code> 做一个域名解析。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$  k edit cm -n kube-system coredns</span><br><span class="line">....</span><br><span class="line">       hosts &#123;</span><br><span class="line">           127.0.0.1 host.minikube.internal</span><br><span class="line">           192.168.10.81 harbor.fumai.com   <span class="comment"># 添加</span></span><br><span class="line">           fallthrough</span><br><span class="line">        &#125;</span><br><span class="line">.....</span><br></pre></td></tr></table></figure>

<p>创建 <code>kaniko-dir-harbor.yaml</code></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kaniko</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hostAliases:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">ip:</span> <span class="string">&quot;192.168.10.81&quot;</span></span><br><span class="line">    <span class="attr">hostnames:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;harbor.fumai.com&quot;</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kaniko</span></span><br><span class="line"><span class="comment">#    image: gcr.io/kaniko-project/executor:debug</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">ghostwritten/kaniko-project-executor:debug</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">args:</span> [<span class="string">&quot;--dockerfile=/workspace/Dockerfile&quot;</span>,</span><br><span class="line">            <span class="string">&quot;--context=dir://workspace&quot;</span>,</span><br><span class="line">            <span class="string">&quot;--skip-tls-verify&quot;</span>,</span><br><span class="line">            <span class="string">&quot;--destination=harbor.fumai.com/library/devops-toolkit:1.0.0&quot;</span>]</span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kaniko-secret</span></span><br><span class="line">        <span class="attr">mountPath:</span> <span class="string">/kaniko/.docker</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">workspace</span></span><br><span class="line">        <span class="attr">mountPath:</span> <span class="string">/workspace</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">hosts</span></span><br><span class="line">        <span class="attr">mountPath:</span> <span class="string">/etc/hosts</span></span><br><span class="line">        <span class="attr">subPath:</span> <span class="string">hosts</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kaniko-secret</span></span><br><span class="line">      <span class="attr">secret:</span></span><br><span class="line">        <span class="attr">secretName:</span> <span class="string">harbor-regcred</span></span><br><span class="line">        <span class="attr">items:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">.dockerconfigjson</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">config.json</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">workspace</span></span><br><span class="line">      <span class="attr">hostPath:</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/root/kaniko/kaniko-demo</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">hosts</span></span><br><span class="line">      <span class="attr">hostPath:</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/etc/hosts</span></span><br></pre></td></tr></table></figure>

<p>执行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ k apply -f kaniko-dir-harbor.yaml  </span><br><span class="line"></span><br><span class="line"><span class="comment">#查看日志</span></span><br><span class="line">$ k logs -f kaniko</span><br><span class="line">......</span><br><span class="line">INFO[0269] Taking snapshot of files...</span><br><span class="line">INFO[0270] EXPOSE 80</span><br><span class="line">INFO[0270] cmd: EXPOSE</span><br><span class="line">INFO[0270] Adding exposed port: 80/tcp</span><br><span class="line">INFO[0270] No files changed <span class="keyword">in</span> this <span class="built_in">command</span>, skipping snapshotting.</span><br><span class="line">INFO[0270] No files were changed, appending empty layer to config. No layer added to image.</span><br><span class="line">2022/12/08 00:46:50 existing blob: sha256:188c0c94c7c576fff0792aca7ec73d67a2f7f4cb3a6e53a84559337260b36964</span><br><span class="line">2022/12/08 00:46:50 existing blob: sha256:0ca72de6f95718a4bd36e45f03fffa98e53819be7e75cb8cd1bcb0705b845939</span><br><span class="line">2022/12/08 00:46:50 existing blob: sha256:9dd8e8e549988a3e2c521f27f805b7a03d909d185bb01cdb4a4029e5a6702919</span><br><span class="line">2022/12/08 00:46:50 existing blob: sha256:f2dc206a393cd74df3fea6d4c1d3cefe209979e8dbcceb4893ec9eadcc10bc14</span><br><span class="line">2022/12/08 00:46:50 existing blob: sha256:85defa007a8b33f817a5113210cca4aca6681b721d4b44dc94928c265959d7d5</span><br><span class="line">2022/12/08 00:46:50 pushed blob sha256:f9bec74bf820b9f4a41c7213263ffb780de1b95008bc112b0b091e84266cccad</span><br><span class="line">2022/12/08 00:46:50 pushed blob sha256:efc9fe50e3a3bba7be0bfdc2afe5c7425eaf5a272e3ba61e957295c714e6b927</span><br><span class="line">2022/12/08 00:46:52 pushed blob sha256:179b791301cd6ca8083e5adcb346d8daa2a0a6ac21fb357b128757602ee1db26</span><br><span class="line">2022/12/08 00:46:52 harbor.fumai.com/library/devops-toolkit:1.0.0: digest: sha256:3a77e618caf751879fce641f96988f9605b377e8421fe5b13aa0e0d694766152 size: 1397</span><br></pre></td></tr></table></figure>

<p>推送镜像入库成功。🥰</p>
<h3 id="10-5-Jenkins-Pipeline-amp-kaniko-构建镜像入库"><a href="#10-5-Jenkins-Pipeline-amp-kaniko-构建镜像入库" class="headerlink" title="10.5 Jenkins Pipeline &amp; kaniko 构建镜像入库"></a>10.5 Jenkins Pipeline &amp; kaniko 构建镜像入库</h3><ul>
<li>Minikube &amp; Helm 部署 Jenkins</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">podTemplate(name:</span> <span class="string">&#x27;kaniko-python-docker&#x27;</span><span class="string">,</span> <span class="attr">namespace:</span> <span class="string">&#x27;default&#x27;</span><span class="string">,</span> <span class="attr">yaml:</span> <span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">              kind: Pod</span></span><br><span class="line"><span class="string">              spec:</span></span><br><span class="line"><span class="string">                containers:</span></span><br><span class="line"><span class="string">                - name: kaniko</span></span><br><span class="line"><span class="string">                #  image: gcr.io/kaniko-project/executor:v1.6.0-debug</span></span><br><span class="line"><span class="string">                  image: ghostwritten/kaniko-project-executor:v1.6.0-debug</span></span><br><span class="line"><span class="string">                  imagePullPolicy: Always</span></span><br><span class="line"><span class="string">                  command:</span></span><br><span class="line"><span class="string">                  - sleep</span></span><br><span class="line"><span class="string">                  args:</span></span><br><span class="line"><span class="string">                  - 99d</span></span><br><span class="line"><span class="string">                  volumeMounts:</span></span><br><span class="line"><span class="string">                    - name: jenkins-docker-cfg</span></span><br><span class="line"><span class="string">                      mountPath: /kaniko/.docker</span></span><br><span class="line"><span class="string">                volumes:</span></span><br><span class="line"><span class="string">                - name: jenkins-docker-cfg</span></span><br><span class="line"><span class="string">                  secret:</span></span><br><span class="line"><span class="string">                    secretName: regcred</span></span><br><span class="line"><span class="string">                    items:</span></span><br><span class="line"><span class="string">                      - key: .dockerconfigjson</span></span><br><span class="line"><span class="string">                        path: config.json</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">  <span class="string">)</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="string">node(POD_LABEL)</span> &#123;</span><br><span class="line">    <span class="string">stage(&#x27;Build</span> <span class="string">with</span> <span class="string">Kaniko&#x27;)</span> &#123;</span><br><span class="line">      <span class="string">git</span> <span class="string">&#x27;https://github.com/Ghostwritten/kaniko-python-docker.git&#x27;</span></span><br><span class="line">      <span class="string">container(&#x27;kaniko&#x27;)</span> &#123;</span><br><span class="line">        <span class="string">sh</span> <span class="string">&#x27;/kaniko/executor -f `pwd`/Dockerfile -c `pwd` --cache=true --destination=ghostwritten/kaniko-python-docker:v1.0.1&#x27;</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>console output</code>:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Started by user Jenkins Admin</span><br><span class="line">[Pipeline] Start of Pipeline</span><br><span class="line">[Pipeline] podTemplate</span><br><span class="line">[Pipeline] &#123;</span><br><span class="line">[Pipeline] node</span><br><span class="line">Created Pod: minikube2 default/kaniko-python-docker-frnd7-1wnb4</span><br><span class="line">Still waiting to schedule task</span><br><span class="line">‘kaniko-python-docker-frnd7-1wnb4’ is offline</span><br><span class="line">Agent kaniko-python-docker-frnd7-1wnb4 is provisioned from template kaniko-python-docker-frnd7</span><br><span class="line">---</span><br><span class="line">apiVersion: <span class="string">&quot;v1&quot;</span></span><br><span class="line">kind: <span class="string">&quot;Pod&quot;</span></span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    buildUrl: <span class="string">&quot;http://192.168.10.26:32000/job/docker/21/&quot;</span></span><br><span class="line">    runUrl: <span class="string">&quot;job/docker/21/&quot;</span></span><br><span class="line">  labels:</span><br><span class="line">    jenkins/jenkins-jenkins-agent: <span class="string">&quot;true&quot;</span></span><br><span class="line">    jenkins/label-digest: <span class="string">&quot;117969f201f5b8afcc688a11799a14d3558b71c0&quot;</span></span><br><span class="line">    jenkins/label: <span class="string">&quot;docker_21-mlxg4&quot;</span></span><br><span class="line">  name: <span class="string">&quot;kaniko-python-docker-frnd7-1wnb4&quot;</span></span><br><span class="line">  namespace: <span class="string">&quot;default&quot;</span></span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - args:</span><br><span class="line">    - <span class="string">&quot;99d&quot;</span></span><br><span class="line">    <span class="built_in">command</span>:</span><br><span class="line">    - <span class="string">&quot;sleep&quot;</span></span><br><span class="line">    image: <span class="string">&quot;ghostwritten/kaniko-project-executor:v1.6.0-debug&quot;</span></span><br><span class="line">    imagePullPolicy: <span class="string">&quot;Always&quot;</span></span><br><span class="line">    name: <span class="string">&quot;kaniko&quot;</span></span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: <span class="string">&quot;/kaniko/.docker&quot;</span></span><br><span class="line">      name: <span class="string">&quot;jenkins-docker-cfg&quot;</span></span><br><span class="line">    - mountPath: <span class="string">&quot;/home/jenkins/agent&quot;</span></span><br><span class="line">      name: <span class="string">&quot;workspace-volume&quot;</span></span><br><span class="line">      readOnly: <span class="literal">false</span></span><br><span class="line">  - <span class="built_in">env</span>:</span><br><span class="line">    - name: <span class="string">&quot;JENKINS_SECRET&quot;</span></span><br><span class="line">      value: <span class="string">&quot;********&quot;</span></span><br><span class="line">    - name: <span class="string">&quot;JENKINS_TUNNEL&quot;</span></span><br><span class="line">      value: <span class="string">&quot;jenkins-agent.jenkins.svc.cluster.local:50000&quot;</span></span><br><span class="line">    - name: <span class="string">&quot;JENKINS_AGENT_NAME&quot;</span></span><br><span class="line">      value: <span class="string">&quot;kaniko-python-docker-frnd7-1wnb4&quot;</span></span><br><span class="line">    - name: <span class="string">&quot;JENKINS_NAME&quot;</span></span><br><span class="line">      value: <span class="string">&quot;kaniko-python-docker-frnd7-1wnb4&quot;</span></span><br><span class="line">    - name: <span class="string">&quot;JENKINS_AGENT_WORKDIR&quot;</span></span><br><span class="line">      value: <span class="string">&quot;/home/jenkins/agent&quot;</span></span><br><span class="line">    - name: <span class="string">&quot;JENKINS_URL&quot;</span></span><br><span class="line">      value: <span class="string">&quot;http://192.168.10.26:32000/&quot;</span></span><br><span class="line">    image: <span class="string">&quot;jenkins/inbound-agent:4.11-1-jdk11&quot;</span></span><br><span class="line">    name: <span class="string">&quot;jnlp&quot;</span></span><br><span class="line">    resources:</span><br><span class="line">      limits: &#123;&#125;</span><br><span class="line">      requests:</span><br><span class="line">        memory: <span class="string">&quot;256Mi&quot;</span></span><br><span class="line">        cpu: <span class="string">&quot;100m&quot;</span></span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: <span class="string">&quot;/home/jenkins/agent&quot;</span></span><br><span class="line">      name: <span class="string">&quot;workspace-volume&quot;</span></span><br><span class="line">      readOnly: <span class="literal">false</span></span><br><span class="line">  nodeSelector:</span><br><span class="line">    kubernetes.io/os: <span class="string">&quot;linux&quot;</span></span><br><span class="line">  restartPolicy: <span class="string">&quot;Never&quot;</span></span><br><span class="line">  volumes:</span><br><span class="line">  - name: <span class="string">&quot;jenkins-docker-cfg&quot;</span></span><br><span class="line">    secret:</span><br><span class="line">      items:</span><br><span class="line">      - key: <span class="string">&quot;.dockerconfigjson&quot;</span></span><br><span class="line">        path: <span class="string">&quot;config.json&quot;</span></span><br><span class="line">      secretName: <span class="string">&quot;regcred&quot;</span></span><br><span class="line">  - emptyDir:</span><br><span class="line">      medium: <span class="string">&quot;&quot;</span></span><br><span class="line">    name: <span class="string">&quot;workspace-volume&quot;</span></span><br><span class="line"></span><br><span class="line">Running on kaniko-python-docker-frnd7-1wnb4 <span class="keyword">in</span> /home/jenkins/agent/workspace/docker</span><br><span class="line">[Pipeline] &#123;</span><br><span class="line">[Pipeline] stage</span><br><span class="line">[Pipeline] &#123; (Build with Kaniko)</span><br><span class="line">[Pipeline] git</span><br><span class="line">The recommended git tool is: NONE</span><br><span class="line">No credentials specified</span><br><span class="line">Cloning the remote Git repository</span><br><span class="line">Cloning repository https://github.com/Ghostwritten/kaniko-python-docker.git</span><br><span class="line"> &gt; git init /home/jenkins/agent/workspace/docker <span class="comment"># timeout=10</span></span><br><span class="line">Fetching upstream changes from https://github.com/Ghostwritten/kaniko-python-docker.git</span><br><span class="line"> &gt; git --version <span class="comment"># timeout=10</span></span><br><span class="line"> &gt; git --version <span class="comment"># &#x27;git version 2.30.2&#x27;</span></span><br><span class="line"> &gt; git fetch --tags --force --progress -- https://github.com/Ghostwritten/kaniko-python-docker.git +refs/heads/*:refs/remotes/origin/* <span class="comment"># timeout=10</span></span><br><span class="line"> &gt; git config remote.origin.url https://github.com/Ghostwritten/kaniko-python-docker.git <span class="comment"># timeout=10</span></span><br><span class="line"> &gt; git config --add remote.origin.fetch +refs/heads/*:refs/remotes/origin/* <span class="comment"># timeout=10</span></span><br><span class="line">Avoid second fetch</span><br><span class="line">Checking out Revision 925d4779eb7b4d41840d9daabb5ef5518d65ed1c (refs/remotes/origin/master)</span><br><span class="line"> &gt; git rev-parse refs/remotes/origin/master^&#123;commit&#125; <span class="comment"># timeout=10</span></span><br><span class="line"> &gt; git config core.sparsecheckout <span class="comment"># timeout=10</span></span><br><span class="line"> &gt; git checkout -f 925d4779eb7b4d41840d9daabb5ef5518d65ed1c <span class="comment"># timeout=10</span></span><br><span class="line"> &gt; git branch -a -v --no-abbrev <span class="comment"># timeout=10</span></span><br><span class="line"> &gt; git checkout -b master 925d4779eb7b4d41840d9daabb5ef5518d65ed1c <span class="comment"># timeout=10</span></span><br><span class="line">Commit message: <span class="string">&quot;add kaniko python docker&quot;</span></span><br><span class="line">First time build. Skipping changelog.</span><br><span class="line">[Pipeline] container</span><br><span class="line">[Pipeline] &#123;</span><br><span class="line">[Pipeline] sh</span><br><span class="line">+ <span class="built_in">pwd</span></span><br><span class="line">+ <span class="built_in">pwd</span></span><br><span class="line">+ /kaniko/executor -f /home/jenkins/agent/workspace/docker/Dockerfile -c /home/jenkins/agent/workspace/docker <span class="string">&#x27;--cache=true&#x27;</span> <span class="string">&#x27;--destination=ghostwritten/kaniko-python-docker:v1.0.1&#x27;</span></span><br><span class="line">[36mINFO[0m[0002] Retrieving image manifest python:3.8-slim-buster </span><br><span class="line">[36mINFO[0m[0002] Retrieving image python:3.8-slim-buster from registry index.docker.io </span><br><span class="line">[36mINFO[0m[0004] Retrieving image manifest python:3.8-slim-buster </span><br><span class="line">[36mINFO[0m[0004] Returning cached image manifest              </span><br><span class="line">[36mINFO[0m[0006] Built cross stage deps: map[]                </span><br><span class="line">[36mINFO[0m[0006] Retrieving image manifest python:3.8-slim-buster </span><br><span class="line">[36mINFO[0m[0006] Returning cached image manifest              </span><br><span class="line">[36mINFO[0m[0006] Retrieving image manifest python:3.8-slim-buster </span><br><span class="line">[36mINFO[0m[0006] Returning cached image manifest              </span><br><span class="line">[36mINFO[0m[0006] Executing 0 build triggers                   </span><br><span class="line">[36mINFO[0m[0006] Checking <span class="keyword">for</span> cached layer index.docker.io/ghostwritten/kaniko-python-docker/cache:1c98e3b76b7eea791ef15553919754ea5ea0384db24733375b20585b5abf5c59... </span><br><span class="line">[36mINFO[0m[0008] No cached layer found <span class="keyword">for</span> cmd RUN pip3 install -r requirements.txt </span><br><span class="line">[36mINFO[0m[0008] Unpacking rootfs as cmd COPY requirements.txt requirements.txt requires it. </span><br><span class="line">[36mINFO[0m[0025] WORKDIR /app                                 </span><br><span class="line">[36mINFO[0m[0025] cmd: workdir                                 </span><br><span class="line">[36mINFO[0m[0025] Changed working directory to /app            </span><br><span class="line">[36mINFO[0m[0025] Creating directory /app                      </span><br><span class="line">[36mINFO[0m[0025] Taking snapshot of files...                  </span><br><span class="line">[36mINFO[0m[0025] COPY requirements.txt requirements.txt       </span><br><span class="line">[36mINFO[0m[0025] Taking snapshot of files...                  </span><br><span class="line">[36mINFO[0m[0025] RUN pip3 install -r requirements.txt         </span><br><span class="line">[36mINFO[0m[0025] Taking snapshot of full filesystem...        </span><br><span class="line">[36mINFO[0m[0027] cmd: /bin/sh                                 </span><br><span class="line">[36mINFO[0m[0027] args: [-c pip3 install -r requirements.txt]  </span><br><span class="line">[36mINFO[0m[0027] Running: [/bin/sh -c pip3 install -r requirements.txt] </span><br><span class="line">Collecting Flask==2.0.2</span><br><span class="line">  Downloading Flask-2.0.2-py3-none-any.whl (95 kB)</span><br><span class="line">     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 95.2/95.2 KB 291.8 kB/s eta 0:00:00</span><br><span class="line">Collecting itsdangerous&gt;=2.0</span><br><span class="line">  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)</span><br><span class="line">Collecting Jinja2&gt;=3.0</span><br><span class="line">  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)</span><br><span class="line">     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.1/133.1 KB 119.1 kB/s eta 0:00:00</span><br><span class="line">Collecting Werkzeug&gt;=2.0</span><br><span class="line">  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)</span><br><span class="line">     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 232.7/232.7 KB 54.5 kB/s eta 0:00:00</span><br><span class="line">Collecting click&gt;=7.1.2</span><br><span class="line">  Downloading click-8.1.3-py3-none-any.whl (96 kB)</span><br><span class="line">     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.6/96.6 KB 30.9 kB/s eta 0:00:00</span><br><span class="line">Collecting MarkupSafe&gt;=2.0</span><br><span class="line">  Downloading MarkupSafe-2.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)</span><br><span class="line">Installing collected packages: MarkupSafe, itsdangerous, click, Werkzeug, Jinja2, Flask</span><br><span class="line">Successfully installed Flask-2.0.2 Jinja2-3.1.2 MarkupSafe-2.1.1 Werkzeug-2.2.2 click-8.1.3 itsdangerous-2.1.2</span><br><span class="line">WARNING: Running pip as the <span class="string">&#x27;root&#x27;</span> user can result <span class="keyword">in</span> broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv</span><br><span class="line">WARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.</span><br><span class="line">You should consider upgrading via the <span class="string">&#x27;/usr/local/bin/python -m pip install --upgrade pip&#x27;</span> <span class="built_in">command</span>.</span><br><span class="line">[36mINFO[0m[0053] Taking snapshot of full filesystem...        </span><br><span class="line">[36mINFO[0m[0056] COPY . .                                     </span><br><span class="line">[36mINFO[0m[0056] Taking snapshot of files...                  </span><br><span class="line">[36mINFO[0m[0056] Pushing layer index.docker.io/ghostwritten/kaniko-python-docker/cache:1c98e3b76b7eea791ef15553919754ea5ea0384db24733375b20585b5abf5c59 to cache now </span><br><span class="line">[36mINFO[0m[0056] Pushing image to index.docker.io/ghostwritten/kaniko-python-docker/cache:1c98e3b76b7eea791ef15553919754ea5ea0384db24733375b20585b5abf5c59 </span><br><span class="line">[36mINFO[0m[0056] CMD [ <span class="string">&quot;python3&quot;</span>, <span class="string">&quot;app.py&quot;</span>]                   </span><br><span class="line">[36mINFO[0m[0056] No files changed <span class="keyword">in</span> this <span class="built_in">command</span>, skipping snapshotting. </span><br><span class="line">[33mWARN[0m[0058] error uploading layer to cache: failed to push to destination index.docker.io/ghostwritten/kaniko-python-docker/cache:1c98e3b76b7eea791ef15553919754ea5ea0384db24733375b20585b5abf5c59: HEAD https://index.docker.io/v2/ghostwritten/kaniko-python-docker/cache/blobs/sha256:c3aa9870d3065edb2286cac744c95fb0d2f1c98b2d8a231257314eda7d3598b0: unexpected status code 401 Unauthorized (HEAD responses have no body, use GET <span class="keyword">for</span> details) </span><br><span class="line">[36mINFO[0m[0058] Pushing image to ghostwritten/kaniko-python-docker:v1.0.1 </span><br><span class="line">[36mINFO[0m[0066] Pushed image to 1 destinations               </span><br><span class="line">[Pipeline] &#125;</span><br><span class="line">[Pipeline] // container</span><br><span class="line">[Pipeline] &#125;</span><br><span class="line">[Pipeline] // stage</span><br><span class="line">[Pipeline] &#125;</span><br><span class="line">[Pipeline] // node</span><br><span class="line">[Pipeline] &#125;</span><br><span class="line">[Pipeline] // podTemplate</span><br><span class="line">[Pipeline] End of Pipeline</span><br><span class="line">Finished: SUCCESS</span><br></pre></td></tr></table></figure>

<p>登陆 dockerhub[11] 查看新构建的镜像。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202212131532092.png" alt="图片"></p>
]]></content>
      <categories>
        <category>kubernetes</category>
        <category>Kaniko</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>Kaniko</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 Containerlab + Kind 快速部署 Cilium BGP 环境</title>
    <url>/2023/01/04/%E4%BD%BF%E7%94%A8Containerlab+Kind%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2CiliumBGP%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<h2 id="使用-Containerlab-Kind-快速部署-Cilium-BGP-环境"><a href="#使用-Containerlab-Kind-快速部署-Cilium-BGP-环境" class="headerlink" title="使用 Containerlab + Kind 快速部署 Cilium BGP 环境"></a>使用 Containerlab + Kind 快速部署 Cilium BGP 环境</h2><h3 id="1-1-Cilium-介绍"><a href="#1-1-Cilium-介绍" class="headerlink" title="1.1 Cilium 介绍"></a>1.1 Cilium 介绍</h3><p>Cilium 是一款基于 eBPF 技术的 Kubernetes CNI 插件，Cilium 在其官网上对产品的定位为 <strong>“eBPF-based Networking, Observability, Security”</strong>，致力于为容器工作负载提供基于 eBPF 的网络、可观察性和安全性的一系列解决方案。Cilium 通过使用 eBPF 技术在 Linux 内部动态插入一些控制逻辑，可以在不修改应用程序代码或容器配置的情况下进行应用和更新，从而实现网络、可观察性和安全性相关的功能。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081820396.png" alt="图片"></p>
<h3 id="1-2-Cilium-BGP-介绍"><a href="#1-2-Cilium-BGP-介绍" class="headerlink" title="1.2 Cilium BGP 介绍"></a>1.2 Cilium BGP 介绍</h3><p>BGP（Border Gateway Protocol，边界网关协议）是一种用于 AS（Autonomous System，自治系统）之间的动态路由协议。BGP 协议提供了丰富灵活的路由控制策略，早期主要用于互联网 AS 之间的互联。随着技术的发展，现在 BGP 协议在数据中心也得到了广泛的应用，现代数据中心网络通常是基于 Spine-Leaf 架构，其中 BGP 可用于传播端点的可达性信息。<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081814179.png" alt="图片"></p>
<p>Leaf 层由接入交换机组成，这些交换机会对来自服务器的流量进行汇聚并直接连接到 Spine 或网络核心，Spine 交换机以一种全网格拓扑与所有 Leaf 交换机实现互连。</p>
<p>随着 Kubernetes 在企业中的应用越来越多，这些端点有可能是 Kubernetes Pod，为了让 Kubernetes 集群外部的网络能够通过 BGP 协议动态获取到访问的 Pod 的路由，显然 Cilium 应该引入对 BGP 协议的支持。</p>
<p>在 Cilium 最初在 1.10 版本中引入了 BGP，通过为应用分配 LoadBalancer 类型的 Service 并结合 MetalLB，从而向 BGP 邻居宣告路由信息。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081808150.png" alt="图片"></p>
<p>然而，随着 IPv6 的使用持续增长，很明显 Cilium 需要 BGP IPv6 功能 – 包括 Segment Routing v6 (SRv6)。MetalLB 目前通过 FRR 对 IPv6 的支持有限，并且仍处于试验阶段。Cilium 团队评估了各种选项，并决定转向功能更丰富的 **GoBGP [1]**。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081803266.png" alt="图片"></p>
<p>在最新的 Cilium 1.12 版本中，启用对 BGP 的支持只需要设置 <code>--enable-bgp-control-plane=true</code> 参数，并且通过一个新的 CRD <code>CiliumBGPPeeringPolicy</code> 实现更加细粒度和可扩展的配置。</p>
<ul>
<li>使用 <code>nodeSelector</code> 参数通过标签选择，可以将相同的 BGP 配置应用于多个节点。</li>
<li>当 <code>exportPodCIDR</code> 参数设置为 true 时，可以动态地宣告所有 Pod CIDR，无需手动指定需要宣告哪些路由前缀。</li>
<li><code>neighbors</code> 参数用于设置 BGP 邻居信息，通常是集群外部的网络设备。</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">&quot;cilium.io/v2alpha1&quot;</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CiliumBGPPeeringPolicy</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">rack0</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">nodeSelector:</span></span><br><span class="line"><span class="attr">matchLabels:</span></span><br><span class="line"><span class="attr">rack:</span> <span class="string">rack0</span></span><br><span class="line"><span class="attr">virtualRouters:</span></span><br><span class="line">  <span class="attr">localASN:</span> <span class="number">65010</span></span><br><span class="line">    <span class="attr">exportPodCIDR:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">neighbors:</span></span><br><span class="line">      <span class="attr">peerAddress:</span> <span class="string">&quot;10.0.0.1/32&quot;</span></span><br><span class="line">        <span class="attr">peerASN:</span> <span class="number">65010</span></span><br></pre></td></tr></table></figure>

<h2 id="1-3-Kind-介绍"><a href="#1-3-Kind-介绍" class="headerlink" title="1.3 Kind 介绍"></a>1.3 Kind 介绍</h2><p>**Kind [2]**（Kubernetes in Docker）是一种使用 Docker 容器作为 Node 节点，运行本地 Kubernetes 集群的工具。我们仅需要安装好 Docker，就可以在几分钟内快速创建一个或多个 Kubernetes 集群。为了方便实验，本文使用 Kind 来搭建 Kubernetes 集群环境。</p>
<h3 id="1-4-Containerlab-介绍"><a href="#1-4-Containerlab-介绍" class="headerlink" title="1.4 Containerlab 介绍"></a>1.4 Containerlab 介绍</h3><p><strong>Containerlab [3]</strong> 提供了一种简单、轻量的、基于容器的编排网络实验的方案，支持各种容器化网络操作系统，例如：Cisco，Juniper，Nokia，Arista 等等。Containerlab 可以根据用户定义的配置文件，启动容器并在它们之间创建虚拟连接以构建用户定义网络拓扑。<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081757366.jpeg" alt="图片"></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">sonic01</span></span><br><span class="line"></span><br><span class="line"><span class="attr">topology:</span></span><br><span class="line">  <span class="attr">nodes:</span></span><br><span class="line">    <span class="attr">srl:</span></span><br><span class="line">      <span class="attr">kind:</span> <span class="string">srl</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">ghcr.io/nokia/srlinux</span></span><br><span class="line">    <span class="attr">sonic:</span></span><br><span class="line">      <span class="attr">kind:</span> <span class="string">sonic-vs</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">docker-sonic-vs:2020-11-12</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">links:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">endpoints:</span> [<span class="string">&quot;srl:e1-1&quot;</span>, <span class="string">&quot;sonic:eth1&quot;</span>]</span><br></pre></td></tr></table></figure>

<p>容器的管理接口会连接到名为 clab 的 bridge 类型的 Docker 网络中，业务接口通过配置文件中定义的 links 规则相连。这就好比数据中心中网络管理对应的带外管理（out-of-band）和带内管理（in-band）两种管理模式。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081750389.png" alt="图片"></p>
<p>Containerlab 还为我们提供了丰富的实验案例，可以在 <strong>Lab examples[4]</strong> 中找到。我们甚至可以通过 Containerlab 创建出一个数据中心级别的网络架构(参见 <strong>5-stage Clos fabric[5]</strong>)</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081745455.png" alt="图片"></p>
<h2 id="2-前提准备"><a href="#2-前提准备" class="headerlink" title="2 前提准备"></a>2 前提准备</h2><p>请根据相应的操作系统版本，选择合适的安装方式：</p>
<ul>
<li>安装 Docker: <a href="https://docs.docker.com/engine/install/">https://docs.docker.com/engine/install/</a></li>
<li>安装 Containerlab: <a href="https://containerlab.dev/install/">https://containerlab.dev/install/</a></li>
<li>安装 Kind: <a href="https://kind.sigs.k8s.io/docs/user/quick-start/#installing-with-a-package-manager">https://kind.sigs.k8s.io/docs/user/quick-start/#installing-with-a-package-manager</a></li>
<li>安装 Helm: <a href="https://helm.sh/docs/intro/install/">https://helm.sh/docs/intro/install/</a></li>
</ul>
<p>本文所用到的配置文件可以在 <a href="https://github.com/cr7258/kubernetes-guide/tree/master/containerlab/cilium-bgp">https://github.com/cr7258/kubernetes-guide/tree/master/containerlab/cilium-bgp</a> 中获取。</p>
<h2 id="3-通过-Kind-启动-Kubernetes-集群"><a href="#3-通过-Kind-启动-Kubernetes-集群" class="headerlink" title="3 通过 Kind 启动 Kubernetes 集群"></a>3 通过 Kind 启动 Kubernetes 集群</h2><p>准备一个 Kind 的配置文件，创建一个 4 节点的 Kubernetes 集群。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cluster.yaml</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Cluster</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">clab-bgp-cplane-demo</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">kind.x-k8s.io/v1alpha4</span></span><br><span class="line"><span class="attr">networking:</span></span><br><span class="line">  <span class="attr">disableDefaultCNI:</span> <span class="literal">true</span> <span class="comment"># 禁用默认 CNI</span></span><br><span class="line">  <span class="attr">podSubnet:</span> <span class="string">&quot;10.1.0.0/16&quot;</span> <span class="comment"># Pod CIDR</span></span><br><span class="line"><span class="attr">nodes:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">role:</span> <span class="string">control-plane</span> <span class="comment"># 节点角色</span></span><br><span class="line">  <span class="attr">kubeadmConfigPatches:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">|</span></span><br><span class="line"><span class="string">    kind: InitConfiguration</span></span><br><span class="line"><span class="string">    nodeRegistration:</span></span><br><span class="line"><span class="string">      kubeletExtraArgs:</span></span><br><span class="line"><span class="string">        node-ip: 10.0.1.2 # 节点 IP</span></span><br><span class="line"><span class="string">        node-labels: &quot;rack=rack0&quot; # 节点标签</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">role:</span> <span class="string">worker</span></span><br><span class="line">  <span class="attr">kubeadmConfigPatches:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">|</span></span><br><span class="line"><span class="string">    kind: JoinConfiguration</span></span><br><span class="line"><span class="string">    nodeRegistration:</span></span><br><span class="line"><span class="string">      kubeletExtraArgs:</span></span><br><span class="line"><span class="string">        node-ip: 10.0.2.2</span></span><br><span class="line"><span class="string">        node-labels: &quot;rack=rack0&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">role:</span> <span class="string">worker</span></span><br><span class="line">  <span class="attr">kubeadmConfigPatches:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">|</span></span><br><span class="line"><span class="string">    kind: JoinConfiguration</span></span><br><span class="line"><span class="string">    nodeRegistration:</span></span><br><span class="line"><span class="string">      kubeletExtraArgs:</span></span><br><span class="line"><span class="string">        node-ip: 10.0.3.2</span></span><br><span class="line"><span class="string">        node-labels: &quot;rack=rack1&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">role:</span> <span class="string">worker</span></span><br><span class="line">  <span class="attr">kubeadmConfigPatches:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">|</span></span><br><span class="line"><span class="string">    kind: JoinConfiguration</span></span><br><span class="line"><span class="string">    nodeRegistration:</span></span><br><span class="line"><span class="string">      kubeletExtraArgs:</span></span><br><span class="line"><span class="string">        node-ip: 10.0.4.2</span></span><br><span class="line"><span class="string">        node-labels: &quot;rack=rack1&quot;</span></span><br></pre></td></tr></table></figure>

<p>执行以下命令，通过 Kind 创建 Kubernetes 集群。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kind create cluster --config cluster.yaml</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081737515.png" alt="图片"></p>
<p>查看集群节点状态，由于当前我们尚未安装 CNI 插件，因此节点的状态是 NotReady。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get node</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081732970.png" alt="图片"></p>
<h2 id="4-启动-Containerlab"><a href="#4-启动-Containerlab" class="headerlink" title="4 启动 Containerlab"></a>4 启动 Containerlab</h2><p>定义 Containerlab 的配置文件，创建网络基础设施并连接 Kind 创建的 Kubernetes 集群：</p>
<ul>
<li>router0, tor0, tor1 作为 Kubernetes 集群外部的网络设备，在 exec 参数中设置网络接口信息以及 BGP 配置。router0 与 tor0, tor1 建立 BGP 邻居，tor0 与 server0, server1, router0 建立 BGP 邻居，tor1 与 server2, server3, router0 建立 BGP 邻居。</li>
<li>设置 <code>network-mode: container:&lt;容器名&gt;</code> 可以让 Containerlab 共享 Containerlab 之外启动的容器的网络命名空间，设置 server0, server1, server2, server3 容器分别连接到第 3 小节中通过 Kind 创建的 Kubernetes 集群的 4 个 Node 上。</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># topo.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="attr">name:</span> <span class="string">bgp-cplane-demo</span></span><br><span class="line"><span class="attr">topology:</span></span><br><span class="line"><span class="attr">kinds:</span></span><br><span class="line"><span class="attr">linux:</span></span><br><span class="line"><span class="attr">cmd:</span> <span class="string">bash</span></span><br><span class="line"><span class="attr">nodes:</span></span><br><span class="line"><span class="attr">router0:</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">linux</span></span><br><span class="line"><span class="attr">image:</span> <span class="string">frrouting/frr\:v8.2.2</span></span><br><span class="line"><span class="attr">labels:</span></span><br><span class="line"><span class="attr">app:</span> <span class="string">frr</span></span><br><span class="line"><span class="attr">exec:</span></span><br><span class="line"><span class="string">\-</span> <span class="string">iptables</span> <span class="string">-t</span> <span class="string">nat</span> <span class="string">-A</span> <span class="string">POSTROUTING</span> <span class="string">-o</span> <span class="string">eth0</span> <span class="string">-j</span> <span class="string">MASQUERADE</span></span><br><span class="line"><span class="string">\-</span> <span class="string">ip</span> <span class="string">addr</span> <span class="string">add</span> <span class="number">10.0</span><span class="number">.0</span><span class="number">.0</span><span class="string">/32</span> <span class="string">dev</span> <span class="string">lo</span></span><br><span class="line"><span class="string">\-</span> <span class="string">ip</span> <span class="string">route</span> <span class="string">add</span> <span class="string">blackhole</span> <span class="number">10.0</span><span class="number">.0</span><span class="number">.0</span><span class="string">/8</span></span><br><span class="line"><span class="string">\-</span> <span class="string">touch</span> <span class="string">/etc/frr/vtysh.conf</span></span><br><span class="line"><span class="string">\-</span> <span class="string">sed</span> <span class="string">-i</span> <span class="string">-e</span> <span class="string">&#x27;s/bgpd=no/bgpd=yes/g&#x27;</span> <span class="string">/etc/frr/daemons</span></span><br><span class="line"><span class="string">\-</span> <span class="string">usr/lib/frr/frrinit.sh</span> <span class="string">start</span></span><br><span class="line"><span class="string">\-</span> <span class="string">&gt;-</span></span><br><span class="line"><span class="string">vtysh</span> <span class="string">-c</span> <span class="string">&#x27;conf t&#x27;</span></span><br><span class="line"><span class="string">\-c</span> <span class="string">&#x27;router bgp 65000&#x27;</span></span><br><span class="line"><span class="string">\-c</span> <span class="string">&#x27; bgp router-id 10.0.0.0&#x27;</span></span><br><span class="line"><span class="string">\-c</span> <span class="string">&#x27; no bgp ebgp-requires-policy&#x27;</span></span><br><span class="line"><span class="string">\-c</span> <span class="string">&#x27; neighbor ROUTERS peer-group&#x27;</span></span><br><span class="line"><span class="string">\-c</span> <span class="string">&#x27; neighbor ROUTERS remote-as external&#x27;</span></span><br><span class="line"><span class="string">\-c</span> <span class="string">&#x27; neighbor ROUTERS default-originate&#x27;</span></span><br><span class="line"><span class="string">\-c</span> <span class="string">&#x27; neighbor net0 interface peer-group ROUTERS&#x27;</span></span><br><span class="line"><span class="string">\-c</span> <span class="string">&#x27; neighbor net1 interface peer-group ROUTERS&#x27;</span></span><br><span class="line"><span class="string">\-c</span> <span class="string">&#x27; address-family ipv4 unicast&#x27;</span></span><br><span class="line"><span class="string">\-c</span> <span class="string">&#x27;   redistribute connected&#x27;</span></span><br><span class="line"><span class="string">\-c</span> <span class="string">&#x27; exit-address-family&#x27;</span></span><br><span class="line"><span class="string">\-c</span> <span class="string">&#x27;!&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">tor0:</span></span><br><span class="line">      <span class="attr">kind:</span> <span class="string">linux</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">frrouting/frr:v8.2.2</span>  </span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">frr</span></span><br><span class="line">      <span class="attr">exec:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ip</span> <span class="string">link</span> <span class="string">del</span> <span class="string">eth0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ip</span> <span class="string">addr</span> <span class="string">add</span> <span class="number">10.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">/32</span> <span class="string">dev</span> <span class="string">lo</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ip</span> <span class="string">addr</span> <span class="string">add</span> <span class="number">10.0</span><span class="number">.1</span><span class="number">.1</span><span class="string">/24</span> <span class="string">dev</span> <span class="string">net1</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ip</span> <span class="string">addr</span> <span class="string">add</span> <span class="number">10.0</span><span class="number">.2</span><span class="number">.1</span><span class="string">/24</span> <span class="string">dev</span> <span class="string">net2</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">touch</span> <span class="string">/etc/frr/vtysh.conf</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">sed</span> <span class="string">-i</span> <span class="string">-e</span> <span class="string">&#x27;s/bgpd=no/bgpd=yes/g&#x27;</span> <span class="string">/etc/frr/daemons</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/usr/lib/frr/frrinit.sh</span> <span class="string">start</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&gt;-</span></span><br><span class="line"><span class="string">         vtysh -c &#x27;conf t&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27;frr defaults datacenter&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27;router bgp 65010&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27; bgp router-id 10.0.0.1&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27; no bgp ebgp-requires-policy&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27; neighbor ROUTERS peer-group&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27; neighbor ROUTERS remote-as external&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27; neighbor SERVERS peer-group&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27; neighbor SERVERS remote-as internal&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27; neighbor net0 interface peer-group ROUTERS&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27; neighbor 10.0.1.2 peer-group SERVERS&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27; neighbor 10.0.2.2 peer-group SERVERS&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27; address-family ipv4 unicast&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27;   redistribute connected&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27;  exit-address-family&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27;!&#x27;</span></span><br><span class="line"><span class="string">          </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"></span><br><span class="line">    <span class="attr">tor1:</span></span><br><span class="line">      <span class="attr">kind:</span> <span class="string">linux</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">frrouting/frr:v8.2.2</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">frr</span></span><br><span class="line">      <span class="attr">exec:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ip</span> <span class="string">link</span> <span class="string">del</span> <span class="string">eth0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ip</span> <span class="string">addr</span> <span class="string">add</span> <span class="number">10.0</span><span class="number">.0</span><span class="number">.2</span><span class="string">/32</span> <span class="string">dev</span> <span class="string">lo</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ip</span> <span class="string">addr</span> <span class="string">add</span> <span class="number">10.0</span><span class="number">.3</span><span class="number">.1</span><span class="string">/24</span> <span class="string">dev</span> <span class="string">net1</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ip</span> <span class="string">addr</span> <span class="string">add</span> <span class="number">10.0</span><span class="number">.4</span><span class="number">.1</span><span class="string">/24</span> <span class="string">dev</span> <span class="string">net2</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">touch</span> <span class="string">/etc/frr/vtysh.conf</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">sed</span> <span class="string">-i</span> <span class="string">-e</span> <span class="string">&#x27;s/bgpd=no/bgpd=yes/g&#x27;</span> <span class="string">/etc/frr/daemons</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/usr/lib/frr/frrinit.sh</span> <span class="string">start</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&gt;-</span></span><br><span class="line"><span class="string">         vtysh -c &#x27;conf t&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27;frr defaults datacenter&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27;router bgp 65011&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27; bgp router-id 10.0.0.2&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27; no bgp ebgp-requires-policy&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27; neighbor ROUTERS peer-group&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27; neighbor ROUTERS remote-as external&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27; neighbor SERVERS peer-group&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27; neighbor SERVERS remote-as internal&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27; neighbor net0 interface peer-group ROUTERS&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27; neighbor 10.0.3.2 peer-group SERVERS&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27; neighbor 10.0.4.2 peer-group SERVERS&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27; address-family ipv4 unicast&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27;   redistribute connected&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27;  exit-address-family&#x27;</span></span><br><span class="line"><span class="string">         -c &#x27;!&#x27;      </span></span><br><span class="line"><span class="string"></span></span><br><span class="line">    <span class="attr">server0:</span></span><br><span class="line">      <span class="attr">kind:</span> <span class="string">linux</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">nicolaka/netshoot:latest</span></span><br><span class="line">      <span class="attr">network-mode:</span> <span class="string">container:control-plane</span></span><br><span class="line">      <span class="attr">exec:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ip</span> <span class="string">addr</span> <span class="string">add</span> <span class="number">10.0</span><span class="number">.1</span><span class="number">.2</span><span class="string">/24</span> <span class="string">dev</span> <span class="string">net0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ip</span> <span class="string">route</span> <span class="string">replace</span> <span class="string">default</span> <span class="string">via</span> <span class="number">10.0</span><span class="number">.1</span><span class="number">.1</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">server1:</span></span><br><span class="line">      <span class="attr">kind:</span> <span class="string">linux</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">nicolaka/netshoot:latest</span></span><br><span class="line">      <span class="attr">network-mode:</span> <span class="string">container:worker</span></span><br><span class="line">      <span class="attr">exec:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ip</span> <span class="string">addr</span> <span class="string">add</span> <span class="number">10.0</span><span class="number">.2</span><span class="number">.2</span><span class="string">/24</span> <span class="string">dev</span> <span class="string">net0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ip</span> <span class="string">route</span> <span class="string">replace</span> <span class="string">default</span> <span class="string">via</span> <span class="number">10.0</span><span class="number">.2</span><span class="number">.1</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">server2:</span></span><br><span class="line">      <span class="attr">kind:</span> <span class="string">linux</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">nicolaka/netshoot:latest</span></span><br><span class="line">      <span class="attr">network-mode:</span> <span class="string">container:worker2</span></span><br><span class="line">      <span class="attr">exec:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ip</span> <span class="string">addr</span> <span class="string">add</span> <span class="number">10.0</span><span class="number">.3</span><span class="number">.2</span><span class="string">/24</span> <span class="string">dev</span> <span class="string">net0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ip</span> <span class="string">route</span> <span class="string">replace</span> <span class="string">default</span> <span class="string">via</span> <span class="number">10.0</span><span class="number">.3</span><span class="number">.1</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">server3:</span></span><br><span class="line">      <span class="attr">kind:</span> <span class="string">linux</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">nicolaka/netshoot:latest</span></span><br><span class="line">      <span class="attr">network-mode:</span> <span class="string">container:worker3</span></span><br><span class="line">      <span class="attr">exec:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ip</span> <span class="string">addr</span> <span class="string">add</span> <span class="number">10.0</span><span class="number">.4</span><span class="number">.2</span><span class="string">/24</span> <span class="string">dev</span> <span class="string">net0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ip</span> <span class="string">route</span> <span class="string">replace</span> <span class="string">default</span> <span class="string">via</span> <span class="number">10.0</span><span class="number">.4</span><span class="number">.1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">links:</span></span><br><span class="line"></span><br><span class="line"><span class="string">*</span>   <span class="attr">endpoints:</span> <span class="string">\[&quot;router0\:net0&quot;,</span> <span class="string">&quot;tor0\:net0&quot;</span><span class="string">]</span></span><br><span class="line"><span class="string">*</span>   <span class="attr">endpoints:</span> <span class="string">\[&quot;router0\:net1&quot;,</span> <span class="string">&quot;tor1\:net0&quot;</span><span class="string">]</span></span><br><span class="line"><span class="string">*</span>   <span class="attr">endpoints:</span> <span class="string">\[&quot;tor0\:net1&quot;,</span> <span class="string">&quot;server0\:net0&quot;</span><span class="string">]</span></span><br><span class="line"><span class="string">*</span>   <span class="attr">endpoints:</span> <span class="string">\[&quot;tor0\:net2&quot;,</span> <span class="string">&quot;server1\:net0&quot;</span><span class="string">]</span></span><br><span class="line"><span class="string">*</span>   <span class="attr">endpoints:</span> <span class="string">\[&quot;tor1\:net1&quot;,</span> <span class="string">&quot;server2\:net0&quot;</span><span class="string">]</span></span><br><span class="line"><span class="string">*</span>   <span class="attr">endpoints:</span> <span class="string">\[&quot;tor1\:net2&quot;,</span> <span class="string">&quot;server3\:net0&quot;</span><span class="string">]</span></span><br></pre></td></tr></table></figure>

<p>执行以下命令，创建 Containerlab 实验环境。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">clab deploy -t topo.yaml</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081723831.png" alt="图片"></p>
<p>创建完的拓扑如下所示，当前只有 tor0, tor1 和 router0 设备之间建立了 BGP 连接，由于我们尚未通过 CiliumBGPPeeringPolicy 设置 Kubernetes 集群的 BGP 配置，因此 tor0, tor1 与 Kubernetes Node 的 BGP 连接还没有建立。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081719277.png" alt="图片"></p>
<p>分别执行以下命令，可以查看 tor0, tor1, router0 3 个网络设备当前的 BGP 邻居建立情况。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it clab-bgp-cplane-demo-tor0 vtysh -c <span class="string">&quot;show bgp ipv4 summary wide&quot;</span></span><br><span class="line">docker <span class="built_in">exec</span> -it clab-bgp-cplane-demo-tor1 vtysh -c <span class="string">&quot;show bgp ipv4 summary wide&quot;</span></span><br><span class="line">docker <span class="built_in">exec</span> -it clab-bgp-cplane-demo-router0 vtysh -c <span class="string">&quot;show bgp ipv4 summary wide&quot;</span></span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081709640.png" alt="图片"></p>
<p>执行以下命令，查看 router0 设备现在学到的 BGP 路由条目。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it clab-bgp-cplane-demo-router0 vtysh -c <span class="string">&quot;show bgp ipv4 wide&quot;</span></span><br></pre></td></tr></table></figure>

<p>当前总共有 8 条路由条目，此时还未学到 Pod 相关的路由。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081844203.png" alt="图片"></p>
<p>为了方便用户更直观地了解实验的网络结构，Containerlab 提供 <code>graph</code> 命令生成网络拓扑。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">clab graph -t topo.yaml </span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081850931.png" alt="图片"></p>
<p>在浏览器输入 http:&#x2F;&#x2F;&lt;宿主机 IP&gt;:50080 可以查看 Containerlab 生成的拓扑图。<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081857049.png" alt="图片"></p>
<h2 id="5-安装-Cilium"><a href="#5-安装-Cilium" class="headerlink" title="5 安装 Cilium"></a>5 安装 Cilium</h2><p>本例中使用 Helm 来安装 Cilium，在 values.yaml 配置文件中设置我们需要调整的 Cilium 配置参数。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># values.yaml</span></span><br><span class="line"><span class="attr">tunnel:</span> <span class="string">disabled</span></span><br><span class="line"></span><br><span class="line"><span class="attr">ipam:</span></span><br><span class="line">  <span class="attr">mode:</span> <span class="string">kubernetes</span></span><br><span class="line"></span><br><span class="line"><span class="attr">ipv4NativeRoutingCIDR:</span> <span class="number">10.0</span><span class="number">.0</span><span class="number">.0</span><span class="string">/8</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 开启 BGP 功能支持，等同于命令行执行 --enable-bgp-control-plane=true</span></span><br><span class="line"><span class="attr">bgpControlPlane:</span>  </span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="attr">k8s:</span></span><br><span class="line">  <span class="attr">requireIPv4PodCIDR:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p>执行以下命令，安装 Cilium 1.12 版本，开启 BGP 功能支持。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm repo add cilium https://helm.cilium.io/</span><br><span class="line">helm install -n kube-system cilium cilium/cilium --version v1.12.1 -f values.yaml</span><br></pre></td></tr></table></figure>

<p>等待所有 Cilium Pod 启动完毕后，再次查看 Kubernetes Node 状态，可以看到所有 Node 都已经处于 Ready 状态了。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081907268.png" alt="图片"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081914118.png" alt="图片"></p>
<h2 id="6-Cilium-节点配置-BGP"><a href="#6-Cilium-节点配置-BGP" class="headerlink" title="6 Cilium 节点配置 BGP"></a>6 Cilium 节点配置 BGP</h2><p>接下来分别为 rack0 和 rack1 两个机架上 Kubernetes Node 配置 CiliumBGPPeeringPolicy。rack0 和 rack1 分别对应 Node 的 label，在第 3 小节中 Kind 的配置文件中做过设置。</p>
<p>rack0 的 Node 与 tor0 建立 BGP 邻居，rack1 的 Node 与 tor1 建立 BGP 邻居，并自动宣告 Pod CIDR 给 BGP 邻居。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cilium-bgp-peering-policies.yaml </span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">&quot;cilium.io/v2alpha1&quot;</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CiliumBGPPeeringPolicy</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">rack0</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">nodeSelector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">rack:</span> <span class="string">rack0</span></span><br><span class="line">  <span class="attr">virtualRouters:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">localASN:</span> <span class="number">65010</span></span><br><span class="line">    <span class="attr">exportPodCIDR:</span> <span class="literal">true</span> <span class="comment"># 自动宣告 Pod CIDR</span></span><br><span class="line">    <span class="attr">neighbors:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">peerAddress:</span> <span class="string">&quot;10.0.0.1/32&quot;</span> <span class="comment"># tor0 的 IP 地址</span></span><br><span class="line">      <span class="attr">peerASN:</span> <span class="number">65010</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">&quot;cilium.io/v2alpha1&quot;</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CiliumBGPPeeringPolicy</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">rack1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">nodeSelector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">rack:</span> <span class="string">rack1</span></span><br><span class="line">  <span class="attr">virtualRouters:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">localASN:</span> <span class="number">65011</span></span><br><span class="line">    <span class="attr">exportPodCIDR:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">neighbors:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">peerAddress:</span> <span class="string">&quot;10.0.0.2/32&quot;</span> <span class="comment"># tor1 的 IP 地址</span></span><br><span class="line">      <span class="attr">peerASN:</span> <span class="number">65011</span></span><br></pre></td></tr></table></figure>

<p>执行以下命令，应用 CiliumBGPPeeringPolicy。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f cilium-bgp-peering-policies.yaml </span><br></pre></td></tr></table></figure>

<p>创建完的拓扑如下所示，现在 tor0 和 tor1 也已经和 Kubernetes Node 建立了 BGP 邻居。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081922225.png" alt="图片"></p>
<p>分别执行以下命令，可以查看 tor0, tor1, router0 3 个网络设备当前的 BGP 邻居建立情况。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it clab-bgp-cplane-demo-tor0 vtysh -c <span class="string">&quot;show bgp ipv4 summary wide&quot;</span></span><br><span class="line">docker <span class="built_in">exec</span> -it clab-bgp-cplane-demo-tor1 vtysh -c <span class="string">&quot;show bgp ipv4 summary wide&quot;</span></span><br><span class="line">docker <span class="built_in">exec</span> -it clab-bgp-cplane-demo-router0 vtysh -c <span class="string">&quot;show bgp ipv4 summary wide&quot;</span></span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081927456.png" alt="图片"></p>
<p>执行以下命令，查看 router0 设备现在学到的 BGP 路由条目。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it clab-bgp-cplane-demo-router0 vtysh -c <span class="string">&quot;show bgp ipv4 wide&quot;</span></span><br></pre></td></tr></table></figure>

<p>当前总共有 12 条路由条目，其中多出来的 4 条路由是从 Kubernetes 4 个 Node 学到的 10.1.x.0&#x2F;24 网段的路由。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081934566.png" alt="图片"></p>
<h2 id="7-验证测试"><a href="#7-验证测试" class="headerlink" title="7 验证测试"></a>7 验证测试</h2><p>分别在 rack0 和 rack1 所在的节点上创建 1 个 Pod 用于测试网络的连通性。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># nettool.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">run:</span> <span class="string">nettool-1</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nettool-1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">cr7258/nettool:v1</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">nettool-1</span></span><br><span class="line">  <span class="attr">nodeSelector:</span></span><br><span class="line">    <span class="attr">rack:</span> <span class="string">rack0</span> </span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">run:</span> <span class="string">nettool-2</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nettool-2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">cr7258/nettool:v1</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">nettool-2</span></span><br><span class="line">  <span class="attr">nodeSelector:</span></span><br><span class="line">    <span class="attr">rack:</span> <span class="string">rack1</span></span><br></pre></td></tr></table></figure>

<p>执行以下命令，创建 2 个测试 Pod。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f nettool.yaml</span><br></pre></td></tr></table></figure>

<p>查看 Pod 的 IP 地址。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pod -o wide</span><br></pre></td></tr></table></figure>

<p>nettool-1 Pod 位于 clab-bgp-cplane-demo-worker（server1, rack0）上，IP 地址是 10.1.2.185；nettool-2 Pod 位于 clab-bgp-cplane-demo-worker3（server3, rack1） 上，IP 地址是 10.1.3.56。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081941722.png" alt="图片"></p>
<p>执行以下命令，在 nettool-1 Pod 中尝试 ping nettool-2 Pod。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl <span class="built_in">exec</span> -it nettool-1 -- ping 10.1.3.56 </span><br></pre></td></tr></table></figure>

<p>可以看到 nettool-1 Pod 能够正常访问 nettool-2 Pod。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081948904.png" alt="图片"></p>
<p>接下来使用 traceroute 命令观察网络数据包的走向。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl <span class="built_in">exec</span> -it nettool-1 -- traceroute -n 10.1.3.56</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081953445.png" alt="图片"></p>
<p>数据包从 nettool-1 Pod 发出，依次经过了：</p>
<blockquote>
<p>1.<strong>server1 的 cilium_host 接口</strong>：Cilium 网络中 Pod 的默认路由指向了本机的 cilium_host。cilium_host 和cilium_net 是一对 veth pair 设备。Cilium 通过 hardcode ARP 表，强制将 Pod 流量的下一跳劫持到 veth pair 的主机端。</p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901081959740.png" alt="图片"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901082004795.png" alt="图片"></p>
<blockquote>
<p>2.<strong>tor0 的 net2 接口</strong>。<br>3.<strong>router0 的 lo0 接口</strong>：tor0, tor1 和 router0 3 个网络设备间通过本地环回口 lo0 建立 BGP 邻居，这样做可以在有多条物理链路备份的情况下提升 BGP 邻居的稳健性，不会因为某个物理接口故障时而影响到邻居关系。<br>4.<strong>tor1 的 lo0 接口</strong>。<br>5.<strong>server3 的 net0 接口</strong>。<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/640-20220901082010611.png" alt="图片"></p>
</blockquote>
<h2 id="8-清理环境"><a href="#8-清理环境" class="headerlink" title="8 清理环境"></a>8 清理环境</h2><p>执行以下命令，清理 Containerlab 和 Kind 创建的实验环境。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">clab destroy -t topo.yaml</span><br><span class="line">kind delete clusters clab-bgp-cplane-demo</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kubernetes</category>
        <category>Cilium</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>Cilium</tag>
        <tag>Kind</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式存储系统 Ceph操作</title>
    <url>/2023/01/09/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%20Ceph%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><blockquote>
<p>Ceph 是当前非常流行的开源分布式存储系统，具有高扩展性、高性能、高可靠性等优点，同时提供**块存储服务(rbd)*<em>、*<em>对象存储服务(rgw)</em></em> 以及 文件系统存储服务(cephfs)，Ceph 在存储的时候充分利用存储节点的计算能力，在存储每一个数据时都会通过计算得出该数据的位置，尽量的分布均衡。目前也是 OpenStack 的主流后端存储。</p>
</blockquote>
<p>关于 Ceph 更详细的介绍和环境部署可以参考这篇文章：<a href="http://mp.weixin.qq.com/s?__biz=MjM5MzU5NDYwNA==&mid=2247506751&idx=2&sn=a374e3102475118d5ef56dfaf031e98b&chksm=a69636bc91e1bfaa0c26309d5e802606ecc33048a0637e4bc8024dc7c26e9c9fdf79b15c0cdf&scene=21#wechat_redirect"><em>分布式存储系统 Ceph 介绍与环境部署</em></a></p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301091052817.png" alt="图片"></p>
<h2 id="二、cephadm-工具的使用"><a href="#二、cephadm-工具的使用" class="headerlink" title="二、cephadm 工具的使用"></a>二、cephadm 工具的使用</h2><p>cephadm 官方文档</p>
<h3 id="1）cephadm-工具的介绍"><a href="#1）cephadm-工具的介绍" class="headerlink" title="1）cephadm 工具的介绍"></a>1）cephadm 工具的介绍</h3><blockquote>
<p>cephadm 是用于管理 Ceph 集群的实用程序或者是管理工具。</p>
</blockquote>
<p>Cephadm 的目标是提供一个功能齐全、健壮且维护良好的安装和管理层，可供不在 Kubernetes 中运行 Ceph 的任何环境使用。具体特性如下：</p>
<ul>
<li><strong>将所有组件部署在容器中</strong>—— 使用容器简化了不同发行版之间的依赖关系和打包复杂度。当然，我们仍在构建 RPM 和 Deb 软件包，但是随着越来越多的用户过渡到 cephadm（或 Rook）并构建容器，我们看到的特定于操作系统的 bug 就越少。</li>
<li><strong>与 Orchestrator API 紧密集成</strong>—— Ceph 的 Orchestrator 界面在 cephadm 的开发过程中得到了广泛的发展，以匹配实现并清晰地抽象出 Rook 中存在的（略有不同）功能。最终结果是不管是看起来还是感觉都像 Ceph 的一部分。</li>
<li><strong>不依赖管理工具</strong>——Salt 和 Ansible 之类的工具在大型环境中进行大规模部署时非常出色，但是使 Ceph 依赖于这种工具意味着用户还需要学习该相关的软件。更重要的是，与专为管理 Ceph 而专门设计的部署工具相比，依赖这些工具（Salt 和 Ansible 等）的部署最终可能变得更加复杂，难以调试并且（最显着）更慢。</li>
<li><strong>最小的操作系统依赖性</strong>—— Cephadm 需要<code>Python 3</code>，<code>LVM</code>和<code>container runtime（Podman或Docker）</code>。任何当前的 Linux 发行版都可以。</li>
<li><strong>将群集彼此隔离</strong>—— 支持多个 Ceph 集群同时存在于同一主机上一直是一个比较小众的场景，但是确实存在，并且以一种健壮，通用的方式将集群彼此隔离，这使得测试和重新部署集群对于开发人员和用户而言都是安全自然的过程。</li>
<li><strong>自动升级</strong>—— 一旦 Ceph“拥有”自己的部署方式，它就可以以安全和自动化的方式升级 Ceph。</li>
<li><strong>从“传统”部署工具轻松迁移</strong>——我们需要从现有工具（例如 ceph-ansible，ceph-deploy 和 DeepSea）中现有的 Ceph 部署轻松过渡到 cephadm。</li>
</ul>
<p>以下是一些事情的列表 cephadm 可以做：</p>
<ul>
<li>cephadm 可以将 Ceph 容器添加到集群。</li>
<li>cephadm 可以从集群中移除 Ceph 容器。</li>
<li>cephadm 可以更新 Ceph 容器。</li>
</ul>
<h3 id="2）cephadm-安装"><a href="#2）cephadm-安装" class="headerlink" title="2）cephadm 安装"></a>2）cephadm 安装</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /opt/ceph/my-cluster ; <span class="built_in">cd</span> /opt/ceph/my-cluster</span><br><span class="line">curl --silent --remote-name --location https://github.com/ceph/ceph/raw/octopus/src/cephadm/cephadm  -o cephadm</span><br><span class="line"><span class="built_in">chmod</span> +x cephadm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始安装ceph-common，ceph工具</span></span><br><span class="line">./cephadm install ceph-common ceph</span><br><span class="line"><span class="comment"># 安装cephadm工具</span></span><br><span class="line">./cephadm install</span><br><span class="line"><span class="built_in">which</span> cephadm</span><br><span class="line"><span class="built_in">which</span> ceph</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看帮助</span></span><br><span class="line">cephadm --<span class="built_in">help</span></span><br></pre></td></tr></table></figure>

<h3 id="3）cephadm-常用命令使用"><a href="#3）cephadm-常用命令使用" class="headerlink" title="3）cephadm 常用命令使用"></a>3）cephadm 常用命令使用</h3><p>一般使用 cephadm 用作环境初始化，其它的操作交由 ceph 工具完成，常用命令如下：</p>
<blockquote>
<p>cephadm 模型有一个简单的“ Bootstrap ”步骤，该步骤从命令行启动，该命令行在本地主机上启动一个最小的 Ceph 群集（一个 monitor 与 manager 守护程序）。然后，使用 orchestrator 命令部署集群的其余部分，以添加其他主机，使用存储设备并为集群服务部署守护程序。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">### 1、配置ceph安装源（或指定版本）</span></span><br><span class="line">./cephadm add-repo --release octopus</span><br><span class="line"><span class="comment">#或</span></span><br><span class="line"><span class="comment">#./cephadm add-repo --version 15.2.1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 2、集群初始化</span></span><br><span class="line">cephadm bootstrap --<span class="built_in">help</span> <span class="comment"># 查看帮助</span></span><br><span class="line"><span class="comment"># cephadm bootstrap --mon-ip *&lt;mon-ip&gt;*</span></span><br><span class="line">cephadm bootstrap --mon-ip 192.168.182.130</span><br></pre></td></tr></table></figure>

<h3 id="4）启用-ceph-shell"><a href="#4）启用-ceph-shell" class="headerlink" title="4）启用 ceph shell"></a>4）启用 ceph shell</h3><p>cephadm 命令一般只是作为部署的引导作用。但是，我们建议启用对 ceph 命令，因为 ceph 命令更加简洁强大。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 启用ceph shell</span></span><br><span class="line">cephadm shell</span><br><span class="line"><span class="comment"># 这命令在容器中启动 bash shell 并在本机上安装了所有 Ceph 软件包。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看ceph集群状态，非交互式</span></span><br><span class="line">cephadm shell ceph status</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">cephadm shell ceph -s</span><br></pre></td></tr></table></figure>

<p>您可以安装 <code>ceph-common</code> 包，其中包含所有 Ceph 命令，包括 ceph, rbd, mount.ceph （用于安装 CephFS 文件系统）等：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cephadm add-repo --release quincy</span><br><span class="line">cephadm install ceph-common</span><br><span class="line"><span class="comment"># 当然也只安装ceph命令</span></span><br><span class="line">cephadm install ceph</span><br></pre></td></tr></table></figure>

<p>接下来就可以开心的使用 ceph 命令部署软件等等。</p>
<h2 id="三、ceph-命令使用"><a href="#三、ceph-命令使用" class="headerlink" title="三、ceph 命令使用"></a>三、ceph 命令使用</h2><p>上面我们已经安装了 ceph 的全家桶，这里就不重复了。</p>
<h3 id="1）添加新节点"><a href="#1）添加新节点" class="headerlink" title="1）添加新节点"></a>1）添加新节点</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph orch host add local-168-182-131</span><br><span class="line">ceph orch host add local-168-182-132</span><br><span class="line"></span><br><span class="line"><span class="comment">#第一次部署新节点时直接用上边的命令即可：</span></span><br><span class="line"><span class="comment">#但是之后的节点新增有可能上述命令出错：</span></span><br><span class="line">ceph orch host add local-168-182-131 192.168.182.133  <span class="comment">#后边跟上对应的IP</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看节点</span></span><br><span class="line">ceph orch host <span class="built_in">ls</span></span><br></pre></td></tr></table></figure>

<h3 id="2）使用-ceph-安装软件"><a href="#2）使用-ceph-安装软件" class="headerlink" title="2）使用 ceph 安装软件"></a>2）使用 ceph 安装软件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">### 1、部署监视器（monitor）</span></span><br><span class="line"><span class="comment"># ceph orch apply mon *&lt;number-of-monitors&gt;*</span></span><br><span class="line"><span class="comment"># 确保在此列表中包括第一台（引导）主机。</span></span><br><span class="line">ceph orch apply mon local-168-182-130,local-168-182-131,local-168-182-132</span><br><span class="line"></span><br><span class="line"><span class="comment">### 2、部署 osd</span></span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">ceph orch device <span class="built_in">ls</span></span><br><span class="line"><span class="comment"># 开始部署</span></span><br><span class="line"><span class="comment"># 【第一种方式】告诉Ceph使用任何可用和未使用的存储设备：</span></span><br><span class="line">ceph orch apply osd --all-available-devices</span><br><span class="line"></span><br><span class="line"><span class="comment"># 【第二种方式】或者使用下面命令指定使用的磁盘（推荐使用这种方式吧）</span></span><br><span class="line"><span class="comment"># ceph orch daemon add osd *&lt;host&gt;*:*&lt;device-path&gt;*</span></span><br><span class="line"><span class="comment">#例如：</span></span><br><span class="line"><span class="comment">#从特定主机上的特定设备创建OSD：</span></span><br><span class="line">ceph orch daemon add osd local-168-182-130:/dev/sdb</span><br><span class="line">ceph orch daemon add osd local-168-182-130:/dev/sdc</span><br><span class="line"></span><br><span class="line">ceph orch daemon add osd local-168-182-131:/dev/sdb</span><br><span class="line">ceph orch daemon add osd local-168-182-131:/dev/sdc</span><br><span class="line"></span><br><span class="line">ceph orch daemon add osd local-168-182-132:/dev/sdb</span><br><span class="line">ceph orch daemon add osd local-168-182-132:/dev/sdc</span><br><span class="line"></span><br><span class="line"><span class="comment">### 3、部署mds</span></span><br><span class="line"><span class="comment"># ceph orch apply mds *&lt;fs-name&gt;* --placement=&quot;*&lt;num-daemons&gt;* [*&lt;host1&gt;* ...]&quot;</span></span><br><span class="line">ceph orch apply mds myfs --placement=<span class="string">&quot;3 local-168-182-130 local-168-182-131 local-168-182-132&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 4、部署RGW</span></span><br><span class="line"><span class="comment"># 为特定领域和区域部署一组radosgw守护程序：</span></span><br><span class="line"><span class="comment"># ceph orch apply rgw *&lt;realm-name&gt;* *&lt;zone-name&gt;* --placement=&quot;*&lt;num-daemons&gt;* [*&lt;host1&gt;* ...]&quot;</span></span><br><span class="line">ceph orch apply rgw myorg us-east-1 --placement=<span class="string">&quot;3 local-168-182-130 local-168-182-131 local-168-182-132&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">###说明：</span></span><br><span class="line"><span class="comment">#myorg : 领域名  （realm-name）</span></span><br><span class="line"><span class="comment">#us-east-1: 区域名 （zone-name）myrgw</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 5、部署ceph-mgr</span></span><br><span class="line">ceph orch apply mgr local-168-182-130,local-168-182-131,local-168-182-132</span><br></pre></td></tr></table></figure>

<p>删除 OSD 节点</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">### 1.停止osd进程</span></span><br><span class="line">ceph osd stop x  //(x 可以通过ceph osd <span class="built_in">ls</span> 查看)</span><br><span class="line"><span class="comment">#停止osd的进程，这个是通知集群这个osd进程不在了，不提供服务了，因为本身没权重，就不会影响到整体的分布，也就没有迁移</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 2.将节点状态标记为out</span></span><br><span class="line">ceph osd out osd.x</span><br><span class="line"><span class="comment">#停止到osd的进程，这个是通知集群这个osd不再映射数据了，不提供服务了，因为本身没权重，就不会影响到整体的分布，也就没有迁移</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 3. 从crush中移除节点</span></span><br><span class="line">ceph osd crush remove osd.x</span><br><span class="line"><span class="comment"># 这个是从crush中删除，</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 4. 删除节点</span></span><br><span class="line">ceph osd <span class="built_in">rm</span> osd.x</span><br><span class="line"><span class="comment"># 这个是从集群里面删除这个节点的记录ls</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 5. 删除节点认证（不删除编号会占住）</span></span><br><span class="line">ceph auth del osd.x</span><br><span class="line"><span class="comment">#这个是从认证当中去删除这个节点的信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#【注意】</span></span><br><span class="line"><span class="comment">#比如卸载了node3的某osd,(osd.x 即：node:/dev/sdb),在node3上执行以下操作，可以后继续使用node3:/dev/sdb</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#1. lvremove /dev/ceph-3f728c86-8002-47ab-b74a-d00f4cf0fdd2/osd-block-08c6dc02-85d1-4da2-8f71-5499c115cd3c  // dev 后的参数可以通过lsblk查看</span></span><br><span class="line"><span class="comment">#2. vgremove  ceph-3f728c86-8002-47ab-b74a-d00f4cf0fdd2</span></span><br></pre></td></tr></table></figure>

<p>查看服务</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 其实可以通过docker ps查看，但是不太直观，所以既然有ceph命令，肯定是用ceph查看更为详细直观了。</span></span><br><span class="line">ceph orch ps</span><br><span class="line">ceph orch ps --daemon-type alertmanager</span><br><span class="line">ceph orch ps --daemon-type osd</span><br><span class="line"><span class="comment"># ceph orch ps --daemon-type [alertmanager|crash|grafana|mds|mgrmon|node-exporter|osd|prometheus|rgw]</span></span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301091053645.png" alt="图片"></p>
<h3 id="3）主机操作"><a href="#3）主机操作" class="headerlink" title="3）主机操作"></a>3）主机操作</h3><h4 id="1、列出主机"><a href="#1、列出主机" class="headerlink" title="1、列出主机"></a>1、列出主机</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ceph orch host ls [--format yaml] [--host-pattern &lt;name&gt;] [--label &lt;label&gt;] [--host-status &lt;status&gt;]</span></span><br><span class="line">ceph orch host <span class="built_in">ls</span></span><br></pre></td></tr></table></figure>

<h4 id="2、添加主机"><a href="#2、添加主机" class="headerlink" title="2、添加主机"></a>2、添加主机</h4><p>要将每个新主机添加到群集，请执行以下步骤：</p>
<ul>
<li>【1】在新主机的根用户的 authorized_keys 文件：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ssh-copy-id -f -i /etc/ceph/ceph.pub root@*&lt;new-host&gt;*</span></span><br><span class="line">ssh-copy-id -f -i /etc/ceph/ceph.pub root@192.168.182.133</span><br></pre></td></tr></table></figure>

<ul>
<li>【2】告诉 Ceph 新节点是集群的一部分：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ceph orch host add *&lt;newhost&gt;* [*&lt;ip&gt;*] [*&lt;label1&gt; ...*]</span></span><br><span class="line">ceph orch host add local-168-182-130 192.168.182.130</span><br><span class="line"><span class="comment"># 最好显式提供主机 IP 地址。 如果 IP 是 未提供，则主机名将立即通过 将使用该 DNS 和该 IP。</span></span><br></pre></td></tr></table></figure>

<p>还可以包含一个或多个标签以立即标记 新主机。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph orch host add local-168-182-130 192.168.182.130 --labels _admin</span><br></pre></td></tr></table></figure>

<h4 id="3、删除主机"><a href="#3、删除主机" class="headerlink" title="3、删除主机"></a>3、删除主机</h4><p>删除所有守护程序后，可以安全地从集群中移除主机 从它。</p>
<ul>
<li>【1】要从主机中排出所有守护程序，请运行以下形式的命令：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ceph orch host drain *&lt;host&gt;*</span></span><br><span class="line">ceph orch host drain local-168-182-130</span><br><span class="line"></span><br><span class="line"><span class="comment">#将计划删除主机上的所有 osd。您可以通过以下方式检查 osd 删除进度：</span></span><br><span class="line">ceph orch osd <span class="built_in">rm</span> status</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以使用以下命令检查主机上是否没有守护程序：</span></span><br><span class="line"><span class="comment"># ceph orch ps &lt;host&gt;</span></span><br><span class="line">ceph orch ps local-168-182-130</span><br></pre></td></tr></table></figure>

<ul>
<li>【2】删除所有守护程序后，可以使用以下命令删除主机：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ceph orch host rm &lt;host&gt;</span></span><br><span class="line">ceph orch host <span class="built_in">rm</span> local-168-182-130</span><br></pre></td></tr></table></figure>

<p>如果主机处于脱机状态且无法恢复，仍可以通过以下方法将其从群集中移除：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ceph orch host rm &lt;host&gt; --offline --force</span></span><br><span class="line">ceph orch host <span class="built_in">rm</span> local-168-182-130 --offline --force</span><br></pre></td></tr></table></figure>

<h4 id="4、主机标签"><a href="#4、主机标签" class="headerlink" title="4、主机标签"></a>4、主机标签</h4><p>业务流程协调程序支持将标签分配给主机。标签 是自由形式的，本身和每个主机都没有特定的含义 可以有多个标签。它们可用于指定放置 的守护进程。</p>
<ul>
<li>【1】添加标签</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ceph orch host add my_hostname --labels=my_label1</span></span><br><span class="line">ceph orch host add local-168-182-130 --labels=my_label1,my_label2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以，ceph orch host label add my_hostname my_label</span></span><br><span class="line">ceph orch host label add local-168-182-130 my_label</span><br></pre></td></tr></table></figure>

<ul>
<li>【2】删除标签</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ceph orch host label rm my_hostname my_label</span></span><br><span class="line">ceph orch host label <span class="built_in">rm</span> local-168-182-130 my_label</span><br></pre></td></tr></table></figure>

<p><strong>特殊主机标签</strong><br>以下宿主标签对头孢具有特殊含义。一切始于 <code>_.</code></p>
<ul>
<li><code>_no_schedule</code>: 不要在此主机上调度或部署守护程序.</li>
</ul>
<blockquote>
<p>此标签可防止 cephadm 在此主机上部署守护程序。如果它被添加到 已经包含 Ceph 守护进程的现有主机，将导致 cephadm 移动 其他位置的守护程序（OSD 除外，不会自动删除）。</p>
</blockquote>
<ul>
<li><code>_no_autotune_memory</code>: 不自动调整此主机上的内存.</li>
</ul>
<blockquote>
<p>此标签将阻止守护程序内存被调整，即使 osd_memory_target_autotune 或为一个或多个守护程序启用类似选项 在该主机上。</p>
</blockquote>
<ul>
<li><code>_admin</code>: 将 client.admin 和 ceph.conf 分发到此主机.</li>
</ul>
<blockquote>
<p>默认情况下，一个<code>_admin</code>标签应用于群集中的第一个主机（其中 引导程序最初是运行的），并且 <code>client.admin</code> 密钥设置为分发 到该主机通过 功能。添加此标签 到其他主机通常会导致 CEPHADM 部署配置和密钥环文件 在 .从版本 16.2.10 和 17.2.1 开始 添加到默认位置 Cephadm 还存储配置和密钥环 文件中的文件 目录。<code>ceph orch client-keyring .../etc/ceph/etc/ceph//var/lib/ceph/&lt;fsid&gt;/config</code></p>
</blockquote>
<h3 id="4）维护模式"><a href="#4）维护模式" class="headerlink" title="4）维护模式"></a>4）维护模式</h3><p>将主机置于维护模式和退出维护模式（停止主机上的所有 Ceph 守护进程）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 进入维护模式</span></span><br><span class="line"><span class="comment"># ceph orch host maintenance enter &lt;hostname&gt; [--force]</span></span><br><span class="line">ceph orch host maintenance enter local-168-182-130</span><br><span class="line"></span><br><span class="line"><span class="comment"># 退出维护模式</span></span><br><span class="line"><span class="comment"># ceph orch host maintenance exit &lt;hostname&gt;</span></span><br><span class="line">ceph orch host maintenance <span class="built_in">exit</span> local-168-182-130</span><br></pre></td></tr></table></figure>

<h3 id="5）查看服务状态"><a href="#5）查看服务状态" class="headerlink" title="5）查看服务状态"></a>5）查看服务状态</h3><p>查看一个的状态 在 Ceph 集群中运行的服务中，执行以下操作：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ceph orch ls [--service_type type] [--service_name name] [--export] [--format f] [--refresh]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看所有服务</span></span><br><span class="line">ceph orch <span class="built_in">ls</span></span><br><span class="line"><span class="comment"># 查看指定服务</span></span><br><span class="line">ceph orch <span class="built_in">ls</span> alertmanager</span><br><span class="line">ceph orch <span class="built_in">ls</span>  --service_name crash</span><br></pre></td></tr></table></figure>

<h3 id="6）查看守护进程状态"><a href="#6）查看守护进程状态" class="headerlink" title="6）查看守护进程状态"></a>6）查看守护进程状态</h3><p>首先，打印业务流程协调程序已知的所有守护程序的列表：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ceph orch ps [--hostname host] [--daemon_type type] [--service_name name] [--daemon_id id] [--format f] [--refresh]</span></span><br><span class="line">ceph orch ps</span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后查询特定服务实例的状态（mon、osd、mds、rgw）。 对于 OSD，ID 是数字 OSD ID。对于 MDS 服务，id 是文件 系统名称：</span></span><br><span class="line">ceph orch ps --daemon_type osd --daemon_id 0</span><br></pre></td></tr></table></figure>

<h3 id="7）OSD-服务"><a href="#7）OSD-服务" class="headerlink" title="7）OSD 服务"></a>7）OSD 服务</h3><h4 id="1、列出设备"><a href="#1、列出设备" class="headerlink" title="1、列出设备"></a>1、列出设备</h4><p>ceph-volume 按顺序不时扫描群集中的每个主机 确定存在哪些设备以及它们是否有资格 用作 OSD。</p>
<p>查看列表，运行以下命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ceph orch device ls [--hostname=...] [--wide] [--refresh]</span></span><br><span class="line">ceph orch device <span class="built_in">ls</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 --wide 选项提供与设备相关的所有详细信息， 包括设备可能不符合用作 OSD 条件的任何原因。</span></span><br><span class="line">ceph orch device <span class="built_in">ls</span> --wide</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301091053236.png" alt="图片"></p>
<p>在上面的示例中，您可以看到名为“运行状况”、“标识”和“故障”的字段。此信息通过与 libstoragemgmt.默认情况下， 此集成已禁用（因为 libstoragemgmt 可能不是 100% 与您的硬件兼容）。要使 cephadm 包括这些字段， 启用 CEPHADM 的“增强设备扫描”选项，如下所示;</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph config <span class="built_in">set</span> mgr mgr/cephadm/device_enhanced_scan <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<h4 id="2、创建新的-OSD"><a href="#2、创建新的-OSD" class="headerlink" title="2、创建新的 OSD"></a>2、创建新的 OSD</h4><p>有几种方法可以创建新的 OSD：</p>
<ul>
<li>【1】告诉 Ceph 使用任何可用和未使用的存储设备：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 如果将新磁盘添加到群集，它们将自动用于 创建新的 OSD。</span></span><br><span class="line">ceph orch apply osd --all-available-devices</span><br></pre></td></tr></table></figure>

<ul>
<li>【2】从特定主机上的特定设备创建 OSD：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ceph orch daemon add osd *&lt;host&gt;*:*&lt;device-path&gt;*</span></span><br><span class="line">ceph orch daemon add osd local-168-182-133:/dev/sdb</span><br><span class="line">ceph orch daemon add osd local-168-182-133:/dev/sdc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line"><span class="comment"># ceph orch daemon add osd host1:data_devices=/dev/sda,/dev/sdb,db_devices=/dev/sdc,osds_per_device=2</span></span><br><span class="line">ceph orch daemon add osd local-168-182-133:data_devices=/dev/sdb,/dev/sdc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用lvm</span></span><br><span class="line"><span class="comment"># ceph orch daemon add osd *&lt;host&gt;*:*&lt;lvm-path&gt;*</span></span><br><span class="line">ceph orch daemon add osd host1:/dev/vg_osd/lvm_osd1701</span><br></pre></td></tr></table></figure>

<ul>
<li>【3】试运行，不是真正的执行</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 这 --dry-run 标志使业务流程协调程序显示内容的预览 将在不实际创建 OSD 的情况下发生。</span></span><br><span class="line"></span><br><span class="line">ceph orch apply osd --all-available-devices --dry-run</span><br></pre></td></tr></table></figure>

<h4 id="3、移除-OSD"><a href="#3、移除-OSD" class="headerlink" title="3、移除 OSD"></a>3、移除 OSD</h4><p>从集群中删除 OSD 涉及两个步骤：</p>
<ul>
<li>从集群中撤出所有归置组 （PG）</li>
<li>从集群中删除无 PG 的 OSD</li>
</ul>
<p>以下命令执行这两个步骤：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ceph orch osd rm &lt;osd_id(s)&gt; [--replace] [--force]</span></span><br><span class="line">ceph orch osd <span class="built_in">rm</span> 0</span><br></pre></td></tr></table></figure>

<h4 id="4、监控-OSD-删除的状态"><a href="#4、监控-OSD-删除的状态" class="headerlink" title="4、监控 OSD 删除的状态"></a>4、监控 OSD 删除的状态</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph orch osd <span class="built_in">rm</span> status</span><br></pre></td></tr></table></figure>

<h4 id="5、停止删除-OSD"><a href="#5、停止删除-OSD" class="headerlink" title="5、停止删除 OSD"></a>5、停止删除 OSD</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ceph orch osd rm stop &lt;osd_id(s)&gt;</span></span><br><span class="line">ceph orch osd <span class="built_in">rm</span> stop 4</span><br></pre></td></tr></table></figure>

<h4 id="6、激活现有-OSD"><a href="#6、激活现有-OSD" class="headerlink" title="6、激活现有 OSD"></a>6、激活现有 OSD</h4><p>如果重新安装主机的操作系统，则需要激活现有的 OSD 再。对于此用例，cephadm 提供了一个包装器 激活 那 激活主机上的所有现有 OSD。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ceph cephadm osd activate &lt;host&gt;...</span></span><br><span class="line">ceph cephadm osd activate local-168-182-133</span><br></pre></td></tr></table></figure>

<h4 id="7、查看数据延迟"><a href="#7、查看数据延迟" class="headerlink" title="7、查看数据延迟"></a>7、查看数据延迟</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph osd perf</span><br></pre></td></tr></table></figure>

<h4 id="8、详细列出集群每块磁盘的使用情况"><a href="#8、详细列出集群每块磁盘的使用情况" class="headerlink" title="8、详细列出集群每块磁盘的使用情况"></a>8、详细列出集群每块磁盘的使用情况</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph osd <span class="built_in">df</span></span><br></pre></td></tr></table></figure>

<h3 id="8）pool-相关操作"><a href="#8）pool-相关操作" class="headerlink" title="8）pool 相关操作"></a>8）pool 相关操作</h3><h4 id="1、查看-ceph-集群中的-pool-数量"><a href="#1、查看-ceph-集群中的-pool-数量" class="headerlink" title="1、查看 ceph 集群中的 pool 数量"></a>1、查看 ceph 集群中的 pool 数量</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph osd lspools</span><br><span class="line"><span class="comment">#或者</span></span><br><span class="line">ceph osd pool <span class="built_in">ls</span></span><br></pre></td></tr></table></figure>

<h4 id="2、在-ceph-集群中创建一个-pool"><a href="#2、在-ceph-集群中创建一个-pool" class="headerlink" title="2、在 ceph 集群中创建一个 pool"></a>2、在 ceph 集群中创建一个 pool</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#这里的100指的是PG组:</span></span><br><span class="line">ceph osd pool create rbdtest 100</span><br></pre></td></tr></table></figure>

<h3 id="9）PG-相关"><a href="#9）PG-相关" class="headerlink" title="9）PG 相关"></a>9）PG 相关</h3><p>PG &#x3D;“放置组”。当集群中的数据，对象映射到编程器，被映射到这些 PGS 的 OSD。</p>
<h4 id="1、查看-pg-组的映射信息"><a href="#1、查看-pg-组的映射信息" class="headerlink" title="1、查看 pg 组的映射信息"></a>1、查看 pg 组的映射信息</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph pg dump</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line"><span class="comment"># ceph pg ls</span></span><br></pre></td></tr></table></figure>

<h4 id="2、查看一个-PG-的-map"><a href="#2、查看一个-PG-的-map" class="headerlink" title="2、查看一个 PG 的 map"></a>2、查看一个 PG 的 map</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph pg map 7.1a</span><br></pre></td></tr></table></figure>

<h4 id="3、查看-PG-状态"><a href="#3、查看-PG-状态" class="headerlink" title="3、查看 PG 状态"></a>3、查看 PG 状态</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph pg <span class="built_in">stat</span></span><br></pre></td></tr></table></figure>

<h4 id="4、显示一个集群中的所有的-pg-统计"><a href="#4、显示一个集群中的所有的-pg-统计" class="headerlink" title="4、显示一个集群中的所有的 pg 统计"></a>4、显示一个集群中的所有的 pg 统计</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph pg dump --format plain</span><br></pre></td></tr></table></figure>

<p>这里只是列举了一些常用的操作命令，更多的命令可以查看帮助或者查看官方文档。</p>
<h2 id="四、实战操作演示"><a href="#四、实战操作演示" class="headerlink" title="四、实战操作演示"></a>四、实战操作演示</h2><h3 id="1）块存储使用（RDB-）"><a href="#1）块存储使用（RDB-）" class="headerlink" title="1）块存储使用（RDB ）"></a>1）块存储使用（RDB ）</h3><p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301091054109.png" alt="图片"></p>
<h4 id="1、-使用-create-创建-pool-池"><a href="#1、-使用-create-创建-pool-池" class="headerlink" title="1、 使用 create 创建 pool 池"></a>1、 使用 create 创建 pool 池</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph osd lspools</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建</span></span><br><span class="line">ceph osd pool create ceph-demo 64 64</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建命令时需要指定PG、PGP数量，还可以指定复制模型还是纠删码模型，副本数量等等</span></span><br><span class="line"><span class="comment"># osd pool create &lt;pool&gt; [&lt;pg_num:int&gt;] [&lt;pgp_num:int&gt;] [replicated|erasure] [&lt;erasure_code_  create pool profile&gt;] [&lt;rule&gt;] [&lt;expected_num_objects:int&gt;] [&lt;size:int&gt;] [&lt;pg_num_min:int&gt;] [on|off| warn] [&lt;target_size_bytes:int&gt;] [&lt;target_size_ratio:float&gt;]</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>【温馨提示】PG (Placement Group)，pg 是一个虚拟的概念，用于存放 object，PGP(Placement Group for Placement purpose)，相当于是 pg 存放的一种 osd 排列组合。</p>
</blockquote>
<p>获取 pool 池属性信息，可以重新设置，有很多参数，都可以如下设置</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1、获取 pg 个数</span></span><br><span class="line">ceph osd pool get ceph-demo pg_num</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、获取 pgp 个数</span></span><br><span class="line">ceph osd pool get ceph-demo pgp_num</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、获取副本数</span></span><br><span class="line">ceph osd pool get ceph-demo size</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、获取使用模型</span></span><br><span class="line">ceph osd pool get ceph-demo crush_rule</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、设置副本数</span></span><br><span class="line">ceph osd pool <span class="built_in">set</span> ceph-demo size 2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6、设置 pg 数量</span></span><br><span class="line">ceph osd pool <span class="built_in">set</span> ceph-demo pg_num 128</span><br><span class="line"></span><br><span class="line"><span class="comment"># 7、设置 pgp 数量</span></span><br><span class="line">ceph osd pool <span class="built_in">set</span> ceph-demo pgp_num 128</span><br></pre></td></tr></table></figure>

<h4 id="2、需要初始化-pool"><a href="#2、需要初始化-pool" class="headerlink" title="2、需要初始化 pool"></a>2、需要初始化 pool</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rbd pool init ceph-demo</span><br></pre></td></tr></table></figure>

<h4 id="3、创建-rbd-块设备"><a href="#3、创建-rbd-块设备" class="headerlink" title="3、创建 rbd 块设备"></a>3、创建 rbd 块设备</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看 块设备</span></span><br><span class="line">rbd -p ceph-demo <span class="built_in">ls</span></span><br><span class="line"><span class="comment"># 【方式一】创建块设备</span></span><br><span class="line">rbd create -p ceph-demo --image rbd-demo.img --size 10G</span><br><span class="line"><span class="comment"># 【方式二】创建块设备</span></span><br><span class="line">rbd create ceph-demo/rbd-demo2.img --size 10G</span><br><span class="line"><span class="comment"># 查看 块设备</span></span><br><span class="line">rbd -p ceph-demo <span class="built_in">ls</span></span><br></pre></td></tr></table></figure>

<h4 id="4、查看块设备信息"><a href="#4、查看块设备信息" class="headerlink" title="4、查看块设备信息"></a>4、查看块设备信息</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rbd info ceph-demo/rbd-demo2.img</span><br></pre></td></tr></table></figure>

<h4 id="5、删除块设备"><a href="#5、删除块设备" class="headerlink" title="5、删除块设备"></a>5、删除块设备</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rbd <span class="built_in">rm</span> -p ceph-demo --image rbd-demo2.img</span><br></pre></td></tr></table></figure>

<h4 id="6、设备挂载"><a href="#6、设备挂载" class="headerlink" title="6、设备挂载"></a>6、设备挂载</h4><p>由于没有虚拟机进行挂载，所以需要使用内核 map 进行挂载；</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rbd map ceph-demo/rbd-demo.img</span><br></pre></td></tr></table></figure>

<blockquote>
<p>[root@local-168-182-130 ceph]# rbd map ceph-demo&#x2F;rbd-demo.img<br>rbd: sysfs write <code>failed</code><br>RBD image feature set mismatch. You can disable features <code>unsupported</code> by the kernel with “rbd feature disable ceph-demo&#x2F;rbd-demo.img object-map fast-diff deep-flatten”.<br>In some cases useful info is found in syslog - try “dmesg | tail”.<br>rbd: map <code>failed</code>: (6) No such device or address</p>
</blockquote>
<p>映射的过程当中出现错误，这是因为 Centos7 当中不支持这几个特性，我们可以在创建时指定 features 。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rbd feature <span class="built_in">disable</span> ceph-demo/rbd-demo.img deep-flatten</span><br><span class="line">rbd feature <span class="built_in">disable</span> ceph-demo/rbd-demo.img fast-diff</span><br><span class="line">rbd feature <span class="built_in">disable</span> ceph-demo/rbd-demo.img object-map</span><br><span class="line"></span><br><span class="line">rbd feature <span class="built_in">disable</span> ceph-demo/rbd-demo.img exclusive-lock</span><br></pre></td></tr></table></figure>

<p>再次挂载，挂载成功</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rbd map ceph-demo/rbd-demo.img</span><br></pre></td></tr></table></figure>

<p>查看设备列表</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rbd device list</span><br></pre></td></tr></table></figure>

<p>通过 fdisk 查看设备列表</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">fdisk -l</span><br></pre></td></tr></table></figure>

<p>使用 rbd 设备</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 格式化</span></span><br><span class="line">mkfs.ext4 /dev/rbd0</span><br><span class="line"><span class="comment"># 创建挂载目录</span></span><br><span class="line"><span class="built_in">mkdir</span> /mnt/rbd-demo</span><br><span class="line"><span class="comment"># 挂载</span></span><br><span class="line">mount /dev/rbd0 /mnt/rbd-demo/</span><br></pre></td></tr></table></figure>

<h4 id="7、块设备扩容"><a href="#7、块设备扩容" class="headerlink" title="7、块设备扩容"></a>7、块设备扩容</h4><p>设备可以扩容，也可以缩容，但不建议使用缩容，有可能产生数据丢失。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 扩容</span></span><br><span class="line">rbd resize ceph-demo/rbd-demo.img --size 10G</span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">rbd -p ceph-demo info --image rbd-demo.img</span><br><span class="line"><span class="comment"># 也可以通过lsblk查看</span></span><br><span class="line">lsblk</span><br></pre></td></tr></table></figure>

<h4 id="8、卸载"><a href="#8、卸载" class="headerlink" title="8、卸载"></a>8、卸载</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">umount /mnt/rbd-demo</span><br></pre></td></tr></table></figure>

<h3 id="2）文件系统使用（CephFS）"><a href="#2）文件系统使用（CephFS）" class="headerlink" title="2）文件系统使用（CephFS）"></a>2）文件系统使用（CephFS）</h3><p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301091053461.png" alt="图片"></p>
<h4 id="1、查看-ceph-文件系统"><a href="#1、查看-ceph-文件系统" class="headerlink" title="1、查看 ceph 文件系统"></a>1、查看 ceph 文件系统</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph fs <span class="built_in">ls</span></span><br></pre></td></tr></table></figure>

<h4 id="2、创建存储池"><a href="#2、创建存储池" class="headerlink" title="2、创建存储池"></a>2、创建存储池</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph osd pool create cephfs_data 128</span><br><span class="line">ceph osd pool create cephfs_metadata 128</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建命令时需要指定PG、PGP数量，还可以指定复制模型还是纠删码模型，副本数量等等</span></span><br><span class="line"><span class="comment"># osd pool create &lt;pool&gt; [&lt;pg_num:int&gt;] [&lt;pgp_num:int&gt;] [replicated|erasure] [&lt;erasure_code_  create pool profile&gt;] [&lt;rule&gt;] [&lt;expected_num_objects:int&gt;] [&lt;size:int&gt;] [&lt;pg_num_min:int&gt;] [on|off| warn] [&lt;target_size_bytes:int&gt;] [&lt;target_size_ratio:float&gt;]</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>【温馨提示】PG (Placement Group)，pg 是一个虚拟的概念，用于存放 object，PGP(Placement Group for Placement purpose)，相当于是 pg 存放的一种 osd 排列组合。</p>
</blockquote>
<h4 id="3、创建文件系统"><a href="#3、创建文件系统" class="headerlink" title="3、创建文件系统"></a>3、创建文件系统</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph fs new 128 cephfs_metadata cephfs_data</span><br><span class="line"></span><br><span class="line"><span class="comment">#此时再回头查看文件系统，mds节点状态</span></span><br><span class="line">ceph fs <span class="built_in">ls</span></span><br><span class="line">ceph mds <span class="built_in">stat</span></span><br></pre></td></tr></table></figure>

<h4 id="4、查看存储池配额"><a href="#4、查看存储池配额" class="headerlink" title="4、查看存储池配额"></a>4、查看存储池配额</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph osd pool get-quota cephfs_metadata</span><br></pre></td></tr></table></figure>

<h4 id="5、内核驱动挂载-ceph-文件系统"><a href="#5、内核驱动挂载-ceph-文件系统" class="headerlink" title="5、内核驱动挂载 ceph 文件系统"></a>5、内核驱动挂载 ceph 文件系统</h4><p>【1】创建挂载点</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /mnt/mycephfs</span><br></pre></td></tr></table></figure>

<p>【2】获取存储密钥，如果没有前往管理节点重新复制</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> /etc/ceph/ceph.client.admin.keyring</span><br><span class="line"></span><br><span class="line"><span class="comment">#将存储密钥保存到/etc/ceph/admin.secret文件中:</span></span><br><span class="line">vim /etc/ceph/admin.secret</span><br><span class="line"><span class="comment"># AQBFVrFjqst6CRAA9WaF1ml7btkn6IuoUDb9zA==</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#如果想开机挂载可以写入/etc/rc.d/rc.local文件中</span></span><br></pre></td></tr></table></figure>

<p>【3】挂载</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Ceph 存储集群默认需要认证，所以挂载时需要指定用户名 name 和创建密钥文件一节中创建的密钥文件 secretfile ，例如：</span></span><br><span class="line"><span class="comment"># mount -t ceph &#123;ip-address-of-monitor&#125;:6789:/ /mnt/mycephfs</span></span><br><span class="line">mount -t ceph 192.168.182.130:6789:/ /mnt/mycephfs -o name=admin,secretfile=/etc/ceph/admin.secret</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301091054803.png" alt="图片"></p>
<p>【4】卸载</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">umount /mnt/mycephfs</span><br></pre></td></tr></table></figure>

<h4 id="6、常用命令"><a href="#6、常用命令" class="headerlink" title="6、常用命令"></a>6、常用命令</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看存储池副本数</span></span><br><span class="line">ceph osd pool get [存储池名称] size</span><br><span class="line"><span class="comment"># 修改存储池副本数</span></span><br><span class="line">ceph osd pool <span class="built_in">set</span> [存储池名称] size 3</span><br><span class="line"><span class="comment"># 打印存储池列表</span></span><br><span class="line">ceph osd lspools</span><br><span class="line"><span class="comment"># 创建存储池</span></span><br><span class="line">ceph osd pool create [存储池名称] [pg_num的取值] </span><br><span class="line"><span class="comment"># 存储池重命名</span></span><br><span class="line">ceph osd pool rename [旧的存储池名称] [新的存储池名称]</span><br><span class="line"><span class="comment"># 查看存储池的pg_num</span></span><br><span class="line">ceph osd pool get [存储池名称] pg_num</span><br><span class="line"><span class="comment"># 查看存储池的pgp_num</span></span><br><span class="line">ceph osd pool get [存储池名称] pgp_num</span><br><span class="line"><span class="comment"># 修改存储池的pg_num值</span></span><br><span class="line">ceph osd pool <span class="built_in">set</span> [存储池名称] pg_num [pg_num的取值]</span><br><span class="line"><span class="comment"># 修改存储池的pgp_num值</span></span><br><span class="line">ceph osd pool <span class="built_in">set</span> [存储池名称] pgp_num [pgp_num的取值]</span><br></pre></td></tr></table></figure>

<h3 id="3）对象存储使用（RGW）"><a href="#3）对象存储使用（RGW）" class="headerlink" title="3）对象存储使用（RGW）"></a>3）对象存储使用（RGW）</h3><p><code>rados</code> 是和 Ceph 的对象存储集群（RADOS），Ceph 的分布式文件系统的一部分进行交互是一种实用工具。<br><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301091053405.png" alt="图片"></p>
<h4 id="1、查看-ceph-集群中有多少个-pool"><a href="#1、查看-ceph-集群中有多少个-pool" class="headerlink" title="1、查看 ceph 集群中有多少个 pool"></a>1、查看 ceph 集群中有多少个 pool</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rados lspools</span><br><span class="line"><span class="comment"># 同  ceph osd pool ls 输出结果一致</span></span><br></pre></td></tr></table></figure>

<h4 id="2、显示整个系统使用率"><a href="#2、显示整个系统使用率" class="headerlink" title="2、显示整个系统使用率"></a>2、显示整个系统使用率</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rados <span class="built_in">df</span></span><br></pre></td></tr></table></figure>

<h4 id="3、创建一个-pool"><a href="#3、创建一个-pool" class="headerlink" title="3、创建一个 pool"></a>3、创建一个 pool</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph osd pool create <span class="built_in">test</span></span><br></pre></td></tr></table></figure>

<h4 id="4、创建一个对象-object"><a href="#4、创建一个对象-object" class="headerlink" title="4、创建一个对象 object"></a>4、创建一个对象 object</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rados create test-object -p <span class="built_in">test</span></span><br></pre></td></tr></table></figure>

<h4 id="5、查看对象文件"><a href="#5、查看对象文件" class="headerlink" title="5、查看对象文件"></a>5、查看对象文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rados -p <span class="built_in">test</span> <span class="built_in">ls</span></span><br></pre></td></tr></table></figure>

<h4 id="6、删除一个对象"><a href="#6、删除一个对象" class="headerlink" title="6、删除一个对象"></a>6、删除一个对象</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rados <span class="built_in">rm</span> test-object -p <span class="built_in">test</span></span><br></pre></td></tr></table></figure>

<h4 id="7、通过-api-接口使用-Ceph-存储存储"><a href="#7、通过-api-接口使用-Ceph-存储存储" class="headerlink" title="7、通过 api 接口使用 Ceph 存储存储"></a>7、通过 api 接口使用 Ceph 存储存储</h4><p>为了使用 Ceph SGW REST 接口, 我们需要为 S3 接口初始化一个 Ceph 对象网关用户. 然后为 Swif 接口新建一个子用户，最后就可以通过创建的用户访问对象网关验证了。</p>
<p>ceph-restful-api 官方文档</p>
<blockquote>
<p>这里使用<code>radosgw-admin</code>，<code>radosgw-admin</code> 是 RADOS 网关用户管理工具，可用于创建和修改用户。</p>
</blockquote>
<p>【1】创建 S3 网关用户</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">radosgw-admin user create --uid=<span class="string">&quot;rgwuser&quot;</span> --display-name=<span class="string">&quot;This is first rgw test user&quot;</span></span><br></pre></td></tr></table></figure>

<p>info</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;user_id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;rgwuser&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;display_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;This is first rgw test user&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;email&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;suspended&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;max_buckets&quot;</span><span class="punctuation">:</span> <span class="number">1000</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;subusers&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;keys&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;user&quot;</span><span class="punctuation">:</span> <span class="string">&quot;rgwuser&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;access_key&quot;</span><span class="punctuation">:</span> <span class="string">&quot;48AIAPCYK7S4X9P72VOW&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;secret_key&quot;</span><span class="punctuation">:</span> <span class="string">&quot;oC5qKL0BMMzUJHAS76rQAwIoJh4s6NwTnLklnQYX&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;swift_keys&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;caps&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;op_mask&quot;</span><span class="punctuation">:</span> <span class="string">&quot;read, write, delete&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;default_placement&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;default_storage_class&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;placement_tags&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;bucket_quota&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;enabled&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;check_on_raw&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;max_size&quot;</span><span class="punctuation">:</span> <span class="number">-1</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;max_size_kb&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;max_objects&quot;</span><span class="punctuation">:</span> <span class="number">-1</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;user_quota&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;enabled&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;check_on_raw&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;max_size&quot;</span><span class="punctuation">:</span> <span class="number">-1</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;max_size_kb&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;max_objects&quot;</span><span class="punctuation">:</span> <span class="number">-1</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;temp_url_keys&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;rgw&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;mfa_ids&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301091055701.png" alt="图片"></p>
<p>【2】测试访问 S3 接口</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#参照官方文档，我们需要编写一个 Python 测试脚本，该脚本将会连接 radosgw，然后新建一个新的 bucket 再列出所有的 buckets。脚本变量 aws_access_key_id 和 aws_secret_access_key 的值就是上边返回值中的 access_key 和 secret_key。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#首先，我们需要安装 python-boto 包，用于测试连接 S3。：</span></span><br><span class="line">yum install python-boto -y</span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后，编写 python 测试脚本。</span></span><br><span class="line"><span class="comment"># cat s3.py</span></span><br><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"></span><br><span class="line">import boto</span><br><span class="line">import boto.s3.connection</span><br><span class="line">access_key = <span class="string">&#x27;48AIAPCYK7S4X9P72VOW&#x27;</span></span><br><span class="line">secret_key = <span class="string">&#x27;oC5qKL0BMMzUJHAS76rQAwIoJh4s6NwTnLklnQYX&#x27;</span></span><br><span class="line">conn = boto.connect_s3(</span><br><span class="line">    aws_access_key_id = access_key,</span><br><span class="line">    aws_secret_access_key = secret_key,</span><br><span class="line">    host = <span class="string">&#x27;local-168-182-130&#x27;</span>, port=80,</span><br><span class="line">    is_secure=False,</span><br><span class="line">    calling_format = boto.s3.connection.OrdinaryCallingFormat(),</span><br><span class="line">)</span><br><span class="line">bucket = conn.create_bucket(<span class="string">&#x27;my-first-s3-bucket&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> bucket <span class="keyword">in</span> conn.get_all_buckets():</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;&#123;name&#125;\t&#123;created&#125;&quot;</span>.format(</span><br><span class="line">                name = bucket.name,</span><br><span class="line">                created = bucket.creation_date,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>【温馨提示】这里使用了 python-boto 包，使用认证信息连接 S3，然后创建了一个 my-first-s3-bucket 的 bucket，最后列出所有已创建的 bucket，打印名称和创建时间。</p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301091054559.png" alt="图片"></p>
<p>【3】创建 Swift 用户</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#要通过 Swift 访问对象网关，需要 Swift 用户,我们创建subuser作为子用户。</span></span><br><span class="line">radosgw-admin subuser create --uid=rgwuser --subuser=rgwuser:swift --access=full</span><br></pre></td></tr></table></figure>

<p>info</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;user_id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;rgwuser&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;display_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;This is first rgw test user&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;email&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;suspended&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;max_buckets&quot;</span><span class="punctuation">:</span> <span class="number">1000</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;subusers&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;rgwuser:swift&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;permissions&quot;</span><span class="punctuation">:</span> <span class="string">&quot;full-control&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;keys&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;user&quot;</span><span class="punctuation">:</span> <span class="string">&quot;rgwuser&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;access_key&quot;</span><span class="punctuation">:</span> <span class="string">&quot;48AIAPCYK7S4X9P72VOW&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;secret_key&quot;</span><span class="punctuation">:</span> <span class="string">&quot;oC5qKL0BMMzUJHAS76rQAwIoJh4s6NwTnLklnQYX&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;swift_keys&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;user&quot;</span><span class="punctuation">:</span> <span class="string">&quot;rgwuser:swift&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;secret_key&quot;</span><span class="punctuation">:</span> <span class="string">&quot;6bgDOAsosiD28M0eE8U1N5sZeGyrhqB1ca3uDtI2&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;caps&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;op_mask&quot;</span><span class="punctuation">:</span> <span class="string">&quot;read, write, delete&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;default_placement&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;default_storage_class&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;placement_tags&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;bucket_quota&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;enabled&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;check_on_raw&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;max_size&quot;</span><span class="punctuation">:</span> <span class="number">-1</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;max_size_kb&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;max_objects&quot;</span><span class="punctuation">:</span> <span class="number">-1</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;user_quota&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;enabled&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;check_on_raw&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;max_size&quot;</span><span class="punctuation">:</span> <span class="number">-1</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;max_size_kb&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;max_objects&quot;</span><span class="punctuation">:</span> <span class="number">-1</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;temp_url_keys&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;rgw&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;mfa_ids&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>【4】创建密钥</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">radosgw-admin key create --subuser=rgwuser:swift --key-type=swift --gen-secret</span><br><span class="line"></span><br><span class="line"><span class="comment">#注意：返回的 Json 值中，我们要记住swift_keys中的secret_key 因为下边我们测试访问 Swift 接口时需要使用。secret_key以这条命令为准</span></span><br></pre></td></tr></table></figure>

<p>info</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;user_id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;rgwuser&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;display_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;This is first rgw test user&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;email&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;suspended&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;max_buckets&quot;</span><span class="punctuation">:</span> <span class="number">1000</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;subusers&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;rgwuser:swift&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;permissions&quot;</span><span class="punctuation">:</span> <span class="string">&quot;full-control&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;keys&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;user&quot;</span><span class="punctuation">:</span> <span class="string">&quot;rgwuser&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;access_key&quot;</span><span class="punctuation">:</span> <span class="string">&quot;48AIAPCYK7S4X9P72VOW&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;secret_key&quot;</span><span class="punctuation">:</span> <span class="string">&quot;oC5qKL0BMMzUJHAS76rQAwIoJh4s6NwTnLklnQYX&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;swift_keys&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;user&quot;</span><span class="punctuation">:</span> <span class="string">&quot;rgwuser:swift&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;secret_key&quot;</span><span class="punctuation">:</span> <span class="string">&quot;AVThl3FGiVQW3VepkQl4Wsoyq9lbPlLlpKhXLhtR&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;caps&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;op_mask&quot;</span><span class="punctuation">:</span> <span class="string">&quot;read, write, delete&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;default_placement&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;default_storage_class&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;placement_tags&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;bucket_quota&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;enabled&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;check_on_raw&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;max_size&quot;</span><span class="punctuation">:</span> <span class="number">-1</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;max_size_kb&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;max_objects&quot;</span><span class="punctuation">:</span> <span class="number">-1</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;user_quota&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;enabled&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;check_on_raw&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;max_size&quot;</span><span class="punctuation">:</span> <span class="number">-1</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;max_size_kb&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;max_objects&quot;</span><span class="punctuation">:</span> <span class="number">-1</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;temp_url_keys&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;rgw&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;mfa_ids&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>【5】测试访问 Swift 接口</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#注意，以下命令需要python环境和可用的pip服务。</span></span><br><span class="line">yum install python-pip -y</span><br><span class="line">pip install --upgrade python-swiftclient</span><br><span class="line"></span><br><span class="line"><span class="comment">#测试</span></span><br><span class="line">swift -A http://192.168.182.130/auth/1.0 -U rgwuser:swift -K <span class="string">&#x27;AVThl3FGiVQW3VepkQl4Wsoyq9lbPlLlpKhXLhtR&#x27;</span> list</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202301091057138.png" alt="图片"></p>
<p>【5】S3 相关操作</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1、删除S3用户</span></span><br><span class="line">radosgw-admin  user <span class="built_in">rm</span> --uid=rgwuser</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、权限调整,允许rgwuser读写users信息：</span></span><br><span class="line">radosgw-admin caps add --uid=rgwuser --caps=<span class="string">&quot;users=*&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、允许admin读写所有的usage信息</span></span><br><span class="line">radosgw-admin caps add --uid=rgwuser --caps=<span class="string">&quot;usage=read,write&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、删除swift子用户</span></span><br><span class="line">radosgw-admin subuser <span class="built_in">rm</span>  --subuser=rgwuser:swift</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、列出当前系统下所有的bucket信息</span></span><br><span class="line">radosgw-admin bucket list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6、查看具体某个BUCKET属性</span></span><br><span class="line">radosgw-admin bucket stats --bucket=my-first-s3-bucket</span><br></pre></td></tr></table></figure>

<p>一般是通过 api 接口使用对象存储。</p>
]]></content>
      <categories>
        <category>Ceph</category>
      </categories>
      <tags>
        <tag>Ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>在 K8s 中部署主从结构的 MySQL 服务</title>
    <url>/2023/02/20/%E5%9C%A8%20K8s%20%E4%B8%AD%E9%83%A8%E7%BD%B2%E4%B8%BB%E4%BB%8E%E7%BB%93%E6%9E%84%E7%9A%84%20MySQL%20%E6%9C%8D%E5%8A%A1/</url>
    <content><![CDATA[<p>StatefulSet 旨在与有状态的应用及分布式系统一起使用。然而在 Kubernetes 上管理有状态应用和分布式系统是一个宽泛而复杂的话题。为了演示 StatefulSet 的基本特性，并且不使前后的主题混淆。本文使用 StatefulSet 控制器运行一个有状态的应用程序，主从结构的mysql8数据库。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302200920475.jpeg" alt="图片"></p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>RC、Deployment、DaemonSet都是面向无状态的服务，它们所管理的Pod的IP、名字、启停顺序等都是随机分配的，而StatefulSet，管理所有有状态的服务。</p>
<p>StatefulSet为了解决有状态服务的问题，它所管理的Pod拥有固定的Pod名称，一定的启停顺序，在StatefulSet中，Pod名字称为网络标识(hostname)，还必须要用到共享存储。</p>
<p>在Deployment中，与之对应的服务是service，而在StatefulSet中与之对应的headless service。headless service，即无头服务，与service的区别就是它没有Cluster IP，解析它的名称时将返回该Headless Service对应的全部Pod的节点列表。</p>
<p>除此之外，StatefulSet在Headless Service的基础上又为StatefulSet控制的每个Pod副本创建了一个DNS域名，这个域名的格式为：</p>
<p>(podname).(headless server name).namespace.svc.cluster.local</p>
<h2 id="部署mysql"><a href="#部署mysql" class="headerlink" title="部署mysql"></a>部署mysql</h2><p>MySQL 示例部署包含一个ConfigMap、两个存储挂载pv和pvc、两个 Service 与一个 StatefulSet。</p>
<h3 id="创建一个ConfigMap"><a href="#创建一个ConfigMap" class="headerlink" title="创建一个ConfigMap"></a><strong>创建一个ConfigMap</strong></h3><p>使用以下的 YAML 配置文件创建 ConfigMap ：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#master--my.cnf</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql-master-cnf</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">bc-cnp</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">my.cnf:</span> <span class="string">|-</span></span><br><span class="line"><span class="string">    [client]</span></span><br><span class="line"><span class="string">    default-character-set=utf8</span></span><br><span class="line"><span class="string">    [mysql]</span></span><br><span class="line"><span class="string">    default-character-set=utf8</span></span><br><span class="line"><span class="string">    [mysqld]</span></span><br><span class="line"><span class="string">    init_connect=&#x27;SET collation_connection = utf8_unicode_ci&#x27;</span></span><br><span class="line"><span class="string">    init_connect=&#x27;SET NAMES utf8&#x27;</span></span><br><span class="line"><span class="string">    character-set-server=utf8</span></span><br><span class="line"><span class="string">    collation-server=utf8_unicode_ci</span></span><br><span class="line"><span class="string">    skip-character-set-client-handshake</span></span><br><span class="line"><span class="string">    skip-name-resolve</span></span><br><span class="line"><span class="string">    server_id=1</span></span><br><span class="line"><span class="string">    log-bin=mysql-bin</span></span><br><span class="line"><span class="string">    read-only=0</span></span><br><span class="line"><span class="string">    replicate-ignore-db=mysql</span></span><br><span class="line"><span class="string">    replicate-ignore-db=sys</span></span><br><span class="line"><span class="string">    replicate-ignore-db=information_schema</span></span><br><span class="line"><span class="string">    replicate-ignore-db=performance_schema</span></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f mysql-master-cnf.yaml</span><br></pre></td></tr></table></figure>

<p>这个 ConfigMap 提供 my.cnf 覆盖设置，可以独立控制 MySQL 主服务器配置。ConfigMap 本身没有什么特别之处，因而也不会出现不同部分应用于不同的 Pod 的情况。每个 Pod 都会在初始化时基于 StatefulSet 控制器提供的信息决定要查看的部分。slave从服务器配置和主服务器配置基本相同，需要修改metadata.name&#x3D; mysql-slave-cnf,server_id&#x3D;2,read-only&#x3D;0。</p>
<p>获取mysql-master-0和mysql-slave-0的ConfigMap ：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get cm -nbc-cnp</span><br></pre></td></tr></table></figure>

<p>输出类似于：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302200920566.png" alt="图片"></p>
<h3 id="创建pv和pvc，写入稳定存储"><a href="#创建pv和pvc，写入稳定存储" class="headerlink" title="创建pv和pvc，写入稳定存储"></a><strong>创建pv和pvc，写入稳定存储</strong></h3><p>使用以下 YAML 配置文件创建服务：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment">#master--pv</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql-pv-master</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">10Gi</span></span><br><span class="line">  <span class="attr">local:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/home/k8s/master/data</span></span><br><span class="line">  <span class="attr">nodeAffinity:</span></span><br><span class="line">    <span class="attr">required:</span></span><br><span class="line">      <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">kubernetes.io/hostname</span></span><br><span class="line">          <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">          <span class="attr">values:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">paas-cnp-k8s-kce-01</span>  </span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment">#master--pvc</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql-pvc-master</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">bc-cnp</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">10Gi</span></span><br><span class="line">  <span class="attr">volumeName:</span> <span class="string">mysql-pv-master</span></span><br></pre></td></tr></table></figure>

<p>slave采用同样的方式创建pv及pvc，只名字修改为slave即可。</p>
<p>获取master和slave的PersistentVolumeClaims：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pvc -nbc-cnp</span><br></pre></td></tr></table></figure>

<p>输出类似于：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302200920858.png" alt="图片"></p>
<p>为StatefulSet 控制器创建了两个 PersistentVolumeClaims， 绑定到两个 PersistentVolumes。</p>
<p>Mysql 服务器默认会加载位于 &#x2F;var&#x2F;lib&#x2F;mysql-files 的文件。StatefulSet spec 中的 volumeMounts 字段保证了&#x2F;var&#x2F;lib&#x2F;mysql-files 文件夹由一个 PersistentVolume 卷支持。</p>
<h3 id="创建-Service"><a href="#创建-Service" class="headerlink" title="创建 Service"></a><strong>创建 Service</strong></h3><p>使用以下 YAML 配置文件创建服务：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#master--headless service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">bc-cnp</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">mysql-master</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">kubesphere.io/serviceType:</span> <span class="string">statefulservice</span></span><br><span class="line">    <span class="attr">kubesphere.io/alias-name:</span> <span class="string">mysql主节点</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql-master</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">sessionAffinity:</span> <span class="string">ClientIP</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">mysql-master</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tcp-3306</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">3306</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">3306</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tcp-33060</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">33060</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">33060</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">sessionAffinityConfig:</span></span><br><span class="line">    <span class="attr">clientIP:</span></span><br><span class="line">      <span class="attr">timeoutSeconds:</span> <span class="number">10800</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment">#master--nodePort service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql-master-front</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">mysql-master</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">bc-cnp</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">mysql-master</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">3306</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">3306</span></span><br><span class="line">      <span class="attr">nodePort:</span> <span class="number">30001</span>  </span><br><span class="line">  <span class="attr">sessionAffinity:</span> <span class="string">None</span></span><br></pre></td></tr></table></figure>

<p>执行YAML：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f mysql-master-services.yaml </span><br></pre></td></tr></table></figure>

<p>slave同样执行类似yaml，名字需要修改为mysql-slave相关，暴露nodeport改为：30002。</p>
<p>输出类似于：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302200920347.png" alt="图片"></p>
<p>headless service 的 CNAME 指向 SRV 记录（记录每个 Running 和 Ready 状态的 Pod）。SRV 记录指向一个包含 Pod IP 地址的记录表项。</p>
<p>headless service给 StatefulSet 控制器 为集合中每个 Pod 创建的 DNS 条目提供了一个宿主。因为无头服务名为 mysql-master，所以可以通过在同一 Kubernetes 集群和命名空间中的任何其他 Pod 内解析 <code>Pod 名称</code>.mysql-master 来访问 Pod。</p>
<p>mysql-master-front是一种常规 Service，具有其自己的集群 IP。该集群 IP 在报告就绪的所有 MySQL Pod 之间分配连接。可能的端点集合包括 MySQL 主节点和从节点。</p>
<p>请注意，只有读查询才能使用负载平衡的客户端 Service。因为只有一个 MySQL 主服务器，所以客户端应直接连接到 MySQL 主服务器 Pod （通过其在headless service 中的 DNS 条目）以执行写入操作。</p>
<h3 id="创建-StatefulSet"><a href="#创建-StatefulSet" class="headerlink" title="创建 StatefulSet"></a><strong>创建 StatefulSet</strong></h3><p>最后，使用以下 YAML 配置文件创建 StatefulSet：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#master--statefulset</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">bc-cnp</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">mysql-master</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql-master</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">kubesphere.io/alias-name:</span> <span class="string">mysql</span> <span class="string">master</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">mysql-master</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">mysql-master</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">master-container</span></span><br><span class="line">         <span class="comment"># type: worker</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">          <span class="attr">resources:</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">8Gi</span></span><br><span class="line">            <span class="attr">limits:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">&#x27;4&#x27;</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">16Gi</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">nexus.cmss.com:8086/cnp/mysql:8.0.18</span></span><br><span class="line">          <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_ROOT_PASSWORD</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">secretKeyRef:</span></span><br><span class="line">                  <span class="attr">name:</span> <span class="string">mysql-secret</span></span><br><span class="line">                  <span class="attr">key:</span> <span class="string">MYSQL_ROOT_PASSWORD</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">master-cnf-volume</span></span><br><span class="line">              <span class="attr">readOnly:</span> <span class="literal">false</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/etc/mysql</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">master-data-volume</span></span><br><span class="line">              <span class="attr">readOnly:</span> <span class="literal">false</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/var/lib/mysql-files</span></span><br><span class="line">      <span class="attr">serviceAccount:</span> <span class="string">default</span></span><br><span class="line">      <span class="attr">affinity:</span></span><br><span class="line">        <span class="attr">podAntiAffinity:</span></span><br><span class="line">          <span class="attr">preferredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">100</span></span><br><span class="line">              <span class="attr">podAffinityTerm:</span></span><br><span class="line">                <span class="attr">labelSelector:</span></span><br><span class="line">                  <span class="attr">matchLabels:</span></span><br><span class="line">                    <span class="attr">app:</span> <span class="string">mysql-master</span></span><br><span class="line">                <span class="attr">topologyKey:</span> <span class="string">kubernetes.io/hostname</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">master-cnf-volume</span></span><br><span class="line">          <span class="attr">configMap:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">mysql-master-cnf</span></span><br><span class="line">            <span class="attr">items:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">my.cnf</span></span><br><span class="line">                <span class="attr">path:</span> <span class="string">my.cnf</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">master-data-volume</span></span><br><span class="line">          <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">            <span class="attr">claimName:</span> <span class="string">mysql-pvc-master</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">mysql-master</span></span><br></pre></td></tr></table></figure>

<p>slave节点同样是替换yaml中名字跟slave相关，执行apply操作。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f mysql-master-statefulset.yaml</span><br></pre></td></tr></table></figure>

<p>通过运行以下命令查看启动进度：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pods -nbc-cnp</span><br></pre></td></tr></table></figure>

<p>可以看到所有 2 个 Pod 进入 Running 状态：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302200920175.png" alt="图片"></p>
<p>StatefulSet 中的每个 Pod 拥有一个唯一的顺序索引和稳定的网络身份标识。这个标志基于 StatefulSet 控制器分配给每个 Pod 的唯一顺序索引。Pod 名称的格式为 <code>&lt;statefulset 名称&gt;-&lt;序号索引&gt;</code>。</p>
<h2 id="主从同步"><a href="#主从同步" class="headerlink" title="主从同步"></a>主从同步</h2><p>进入mysql-master容器内部</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 1.进入mysql内部</span><br><span class="line">&gt;  mysql -uroot -pdsjbi@Min1a</span><br><span class="line">#切换到 mysql DB</span><br><span class="line">mysql&gt; USE mysql;   </span><br><span class="line"># 查看root用户是否具备远程访问权限</span><br><span class="line">mysql&gt; select Host,User,authentication_string,password_expired,password_last_changed from user; </span><br><span class="line"># 2.授权 root可以远程访问（主从无关，如root没有访问权限，执行以下命令，方便我们远程连接MySQL）</span><br><span class="line">mysql&gt; create user &#x27;root&#x27;@&#x27;%&#x27; identified by &#x27;dsjbi@Min1a&#x27;;</span><br><span class="line">Query OK, 0 rows affected, 1 warning (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; grant all privileges on *.* to &#x27;root&#x27;@&#x27;%&#x27;;</span><br><span class="line">Query OK, 0 rows affected, 1 warning (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; flush privileges;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"># 3.添加用来同步的用户</span><br><span class="line">mysql&gt; GRANT REPLICATION SLAVE ON *.* to &#x27;backup&#x27;@&#x27;%&#x27; identified by &#x27;dsjbi@Min1a&#x27;;</span><br><span class="line">Query OK, 0 rows affected, 1 warning (0.01 sec)</span><br><span class="line"># 4.查看master状态</span><br><span class="line">mysql&gt; show master status\G;</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">             File: mysql-bin.000003</span><br><span class="line">         Position: 2688</span><br><span class="line">     Binlog_Do_DB:</span><br><span class="line"> Binlog_Ignore_DB:</span><br><span class="line">Executed_Gtid_Set:</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure>

<p>然后进入到mysql-slave内部</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 进入mysql内部</span><br><span class="line">mysql -uroot -pdsjbi@Min1a</span><br><span class="line"># 设置主库连接  主库 dns: mysql-master.default.svc.cluster.local</span><br><span class="line">change master to master_host=&#x27;mysql-master.bc-cnp.svc.cluster.local&#x27;,master_user=&#x27;backup&#x27;,master_password=&#x27;dsjbi@Min1a&#x27;,master_log_file=&#x27;mysql_bin.000003&#x27;,master_log_pos=0,master_port=3306;</span><br><span class="line"># 启动从库同步</span><br><span class="line">start slave;</span><br><span class="line"># 查看从从库状态</span><br><span class="line">show slave status\G;</span><br></pre></td></tr></table></figure>

<p>只有当以下两项都是yes，才意味着同步成功。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302200920429.png" alt="图片"></p>
<p>如果同步不成功，尝试执行以下命令，再次查看。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">stop slave;</span><br><span class="line">reset slave;</span><br><span class="line">start slave;</span><br></pre></td></tr></table></figure>

<h2 id="结果验证"><a href="#结果验证" class="headerlink" title="结果验证"></a>结果验证</h2><p>最终验证结果，在master mysql创建一个database及table，插入数据，在slave中依然能够查看相关数据，确认主从同步成功。</p>
<p>进入主的mysql-master容器内部，执行创建操作，如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302200920880.png" alt="图片"></p>
<p>进入从的mysql-slave容器内部，执行创建操作，如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302200920489.png" alt="图片"></p>
<p>至此，确认从库中已有主库中数据，同步成功。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>StatefulSet 中每个 Pod 都拥有一个基于其顺序索引的稳定的主机名，如果pod发生故障，StatefulSet 重启他们，Pod 的序号、主机名、SRV 条目和记录名称没有改变，但和 Pod 相关联的 IP 地址可能发生了改变。这就是为什么不要在其他应用中使用 StatefulSet 中 Pod 的 IP 地址进行连接，这点很重要。</p>
<p>StatefulSet 的活动成员是和 CNAME 相关联的 SRV 记录，其中只会包含 StatefulSet 中处于 Running 和 Ready 状态的 Pod。</p>
<p>如果我们的应用已经实现了用于测试是否已存活（liveness）并就绪（readiness）的连接逻辑，我们可以使用 Pod 的 SRV 记录（mysql-master.default.svc.cluster.local）。并且当里面的 Pod 的状态变为 Running 和 Ready 时，我们的应用就能够发现各个pod的地址。</p>
<p>虽然 mysql-master-0 和 mysql-slave-0 有时候会被重新调度，但它们仍然继续监听各自的主机名，因为和它们的 PersistentVolumeClaim 相关联的 PersistentVolume 卷被重新挂载到了各自的 volumeMount 上。不管mysql-master-0 和 mysql-slave-0 被调度到了哪个节点上，它们的 PersistentVolume 卷将会被挂载到合适的挂载点上。</p>
]]></content>
      <categories>
        <category>kubernetes</category>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2023/03/22/%E5%A6%82%E4%BD%95%E7%94%A8Loki%E6%9D%A5%E5%88%86%E6%9E%90Kubernetes%E4%BA%8B%E4%BB%B6/</url>
    <content><![CDATA[<h2 id="—10title-如何用Loki来分析Kubernetes事件date-2023-03-22-10-52-55type-categoriestags-kubernetes-Grafana-Lokikeywords-kubernetes-Grafana-Lokicategories-kubernetes-Grafana-Loki"><a href="#—10title-如何用Loki来分析Kubernetes事件date-2023-03-22-10-52-55type-categoriestags-kubernetes-Grafana-Lokikeywords-kubernetes-Grafana-Lokicategories-kubernetes-Grafana-Loki" class="headerlink" title="—10title: 如何用Loki来分析Kubernetes事件date: 2023-03-22 10:52:55type: categoriestags:    - kubernetes    - Grafana    - Lokikeywords:    - kubernetes    - Grafana    - Lokicategories:    - kubernetes    - Grafana    - Loki"></a>—10<br>title: 如何用Loki来分析Kubernetes事件<br>date: 2023-03-22 10:52:55<br>type: categories<br>tags:<br>    - kubernetes<br>    - Grafana<br>    - Loki<br>keywords:<br>    - kubernetes<br>    - Grafana<br>    - Loki<br>categories:<br>    - kubernetes<br>    - Grafana<br>    - Loki</h2><p>在Kubernetes API的众多对象中，Events算是最容易被我们忽视的类型之一。与其他对象相比，Event的活动量很大，不太可能长时间存储在etcd中，默认情况下，Event留存时间也只有1小时。当我们使用<code>kubectl describe</code>获取一个对象时，可能因时间超限而无法获取它的历史事件，这对集群的使用者非常的不友好。除了能查看集群事件外，我们可能还有类似追踪一些特定的Warning事件（如Pod生命周期、副本集或worker节点状态）来进行相关告警的需求。那么在开启本期话题之前，我们先来理解下Kubernetes Events的结构，下述是官访问给出的几个重要字段解释</p>
<ul>
<li><strong>Message</strong>: A human-readable description of the status of this operation</li>
<li><strong>Involved Object</strong>: The object that the event is about, like Pod, Deployment, Node, etc.</li>
<li><strong>Reason: Short</strong>, machine-understandable string – in other words, Enum</li>
<li><strong>Source</strong>: The component reporting this event; a short, machine-understandable string, i.e., kube-scheduler</li>
<li><strong>Type</strong>: Currently holds only Normal &amp; Warning, but custom types can be given if desired.</li>
<li><strong>Count</strong>: The number of times the event has occurred</li>
</ul>
<p>对于这些事件，我们期望能有一个采集工具将信息输出到一个持久化的地方进行存储和分析。在以往，通常我们将kubernetes的事件输出到Elasticsearch进行索引分析。</p>
<p>既然本文讨论的是以Loki来分析kubernes的事件，那我们对于事件的处理基本按照如下流程：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">flowchart LR</span><br><span class="line">kubernetes-api --&gt; event-exporter --&gt; fluentd --&gt; loki --&gt; grafana</span><br></pre></td></tr></table></figure>

<p>目前能够采集Kubernetes Events的开源组件主要以阿里云开源的kube-eventer和Opsgenie开源的kubernetes-event-exporter为主（kubesphere也有一个kube-events，不过需要配合其它组件的CRD使用，所以不在讨论范围之中）</p>
<p>当事件进入到Loki后，就可以通过LogQL v2语句在Grafana上进行可视化查询，比如我们可以让Kubernetes中的事件按照等级、类型分类统计展示。通过Dashboard可以快速看到集群当前的的一些异常情况。<img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303221045766.jpeg" alt="图片"><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303221048526.jpeg" alt="图片"></p>
<h2 id="kubernetes-event-exporter"><a href="#kubernetes-event-exporter" class="headerlink" title="kubernetes-event-exporter"></a>kubernetes-event-exporter</h2><p>首先需要部署kubernetes-event-exporter，它会将集群的事件打印到<code>容器stdout当中</code>以方便日志采集</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">event-exporter</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">event-exporter</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">view</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">    <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">event-exporter</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">event-exporter-cfg</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">config.yaml:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    logLevel: error</span></span><br><span class="line"><span class="string">    logFormat: json</span></span><br><span class="line"><span class="string">    route:</span></span><br><span class="line"><span class="string">      routes:</span></span><br><span class="line"><span class="string">        - match:</span></span><br><span class="line"><span class="string">            - receiver: &quot;dump&quot;</span></span><br><span class="line"><span class="string">    receivers:</span></span><br><span class="line"><span class="string">      - name: &quot;dump&quot;</span></span><br><span class="line"><span class="string">        file:</span></span><br><span class="line"><span class="string">          path: &quot;/dev/stdout&quot;</span></span><br><span class="line"><span class="string"></span><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">event-exporter</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">event-exporter</span></span><br><span class="line">        <span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">event-exporter</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">event-exporter</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">opsgenie/kubernetes-event-exporter:0.9</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">          <span class="attr">args:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">-conf=/data/config.yaml</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/data</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">cfg</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cfg</span></span><br><span class="line">          <span class="attr">configMap:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">event-exporter-cfg</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">event-exporter</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v1</span></span><br></pre></td></tr></table></figure>

<p>当容器完全运行之后，通过kubectl logs可以看到event-exporter容器会以json格式打印的集群事件了。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303221048138.jpeg" alt="图片"></p>
<p>通常运行在Kubernetes之上Fluentd和FluentBit默认会采集容器的日志，我们需要做的是将这些内容发送给Loki</p>
<p>这里就不对日志采集的配置做其他说明，有疑问的同学可以参考之前的文章《fluentd和loki的那些事儿》</p>
<p>最终我们可以在Dagger上查询Kubernetes事件的写入情况</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303221048062.jpeg" alt="图片"></p>
<h2 id="扩展-Node-Problem-Detector"><a href="#扩展-Node-Problem-Detector" class="headerlink" title="扩展 Node Problem Detector"></a>扩展 Node Problem Detector</h2><p>Kubernetes中关于Node的事件不多，对于节点上更多偏向底层的状态（如内核死锁、容器运行时无响应等）并不能通过事件的方式通知出来。<strong>Node Problem Detector</strong>作为一个很好的补充，它可以将node上更细节的事件以<code>NodeCondition</code>和<code>Event</code>方式上报给Kubernetes。</p>
<p>安装<strong>Node Problem Detector</strong>非常简单，只需要通过helm的两条命令即可完成。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm repo add deliveryhero https://charts.deliveryhero.io/</span><br><span class="line">helm install deliveryhero/node-problem-detector</span><br></pre></td></tr></table></figure>

<p><strong>Node Problem Detector</strong>支持用户运行自定义脚本来构造事件，本文中的Node Problem Detector除了默认的配置外，还有关于定义的网络监控脚步来做node节点上Conntrack的检查</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">node-problem-detector-config</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">network_problem.sh:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    #!/bin/bash</span></span><br><span class="line"><span class="string">    readonly OK=0</span></span><br><span class="line"><span class="string">    readonly NONOK=1</span></span><br><span class="line"><span class="string">    readonly UNKNOWN=2</span></span><br><span class="line"><span class="string"></span></span><br><span class="line">    <span class="string">readonly</span> <span class="string">NF_CT_COUNT_PATH=&#x27;/proc/sys/net/netfilter/nf_conntrack_count&#x27;</span></span><br><span class="line">    <span class="string">readonly</span> <span class="string">NF_CT_MAX_PATH=&#x27;/proc/sys/net/netfilter/nf_conntrack_max&#x27;</span></span><br><span class="line">    <span class="string">readonly</span> <span class="string">IP_CT_COUNT_PATH=&#x27;/proc/sys/net/ipv4/netfilter/ip_conntrack_count&#x27;</span></span><br><span class="line">    <span class="string">readonly</span> <span class="string">IP_CT_MAX_PATH=&#x27;/proc/sys/net/ipv4/netfilter/ip_conntrack_max&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="string">if</span> [[ <span class="string">-f</span> <span class="string">$NF_CT_COUNT_PATH</span> ]] <span class="string">&amp;&amp;</span> [[ <span class="string">-f</span> <span class="string">$NF_CT_MAX_PATH</span> ]]<span class="string">;</span> <span class="string">then</span></span><br><span class="line">      <span class="string">readonly</span> <span class="string">CT_COUNT_PATH=$NF_CT_COUNT_PATH</span></span><br><span class="line">      <span class="string">readonly</span> <span class="string">CT_MAX_PATH=$NF_CT_MAX_PATH</span></span><br><span class="line">    <span class="string">elif</span> [[ <span class="string">-f</span> <span class="string">$IP_CT_COUNT_PATH</span> ]] <span class="string">&amp;&amp;</span> [[ <span class="string">-f</span> <span class="string">$IP_CT_MAX_PATH</span> ]]<span class="string">;</span> <span class="string">then</span></span><br><span class="line">      <span class="string">readonly</span> <span class="string">CT_COUNT_PATH=$IP_CT_COUNT_PATH</span></span><br><span class="line">      <span class="string">readonly</span> <span class="string">CT_MAX_PATH=$IP_CT_MAX_PATH</span></span><br><span class="line">    <span class="string">else</span></span><br><span class="line">      <span class="string">exit</span> <span class="string">$UNKNOWN</span></span><br><span class="line">    <span class="string">fi</span></span><br><span class="line"></span><br><span class="line">    <span class="string">readonly</span> <span class="string">conntrack_count=$(&lt;</span> <span class="string">$CT_COUNT_PATH)</span> <span class="string">||</span> <span class="string">exit</span> <span class="string">$UNKNOWN</span></span><br><span class="line">    <span class="string">readonly</span> <span class="string">conntrack_max=$(&lt;</span> <span class="string">$CT_MAX_PATH)</span> <span class="string">||</span> <span class="string">exit</span> <span class="string">$UNKNOWN</span></span><br><span class="line">    <span class="string">readonly</span> <span class="string">conntrack_usage_msg=&quot;$&#123;conntrack_count&#125;</span> <span class="string">out</span> <span class="string">of</span> <span class="string">$&#123;conntrack_max&#125;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="string">if</span> <span class="string">((</span> <span class="string">conntrack_count</span> <span class="string">&gt;</span> <span class="string">conntrack_max</span> <span class="string">*</span> <span class="number">9</span> <span class="string">/10</span> <span class="string">));</span> <span class="string">then</span></span><br><span class="line">      <span class="string">echo</span> <span class="string">&quot;Conntrack table usage over 90%: $&#123;conntrack_usage_msg&#125;&quot;</span></span><br><span class="line">      <span class="string">exit</span> <span class="string">$NONOK</span></span><br><span class="line">    <span class="string">else</span></span><br><span class="line">      <span class="string">echo</span> <span class="string">&quot;Conntrack table usage: $&#123;conntrack_usage_msg&#125;&quot;</span></span><br><span class="line">      <span class="string">exit</span> <span class="string">$OK</span></span><br><span class="line">    <span class="string">fi</span></span><br><span class="line">  <span class="attr">network-problem-monitor.json:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">        &quot;plugin&quot;: &quot;custom&quot;,</span></span><br><span class="line"><span class="string">        &quot;pluginConfig&quot;: &#123;</span></span><br><span class="line"><span class="string">            &quot;invoke_interval&quot;: &quot;30s&quot;,</span></span><br><span class="line"><span class="string">            &quot;timeout&quot;: &quot;5s&quot;,</span></span><br><span class="line"><span class="string">            &quot;max_output_length&quot;: 80,</span></span><br><span class="line"><span class="string">            &quot;concurrency&quot;: 3</span></span><br><span class="line"><span class="string">        &#125;,</span></span><br><span class="line"><span class="string">        &quot;source&quot;: &quot;network-plugin-monitor&quot;,</span></span><br><span class="line"><span class="string">        &quot;metricsReporting&quot;: true,</span></span><br><span class="line"><span class="string">        &quot;conditions&quot;: [],</span></span><br><span class="line"><span class="string">        &quot;rules&quot;: [</span></span><br><span class="line"><span class="string">            &#123;</span></span><br><span class="line"><span class="string">                &quot;type&quot;: &quot;temporary&quot;,</span></span><br><span class="line"><span class="string">                &quot;reason&quot;: &quot;ConntrackFull&quot;,</span></span><br><span class="line"><span class="string">                &quot;path&quot;: &quot;/config/network_problem.sh&quot;,</span></span><br><span class="line"><span class="string">                &quot;timeout&quot;: &quot;5s&quot;</span></span><br><span class="line"><span class="string">            &#125;</span></span><br><span class="line"><span class="string">        ]</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string"></span><span class="string">...</span></span><br></pre></td></tr></table></figure>

<p>再编辑node-problem-detector的daemonset文件，将如下的自定义的脚本和规则内容引入</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">node-problem-detector</span></span><br><span class="line">        <span class="attr">command:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/node-problem-detector</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--logtostderr</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--config.system-log-monitor=/config/kernel-monitor.json,/config/docker-monitor.json</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--config.custom-plugin-monitor=/config/network-problem-monitor.json</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--prometheus-address=0.0.0.0</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--prometheus-port=20258</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--k8s-exporter-heartbeat-period=5m0s</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line">        <span class="attr">configMap:</span></span><br><span class="line">          <span class="attr">defaultMode:</span> <span class="number">0777</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">node-problem-detector-config</span></span><br><span class="line">          <span class="attr">items:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">kernel-monitor.json</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">kernel-monitor.json</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">docker-monitor.json</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">docker-monitor.json</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">network-problem-monitor.json</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">network-problem-monitor.json</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">network_problem.sh</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">network_problem.sh</span></span><br></pre></td></tr></table></figure>

<h2 id="Grafana分析面板"><a href="#Grafana分析面板" class="headerlink" title="Grafana分析面板"></a>Grafana分析面板</h2><p>已经将基于Loki的Kubernetes事件分析面板贡献在了Grafana Lab上面，我们可以访问如下网站下载Dashboard</p>
<p><a href="https://grafana.com/grafana/dashboards/14003">https://grafana.com/grafana/dashboards/14003</a></p>
<p>当将面板导入到Grafana之后，我们需要修改Panel的log查询语句，将{job&#x3D;”kubernetes-event-exporter”}替换为自己exporter的标签。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303221045705.jpeg" alt="图片"></p>
<p>之后，我们就可以得到如下的分析面板</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202303221048545.jpeg" alt="图片"></p>
]]></content>
  </entry>
  <entry>
    <title>用 Ansible 简化 K8S 部署</title>
    <url>/2023/02/01/%E7%94%A8%20Ansible%20%E7%AE%80%E5%8C%96%20K8S%20%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><p>前面我写了关于k8s环境部署的几篇文章，k8s部署还是比较麻烦的，所以是有必要考虑一键部署的方案，这里借助ansible playbook来实现k8s环境的一键部署，实现快速部署的目的。</p>
<p>节点信息</p>
<table>
<thead>
<tr>
<th align="center">主机名</th>
<th align="center">IP</th>
<th align="center">角色</th>
<th align="center">操作系统</th>
</tr>
</thead>
<tbody><tr>
<td align="center">local-168-182-110</td>
<td align="center">192.168.182.110</td>
<td align="center">master，ansible</td>
<td align="center">centos7</td>
</tr>
<tr>
<td align="center">local-168-182-111</td>
<td align="center">192.168.182.110</td>
<td align="center">master</td>
<td align="center">centos7</td>
</tr>
<tr>
<td align="center">local-168-182-112</td>
<td align="center">192.168.182.110</td>
<td align="center">master</td>
<td align="center">centos7</td>
</tr>
<tr>
<td align="center">local-168-182-113</td>
<td align="center">192.168.182.110</td>
<td align="center">node</td>
<td align="center">centos7</td>
</tr>
</tbody></table>
<p>k8s 架构图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302141358401.png" alt="图片"></p>
<p>基于ansible部署k8s流程图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302141356310.png" alt="图片"></p>
<h2 id="二、Ansible-部署"><a href="#二、Ansible-部署" class="headerlink" title="二、Ansible 部署"></a>二、Ansible 部署</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum -y install epel-release</span><br><span class="line">yum -y install ansible</span><br><span class="line">ansible --version</span><br></pre></td></tr></table></figure>

<h3 id="1）开启记录日志"><a href="#1）开启记录日志" class="headerlink" title="1）开启记录日志"></a>1）开启记录日志</h3><p>配置文件：<code>/etc/ansible/ansible.cfg</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /etc/ansible/ansible.cfg  </span><br><span class="line"><span class="comment"># 去掉前面的&#x27;#&#x27;号</span></span><br><span class="line"><span class="comment">#log_path = /var/log/ansible.log ==&gt; log_path = /var/log/ansible.log</span></span><br></pre></td></tr></table></figure>

<h3 id="2）去掉第一次连接ssh-ask确认"><a href="#2）去掉第一次连接ssh-ask确认" class="headerlink" title="2）去掉第一次连接ssh ask确认"></a>2）去掉第一次连接ssh ask确认</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /etc/ansible/ansible.cfg  </span><br><span class="line"><span class="comment"># 其实就是把#去掉</span></span><br><span class="line"><span class="comment"># host_key_checking = False  ==&gt; host_key_checking = False</span></span><br></pre></td></tr></table></figure>

<h3 id="3）配置hosts"><a href="#3）配置hosts" class="headerlink" title="3）配置hosts"></a>3）配置hosts</h3><p>配置文件：<code>/etc/ansible/hosts</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[master1]</span><br><span class="line">192.168.182.110</span><br><span class="line"></span><br><span class="line">[master2]</span><br><span class="line">192.168.182.111</span><br><span class="line">192.168.182.112</span><br><span class="line"></span><br><span class="line">[node]</span><br><span class="line">192.168.182.113</span><br><span class="line"></span><br><span class="line">[k8s:children]</span><br><span class="line">master1</span><br><span class="line">master2</span><br><span class="line">node</span><br><span class="line"></span><br><span class="line">[k8s:vars]</span><br><span class="line">ansible_ssh_user=root</span><br><span class="line">ansible_ssh_pass=1331301116</span><br><span class="line">ansible_ssh_port=22</span><br><span class="line"><span class="comment"># k8s 版本</span></span><br><span class="line">k8s_version=1.23.6</span><br></pre></td></tr></table></figure>

<p>测试连通性</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible k8s -m ping</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302141356229.png" alt="图片"></p>
<h2 id="三、开始编排-ansible-playbook"><a href="#三、开始编排-ansible-playbook" class="headerlink" title="三、开始编排 ansible playbook"></a>三、开始编排 ansible playbook</h2><h3 id="1）创建目录"><a href="#1）创建目录" class="headerlink" title="1）创建目录"></a>1）创建目录</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -pv ./install-k8s/&#123;init,install-docker,install-k8s,master-init,install-cni,install-ipvs,master-join,node-join,install-ingress-nginx,install-nfs-provisioner,install-harbor,install-metrics-server,uninstall-k8s&#125;/&#123;files,templates,vars,tasks,handlers,meta,default&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2）节点初始化"><a href="#2）节点初始化" class="headerlink" title="2）节点初始化"></a>2）节点初始化</h3><ul>
<li>准备<code>install-k8s/init/files/hosts</code>文件</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">192.168.182.110 local-168-182-110</span><br><span class="line">192.168.182.111 local-168-182-111</span><br><span class="line">192.168.182.112 local-168-182-112</span><br><span class="line">192.168.182.113 local-168-182-113</span><br></pre></td></tr></table></figure>

<ul>
<li>准备脚本<code>install-k8s/init/templates/init.sh</code>，内容如下：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 【第一步】修改主机名</span></span><br><span class="line"><span class="comment"># 获取主机名</span></span><br><span class="line">hostnamectl set-hostname $(grep `hostname -i` /tmp/hosts|awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 【第二步】配置hosts</span></span><br><span class="line"><span class="comment"># 先删除</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> `<span class="built_in">cat</span> /tmp/hosts`</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    sed -i <span class="string">&quot;/<span class="variable">$line</span>/d&quot;</span> /etc/hosts</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="comment"># 追加</span></span><br><span class="line"><span class="built_in">cat</span> /tmp/hosts &gt;&gt; /etc/hosts</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 【第三步】添加互信</span></span><br><span class="line"><span class="comment"># 先创建秘钥对</span></span><br><span class="line">ssh-keygen -f ~/.ssh/id_rsa -P <span class="string">&#x27;&#x27;</span> -q</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装expect</span></span><br><span class="line">yum -y install expect -y</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量推送公钥</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> `<span class="built_in">cat</span> /tmp/hosts`</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line"></span><br><span class="line">ip=`<span class="built_in">echo</span> <span class="variable">$line</span>|awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>`</span><br><span class="line">password=&#123;&#123; ansible_ssh_pass &#125;&#125;</span><br><span class="line"></span><br><span class="line">expect &lt;&lt;-<span class="string">EOF</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">spawn ssh-copy-id -i /root/.ssh/id_rsa.pub $ip</span></span><br><span class="line"><span class="string">expect &#123;</span></span><br><span class="line"><span class="string">    &quot;(yes/no)?&quot;</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">        send &quot;yes\n&quot;</span></span><br><span class="line"><span class="string">        expect &quot;*assword:&quot; &#123; send &quot;$password\n&quot;&#125;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    &quot;*assword:&quot;</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">        send &quot;$password\n&quot;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">expect eof</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 【第四步】时间同步</span></span><br><span class="line">yum install chrony -y</span><br><span class="line">systemctl start chronyd</span><br><span class="line">systemctl <span class="built_in">enable</span> chronyd</span><br><span class="line">chronyc sources</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 【第五步】关闭防火墙</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 【第六步】关闭swap</span></span><br><span class="line"><span class="comment"># 临时关闭；关闭swap主要是为了性能考虑</span></span><br><span class="line">swapoff -a</span><br><span class="line"><span class="comment"># 永久关闭</span></span><br><span class="line">sed -ri <span class="string">&#x27;s/.*swap.*/#&amp;/&#x27;</span> /etc/fstab</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 【第七步】禁用SELinux</span></span><br><span class="line"><span class="comment"># 临时关闭</span></span><br><span class="line">setenforce 0</span><br><span class="line"><span class="comment"># 永久禁用</span></span><br><span class="line">sed -i <span class="string">&#x27;s/^SELINUX=enforcing$/SELINUX=disabled/&#x27;</span> /etc/selinux/config</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 【第八步】允许 iptables 检查桥接流量</span></span><br><span class="line">sudo modprobe br_netfilter</span><br><span class="line">lsmod | grep br_netfilter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 先删</span></span><br><span class="line"><span class="built_in">rm</span> -rf /etc/modules-load.d/k8s.conf</span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> &lt;&lt;<span class="string">EOF | sudo tee /etc/modules-load.d/k8s.conf</span></span><br><span class="line"><span class="string">overlay</span></span><br><span class="line"><span class="string">br_netfilter</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">sudo modprobe overlay</span><br><span class="line">sudo modprobe br_netfilter</span><br><span class="line"></span><br><span class="line"><span class="built_in">rm</span> -rf /etc/sysctl.d/k8s.conf</span><br><span class="line"><span class="comment"># 设置所需的 sysctl 参数，参数在重新启动后保持不变</span></span><br><span class="line"><span class="built_in">cat</span> &lt;&lt;<span class="string">EOF | sudo tee /etc/sysctl.d/k8s.conf</span></span><br><span class="line"><span class="string">net.bridge.bridge-nf-call-iptables  = 1</span></span><br><span class="line"><span class="string">net.bridge.bridge-nf-call-ip6tables = 1</span></span><br><span class="line"><span class="string">net.ipv4.ip_forward                 = 1</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 应用 sysctl 参数而不重新启动</span></span><br><span class="line">sudo sysctl --system</span><br></pre></td></tr></table></figure>

<ul>
<li>任务编排 <code>install-k8s/init/tasks/main.yml</code></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cp</span> <span class="string">hosts</span></span><br><span class="line">  <span class="attr">copy:</span> <span class="string">src=hosts</span> <span class="string">dest=/tmp/hosts</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">init</span> <span class="string">cp</span></span><br><span class="line">  <span class="attr">template:</span> <span class="string">src=init.sh</span> <span class="string">dest=/tmp/init.sh</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">init</span> <span class="string">install</span></span><br><span class="line">  <span class="attr">shell:</span> <span class="string">sh</span> <span class="string">/tmp/init.sh</span></span><br></pre></td></tr></table></figure>

<h3 id="3）安装-docker"><a href="#3）安装-docker" class="headerlink" title="3）安装 docker"></a>3）安装 docker</h3><ul>
<li><code>install-k8s/install-docker/files/install-docker.sh</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 安装docker</span></span><br><span class="line"><span class="comment"># 配置yum源</span></span><br><span class="line"><span class="built_in">cd</span> /etc/yum.repos.d ; <span class="built_in">mkdir</span> bak; <span class="built_in">mv</span> CentOS-Linux-* bak/</span><br><span class="line"><span class="comment"># centos7</span></span><br><span class="line">wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class="line"><span class="comment"># centos8</span></span><br><span class="line"><span class="comment"># wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-8.repo</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装yum-config-manager配置工具</span></span><br><span class="line">yum -y install yum-utils</span><br><span class="line"><span class="comment"># 设置yum源</span></span><br><span class="line">yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line"><span class="comment"># 安装docker-ce版本</span></span><br><span class="line">yum install -y docker-ce</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动并开机自启</span></span><br><span class="line">systemctl <span class="built_in">enable</span> --now docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># Docker镜像源设置</span></span><br><span class="line"><span class="comment"># 修改文件 /etc/docker/daemon.json，没有这个文件就创建</span></span><br><span class="line"><span class="comment"># 添加以下内容后，重启docker服务：</span></span><br><span class="line"><span class="built_in">cat</span> &gt;/etc/docker/daemon.json&lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">   &quot;registry-mirrors&quot;: [&quot;http://hub-mirror.c.163.com&quot;],</span></span><br><span class="line"><span class="string">    &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="comment"># 重启</span></span><br><span class="line">systemctl restart docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">systemctl status docker containerd</span><br></pre></td></tr></table></figure>

<ul>
<li>任务编排 <code>install-k8s/install-docker/tasks/main.yml</code></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install</span> <span class="string">docker</span> <span class="string">cp</span></span><br><span class="line">  <span class="attr">copy:</span> <span class="string">src=install-docker.sh</span> <span class="string">dest=/tmp/install-docker.sh</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install</span> <span class="string">docker</span></span><br><span class="line">  <span class="attr">shell:</span> <span class="string">sh</span> <span class="string">/tmp/install-docker.sh</span></span><br></pre></td></tr></table></figure>

<h3 id="4）安装-k8s-相关组件"><a href="#4）安装-k8s-相关组件" class="headerlink" title="4）安装 k8s 相关组件"></a>4）安装 k8s 相关组件</h3><ul>
<li><code>install-k8s/install-k8s/templates/install-k8s.sh</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查是否已经安装</span></span><br><span class="line">yum list installed kubelet</span><br><span class="line"><span class="keyword">if</span> [ $? -eq 0 ];<span class="keyword">then</span></span><br><span class="line">   <span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[k8s]</span></span><br><span class="line"><span class="string">name=k8s</span></span><br><span class="line"><span class="string">enabled=1</span></span><br><span class="line"><span class="string">gpgcheck=0</span></span><br><span class="line"><span class="string">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># disableexcludes=kubernetes：禁掉除了这个kubernetes之外的别的仓库</span></span><br><span class="line">yum install -y kubelet-&#123;&#123; k8s_version &#125;&#125; kubeadm-&#123;&#123; k8s_version &#125;&#125; kubectl-&#123;&#123; k8s_version &#125;&#125; --disableexcludes=kubernetes</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置为开机自启并现在立刻启动服务 --now：立刻启动服务</span></span><br><span class="line">systemctl <span class="built_in">enable</span> --now kubelet</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看状态，这里需要等待一段时间再查看服务状态，启动会有点慢</span></span><br><span class="line">systemctl status kubelet</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提前下载好</span></span><br><span class="line">docker pull registry.aliyuncs.com/google_containers/kube-apiserver:v&#123;&#123; k8s_version &#125;&#125;</span><br><span class="line">docker pull registry.aliyuncs.com/google_containers/kube-controller-manager:v&#123;&#123; k8s_version &#125;&#125;</span><br><span class="line">docker pull registry.aliyuncs.com/google_containers/kube-scheduler:v&#123;&#123; k8s_version &#125;&#125;</span><br><span class="line">docker pull registry.aliyuncs.com/google_containers/kube-proxy:v&#123;&#123; k8s_version &#125;&#125;</span><br><span class="line">docker pull registry.aliyuncs.com/google_containers/pause:3.6</span><br><span class="line">docker pull registry.aliyuncs.com/google_containers/etcd:3.5.1-0</span><br><span class="line">docker pull registry.aliyuncs.com/google_containers/coredns:v1.8.6</span><br></pre></td></tr></table></figure>

<ul>
<li>任务编排 <code>install-k8s/install-k8s/tasks/main.yml</code></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install</span> <span class="string">k8s</span> <span class="string">cp</span></span><br><span class="line">  <span class="attr">template:</span> <span class="string">src=install-k8s.sh</span> <span class="string">dest=/tmp/install-k8s.sh</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install</span> <span class="string">k8s</span></span><br><span class="line">  <span class="attr">shell:</span> <span class="string">sh</span> <span class="string">/tmp/install-k8s.sh</span></span><br></pre></td></tr></table></figure>

<h3 id="5）k8s-master节点初始化"><a href="#5）k8s-master节点初始化" class="headerlink" title="5）k8s master节点初始化"></a>5）k8s master节点初始化</h3><ul>
<li><code>install-k8s/master-init/templates/master-init.sh</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 判断是否已经初始化了</span></span><br><span class="line">kubectl get nodes |grep -q `hostname` 1&gt;&amp;2 &gt;/dev/null</span><br><span class="line"><span class="keyword">if</span> [ $? -eq 0 ];<span class="keyword">then</span></span><br><span class="line">   <span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">ip=`hostname -i`</span><br><span class="line"></span><br><span class="line">kubeadm init \</span><br><span class="line">  --apiserver-advertise-address=<span class="variable">$ip</span> \</span><br><span class="line">  --image-repository registry.aliyuncs.com/google_containers \</span><br><span class="line">  --kubernetes-version v&#123;&#123; k8s_version &#125;&#125; \</span><br><span class="line">  --control-plane-endpoint=<span class="variable">$ip</span> \</span><br><span class="line">  --service-cidr=10.1.0.0/16 \</span><br><span class="line">  --pod-network-cidr=10.244.0.0/16 \</span><br><span class="line">  --v=5</span><br><span class="line"></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$HOME</span>/.kube</span><br><span class="line"><span class="built_in">rm</span> -rf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">sudo <span class="built_in">cp</span> -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">sudo <span class="built_in">chown</span> $(<span class="built_in">id</span> -u):$(<span class="built_in">id</span> -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure>

<ul>
<li>任务编排 <code>install-k8s/master-init/tasks/main.yml</code></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">k8s</span> <span class="string">master</span> <span class="string">init</span> <span class="string">cp</span></span><br><span class="line">  <span class="attr">template:</span> <span class="string">src=master-init.sh</span> <span class="string">dest=/tmp/master-init.sh</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">k8s</span> <span class="string">master</span> <span class="string">init</span></span><br><span class="line">  <span class="attr">shell:</span> <span class="string">sh</span> <span class="string">/tmp/master-init.sh</span></span><br></pre></td></tr></table></figure>

<h3 id="6）安装-CNI（flannel）"><a href="#6）安装-CNI（flannel）" class="headerlink" title="6）安装 CNI（flannel）"></a>6）安装 CNI（flannel）</h3><ul>
<li><code>install-k8s/install-cni/files/install-flannel.sh</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 去掉master污点</span></span><br><span class="line">kubectl taint nodes `hostname` node-role.kubernetes.io/master:NoSchedule- 2&gt;/dev/null</span><br><span class="line">kubectl taint nodes `hostname` node.kubernetes.io/not-ready:NoSchedule- 2&gt;/dev/null</span><br><span class="line"></span><br><span class="line"><span class="comment"># For Kubernetes v1.17+</span></span><br><span class="line">kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/v0.20.2/Documentation/kube-flannel.yml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">kubectl get all -n kube-flannel</span><br><span class="line"></span><br><span class="line"><span class="comment"># 持续检查</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">true</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">   kubectl get pods -n kube-flannel|grep -q <span class="string">&#x27;0/1&#x27;</span></span><br><span class="line">   <span class="keyword">if</span> [ $? -ne 0 ];<span class="keyword">then</span></span><br><span class="line">      <span class="built_in">echo</span> <span class="string">&quot;flannel started&quot;</span></span><br><span class="line">      <span class="built_in">break</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      <span class="built_in">echo</span> <span class="string">&quot;flannel starting...&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="built_in">sleep</span> 1</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<ul>
<li>任务编排 <code>install-k8s/install-cni/tasks/main.yml</code></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install</span> <span class="string">cni</span> <span class="string">flannel</span> <span class="string">cp</span></span><br><span class="line">  <span class="attr">copy:</span> <span class="string">src=install-flannel.sh</span> <span class="string">dest=/tmp/install-flannel.sh</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install</span> <span class="string">cni</span> <span class="string">flannel</span></span><br><span class="line">  <span class="attr">shell:</span> <span class="string">sh</span> <span class="string">/tmp/install-flannel.sh</span></span><br></pre></td></tr></table></figure>

<h3 id="7）master-节点加入k8s集群"><a href="#7）master-节点加入k8s集群" class="headerlink" title="7）master 节点加入k8s集群"></a>7）master 节点加入k8s集群</h3><ul>
<li><code>install-k8s/master-join/files/master-join.sh</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取master ip，假设都是第一个节点为master</span></span><br><span class="line"><span class="comment"># 证如果过期了，可以使用下面命令生成新证书上传，这里会打印出certificate key，后面会用到</span></span><br><span class="line">maser_ip=`<span class="built_in">head</span> -1 /tmp/hosts |awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>`</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判断节点是否加入</span></span><br><span class="line">ssh <span class="variable">$maser_ip</span> <span class="string">&quot;kubectl get nodes|grep -q `hostname`&quot;</span></span><br><span class="line"><span class="keyword">if</span> [ $? -eq 0 ];<span class="keyword">then</span></span><br><span class="line"> <span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">CERT_KEY=`ssh <span class="variable">$maser_ip</span> <span class="string">&quot;kubeadm init phase upload-certs --upload-certs|tail -1&quot;</span>`</span><br><span class="line"></span><br><span class="line">join_str=`ssh <span class="variable">$maser_ip</span> kubeadm token create --print-join-command`</span><br><span class="line"></span><br><span class="line">$( <span class="built_in">echo</span> <span class="variable">$join_str</span> <span class="string">&quot; --control-plane --certificate-key <span class="variable">$CERT_KEY</span> --v=5&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拿到上面打印的命令在需要添加的节点上执行</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --control-plane 标志通知 kubeadm join 创建一个新的控制平面。加入master必须加这个标记</span></span><br><span class="line"><span class="comment"># --certificate-key ... 将导致从集群中的 kubeadm-certs Secret 下载控制平面证书并使用给定的密钥进行解密。这里的值就是上面这个命令（kubeadm init phase upload-certs --upload-certs）打印出的key。</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">sudo <span class="built_in">cp</span> -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">sudo <span class="built_in">chown</span> $(<span class="built_in">id</span> -u):$(<span class="built_in">id</span> -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"></span><br><span class="line"><span class="comment"># 去掉master污点</span></span><br><span class="line">kubectl taint nodes `hostname` node-role.kubernetes.io/master:NoSchedule- 2&gt;/dev/null</span><br><span class="line">kubectl taint nodes `hostname` node.kubernetes.io/not-ready:NoSchedule- 2&gt;/dev/null</span><br></pre></td></tr></table></figure>

<ul>
<li>任务编排 <code>install-k8s/master-join/tasks/main.yml</code></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">master</span> <span class="string">join</span> <span class="string">cp</span></span><br><span class="line">  <span class="attr">copy:</span> <span class="string">src=master-join.sh</span> <span class="string">dest=/tmp/master-join.sh</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">master</span> <span class="string">join</span></span><br><span class="line">  <span class="attr">shell:</span> <span class="string">sh</span> <span class="string">/tmp/master-join.sh</span></span><br></pre></td></tr></table></figure>

<h3 id="8）node-节点加入k8s集群"><a href="#8）node-节点加入k8s集群" class="headerlink" title="8）node 节点加入k8s集群"></a>8）node 节点加入k8s集群</h3><ul>
<li><code>install-k8s/node-join/files/node-join.sh</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取master ip，假设都是第一个节点为master</span></span><br><span class="line">maser_ip=`<span class="built_in">head</span> -1 /tmp/hosts |awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>`</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判断节点是否加入</span></span><br><span class="line">ssh <span class="variable">$maser_ip</span> <span class="string">&quot;kubectl get nodes|grep -q `hostname`&quot;</span></span><br><span class="line"><span class="keyword">if</span> [ $? -eq 0 ];<span class="keyword">then</span></span><br><span class="line"> <span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">CERT_KEY=`ssh <span class="variable">$maser_ip</span> <span class="string">&quot;kubeadm init phase upload-certs --upload-certs|tail -1&quot;</span>`</span><br><span class="line"></span><br><span class="line">join_str=`ssh <span class="variable">$maser_ip</span> kubeadm token create --print-join-command`</span><br><span class="line"></span><br><span class="line">$( <span class="built_in">echo</span> <span class="variable">$join_str</span> <span class="string">&quot; --certificate-key <span class="variable">$CERT_KEY</span> --v=5&quot;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>任务编排 <code>install-k8s/node-join/tasks/main.yml</code></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">node</span> <span class="string">join</span> <span class="string">cp</span></span><br><span class="line">  <span class="attr">copy:</span> <span class="string">src=node-join.yaml</span> <span class="string">dest=/tmp/node-join.yaml</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">node</span> <span class="string">join</span></span><br><span class="line">  <span class="attr">shell:</span> <span class="string">sh</span> <span class="string">/tmp/node-join.yaml</span></span><br></pre></td></tr></table></figure>

<h3 id="9）安装-ingress-nginx"><a href="#9）安装-ingress-nginx" class="headerlink" title="9）安装 ingress-nginx"></a>9）安装 ingress-nginx</h3><ul>
<li><code>install-k8s/install-ingress-nginx/files/ingress-nginx.sh</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.2.0/deploy/static/provider/cloud/deploy.yaml -O /tmp/deploy.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以先把镜像下载，再安装</span></span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:v1.2.0</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-webhook-certgen:v1.1.1</span><br><span class="line"></span><br><span class="line">kubectl apply -f /tmp/deploy.yaml</span><br></pre></td></tr></table></figure>

<ul>
<li>任务编排 <code>install-k8s/install-ingress-nginx/tasks/main.yml</code></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ingress-nginx</span> <span class="string">deploy</span> <span class="string">cp</span></span><br><span class="line">  <span class="attr">copy:</span> <span class="string">src=deploy.yaml</span> <span class="string">dest=/tmp/deploy.yaml</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install</span> <span class="string">ingress-nginx</span> <span class="string">cp</span></span><br><span class="line">  <span class="attr">copy:</span> <span class="string">src=ingress-nginx.sh</span> <span class="string">dest=/tmp/ingress-nginx.sh</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install</span> <span class="string">ingress-nginx</span></span><br><span class="line">  <span class="attr">shell:</span> <span class="string">sh</span> <span class="string">/tmp/ingress-nginx.sh</span></span><br></pre></td></tr></table></figure>

<h3 id="10）安装-nfs-共享存储"><a href="#10）安装-nfs-共享存储" class="headerlink" title="10）安装 nfs 共享存储"></a>10）安装 nfs 共享存储</h3><ul>
<li><code>install-k8s/install-nfs-provisioner/files/nfs-provisioner.sh</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 安装helm</span></span><br><span class="line"><span class="comment"># 下载包</span></span><br><span class="line">wget https://get.helm.sh/helm-v3.7.1-linux-amd64.tar.gz -O /tmp/helm-v3.7.1-linux-amd64.tar.gz</span><br><span class="line"><span class="comment"># 解压压缩包</span></span><br><span class="line">tar -xf /tmp/helm-v3.7.1-linux-amd64.tar.gz -C /root/</span><br><span class="line"><span class="comment"># 制作软连接</span></span><br><span class="line"><span class="built_in">rm</span> -rf /usr/local/bin/helm</span><br><span class="line"><span class="built_in">ln</span> -s /root/linux-amd64/helm /usr/local/bin/helm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判断是否已经部署</span></span><br><span class="line">helm list -n nfs-provisioner|grep -q nfs-provisioner</span><br><span class="line"><span class="keyword">if</span> [ $? -eq 0 ];<span class="keyword">then</span></span><br><span class="line">   <span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 开始安装nfs-provisioner</span></span><br><span class="line"><span class="comment"># 添加helm仓库源</span></span><br><span class="line">helm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner/</span><br><span class="line"></span><br><span class="line"><span class="comment">#### 安装nfs</span></span><br><span class="line">yum -y install  nfs-utils rpcbind</span><br><span class="line"></span><br><span class="line"><span class="comment"># 服务端</span></span><br><span class="line"><span class="built_in">mkdir</span> -p /opt/nfsdata</span><br><span class="line"><span class="comment"># 授权共享目录</span></span><br><span class="line"><span class="built_in">chmod</span> 666 /opt/nfsdata</span><br><span class="line"><span class="built_in">cat</span> &gt; /etc/exports&lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">/opt/nfsdata *(rw,no_root_squash,no_all_squash,sync)</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="comment"># 配置生效</span></span><br><span class="line">exportfs -r</span><br><span class="line"></span><br><span class="line">systemctl <span class="built_in">enable</span> --now rpcbind</span><br><span class="line">systemctl <span class="built_in">enable</span> --now nfs-server</span><br><span class="line"></span><br><span class="line"><span class="comment"># 客户端</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> `<span class="built_in">cat</span> /tmp/hosts`</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    ip=`<span class="built_in">echo</span> <span class="variable">$line</span>|awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>`</span><br><span class="line">    master_ip=`<span class="built_in">head</span> -1 /tmp/hosts|awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>`</span><br><span class="line">    <span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$ip</span>&quot;</span> != <span class="string">&quot;<span class="variable">$master_ip</span>&quot;</span> ];<span class="keyword">then</span></span><br><span class="line">       ssh <span class="variable">$ip</span> <span class="string">&quot;yum -y install rpcbind&quot;</span></span><br><span class="line">       ssh <span class="variable">$ip</span> <span class="string">&quot;systemctl enable --now rpcbind&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### helm安装nfs provisioner</span></span><br><span class="line">ip=`hostname -i`</span><br><span class="line">helm install nfs-subdir-external-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \</span><br><span class="line">  --namespace=nfs-provisioner \</span><br><span class="line">  --create-namespace \</span><br><span class="line">  --<span class="built_in">set</span> image.repository=willdockerhub/nfs-subdir-external-provisioner \</span><br><span class="line">  --<span class="built_in">set</span> image.tag=v4.0.2 \</span><br><span class="line">  --<span class="built_in">set</span> replicaCount=2 \</span><br><span class="line">  --<span class="built_in">set</span> storageClass.name=nfs-client \</span><br><span class="line">  --<span class="built_in">set</span> storageClass.defaultClass=<span class="literal">true</span> \</span><br><span class="line">  --<span class="built_in">set</span> nfs.server=<span class="variable">$&#123;ip&#125;</span> \</span><br><span class="line">  --<span class="built_in">set</span> nfs.path=/opt/nfsdata</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">kubectl get pods,deploy,sc -n nfs-provisioner</span><br><span class="line"></span><br><span class="line"><span class="comment"># 持续检查</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">true</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">   kubectl get pods -n nfs-provisioner|grep -q <span class="string">&#x27;0/1&#x27;</span></span><br><span class="line">   <span class="keyword">if</span> [ $? -ne 0 ];<span class="keyword">then</span></span><br><span class="line">      <span class="built_in">echo</span> <span class="string">&quot;nfs-provisioner started&quot;</span></span><br><span class="line">      <span class="built_in">break</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      <span class="built_in">echo</span> <span class="string">&quot;nfs-provisioner starting...&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="built_in">sleep</span> 1</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<ul>
<li>任务编排 <code>install-k8s/install-nfs-provisioner/tasks/main.yml</code></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install</span> <span class="string">nfs-provisioner</span> <span class="string">cp</span></span><br><span class="line">  <span class="attr">copy:</span> <span class="string">src=nfs-provisioner.sh</span> <span class="string">dest=/tmp/nfs-provisioner.sh</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install</span> <span class="string">nfs-provisioner</span></span><br><span class="line">  <span class="attr">shell:</span> <span class="string">sh</span> <span class="string">/tmp/nfs-provisioner.sh</span></span><br></pre></td></tr></table></figure>

<h3 id="11）k8s-环境安装编排-roles"><a href="#11）k8s-环境安装编排-roles" class="headerlink" title="11）k8s 环境安装编排 roles"></a>11）k8s 环境安装编排 roles</h3><ul>
<li><code>install-k8s.yaml</code></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">k8s</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line">  <span class="attr">roles:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">init</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">k8s</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line">  <span class="attr">roles:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">install-docker</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">k8s</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line">  <span class="attr">roles:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">install-k8s</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">master1</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line">  <span class="attr">roles:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">master-init</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">master1</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line">  <span class="attr">roles:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">install-cni</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">master2</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line">  <span class="attr">roles:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">master-join</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">node</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line">  <span class="attr">roles:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">node-join</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">master1</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line">  <span class="attr">roles:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">install-ingress-nginx</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">master1</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line">  <span class="attr">roles:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">install-nfs-provisioner</span></span><br></pre></td></tr></table></figure>

<p>执行安装</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 可以加上-vvv显示更多信息</span></span><br><span class="line">ansible-playbook install-k8s.yaml</span><br><span class="line">kubectl get nodes</span><br><span class="line">kubectl get pods -A</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302011034281.png" alt="图片">)</p>
<h3 id="12）k8s-环境卸载"><a href="#12）k8s-环境卸载" class="headerlink" title="12）k8s 环境卸载"></a>12）k8s 环境卸载</h3><ul>
<li><code>install-k8s/uninstall-k8s/files/uninstall-k8s.sh</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">expect &lt;&lt;-<span class="string">EOF</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">spawn kubeadm reset</span></span><br><span class="line"><span class="string">expect &quot;*y/N*&quot;</span></span><br><span class="line"><span class="string">send &quot;y\n&quot;</span></span><br><span class="line"><span class="string">expect eof</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">rm</span> -rf /etc/kubernetes/*</span><br><span class="line"><span class="built_in">rm</span> -fr ~/.kube</span><br><span class="line"><span class="built_in">rm</span> -fr /var/lib/etcd</span><br></pre></td></tr></table></figure>

<ul>
<li>任务编排 <code>install-k8s/uninstall-k8s/tasks/main.yaml</code></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">uninstall</span> <span class="string">k8s</span> <span class="string">cp</span></span><br><span class="line">  <span class="attr">copy:</span> <span class="string">src=uninstall-k8s.sh</span> <span class="string">dest=/tmp/uninstall-k8s.sh</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">uninstall</span> <span class="string">k8s</span></span><br><span class="line">  <span class="attr">shell:</span> <span class="string">sh</span> <span class="string">/tmp/uninstall-k8s.sh</span></span><br></pre></td></tr></table></figure>

<h3 id="13）k8s-环境卸载编排-roles"><a href="#13）k8s-环境卸载编排-roles" class="headerlink" title="13）k8s 环境卸载编排 roles"></a>13）k8s 环境卸载编排 roles</h3><ul>
<li><code>uninstall-k8s.yaml</code></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">k8s</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line">  <span class="attr">roles:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">uninstall-k8s</span></span><br></pre></td></tr></table></figure>

<p>执行卸载</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-playbook uninstall-k8s.yaml</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202302141356534.png" alt="图片"><br>温馨提示：</p>
<ul>
<li>其实创建目录结构可以通过<code>ansible-galaxy</code>工具，也可以通过这个工具安装在线别人编排好的包，非常方便的。</li>
<li>这里只是验证了<code>k8s v1.23.6</code>版本的，其它高版本和低版本后续会继续完善验证，还有就是如果执行脚本的话，可以将copy和shell模块并用一个script模块，编排就会变更更简洁，其实script内部也是先copy文件，执行完后会清理。</li>
</ul>
<p>k8s 一键部署（ansible）就先到这里了，后续会继续完善，增加其它组件和验证其它版本，让部署k8s环境变得更简单方便</p>
]]></content>
      <categories>
        <category>kubernetes</category>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>盘点Linux的几种配置代理方式</title>
    <url>/2023/01/04/%E7%9B%98%E7%82%B9Linux%E7%9A%84%E5%87%A0%E7%A7%8D%E9%85%8D%E7%BD%AE%E4%BB%A3%E7%90%86%E6%96%B9%E5%BC%8F/</url>
    <content><![CDATA[<h2 id="编译环境代理"><a href="#编译环境代理" class="headerlink" title="编译环境代理"></a>编译环境代理</h2><h3 id="1、linux设置代理"><a href="#1、linux设置代理" class="headerlink" title="1、linux设置代理"></a>1、linux设置代理</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="built_in">export</span> http_proxy=http://10.67.11.138:7890</span><br><span class="line"><span class="built_in">export</span> https_proxy=http://10.67.11.138:7890</span><br></pre></td></tr></table></figure>

<h3 id="2、Container设置代理（container内部服务代理）"><a href="#2、Container设置代理（container内部服务代理）" class="headerlink" title="2、Container设置代理（container内部服务代理）"></a>2、Container设置代理（container内部服务代理）</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> /root/.docker/config.json </span><br></pre></td></tr></table></figure>

<figure class="highlight toml"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;proxies&quot;: &#123;</span><br><span class="line"> &quot;default&quot;: &#123;</span><br><span class="line">  &quot;httpProxy&quot;: &quot;http://10.67.11.138:7890&quot;,</span><br><span class="line">  &quot;httpsProxy&quot;: &quot;http://10.67.11.138:7890&quot;</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3、dockerd代理（docker-pull）"><a href="#3、dockerd代理（docker-pull）" class="headerlink" title="3、dockerd代理（docker pull）"></a>3、dockerd代理（docker pull）</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl <span class="built_in">cat</span> docker</span><br><span class="line"><span class="comment"># /usr/lib/systemd/system/docker.service</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">...</span><br><span class="line">Environment=<span class="string">&quot;HTTP_PROXY=http://10.67.11.138:7890/&quot;</span></span><br><span class="line">Environment=<span class="string">&quot;HTTPS_PROXY=http://10.67.11.138:7890/&quot;</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Docker</tag>
        <tag>Containerd</tag>
      </tags>
  </entry>
  <entry>
    <title>容器运行时概览</title>
    <url>/2022/12/29/%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6%E6%A6%82%E8%A7%88/</url>
    <content><![CDATA[<h2 id="01-容器运行时分类"><a href="#01-容器运行时分类" class="headerlink" title="01 容器运行时分类"></a>01 容器运行时分类</h2><p>Docker属于容器技术早期的发展项目，也是目前最广泛的容器引擎技术。当然，随着容器生态圈的日益繁荣，业界慢慢也出现了其他各种运行时工具，如containerd、rkt、Kata Container、CRI-O等。这些工具提供的功能不尽相同，有些只有容器运行的功能，有些除运行容器外还提供了容器镜像的管理功能。根据容器运行时提供功能，可以讲容器运行时分为<strong>低层运行时</strong>和<strong>高层运行时</strong>。</p>
<p>低层运行时主要负责与宿主机操作系统打交道，根据指定的容器镜像在宿主机上运行容器的进程，并对容器的整个生命周期进行管理。而这个低层运行时，正是负责执行我们前面讲解过的设置容器 Namespace、Cgroups等基础操作的组件。常见的低层运行时种类有：</p>
<blockquote>
<p>runc：传统的运行时，基于Linux Namespace和Cgroups技术实现，代表实现Docker<br>runv：基于虚拟机管理程序的运行时，通过虚拟化 guest kernel，将容器和主机隔离开来，使得其边界更加清晰，代表实现是Kata Container和Firecracker<br>runsc：runc + safety ，通过拦截应用程序的所有系统调用，提供安全隔离的轻量级容器运行时沙箱，代表实现是谷歌的gVisor</p>
</blockquote>
<p>高层运行时主要负责镜像的管理、转化等工作，为容器的运行做前提准备。主流的高层运行时主要containerd和CRI-O。</p>
<p>高层运行时与低层运行时各司其职，容器运行时一般先由高层运行时将容器镜像下载下来，并解压转换为容器运行需要的操作系统文件，再由低层运行时启动和管理容器。</p>
<p>两者之间的关系如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202211091027007.png" alt="图片"></p>
<h2 id="02-Kubernetes容器运行时"><a href="#02-Kubernetes容器运行时" class="headerlink" title="02 Kubernetes容器运行时"></a>02 Kubernetes容器运行时</h2><p>前面的两部分，我们介绍了容器运行的原理及常见的容器运行时工具，Kubernetes作为容器编排工具会对容器进行调度和管理。那Kubernetes如何启动容器的？</p>
<p>Kubernetes早期是利用Docker作为容器运行时管理工具的，在1.6版本之前Kubernetes将Docker默认为自己的运行时工具，通过直接调用Docker的API来创建和管理容器。在Docker项目盛行不久，CoreOS推出了rkt运行时工具，Kubernetes又添加了对rkt的支持。但随着容器技术的蓬勃发展，越来越多的运行时工具出现，提供对所有运行时工具的支持，显然是一项庞大的工程；而且直接将运行时的集成内置于Kubernetes，两者紧密结合，对Kubernetes代码本身也是一种负担，每更新一次重要的功能，Kubernetes都需要考虑对所有容器运行时的兼容适配。</p>
<p>为了打破这种尴尬的局面，Kubernetes将对容器的操作抽象为一个接口，将接口作为kubelet与运行时工具之间的桥梁，kubelet通过发送接口请求对容器进行启动和管理，各个容器工具通过实现这个接口即可接入Kubernetes。这个统一的容器操作接口，就是容器运行时接口(Container Runtime Interface, CRI)。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202211091029474.png" alt="图片"></p>
<p>我们来具体看下CRI的工作流程，上图可以看到，<code>CRI</code>主要有<code>gRPC client</code>、<code>gRPC Server</code>和具体的容器运行时工具**三个组件。其中kubelet作为gRPC 的客户端来调用 CRI 接口；CRI shim作为gRPC服务端来响应CRI请求，负责将CRI请求的内容转换为具体的容器运行时API，在kubelet和运行时之间充当翻译的角色。具体的容器创建逻辑是，Kubernetes在通过调度指定一个具体的节点运行pod，该节点的Kubelet在接到pod创建请求后，调用一个叫作 GenericRuntime 的通用组件来发起创建 Pod 的 CRI 请求给CRI shim；<code>CRI shim</code>监听一个端口来响应kubelet， 在收到CRI请求后，将其转化为具体的容器运行时指令，并调用相应的容器运行时来创建pod。</p>
<p>因此，任何容器运行时如果想接入Kubernetes，都需要实现一个自己的CRI shim，来实现CRI接口规范。那么CRI有哪些接口需要实现呢？查看Kubernetes代码可以发现，它定义了下图所示两类接口：<code>RuntimeService</code>和<code>ImageService</code>。<code>RuntimeService</code>定义了跟容器相关的操作，如创建、启动、删除容器等。ImageService主要定义了容器镜像相关的操作，如拉取镜像、删除镜像等。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202211091030385.png" alt="图片"></p>
<p>ImageService的操作比较简单，就是拉取、删除、查看镜像状态及获取镜像列表这几个操作。下面着重介绍下RuntimeService。</p>
<p>从上图可以看到，RuntimeService除了有container的管理接口外，还包含PodSandbox相关的管理接口和exec、attach等与容器交互的接口。</p>
<p>顾名思义，PodSandbox这个概念对应的是Kubernetes里的Pod，它描述了Kubernetes里的Pod与容器运行相关的属性或者信息，如HostName、CgroupParent等。设计这个的初衷是因为Pod里所有容器的资源和环境信息是共享的，但是不同的容器运行时实现共享的机制不同，如Docker中Pod会是一个Linux命名空间，各容器网络信息的共享通过创建pause 容器的方法来实现，而Kata Containers则直接将pod具化为一个轻量级的虚拟机。将这个逻辑抽象为PodSandbox接口，可以让不同的容器运行时在pod实现上自由发挥，自己解释和实现pod的的逻辑。</p>
<p>Exec、Attach 和 PortForward 是三个和容器进行数据交互的接口，由于交互数据需要长链接来传输，称这些接口为 Streaming API。CRI shim依赖一套独立的Streaming Server机制来实现客户端与容器的交互需求。长连接比较消耗网络资源，为了避免因长连接给kubelet节点带来网络流量瓶颈，CRI要求容器运行时启动一个对应请求的单独的流服务器，让客户端直接与流服务器进行连同交互。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202211091030229.png" alt="图片"></p>
<p>上图所示，kubectl exec命令实现过程如下：</p>
<ol>
<li><p>客户端发送 kubectl exec命令给apiserver；</p>
</li>
<li><p>apiserver 调用 kubelet 的 Exec API；</p>
</li>
<li><p>kubelet 调用CRI 的Exec接口（具体的执行者为实现该接口的 CRI Shim ）；</p>
</li>
<li><p>CRI Shim 向 kubelet 返回Streaming Server 的地址和端口；</p>
</li>
<li><p>kubelet 以 redirect 的方式返回给apiserver</p>
</li>
<li><p>apiserver 通过重定向来向 Streaming Server 发起真正的 &#x2F;exec 请求，与它建立长连接，完成 Exec 的请求和响应。</p>
</li>
</ol>
<p>以上是CRI的设计及工作原理。</p>
<p>概括来讲，kubelet在引入CRI之后，主要的架构如下图所示。其中Generic Runtime Manager负责发送容器创建、删除等CRI请求，Container Runtime Interface(CRI)负责定义CRI接口规范，具体的CRI实现可分为两种：kubelet内置的dockershim和远端的CRI shim。其中dockershim是Kubernetes自己实现的适配Docker接口的CRI接口实现，主要用来将CRI 请求里的内容组装成 Docker API 请求发给 Docker Daemon；远端的CRI shim主要是用来匹配其他的容器运行时工具到kubelet。CRI shim主要负责响应kubelect发送的CRI请求，并将请求转化为具体的运行时命令发送给具体的运行时（如runc、kata等）；Stream Server用来响应客户端与容器的交互，除此之外，CRI还提供接入CNI的能力以实现pod网络的共享。常用的远端CRI的实现有CRI-Containerd、CRI-O等。</p>
<p> <img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202211091031022.png" alt="图片"></p>
<p>从上图可以看出，Kubernetes把docker shim内置在了官方的代码库中，将Docker设计为Kubernetes默认的容器运行时工具。但是官方在Kubernetes 1.20版本的更新日志中声明已经废用对Docker的支持，并将在未来的版本中将其删除。在Kubernetes 1.24版本中，dockershim代码也如期被删除，替换为containerd作为其默认运行时。</p>
<p>那Kubernetes为何要抛弃Docker转而使用containerd，其中的缘由是什么？</p>
<p>这话要从头说起，Docker最初是一个单体引擎，主要负责容器镜像的制作、上传、拉取及容器的运行及管理。随着容器技术的繁荣发展，为了促进容器技术相关的规范生成和Docker自身项目的发展，Docker将单体引擎拆分为三部分，分别为runC、containerd和dockerd，其中runC主要负责容器的运行和生命周期的管理（即前述的低层运行时）、containerd主要负责容器镜像的下载和解压等镜像管理功能（即前述的高层运行时）、dockerd主要负责提供镜像制作、上传等功能同时提供容器存储和网络的映射功能，同时也是Docker服务器端的守护进程，用来响应Docker客户端（命令行CLI工具）发来的各种容器、镜像管理的任务。Docker公司将runC捐献给了OCI，将containerd捐献给了CNCF，剩下的dockerd作为Docker运行时由Docker公司自己维护。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202211091031627.png" alt="图片"></p>
<p>如前所述，Kubernetes在引入CRI之后，kubelet需要通过CRI shim去调用具体的容器运行时工具，由于早期Kubernetes对Docker的支持是内置的，因此官方自己实现了dockershim，通过dockershim去访问dockerd。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202211091034732.png" alt="图片"></p>
<p>由于dockershim的维护出现了问题，官方废弃了对Docker的支持，使用containerd为默认运行时。那我们知道，kubelet需要一个CRI shim作为中间件去调用运行时，那kubelet在抛弃了dockershim之后又是怎么访问containerd的呢？答案是containerd自己集成了CRI shim，提供了一个CRI插件来实现shim的功能，这样kubelet就可以直接访问containerd。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Ghostpanter/tuchuang/img/202211091027367.png" alt="图片"></p>
<p>由此可以看到，废弃dockershim之前kubelet其实也是使用containerd作为高层运行时，只是中间通过了dockershim和dockerd两步转发；<strong>在将dockershim移除之后，kubelet越过docker门户直接访问了containerd</strong>，这明显的轻量化了调用过程，大大加快了kubelet调用运行时的速度。</p>
<h2 id="03-安全容器运行时"><a href="#03-安全容器运行时" class="headerlink" title="03 安全容器运行时"></a>03 安全容器运行时</h2><p>Kubernetes目前作为企业级容器平台，企业生产最重要的是安全。前面我们讲过，Docker 容器通过Linux Namespace和Cgroups实现容器之间的资源限制和隔离，在实际运行中各容器资源（网络、存储、计算）仍由宿主机直接提供，这就可能出现某个容器进程夺取整个宿主机控制权的问题，在安全问题上存在一定的隐患。于是，Kata Container和gVisor等安全容器运行时应用而生。</p>
<p>Kata Container 来源于 Intel Clear Containers 和 Hyper runV 项目的合并，它使用传统的虚拟化技术，通过虚拟硬件模拟出了一台“小虚拟机”，然后再这台小虚拟机中安装了一个裁剪后的Linux内核来实现容器建的隔离。gVisor由谷歌公司发布，它通过为容器进程配置一个用Go语言实现的、在用户态实现的、极小的“独立内核”，通过这个内核控制容器进程向宿主机发起有限可控的系统调用。</p>
<p>那Kubernetes如何集成这些安全运行时呢？下面以Kata Container为例，介绍安全容器运行时如何集成到Kubernetes中对各种资源进行管控。</p>
<p>Kata Container支持OCI运行时规范，可以以插件形式嵌入到 Docker 中作为低层的容器运行时；也支持 Kubernetes 的 CRI 接口，可以与 CRI-O 和 containerd 集成。由于目前Kubernetes默认的运行时是containerd，下面主要讲解Kata Container如何与containerd集成以及集成后Kubernetes如何使用Kata Container创建负载。</p>
<p>由于Kata Container使用虚拟化技术实现，首先需要集成的Kubernetes环境支持Intel VT-x technology、ARM Hyp mode、IBM Power Systems或IBM Z manframes四种中的任意一种<strong>CPU虚拟化技术</strong>。</p>
<p>集成及使用过程如下：</p>
<h3 id="1、安装Kata-Container（以centos为例）"><a href="#1、安装Kata-Container（以centos为例）" class="headerlink" title="1、安装Kata Container（以centos为例）"></a>1、安装Kata Container（以centos为例）</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/os-releasesudo </span><br><span class="line">yum -y install yum-utils</span><br><span class="line"><span class="built_in">export</span> BRANCH=<span class="string">&#x27;stable-1.10&#x27;</span></span><br><span class="line">ARCH=$(<span class="built_in">arch</span>)</span><br><span class="line">BRANCH=<span class="string">&quot;<span class="variable">$&#123;BRANCH:-master&#125;</span>&quot;</span></span><br><span class="line">sudo -E yum-config-manager --add-</span><br><span class="line">repo <span class="string">&quot;http://download.opensuse.org/repositories/home:/katacontainers:/releases:/<span class="variable">$&#123;ARCH&#125;</span>:/<span class="variable">$&#123;BRANCH&#125;</span>/CentOS_<span class="variable">$&#123;VERSION_ID&#125;</span>/home:katacontainers:releases:<span class="variable">$&#123;ARCH&#125;</span>:<span class="variable">$&#123;BRANCH&#125;</span>.repo&quot;</span></span><br><span class="line">sudo -E yum -y install kata-runtime kata-proxy kata-shim</span><br></pre></td></tr></table></figure>

<p>安装完成之后，执行命令 kata-runtime kata-check 检查系统是否支持运行 kata runtime，下面的输出表示运行环境支持 Kata Containers 。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># kata-runtime kata-check</span></span><br><span class="line">System is capable of running Kata Containers</span><br><span class="line">System can currently create Kata Containers</span><br></pre></td></tr></table></figure>

<h3 id="2、修改Kubernetes-启动参数"><a href="#2、修改Kubernetes-启动参数" class="headerlink" title="2、修改Kubernetes 启动参数"></a>2、修改Kubernetes 启动参数</h3><h4 id="1）修改-kubelet-启动参数"><a href="#1）修改-kubelet-启动参数" class="headerlink" title="1）修改 kubelet 启动参数"></a>1）修改 kubelet 启动参数</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p  /etc/systemd/system/kubelet.service.d/</span><br><span class="line"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF | sudo tee  /etc/systemd/system/kubelet.service.d/0-containerd.conf</span></span><br><span class="line"><span class="string">[Service]                                                 </span></span><br><span class="line"><span class="string">Environment=&quot;KUBELET_EXTRA_ARGS=--container-runtime=remote --runtime-request-timeout=15m --container-runtime-endpoint=unix:///run/containerd/containerd.sock&quot;5.EOF</span></span><br></pre></td></tr></table></figure>

<h4 id="2）重启-containerd-和-kubelet"><a href="#2）重启-containerd-和-kubelet" class="headerlink" title="2）重启 containerd 和 kubelet"></a>2）重启 containerd 和 kubelet</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start containerd</span><br><span class="line">systemctl restart kubelet</span><br></pre></td></tr></table></figure>

<h3 id="3、Kubernetes-配置使用Kata-Container"><a href="#3、Kubernetes-配置使用Kata-Container" class="headerlink" title="3、Kubernetes 配置使用Kata Container"></a>3、Kubernetes 配置使用Kata Container</h3><p>配置了Kata Container之后，我们就可以在Kubernetes集群中使用Kata Container进行容器管理了。如上所述，目前containerd中存在两个低层运行时，分别是默认的runC和新接入的Kata Container。那我们该如何告诉 Kubernetes 哪些负载需要使用 Kata Container呢？根据不同的版本，Kata 提供了不同的方式：</p>
<blockquote>
<p>使用 Kubernetes 的 RuntimeClass（推荐）<br>使用 Kubernetes的untrusted_workload_runtime</p>
</blockquote>
<h4 id="1）使用RuntimClass"><a href="#1）使用RuntimClass" class="headerlink" title="1）使用RuntimClass"></a>1）使用RuntimClass</h4><p>这种方式对相关组件版本有要求：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Kata Containers v1.5.0 or above (including 1.5.0-rc)</span><br><span class="line">Containerd v1.2.0 or above</span><br><span class="line">Kubernetes v1.12.0 or above</span><br></pre></td></tr></table></figure>

<h5 id="a-、修改containerd的配置文件"><a href="#a-、修改containerd的配置文件" class="headerlink" title="a)、修改containerd的配置文件"></a>a)、修改containerd的配置文件</h5><p>在&#x2F;etc&#x2F;containerd&#x2F;config.toml配置文件中[plugins.”io.containerd.grpc.v1.cri”.containerd.runtimes]下增加kata运行时配置：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#这里最后的这个kata 将被作为 RuntimeClass handler 关键字</span></span><br><span class="line">[<span class="string">plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.kata</span>] </span><br><span class="line"> <span class="string">runtime_type</span> <span class="string">=</span> <span class="string">&quot;io.containerd.kata.v2&quot;</span></span><br><span class="line"> [<span class="string">plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.katacli</span>]</span><br><span class="line">   <span class="string">runtime_type</span> <span class="string">=</span> <span class="string">&quot;io.containerd.runc.v1&quot;</span></span><br><span class="line">   [<span class="string">plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.katacli.options</span>]</span><br><span class="line">     <span class="string">NoPivotRoot</span> <span class="string">=</span> <span class="literal">false</span></span><br><span class="line">     <span class="string">NoNewKeyring</span> <span class="string">=</span> <span class="literal">false</span></span><br><span class="line">     <span class="string">ShimCgroup</span> <span class="string">=</span> <span class="string">&quot;&quot;</span></span><br><span class="line">     <span class="string">IoUid</span> <span class="string">=</span> <span class="number">0</span></span><br><span class="line">     <span class="string">IoGid</span> <span class="string">=</span> <span class="number">0</span></span><br><span class="line">     <span class="string">BinaryName</span> <span class="string">=</span> <span class="string">&quot;/usr/bin/kata-runtime&quot;</span></span><br><span class="line">     <span class="string">Root</span> <span class="string">=</span> <span class="string">&quot;&quot;</span></span><br><span class="line">     <span class="string">CriuPath</span> <span class="string">=</span> <span class="string">&quot;&quot;</span></span><br><span class="line">     <span class="string">SystemdCgroup</span> <span class="string">=</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure>

<p>需要注意的是，[plugins.”io.containerd.grpc.v1.cri”.containerd.runtimes.kata] 中的 kata 将被作为 RuntimeClass handler 关键字。</p>
<h5 id="b-、重启-containerd"><a href="#b-、重启-containerd" class="headerlink" title="b)、重启 containerd"></a>b)、重启 containerd</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart containerd</span><br></pre></td></tr></table></figure>

<h5 id="c-、使用Kata-Container"><a href="#c-、使用Kata-Container" class="headerlink" title="c)、使用Kata Container"></a>c)、使用Kata Container</h5><blockquote>
<p>准备RuntimeClass，并用该RuntimeClass创建Pod声明文件</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">runtime.yaml</span><br><span class="line">apiVersion: node.k8s.io/v1beta1  <span class="comment"># RuntimeClass is defined in the node.k8s.io API group</span></span><br><span class="line">kind: RuntimeClass</span><br><span class="line">metadata:</span><br><span class="line">  name: kata  </span><br><span class="line">handler: kata  <span class="comment"># 这里与containerd配置文件中的 [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.&#123;handler&#125;] 匹配</span></span><br><span class="line">pod.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: kata-nginx</span><br><span class="line">spec:</span><br><span class="line">  runtimeClassName: kata</span><br><span class="line">  containers:</span><br><span class="line">    - name: nginx</span><br><span class="line">      image: nginx</span><br><span class="line">      ports:</span><br><span class="line">      - containerPort: 80</span><br></pre></td></tr></table></figure>

<blockquote>
<p>执行yaml，创建RuntimeClass和Pod</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@node1 zhh]<span class="comment"># kubectl apply -f runtime.yaml</span></span><br><span class="line">runtimeclass.node.k8s.io/kata created</span><br><span class="line">[root@node1 zhh]<span class="comment"># kubectl get runtimeclass</span></span><br><span class="line">NAME   HANDLER   AGE</span><br><span class="line">kata   kata      7s</span><br><span class="line">[root@node1 zhh]<span class="comment"># kubectl apply -f pod.yaml</span></span><br><span class="line">pod/kata-nginx created</span><br></pre></td></tr></table></figure>

<blockquote>
<p>验证是否正确创建：通过kata-runtime list 可以查看创建出来的 container</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@node1 zhh]<span class="comment"># kata-runtime list</span></span><br><span class="line">ID                                                                 PID         STATUS      BUNDLE                                                                                                                  CREATED                          OWNER</span><br><span class="line">a5abf7227bf3e1868ff590e207d4f755ff6c879d821274a6ae25ae33839f5933   -1          running     /run/containerd/io.containerd.runtime.v2.task/k8s.io/a5abf7227bf3e1868ff590e207d4f755ff6c879d821274a6ae25ae33839f5933   2022-10-12T11:30:44.156957259Z   <span class="comment">#0</span></span><br><span class="line">[root@node1 zhh]<span class="comment"># kubectl get pod</span></span><br><span class="line">NAME                                READY   STATUS              RESTARTS   AGE</span><br><span class="line">kata-nginx                          0/1     ContainerCreating   0          33s</span><br><span class="line">nginx-deployment-746fbb99df-lmjcv   1/1     Running             1          18h</span><br></pre></td></tr></table></figure>

<h4 id="2-使用untrusted-workload-runtime"><a href="#2-使用untrusted-workload-runtime" class="headerlink" title="2) 使用untrusted_workload_runtime"></a>2) 使用untrusted_workload_runtime</h4><p>对于不符合上述版本要求的环境，可以使用untrusted_workload_runtime的方式，该方式对版本无要求。</p>
<blockquote>
<p>修改containerd的配置文件</p>
</blockquote>
<p>在&#x2F;etc&#x2F;containerd&#x2F;config.toml配置文件中新增untrusted_workload_runtime运行时配置：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[plugins.<span class="string">&quot;io.containerd.grpc.v1.cri&quot;</span>.containerd.untrusted_workload_runtime] </span><br><span class="line">runtime_type = <span class="string">&quot;io.containerd.kata.v2&quot;</span></span><br></pre></td></tr></table></figure>

<p>对于不支持Runtime V2 (Shim API)的早期版本的Kata Containers和containd，可以使用以下替代配置:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[plugins.<span class="string">&quot;io.containerd.grpc.v1.cri&quot;</span>.containerd.untrusted_workload_runtime]</span><br><span class="line">  <span class="comment"># runtime_type is the runtime type to use in containerd e.g. io.containerd.runtime.v1.linux</span></span><br><span class="line">  runtime_type = <span class="string">&quot;io.containerd.runtime.v1.linux&quot;</span></span><br><span class="line">  <span class="comment"># runtime_engine is the name of the runtime engine used by containerd.</span></span><br><span class="line">  runtime_engine = <span class="string">&quot;/usr/bin/kata-runtime&quot;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>重启 containerd</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload &amp; systemctl restart containerd</span><br></pre></td></tr></table></figure>

<blockquote>
<p>使用Kata Container</p>
</blockquote>
<p>untrusted_workload_runtime 使用 annotations 告诉 Kubernetes 集群哪些负载需要使用 kata-runtime。因此需要使用kata-runtime的资源，只需要在annotations中声明即可。如:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-untrusted</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">io.kubernetes.cri.untrusted-workload:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="string">k8s3</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx</span></span><br></pre></td></tr></table></figure>

<p>验证方式Pod是否被正确创建方法同RuntimClass。</p>
<p>当然，如果想直接把Kata Container作为Kubernetes默认的运行时也是可以的。我们知道Kubernetes默认的低层运行时是runC，如果想把Kata Container设置为默认的低层运行时，在containerd的配置文件中设置default_runtime，重启containerd（systemctl daemon-reload &amp; systemctl restart containerd）后，创建的负载就自动使用Kata Container来进行管理了。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[plugins.<span class="string">&quot;io.containerd.grpc.v1.cri&quot;</span>.containerd]</span><br><span class="line">  [plugins.<span class="string">&quot;io.containerd.grpc.v1.cri&quot;</span>.containerd.default_runtime]</span><br><span class="line">    runtime_type = <span class="string">&quot;io.containerd.kata.v2&quot;</span></span><br></pre></td></tr></table></figure>

<p>对于不支持Runtime V2 (Shim API)的早期版本的Kata Containers和containerd，可以使用以下替代配置:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[plugins.<span class="string">&quot;io.containerd.grpc.v1.cri&quot;</span>.containerd]</span><br><span class="line">   [plugins.<span class="string">&quot;io.containerd.grpc.v1.cri&quot;</span>.containerd.default_runtime]</span><br><span class="line">     runtime_type = <span class="string">&quot;io.containerd.runtime.v1.linux&quot;</span></span><br><span class="line">     runtime_engine = <span class="string">&quot;/usr/bin/kata-runtime&quot;</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>Docker</tag>
        <tag>Containerd</tag>
      </tags>
  </entry>
  <entry>
    <title>配置Kubelet的垃圾回收</title>
    <url>/2023/01/05/%E9%85%8D%E7%BD%AEKubelet%E7%9A%84%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</url>
    <content><![CDATA[<p>Kubelet的垃圾回收功能可以清理不再使用的容器和镜像，kubelet对容器进行垃圾回收的频率是每分钟一次，对镜像进行垃圾回收的频率是每五分钟一次。</p>
<p>不推荐使用外部的垃圾回收工具，因为这些工具有可能会删除 kubelet 仍然需要的容器或者镜像。</p>
<ul>
<li>镜像回收</li>
<li>容器回收</li>
<li>配置</li>
<li>Deprecation</li>
</ul>
<h2 id="镜像回收"><a href="#镜像回收" class="headerlink" title="镜像回收"></a>镜像回收</h2><p>Kubernetes 通过 imageManager 配合 cadvisor 管理所有镜像的生命周期。</p>
<p>镜像的垃圾回收策略主要考虑两方面因素： <code>HighThresholdPercent</code> 和 <code>LowThresholdPercent</code>。</p>
<ul>
<li>磁盘利用率超过 <code>high threshold</code> 将触发垃圾回收动作</li>
<li>垃圾回收功能将删除最近最少使用的镜像，直到磁盘利用率低于 <code>low threshold</code></li>
</ul>
<h2 id="容器回收"><a href="#容器回收" class="headerlink" title="容器回收"></a>容器回收</h2><p>容器的垃圾回收侧率主要考虑三个用户自定义的变量：</p>
<ul>
<li><code>MinAge</code>： 容器创建到现在的最小时长，低于此时长的不能被垃圾回收；如果设置为 0，则禁用该选项</li>
<li><code>MaxPerPodContainer</code>：以 <code>Pod UID</code> + <code>容器名</code> 作为组合键，<code>MaxPerPodContainer</code> 指定了同一个 <code>Pod UID</code> + <code>容器名</code> 组合键下可以包含的已停止容器的最大数量。如果设置为小于 0 的数值，则禁用该选项</li>
<li><code>MaxContainers</code>： 指定了最大的已停止容器的数量。如果设置为小于 0 的数值，则禁用该选项</li>
</ul>
<p>Kubelet 将对满足上述三个条件，且已经停止的容器执行垃圾回收的动作。通常，创建时间最长的容器将被最早移除。 <code>MaxPerPodContainer</code> 和 <code>MaxContainer</code> 这两个参数可能会相互冲突，例如， 如果要为每个 Pod 保存 <code>MaxPerPodContainer</code> 个已停止容器的话，可能最终总的已停止的容器的数量要超过 <code>MaxContainers</code> 的定义。 此时，优先保证 <code>MaxContainers</code> 的限定， <code>MaxPerPodContainer</code> 将被重新调整：最坏的情况下，kubelet 将 <code>MaxPerPodContainer</code> 的要求降低到 1，并删除创建时间最久的已停止的容器。此外，当 Pod 的已停止容器创建时长超过 <code>MinAge</code> 时，该容器将被即刻删除。</p>
<p>对于那些不是通过 kubelet 创建的容器，kubelet 不能对其进行垃圾回收操作。</p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>通过以下 kubelet 启动参数，可以调整镜像垃圾回收的变量：</p>
<ul>
<li><code>image-gc-high-threshold</code>，磁盘利用率高于此参数时，将触发镜像的垃圾回收。默认值为 85%</li>
<li><code>iamge-gc-low-threshold</code>，磁盘利用率低于此参数时，镜像的垃圾回收将停止。默认值为 80%</li>
</ul>
<p>通过以下 kubelet 启动参数，可以调整容器的垃圾回收的变量：</p>
<ul>
<li><code>minimum-container-ttl-duration</code>，容器创建到现在的最小时长，低于此时长的不能被垃圾回收。默认值为 0 分钟，即，每一个已停止的容器都可以被垃圾回收</li>
<li><code>maximum-dead-containers-per-container</code>，对于每个容器的旧实例，最多可以保留的个数。默认值为 1</li>
<li><code>maximum-dead-containers</code>，全局最大可以保留的已停止的容器数量。默认值为 -1，即，不做全局性限制</li>
</ul>
<p>容器在被垃圾回收时，也许仍然是有用的。例如，这些容器可能包含了对于问题诊断（trouble shooting）来说非常有用的日志和数据。强烈建议将 <code>maximum-dead-containers-per-container</code> 设置为足够大的数值，至少不能小于1，以便为每一个容器至少保留一个已停止的容器。同样的，也建议为 <code>maximum-dead-containers</code> 设置一个比较大的数值。 参考 <a href="https://github.com/kubernetes/kubernetes/issues/13287">issue #13287(opens new window)</a></p>
<h2 id="Deprecation"><a href="#Deprecation" class="headerlink" title="Deprecation"></a>Deprecation</h2><p>此文档的某些特性已经不推荐使用，未来将被 kubelet eviction 替代。</p>
<p>包括：</p>
<table>
<thead>
<tr>
<th>Existing Flag</th>
<th>New Flag</th>
<th>Rationale</th>
</tr>
</thead>
<tbody><tr>
<td><code>--image-gc-high-threshold</code></td>
<td><code>--eviction-hard</code> or <code>--eviction-soft</code></td>
<td>已有的 eviction 信号可以触发镜像的垃圾回收</td>
</tr>
<tr>
<td><code>--image-gc-low-threshold</code></td>
<td><code>--eviction-minimum-reclaim</code></td>
<td>eviction reclaims 可实现相同的效果</td>
</tr>
<tr>
<td><code>--maximum-dead-containers</code></td>
<td></td>
<td>如果日志被存储在容器外部，就不推荐使用此特性</td>
</tr>
<tr>
<td><code>--maximum-dead-containers-per-container</code></td>
<td></td>
<td>如果日志被存储在容器外部，就不推荐使用此特性</td>
</tr>
<tr>
<td><code>--minimum-container-ttl-duration</code></td>
<td></td>
<td>如果日志被存储在容器外部，就不推荐使用此特性</td>
</tr>
<tr>
<td><code>--low-diskspace-threshold-mb</code></td>
<td><code>--eviction-hard</code> or <code>eviction-soft</code></td>
<td>eviction 通过其他资源判断是否要垃圾回收，而不再通过磁盘利用率这个参数</td>
</tr>
<tr>
<td><code>--outofdisk-transition-frequency</code></td>
<td><code>--eviction-pressure-transition-period</code></td>
<td>eviction generalizes disk pressure transition to other resources</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>kubernetes</category>
        <category>Kubelet</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>Kubelet</tag>
      </tags>
  </entry>
  <entry>
    <title>解决ArgoCD Ingress资源一直处于Progressing状态</title>
    <url>/2023/01/12/%E8%A7%A3%E5%86%B3ArgoCD%20Ingress%E8%B5%84%E6%BA%90%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8EProgressing%E7%8A%B6%E6%80%81/</url>
    <content><![CDATA[<h2 id="解决ArgoCD-Ingress资源一直处于Progressing状态"><a href="#解决ArgoCD-Ingress资源一直处于Progressing状态" class="headerlink" title="解决ArgoCD Ingress资源一直处于Progressing状态"></a>解决ArgoCD Ingress资源一直处于Progressing状态</h2><p>这个问题，其实需要分版本做不同的处理。<br>主要是通过ArgoCD健康检查的自定义的资源检查来排除对Ingress的检查，主要请参考这两篇文章：<br><a href="https://argo-cd.readthedocs.io/en/stable/operator-manual/health/#ingress">https://argo-cd.readthedocs.io/en/stable/operator-manual/health/#ingress</a><br><a href="https://github.com/argoproj/argo-cd/issues/1704">https://github.com/argoproj/argo-cd/issues/1704</a></p>
<p>我这里是使用的Ngnix Ingress，并且版本为v1.20.0所以进行如下设置：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl edit cm -n argocd argocd-cm</span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">data:ba</span></span><br><span class="line">  <span class="attr">resource.customizations:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    networking.k8s.io/Ingress:</span></span><br><span class="line"><span class="string">        health.lua: |</span></span><br><span class="line"><span class="string">          hs = &#123;&#125;</span></span><br><span class="line"><span class="string">          hs.status = &quot;Healthy&quot;</span></span><br><span class="line"><span class="string">          return hs</span></span><br></pre></td></tr></table></figure>

<p>如果是v1.20.0版本以下的集群。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">resource.customizations.health.extensions_Ingress:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    hs = &#123;&#125;</span></span><br><span class="line"><span class="string">    hs.status = &quot;Healthy&quot;</span></span><br><span class="line"><span class="string">    hs.message = &quot;SoulChild&quot;</span></span><br><span class="line"><span class="string">    return hs</span></span><br><span class="line"><span class="string"></span>  <span class="attr">resource.customizations.useOpenLibs.extensions_Ingress:</span> <span class="string">&quot;true&quot;</span></span><br></pre></td></tr></table></figure>

<p>最后同步。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">argocd app <span class="built_in">sync</span> &lt;Your APP&gt; --force</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kubernetes</category>
        <category>CICD</category>
        <category>ArgoCD</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>CICD</tag>
        <tag>ArgoCD</tag>
      </tags>
  </entry>
  <entry>
    <title>（Docker）Alpine apk设置国内源</title>
    <url>/2022/12/29/%EF%BC%88Docker%EF%BC%89Alpine%20apk%E8%AE%BE%E7%BD%AE%E5%9B%BD%E5%86%85%E6%BA%90/</url>
    <content><![CDATA[<h2 id="运行容器xxx，示例"><a href="#运行容器xxx，示例" class="headerlink" title="运行容器xxx，示例"></a>运行容器xxx，示例</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d  \</span><br><span class="line">--name jk -u root \</span><br><span class="line">-p 9090:8080  \</span><br><span class="line">-v /var/jenkins_home:/var/jenkins_home  \</span><br><span class="line">jenkinsci/blueocean</span><br></pre></td></tr></table></figure>

<h2 id="进入容器"><a href="#进入容器" class="headerlink" title="进入容器"></a>进入容器</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it jk bash <span class="comment">#这里的“jk”是指你创建的镜像容器</span></span><br></pre></td></tr></table></figure>

<p>修改源</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i <span class="string">&#x27;s/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g&#x27;</span> /etc/apk/repositories</span><br></pre></td></tr></table></figure>

<p>更新设置</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apk update</span><br></pre></td></tr></table></figure>

<p>然后你就可以愉快的使用apk了：apk add maven</p>
<p>附录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#apk命令</span></span><br><span class="line"></span><br><span class="line">apk update <span class="comment">#更新最新本地镜像源</span></span><br><span class="line">apk upgrade <span class="comment">#升级软件</span></span><br><span class="line">apk add --upgrade busybox <span class="comment">#指定升级部分软件包</span></span><br><span class="line">apk search <span class="comment">#查找所以可用软件包</span></span><br><span class="line">apk search -v <span class="comment">#查找所有可用软件包及其描述内容</span></span><br><span class="line">apk search -v <span class="string">&#x27;acf*&#x27;</span> <span class="comment">#通过软件包名称查找软件包</span></span><br><span class="line">apk search -v -d <span class="string">&#x27;docker&#x27;</span> <span class="comment">#通过描述文件查找特定的软件包</span></span><br><span class="line">apk info <span class="comment">#列出所有已安装的软件包</span></span><br><span class="line">apk info -a zlib <span class="comment">#显示完整的软件包信息</span></span><br><span class="line">apk info --who-owns /sbin/lbu <span class="comment">#显示指定文件属于的包</span></span><br><span class="line">apk add --allow-untrusted /path/to/file.apk  <span class="comment">#本地安装</span></span><br></pre></td></tr></table></figure>

<p>添加镜像地址</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">a. 编辑/etc/apk/repositories，在文件内添加对应的镜像源</span><br><span class="line">b. 使用sed命令，如：sed -i <span class="string">&#x27;s/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g&#x27;</span> /etc/apk/repositories</span><br></pre></td></tr></table></figure>

<p>常用apk镜像站<br>清华TUNA镜像源：<code>https://mirror.tuna.tsinghua.edu.cn/alpine/</code><br>中科大镜像源：<code>http://mirrors.ustc.edu.cn/alpine/</code><br>阿里云镜像源：<code>http://mirrors.aliyun.com/alpine/</code></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">http://dl-cdn.alpinelinux.org/alpine/</span><br><span class="line">http://nl.alpinelinux.org/alpine/</span><br><span class="line">http://uk.alpinelinux.org/alpine/</span><br><span class="line">http://dl-2.alpinelinux.org/alpine/</span><br><span class="line">http://dl-3.alpinelinux.org/alpine/</span><br><span class="line">http://dl-4.alpinelinux.org/alpine/</span><br><span class="line">http://dl-5.alpinelinux.org/alpine/</span><br><span class="line">http://dl-8.alpinelinux.org/alpine/</span><br><span class="line">http://mirror.yandex.ru/mirrors/alpine/</span><br><span class="line">http://mirrors.gigenet.com/alpinelinux/</span><br><span class="line">http://mirror1.hs-esslingen.de/pub/Mirrors/alpine/</span><br><span class="line">http://mirror.leaseweb.com/alpine/</span><br><span class="line">http://repository.fit.cvut.cz/mirrors/alpine/</span><br><span class="line">http://alpine.mirror.far.fi/</span><br><span class="line">http://alpine.mirror.wearetriple.com/</span><br><span class="line">http://mirror.clarkson.edu/alpine/</span><br><span class="line">http://linorg.usp.br/AlpineLinux/</span><br><span class="line">http://ftp.yzu.edu.tw/Linux/alpine/</span><br><span class="line">http://mirror.aarnet.edu.au/pub/alpine</span><br><span class="line">http://mirror.csclub.uwaterloo.ca/alpine</span><br><span class="line">http://ftp.acc.umu.se/mirror/alpinelinux.org</span><br><span class="line">http://ftp.halifax.rwth-aachen.de/alpine</span><br><span class="line">http://speglar.siminn.is/alpine</span><br><span class="line">http://mirrors.dotsrc.org/alpine</span><br><span class="line">http://ftp.tsukuba.wide.ad.jp/Linux/alpine</span><br><span class="line">http://mirror.rise.ph/alpine</span><br><span class="line">http://mirror.neostrada.nl/alpine/</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
</search>
